-DOCSTART- -X- O
We -X- _ O
tested -X- _ O
our -X- _ O
adaptation -X- _ O
strategy -X- _ O
on -X- _ O
three -X- _ O
different -X- _ O
language -X- _ O
encoders -X- _ O
coupled -X- _ O
with -X- _ O
CLIP -X- _ B-MethodName
- -X- _ I-MethodName
T -X- _ I-MethodName
, -X- _ O
including -X- _ O
BERT -X- _ B-MethodName
- -X- _ I-MethodName
base -X- _ I-MethodName
, -X- _ O
ELECTRA -X- _ B-MethodName
- -X- _ I-MethodName
base -X- _ I-MethodName
, -X- _ O
and -X- _ O
ELECTRA -X- _ B-MethodName
- -X- _ I-MethodName
large -X- _ I-MethodName
. -X- _ O

3 -X- _ O
Experimental -X- _ O
Results -X- _ O
We -X- _ O
evaluated -X- _ O
our -X- _ O
model -X- _ O
on -X- _ O
three -X- _ O
NLU -X- _ B-DatasetName
benchmarks -X- _ I-DatasetName
, -X- _ O
namely -X- _ O
GLUE -X- _ B-DatasetName
, -X- _ O
SWAG -X- _ B-DatasetName
and -X- _ O
READ -X- _ B-DatasetName
. -X- _ O

2.4 -X- _ O
Finetuning -X- _ O
Finetuning -X- _ O
follows -X- _ O
the -X- _ O
methods -X- _ O
described -X- _ O
in -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
is -X- _ O
applied -X- _ O
to -X- _ O
the -X- _ O
language -X- _ O
encoder -X- _ O
only -X- _ O
( -X- _ O
XDBERT -X- _ B-MethodName
) -X- _ O
, -X- _ O
therefore -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
parameters -X- _ O
are -X- _ O
kept -X- _ O
equal -X- _ O
to -X- _ O
pretrained -X- _ O
- -X- _ O
BERT -X- _ B-MethodName
. -X- _ O

We -X- _ O
address -X- _ O
concerns -X- _ O
on -X- _ O
trivial -X- _ O
solutions -X- _ O
learned -X- _ O
by -X- _ O
the -X- _ O
model -X- _ O
in -X- _ O
Section -X- _ O
5 -X- _ O
and -X- _ O
9 -X- _ O
in -X- _ O
the -X- _ O
appendix -X- _ O
. -X- _ O

Same -X- _ O
as -X- _ O
MLM -X- _ B-MethodName
, -X- _ O
15% -X- _ O
of -X- _ O
the -X- _ O
tokens -X- _ O
are -X- _ O
randomly -X- _ O
selected -X- _ O
for -X- _ O
reconstruction -X- _ O
. -X- _ O

This -X- _ O
motivates -X- _ O
the -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
output -X- _ O
to -X- _ O
encode -X- _ O
sentence -X- _ O
related -X- _ O
information -X- _ O
, -X- _ O
and -X- _ O
trains -X- _ O
the -X- _ O
cross -X- _ O
- -X- _ O
attention -X- _ O
weights -X- _ O
. -X- _ O

A -X- _ O
binary -X- _ O
classifier -X- _ O
over -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
differentiates -X- _ O
between -X- _ O
the -X- _ O
two -X- _ O
cases -X- _ O
. -X- _ O

When -X- _ O
choosing -X- _ O
the -X- _ O
input -X- _ O
sentences -X- _ O
for -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
CLIPT -X- _ B-MethodName
, -X- _ O
we -X- _ O
make -X- _ O
the -X- _ O
inputs -X- _ O
nonidentical -X- _ O
50% -X- _ B-MetricValue
of -X- _ O
the -X- _ O
time -X- _ O
. -X- _ O

We -X- _ O
modify -X- _ O
this -X- _ O
objective -X- _ O
to -X- _ O
same -X- _ O
sentence -X- _ O
prediction -X- _ O
as -X- _ O
both -X- _ O
streams -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
takes -X- _ O
text -X- _ O
as -X- _ O
input -X- _ O
. -X- _ O

2.3.2 -X- _ O
Same -X- _ B-MethodName
sentence -X- _ I-MethodName
prediction -X- _ I-MethodName
( -X- _ I-MethodName
MATCH -X- _ I-MethodName
) -X- _ I-MethodName
The -X- _ O
Image -X- _ B-MethodName
- -X- _ I-MethodName
Text -X- _ I-MethodName
Matching -X- _ I-MethodName
( -X- _ I-MethodName
ITM -X- _ I-MethodName
) -X- _ I-MethodName
objective -X- _ O
is -X- _ O
widely -X- _ O
used -X- _ O
in -X- _ O
multimodal -X- _ B-TaskName
learning -X- _ I-TaskName
( -X- _ O
Tan -X- _ O
and -X- _ O
Bansal -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

Since -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
equivalent -X- _ O
of -X- _ O
a -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
token -X- _ O
in -X- _ O
CLIP -X- _ B-MethodName
, -X- _ O
we -X- _ O
leave -X- _ O
the -X- _ O
sentence -X- _ O
as -X- _ O
is -X- _ O
. -X- _ O

The -X- _ O
masked -X- _ O
ratio -X- _ O
and -X- _ O
masked -X- _ O
token -X- _ O
replacement -X- _ O
probabilities -X- _ O
follow -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

2.3.1 -X- _ O
Joint -X- _ B-MethodName
Masked -X- _ I-MethodName
Language -X- _ I-MethodName
Modeling -X- _ I-MethodName
( -X- _ I-MethodName
MLM -X- _ I-MethodName
) -X- _ I-MethodName
The -X- _ O
MLM -X- _ B-MethodName
objective -X- _ O
teaches -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
reconstruct -X- _ O
masked -X- _ O
tokens -X- _ O
. -X- _ O

Further -X- _ O
training -X- _ O
details -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
Appendix -X- _ O
C -X- _ O
. -X- _ O

Unlike -X- _ O
pretraining -X- _ O
, -X- _ O
the -X- _ O
adaptation -X- _ O
is -X- _ O
computationally -X- _ O
inexpensive -X- _ O
, -X- _ O
as -X- _ O
we -X- _ O
found -X- _ O
that -X- _ O
training -X- _ O
1 -X- _ O
epoch -X- _ O
on -X- _ O
wiki103 -X- _ O
was -X- _ O
already -X- _ O
effective -X- _ O
. -X- _ O

Our -X- _ O
adapting -X- _ O
tasks -X- _ O
closely -X- _ O
follow -X- _ O
BERT -X- _ B-MethodName
text -X- _ O
pretraining -X- _ O
strategies -X- _ O
to -X- _ O
retain -X- _ O
linguistic -X- _ O
competence -X- _ O
. -X- _ O

In -X- _ O
these -X- _ O
tasks -X- _ O
, -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
CLIP -X- _ B-MethodName
- -X- _ I-MethodName
T -X- _ I-MethodName
takes -X- _ O
sentences -X- _ O
A -X- _ O
and -X- _ O
B -X- _ O
respectively -X- _ O
as -X- _ O
input -X- _ O
, -X- _ O
and -X- _ O
losses -X- _ O
are -X- _ O
calculated -X- _ O
from -X- _ O
both -X- _ O
BERT -X- _ B-MethodName
output -X- _ O
and -X- _ O
CLIP -X- _ B-MethodName
- -X- _ I-MethodName
T -X- _ I-MethodName
output -X- _ O
. -X- _ O

2.3 -X- _ O
Adaptation -X- _ O
We -X- _ O
define -X- _ O
three -X- _ O
adapting -X- _ O
tasks -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
learned -X- _ O
in -X- _ O
a -X- _ O
self -X- _ O
- -X- _ O
supervised -X- _ O
manner -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
visualized -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
. -X- _ O

ViT -X- _ B-MethodName
stands -X- _ O
for -X- _ O
Vision -X- _ B-MethodName
Transformer -X- _ I-MethodName
( -X- _ O
Dosovitskiy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
input -X- _ O
i -X- _ O
d -X- _ O
103 -X- _ O
is -X- _ O
the -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
token -X- _ O
in -X- _ O
BERT -X- _ B-MethodName
. -X- _ O

Finetuning -X- _ O
is -X- _ O
performed -X- _ O
on -X- _ O
the -X- _ O
language -X- _ O
encoder -X- _ O
only -X- _ O
( -X- _ O
XDBERT -X- _ B-MethodName
) -X- _ O
; -X- _ O
in -X- _ O
this -X- _ O
case -X- _ O
, -X- _ O
a -X- _ O
positive -X- _ O
CoLA -X- _ B-MethodName
example -X- _ O
is -X- _ O
being -X- _ O
processed -X- _ O
to -X- _ O
determine -X- _ O
its -X- _ O
linguistic -X- _ O
acceptability -X- _ O
. -X- _ O

The -X- _ O
pretraining -X- _ O
phase -X- _ O
pretrains -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
CLIP -X- _ B-MethodName
- -X- _ I-MethodName
T -X- _ I-MethodName
, -X- _ O
both -X- _ O
of -X- _ O
which -X- _ O
are -X- _ O
then -X- _ O
used -X- _ O
in -X- _ O
the -X- _ O
adaptation -X- _ O
phase -X- _ O
and -X- _ O
concatenated -X- _ O
with -X- _ O
a -X- _ O
cross -X- _ B-MethodName
- -X- _ I-MethodName
modal -X- _ I-MethodName
encoder -X- _ I-MethodName
. -X- _ O

CLIP -X- _ B-MethodName
is -X- _ O
an -X- _ O
imagetext -X- _ O
matching -X- _ O
system -X- _ O
with -X- _ O
two -X- _ O
components -X- _ O
, -X- _ O
a -X- _ O
text -X- _ B-MethodName
encoder -X- _ I-MethodName
( -X- _ I-MethodName
CLIP -X- _ I-MethodName
- -X- _ I-MethodName
T -X- _ I-MethodName
) -X- _ I-MethodName
, -X- _ O
and -X- _ O
an -X- _ O
image -X- _ B-MethodName
encoder -X- _ I-MethodName
( -X- _ I-MethodName
CLIPViT -X- _ I-MethodName
) -X- _ I-MethodName
, -X- _ O
which -X- _ O
learn -X- _ O
to -X- _ O
encode -X- _ O
paired -X- _ O
inputs -X- _ O
to -X- _ O
closer -X- _ O
output -X- _ O
embeddings -X- _ O
via -X- _ O
contrastive -X- _ O
loss -X- _ O
. -X- _ O

2.2 -X- _ O
Pretraining -X- _ O
BERT -X- _ B-MethodName
is -X- _ O
trained -X- _ O
using -X- _ O
the -X- _ O
next -X- _ O
sentence -X- _ O
prediction -X- _ O
and -X- _ O
masked -X- _ O
language -X- _ O
modeling -X- _ O
. -X- _ O

We -X- _ O
choose -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
cross -X- _ O
- -X- _ O
modal -X- _ O
encoder -X- _ O
layers -X- _ O
to -X- _ O
be -X- _ O
2 -X- _ O
. -X- _ O

The -X- _ O
cross -X- _ O
- -X- _ O
modal -X- _ O
encoder -X- _ O
consists -X- _ O
of -X- _ O
repeating -X- _ O
cross -X- _ O
- -X- _ O
modal -X- _ O
encoder -X- _ O
layers -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
an -X- _ O
extension -X- _ O
to -X- _ O
single -X- _ O
- -X- _ O
modality -X- _ O
encoder -X- _ O
layers -X- _ O
( -X- _ O
layers -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
/ -X- _ O
CLIP -X- _ B-MethodName
- -X- _ I-MethodName
T -X- _ I-MethodName
) -X- _ O
in -X- _ O
Figure -X- _ O
3 -X- _ O
. -X- _ O

CLIP -X- _ B-MethodName
- -X- _ I-MethodName
T -X- _ I-MethodName
has -X- _ O
the -X- _ O
same -X- _ O
module -X- _ O
connections -X- _ O
as -X- _ O
BERT -X- _ B-MethodName
with -X- _ O
only -X- _ O
parameter -X- _ O
differences -X- _ O
( -X- _ O
specifications -X- _ O
in -X- _ O
Appendix -X- _ O
B -X- _ O
) -X- _ O
. -X- _ O

2.1 -X- _ O
Model -X- _ O
Architecture -X- _ O
The -X- _ O
cross -X- _ O
- -X- _ O
modal -X- _ O
transformer -X- _ O
( -X- _ O
middle -X- _ O
of -X- _ O
Figure -X- _ O
2 -X- _ O
) -X- _ O
consists -X- _ O
of -X- _ O
a -X- _ O
cross -X- _ O
- -X- _ O
modal -X- _ O
encoder -X- _ O
, -X- _ O
CLIP -X- _ B-MethodName
- -X- _ I-MethodName
T -X- _ I-MethodName
and -X- _ O
BERT -X- _ B-MethodName
. -X- _ O

The -X- _ O
adaptation -X- _ O
phase -X- _ O
incorporates -X- _ O
the -X- _ O
cross -X- _ O
- -X- _ O
modal -X- _ O
transformer -X- _ O
structure -X- _ O
to -X- _ O
jointly -X- _ O
learn -X- _ O
from -X- _ O
CLIP -X- _ B-MethodName
- -X- _ I-MethodName
T -X- _ I-MethodName
and -X- _ O
BERT -X- _ B-MethodName
outputs -X- _ O
. -X- _ O

Our -X- _ O
proposed -X- _ O
method -X- _ O
focuses -X- _ O
on -X- _ O
the -X- _ O
adaptation -X- _ O
phase -X- _ O
with -X- _ O
pretrained -X- _ O
models -X- _ O
, -X- _ O
so -X- _ O
pretraining -X- _ O
is -X- _ O
not -X- _ O
a -X- _ O
part -X- _ O
of -X- _ O
our -X- _ O
experiment -X- _ O
, -X- _ O
but -X- _ O
we -X- _ O
explain -X- _ O
all -X- _ O
three -X- _ O
phases -X- _ O
for -X- _ O
completeness -X- _ O
. -X- _ O

Our -X- _ O
adapting -X- _ O
method -X- _ O
is -X- _ O
efficient -X- _ O
and -X- _ O
extensible -X- _ O
to -X- _ O
different -X- _ O
combinations -X- _ O
of -X- _ O
pretrainedlanguage -X- _ O
encoders -X- _ O
( -X- _ O
BERT -X- _ B-MethodName
/ -X- _ O
ELECTRA -X- _ B-MethodName
) -X- _ O
. -X- _ O

We -X- _ O
summarize -X- _ O
our -X- _ O
contribution -X- _ O
as -X- _ O
follow -X- _ O
: -X- _ O
We -X- _ O
explore -X- _ O
distilling -X- _ O
visual -X- _ O
information -X- _ O
from -X- _ O
a -X- _ O
pretrained -X- _ O
multimodal -X- _ B-MethodName
transformer -X- _ I-MethodName
to -X- _ O
a -X- _ O
pretrained -X- _ O
language -X- _ B-MethodName
transformer -X- _ I-MethodName
and -X- _ O
improved -X- _ O
NLU -X- _ B-TaskName
performance -X- _ O
. -X- _ O

We -X- _ O
provide -X- _ O
analysis -X- _ O
to -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
improvements -X- _ O
are -X- _ O
visually -X- _ O
grounded -X- _ O
. -X- _ O

The -X- _ O
resulting -X- _ O
XDBERT -X- _ B-MethodName
outperforms -X- _ O
pretrained -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
proving -X- _ O
that -X- _ O
our -X- _ O
adaptation -X- _ O
strategy -X- _ O
distills -X- _ O
useful -X- _ O
visual -X- _ O
knowledge -X- _ O
into -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
right -X- _ O
of -X- _ O
Figure -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
evaluate -X- _ O
the -X- _ O
linguistic -X- _ O
capabilities -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
by -X- _ O
finetuning -X- _ O
on -X- _ O
GLUE -X- _ B-TaskName
, -X- _ O
situations -X- _ O
with -X- _ O
adversarial -X- _ B-DatasetName
generations -X- _ I-DatasetName
( -X- _ I-DatasetName
SWAG -X- _ I-DatasetName
( -X- _ I-DatasetName
Zellers -X- _ I-DatasetName
et -X- _ I-DatasetName
al -X- _ I-DatasetName
. -X- _ I-DatasetName
, -X- _ I-DatasetName
2018 -X- _ I-DatasetName
) -X- _ I-DatasetName
) -X- _ I-DatasetName
benchmarks -X- _ I-DatasetName
, -X- _ O
and -X- _ O
readability -X- _ B-DatasetName
benchmarks2 -X- _ I-DatasetName
. -X- _ O

During -X- _ O
finetuning -X- _ O
, -X- _ O
we -X- _ O
finetune -X- _ O
XDBERT -X- _ B-MethodName
( -X- _ O
crossmodal -X- _ B-MethodName
distilled -X- _ I-MethodName
BERT -X- _ I-MethodName
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
the -X- _ O
language -X- _ O
encoder -X- _ O
after -X- _ O
adaptation -X- _ O
. -X- _ O

We -X- _ O
do -X- _ O
ablation -X- _ O
studies -X- _ O
to -X- _ O
show -X- _ O
that -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
task -X- _ O
provides -X- _ O
improvement -X- _ O
( -X- _ O
Section -X- _ O
5 -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
adapting -X- _ O
tasks -X- _ O
are -X- _ O
joint -X- _ O
masked -X- _ B-MethodName
language -X- _ I-MethodName
modeling -X- _ I-MethodName
( -X- _ I-MethodName
MLM -X- _ I-MethodName
) -X- _ I-MethodName
, -X- _ O
same -X- _ O
sentence -X- _ O
prediction -X- _ O
, -X- _ O
and -X- _ O
CLIP -X- _ B-MethodName
token -X- _ O
classification -X- _ B-TaskName
tasks -X- _ I-TaskName
, -X- _ O
which -X- _ O
are -X- _ O
resemblant -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
pretraining -X- _ O
tasks -X- _ O
to -X- _ O
cater -X- _ O
to -X- _ O
the -X- _ O
language -X- _ O
- -X- _ O
heavy -X- _ O
characteristics -X- _ O
of -X- _ O
NLU -X- _ B-TaskName
. -X- _ O

While -X- _ O
adapting -X- _ O
pretrained -X- _ O
- -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
we -X- _ O
favor -X- _ O
a -X- _ O
document -X- _ O
- -X- _ O
level -X- _ O
corpus -X- _ O
( -X- _ O
wiki103 -X- _ O
) -X- _ O
over -X- _ O
a -X- _ O
vision -X- _ B-MethodName
- -X- _ I-MethodName
language -X- _ I-MethodName
corpus -X- _ I-MethodName
( -X- _ I-MethodName
MSCOCO -X- _ I-MethodName
) -X- _ I-MethodName
due -X- _ O
to -X- _ O
claims -X- _ O
from -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019)1and -X- _ O
results -X- _ O
from -X- _ O
Tan -X- _ O
and -X- _ O
Bansal -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
( -X- _ O
Appendix -X- _ O
A -X- _ O
) -X- _ O
. -X- _ O

Methodologically -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
cross -X- _ O
- -X- _ O
modal -X- _ O
encoder -X- _ O
structure -X- _ O
inspired -X- _ O
by -X- _ O
Tan -X- _ O
and -X- _ O
Bansal -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
to -X- _ O
concatenate -X- _ O
the -X- _ O
two -X- _ O
models -X- _ O
and -X- _ O
further -X- _ O
adapt -X- _ O
the -X- _ O
ensemble -X- _ O
for -X- _ O
some -X- _ O
extra -X- _ O
steps -X- _ O
( -X- _ O
a -X- _ O
lot -X- _ O
fewer -X- _ O
than -X- _ O
the -X- _ O
original -X- _ O
pretraining -X- _ O
steps -X- _ O
) -X- _ O
. -X- _ O

3 -X- _ O
) -X- _ O
, -X- _ O
to -X- _ O
prove -X- _ O
that -X- _ O
the -X- _ O
distilled -X- _ O
information -X- _ O
is -X- _ O
predominantly -X- _ O
visual -X- _ O
and -X- _ O
thus -X- _ O
non -X- _ O
- -X- _ O
trivial -X- _ O
to -X- _ O
the -X- _ O
pretrained -X- _ O
- -X- _ O
language -X- _ O
transformer -X- _ O
despite -X- _ O
having -X- _ O
textual -X- _ O
inputs -X- _ O
. -X- _ O

2.2 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
also -X- _ O
the -X- _ O
linguistic -X- _ O
competence -X- _ O
of -X- _ O
CLIP -X- _ B-MethodName
- -X- _ I-MethodName
T -X- _ I-MethodName
is -X- _ O
low -X- _ O
( -X- _ O
Sec -X- _ O
. -X- _ O

We -X- _ O
show -X- _ O
that -X- _ O
it -X- _ O
is -X- _ O
mathematically -X- _ O
logical -X- _ O
that -X- _ O
the -X- _ O
CLIP -X- _ B-MethodName
- -X- _ I-MethodName
T -X- _ I-MethodName
output -X- _ O
approximates -X- _ O
visual -X- _ O
features -X- _ O
( -X- _ O
Sec -X- _ O
. -X- _ O

The -X- _ O
usage -X- _ O
of -X- _ O
a -X- _ O
visually -X- _ O
grounded -X- _ O
text -X- _ O
- -X- _ O
transformer -X- _ O
as -X- _ O
a -X- _ O
teacher -X- _ O
allows -X- _ O
us -X- _ O
to -X- _ O
implement -X- _ O
straightforward -X- _ O
and -X- _ O
non -X- _ O
- -X- _ O
fuzzy -X- _ O
adapting -X- _ O
tasks -X- _ O
for -X- _ O
distillation -X- _ O
. -X- _ O

language -X- _ O
transformers -X- _ O
( -X- _ O
BERT -X- _ B-MethodName
/ -X- _ O
ELECTRA -X- _ B-MethodName
) -X- _ O
, -X- _ O
to -X- _ O
incorporate -X- _ O
versatile -X- _ O
perception -X- _ O
of -X- _ O
words -X- _ O
into -X- _ O
the -X- _ O
model -X- _ O
( -X- _ O
Figure -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
devise -X- _ O
a -X- _ O
way -X- _ O
to -X- _ O
distill -X- _ O
visual -X- _ O
information -X- _ O
from -X- _ O
components -X- _ O
of -X- _ O
a -X- _ O
pretrained -X- _ B-MethodName
multimodal -X- _ I-MethodName
transformer -X- _ I-MethodName
( -X- _ I-MethodName
CLIP -X- _ I-MethodName
texttransfomer -X- _ I-MethodName
, -X- _ I-MethodName
abbreviated -X- _ I-MethodName
as -X- _ I-MethodName
CLIP -X- _ I-MethodName
- -X- _ I-MethodName
T -X- _ I-MethodName
) -X- _ O
to -X- _ O
pretrained479 -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
establish -X- _ O
the -X- _ O
link -X- _ O
between -X- _ O
pretrained -X- _ O
multimodal -X- _ B-MethodName
transformers -X- _ I-MethodName
and -X- _ O
visuallygrounded -X- _ O
language -X- _ B-TaskName
learning -X- _ I-TaskName
. -X- _ O

CLIP -X- _ B-MethodName
( -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
utilizes -X- _ O
contrastive -X- _ O
loss -X- _ O
to -X- _ O
reach -X- _ O
SOTA -X- _ B-MethodName
on -X- _ O
zero -X- _ B-TaskName
- -X- _ I-TaskName
shot -X- _ I-TaskName
image -X- _ I-TaskName
classification -X- _ I-TaskName
in -X- _ O
a -X- _ O
retrieval -X- _ O
fashion -X- _ O
. -X- _ O

Tan -X- _ O
and -X- _ O
Bansal -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
tested -X- _ O
these -X- _ O
models -X- _ O
with -X- _ O
general -X- _ B-TaskName
language -X- _ I-TaskName
understanding -X- _ I-TaskName
evaluation -X- _ I-TaskName
( -X- _ O
GLUE -X- _ B-TaskName
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
) -X- _ O
and -X- _ O
found -X- _ O
that -X- _ O
the -X- _ O
performance -X- _ O
does -X- _ O
not -X- _ O
exceed -X- _ O
using -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Appendix -X- _ O
A -X- _ O
) -X- _ O
, -X- _ O
drawing -X- _ O
the -X- _ O
conclusion -X- _ O
that -X- _ O
vision -X- _ O
- -X- _ O
and -X- _ O
- -X- _ O
language -X- _ O
pretraining -X- _ O
on -X- _ O
visually -X- _ O
- -X- _ O
grounded -X- _ O
language -X- _ O
dataset -X- _ O
failed -X- _ O
to -X- _ O
distill -X- _ O
useful -X- _ O
information -X- _ O
for -X- _ O
general -X- _ O
NLU -X- _ B-TaskName
. -X- _ O

Another -X- _ O
branch -X- _ O
of -X- _ O
research -X- _ O
focuses -X- _ O
on -X- _ O
solving -X- _ O
multimodal -X- _ O
downstream -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
visual -X- _ B-TaskName
question -X- _ I-TaskName
answering -X- _ I-TaskName
and -X- _ O
image -X- _ B-TaskName
retrieval -X- _ I-TaskName
. -X- _ O

Tan -X- _ O
and -X- _ O
Bansal -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
reported -X- _ O
improvements -X- _ O
over -X- _ O
BERT -X- _ B-MethodName
on -X- _ O
NLU -X- _ B-TaskName
by -X- _ O
proposing -X- _ O
the -X- _ O
concept -X- _ O
of -X- _ O
vokenization -X- _ O
. -X- _ O

The -X- _ O
two -X- _ O
modalities -X- _ O
have -X- _ O
different -X- _ O
collocations -X- _ O
of -X- _ O
concepts -X- _ O
, -X- _ O
which -X- _ O
incentivize -X- _ O
joint -X- _ O
learning -X- _ O
from -X- _ O
the -X- _ O
two -X- _ O
systems -X- _ O
. -X- _ O

While -X- _ O
BERT -X- _ B-MethodName
excels -X- _ O
in -X- _ O
masked -X- _ O
word -X- _ O
reconstruction -X- _ O
, -X- _ O
CLIP -X- _ B-MethodName
( -X- _ O
Section -X- _ O
3 -X- _ O
) -X- _ O
specializes -X- _ O
at -X- _ O
image -X- _ B-TaskName
- -X- _ I-TaskName
text -X- _ I-TaskName
matching -X- _ I-TaskName
. -X- _ O

ViCo -X- _ B-MethodName
( -X- _ O
Gupta -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
learned -X- _ O
visual -X- _ O
co -X- _ O
- -X- _ O
occurrences -X- _ O
in -X- _ O
text -X- _ O
and -X- _ O
reported -X- _ O
superior -X- _ O
performance -X- _ O
to -X- _ O
GloVe -X- _ B-MethodName
in -X- _ O
word -X- _ O
analogy -X- _ O
problems -X- _ O
. -X- _ O

Some -X- _ O
studies -X- _ O
have -X- _ O
succeeded -X- _ O
with -X- _ O
visually -X- _ O
grounded -X- _ O
information -X- _ O
used -X- _ O
in -X- _ O
NLU -X- _ B-TaskName
. -X- _ O

In -X- _ O
the -X- _ O
real -X- _ O
world -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
humans -X- _ O
can -X- _ O
benefit -X- _ O
from -X- _ O
the -X- _ O
visual -X- _ O
modality -X- _ O
when -X- _ O
acquiring -X- _ O
knowledge -X- _ O
from -X- _ O
language -X- _ O
; -X- _ O
an -X- _ O
obvious -X- _ O
example -X- _ O
is -X- _ O
learning -X- _ O
visually -X- _ O
grounded -X- _ O
words -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
colors -X- _ O
and -X- _ O
shapes -X- _ O
. -X- _ O

Despite -X- _ O
their -X- _ O
differences -X- _ O
in -X- _ O
curating -X- _ O
the -X- _ O
learning -X- _ O
objectives -X- _ O
, -X- _ O
they -X- _ O
all -X- _ O
utilize -X- _ O
text -X- _ O
- -X- _ O
based -X- _ O
datasets -X- _ O
only -X- _ O
. -X- _ O

1 -X- _ O
Introduction -X- _ O
Transformer -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
models -X- _ I-MethodName
are -X- _ O
extensively -X- _ O
used -X- _ O
in -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
understanding -X- _ I-TaskName
( -X- _ I-TaskName
NLU -X- _ I-TaskName
) -X- _ I-TaskName
tasks -X- _ O
, -X- _ O
and -X- _ O
some -X- _ O
prominent -X- _ O
pretraining -X- _ O
strategies -X- _ O
include -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
RoBERTa -X- _ B-MethodName
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
ALBERT -X- _ B-MethodName
( -X- _ O
Lan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
ELECTRA -X- _ B-MethodName
( -X- _ O
Clark -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
analyze -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
XDBERT -X- _ B-MethodName
on -X- _ O
GLUE -X- _ B-TaskName
to -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
improvement -X- _ O
is -X- _ O
likely -X- _ O
visually -X- _ O
grounded -X- _ O
. -X- _ O

After -X- _ O
training -X- _ O
with -X- _ O
a -X- _ O
small -X- _ O
number -X- _ O
of -X- _ O
extra -X- _ O
adapting -X- _ O
steps -X- _ O
and -X- _ O
finetuned -X- _ O
, -X- _ O
the -X- _ O
proposed -X- _ O
XDBERT -X- _ B-MethodName
( -X- _ I-MethodName
cross -X- _ I-MethodName
- -X- _ I-MethodName
modal -X- _ I-MethodName
distilled -X- _ I-MethodName
BERT -X- _ I-MethodName
) -X- _ I-MethodName
outperforms -X- _ O
pretrained -X- _ O
- -X- _ O
BERT -X- _ B-MethodName
in -X- _ O
general -X- _ B-TaskName
language -X- _ I-TaskName
understanding -X- _ I-TaskName
evaluation -X- _ I-TaskName
( -X- _ I-TaskName
GLUE -X- _ I-TaskName
) -X- _ I-TaskName
, -X- _ O
situations -X- _ O
with -X- _ O
adversarial -X- _ B-DatasetName
generations -X- _ I-DatasetName
( -X- _ I-DatasetName
SWAG -X- _ I-DatasetName
) -X- _ I-DatasetName
benchmarks -X- _ I-DatasetName
, -X- _ O
and -X- _ O
readability -X- _ B-DatasetName
benchmarks -X- _ I-DatasetName
. -X- _ O

Our -X- _ O
framework -X- _ O
is -X- _ O
inspired -X- _ O
by -X- _ O
cross -X- _ B-MethodName
- -X- _ I-MethodName
modal -X- _ I-MethodName
encoders -X- _ I-MethodName
success -X- _ O
in -X- _ O
visual -X- _ B-TaskName
- -X- _ I-TaskName
language -X- _ I-TaskName
tasks -X- _ I-TaskName
while -X- _ O
we -X- _ O
alter -X- _ O
the -X- _ O
learning -X- _ O
objective -X- _ O
to -X- _ O
cater -X- _ O
to -X- _ O
the -X- _ O
language -X- _ O
- -X- _ O
heavy -X- _ O
characteristics -X- _ O
of -X- _ O
NLU -X- _ B-TaskName
. -X- _ O

This -X- _ O
study -X- _ O
explores -X- _ O
distilling -X- _ O
visual -X- _ O
information -X- _ O
from -X- _ O
pretrained -X- _ B-MethodName
multimodal -X- _ I-MethodName
transformers -X- _ I-MethodName
to -X- _ O
pretrained -X- _ B-MethodName
language -X- _ I-MethodName
encoders -X- _ I-MethodName
. -X- _ O

If -X- _ O
human -X- _ O
raters -X- _ O
answered -X- _ O
that -X- _ O
the -X- _ O
highlighted -X- _ O
span -X- _ O
in -X- _ O
the -X- _ O
source -X- _ O
sequence -X- _ O
was -X- _ O
indeed -X- _ O
badly -X- _ O
translated -X- _ O
, -X- _ O
they -X- _ O
were -X- _ O
offered -X- _ O
the -X- _ O
four -X- _ O
explanation -X- _ O
options -X- _ O
on -X- _ O
the -X- _ O
left -X- _ O
. -X- _ O

Otherwise -X- _ O
they -X- _ O
chose -X- _ O
from -X- _ O
the -X- _ O
four -X- _ O
options -X- _ O
on -X- _ O
the -X- _ O
right -X- _ O
. -X- _ O

If -X- _ O
human -X- _ O
raters -X- _ O
answered -X- _ O
that -X- _ O
the -X- _ O
highlighted -X- _ O
span -X- _ O
in -X- _ O
the -X- _ O
translation -X- _ O
was -X- _ O
indeed -X- _ O
badly -X- _ O
translated -X- _ O
, -X- _ O
they -X- _ O
were -X- _ O
offered -X- _ O
the -X- _ O
four -X- _ O
explanation -X- _ O
options -X- _ O
on -X- _ O
the -X- _ O
left -X- _ O
. -X- _ O

The -X- _ O
translation -X- _ O
is -X- _ O
syntactically -X- _ O
different -X- _ O
from -X- _ O
the -X- _ O
source -X- _ O
. -X- _ O

The -X- _ O
span -X- _ O
is -X- _ O
badly -X- _ O
translated -X- _ O
because -X- _ O
of -X- _ O
a -X- _ O
uency -X- _ B-MetricName
error -X- _ I-MetricName
. -X- _ O
The -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
span -X- _ O
are -X- _ O
redundant -X- _ O
but -X- _ O
uent -X- _ O
. -X- _ O

The -X- _ O
span -X- _ O
is -X- _ O
badly -X- _ O
translated -X- _ O
because -X- _ O
of -X- _ O
an -X- _ O
accuracy -X- _ B-MetricName
error -X- _ I-MetricName
. -X- _ O

The -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
span -X- _ O
do -X- _ O
not -X- _ O
need -X- _ O
to -X- _ O
be -X- _ O
translated -X- _ O
. -X- _ O

Answer -X- _ O
by -X- _ O
our -X- _ O
human -X- _ O
rater -X- _ O
: -X- _ O
The -X- _ O
highlighted -X- _ O
source -X- _ O
span -X- _ O
is -X- _ O
not -X- _ O
translated -X- _ O
badly -X- _ O
. -X- _ O

Original -X- _ O
MQM -X- _ B-MethodName
rating -X- _ O
: -X- _ O
No -X- _ O
accuracy -X- _ B-MetricName
error -X- _ O
marked -X- _ O
by -X- _ O
the -X- _ O
three -X- _ O
raters -X- _ O
. -X- _ O

No -X- _ O
phenomenon -X- _ O
that -X- _ O
might -X- _ O
have -X- _ O
caused -X- _ O
the -X- _ O
prediction -X- _ O
was -X- _ O
identified -X- _ O
. -X- _ O

Answer -X- _ O
by -X- _ O
our -X- _ O
human -X- _ O
rater -X- _ O
: -X- _ O
The -X- _ O
highlighted -X- _ O
target -X- _ O
span -X- _ O
is -X- _ O
not -X- _ O
translated -X- _ O
badly -X- _ O
. -X- _ O

Answer -X- _ O
by -X- _ O
our -X- _ O
human -X- _ O
rater -X- _ O
: -X- _ O
The -X- _ O
highlighted -X- _ O
source -X- _ O
span -X- _ O
is -X- _ O
not -X- _ O
translated -X- _ O
badly -X- _ O
. -X- _ O

Original -X- _ O
MQM -X- _ B-MethodName
rating -X- _ O
: -X- _ O
No -X- _ O
related -X- _ O
accuracy -X- _ B-MetricName
error -X- _ O
marked -X- _ O
by -X- _ O
the -X- _ O
three -X- _ O
raters -X- _ O
. -X- _ O

Answer -X- _ O
by -X- _ O
our -X- _ O
human -X- _ O
rater -X- _ O
: -X- _ O
The -X- _ O
highlighted -X- _ O
source -X- _ O
span -X- _ O
is -X- _ O
indeed -X- _ O
translated -X- _ O
badly -X- _ O
. -X- _ O

Finally -X- _ O
, -X- _ O
using -X- _ O
a -X- _ O
more -X- _ O
efficient -X- _ O
parser -X- _ O
, -X- _ O
or -X- _ O
no -X- _ O
parser -X- _ O
at -X- _ O
all -X- _ O
, -X- _ O
could -X- _ O
speed -X- _ O
up -X- _ O
inference.497 -X- _ O
. -X- _ O

Furthermore -X- _ O
, -X- _ O
scoring -X- _ O
could -X- _ O
be -X- _ O
parallelized -X- _ O
across -X- _ O
batches -X- _ O
of -X- _ O
multiple -X- _ O
translations -X- _ O
. -X- _ O

The -X- _ O
required -X- _ O
number -X- _ O
of -X- _ O
scores -X- _ O
could -X- _ O
be -X- _ O
reduced -X- _ O
by -X- _ O
considering -X- _ O
fewer -X- _ O
potential -X- _ O
error -X- _ O
spans -X- _ O
. -X- _ O

Still -X- _ O
, -X- _ O
the -X- _ O
time -X- _ O
needed -X- _ O
for -X- _ O
computing -X- _ O
all -X- _ O
these -X- _ O
scores -X- _ O
is -X- _ O
only -X- _ O
a -X- _ O
fraction -X- _ O
of -X- _ O
the -X- _ O
time -X- _ O
it -X- _ O
takes -X- _ O
to -X- _ O
generate -X- _ O
a -X- _ O
translation -X- _ O
( -X- _ O
254 -X- _ O
ms -X- _ O
for -X- _ O
the -X- _ O
short -X- _ O
source -X- _ O
sentence -X- _ O
and -X- _ O
861 -X- _ O
ms -X- _ O
for -X- _ O
the -X- _ O
long -X- _ O
sentence -X- _ O
, -X- _ O
assuming -X- _ O
a -X- _ O
beam -X- _ O
size -X- _ O
of -X- _ O
5 -X- _ O
) -X- _ O
. -X- _ O

On -X- _ O
average -X- _ O
, -X- _ O
we -X- _ O
compute -X- _ O
30 -X- _ O
scores -X- _ O
per -X- _ O
sentence -X- _ O
in -X- _ O
the -X- _ B-DatasetName
EnglishGerman -X- _ I-DatasetName
MQM -X- _ I-DatasetName
dataset -X- _ I-DatasetName
, -X- _ O
and -X- _ O
44 -X- _ O
per -X- _ O
sentence -X- _ O
in -X- _ O
the -X- _ O
ChineseEnglish -X- _ B-DatasetName
MQM -X- _ I-DatasetName
dataset -X- _ I-DatasetName
. -X- _ O

The -X- _ O
higher -X- _ O
inference -X- _ O
times -X- _ O
for -X- _ O
our -X- _ O
approach -X- _ O
can -X- _ O
be -X- _ O
explained -X- _ O
by -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
translation -X- _ O
probabilities -X- _ O
that -X- _ O
need -X- _ O
to -X- _ O
be -X- _ O
estimated -X- _ O
. -X- _ O

We -X- _ O
average -X- _ O
over -X- _ O
1000 -X- _ O
repetitions -X- _ O
on -X- _ O
RTX -X- _ O
2080 -X- _ O
Ti -X- _ O
GPUs -X- _ O
. -X- _ O

The -X- _ O
short -X- _ O
sentence -X- _ O
pair -X- _ O
is -X- _ O
taken -X- _ O
from -X- _ O
Figure -X- _ O
1 -X- _ O
and -X- _ O
the -X- _ O
long -X- _ O
sentence -X- _ O
pair -X- _ O
has -X- _ O
40 -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
source -X- _ O
sequence -X- _ O
and -X- _ O
47 -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
target -X- _ O
sequence -X- _ O
. -X- _ O

We -X- _ O
measure -X- _ O
the -X- _ O
time -X- _ O
needed -X- _ O
to -X- _ O
run -X- _ O
the -X- _ O
coverage -X- _ O
error -X- _ O
detection -X- _ O
methods -X- _ O
on -X- _ O
a -X- _ O
short -X- _ O
sentence -X- _ O
pair -X- _ O
and -X- _ O
on -X- _ O
a -X- _ O
long -X- _ O
sentence -X- _ O
pair -X- _ O
for -X- _ O
EnglishGerman -X- _ O
. -X- _ O

In -X- _ O
comparison -X- _ O
, -X- _ O
our -X- _ O
approach -X- _ O
performs -X- _ O
clearly -X- _ O
worse -X- _ O
than -X- _ O
the -X- _ O
supervised -X- _ O
baseline -X- _ O
on -X- _ O
the -X- _ O
synthetic -X- _ O
errors -X- _ O
. -X- _ O
C -X- _ O
Inference -X- _ O
Time -X- _ O
Inference -X- _ O
times -X- _ O
are -X- _ O
reported -X- _ O
in -X- _ O
Table -X- _ O
A2 -X- _ O
. -X- _ O

The -X- _ O
supervised -X- _ O
baseline -X- _ O
has -X- _ O
a -X- _ O
high -X- _ O
accuracy -X- _ O
on -X- _ O
EnglishGerman -X- _ B-TaskName
translations -X- _ I-TaskName
and -X- _ O
a -X- _ O
moderate -X- _ O
accuracy -X- _ B-MetricName
on -X- _ O
ChineseEnglish -X- _ B-TaskName
translations -X- _ I-TaskName
. -X- _ O

On -X- _ O
the -X- _ O
word -X- _ O
level -X- _ O
, -X- _ O
we -X- _ O
follow -X- _ O
previous -X- _ O
work -X- _ O
on -X- _ O
word -X- _ B-MethodName
- -X- _ I-MethodName
level -X- _ I-MethodName
QE -X- _ I-MethodName
( -X- _ O
Specia -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
report -X- _ O
the -X- _ O
Matthews -X- _ B-MetricName
correlation -X- _ I-MetricName
coefficient -X- _ I-MetricName
( -X- _ I-MetricName
MCC -X- _ I-MetricName
) -X- _ I-MetricName
across -X- _ O
all -X- _ O
the -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
. -X- _ O

Since -X- _ O
we -X- _ O
did -X- _ O
not -X- _ O
use -X- _ O
a -X- _ O
parser -X- _ O
that -X- _ O
is -X- _ O
optimized -X- _ O
for -X- _ O
efficiency -X- _ O
, -X- _ O
we -X- _ O
additionally -X- _ O
report -X- _ O
inference -X- _ O
time -X- _ O
without -X- _ O
including -X- _ O
the -X- _ O
time -X- _ O
needed -X- _ O
for -X- _ O
parsing -X- _ O
. -X- _ O

Should -X- _ O
multiple -X- _ O
explanations -X- _ O
be -X- _ O
equally -X- _ O
plausible -X- _ O
, -X- _ O
select -X- _ O
the -X- _ O
first -X- _ O
from -X- _ O
the -X- _ O
top.496 -X- _ O
. -X- _ O

On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
if -X- _ O
you -X- _ O
disagree -X- _ O
and -X- _ O
think -X- _ O
that -X- _ O
the -X- _ O
span -X- _ O
is -X- _ O
well -X- _ O
- -X- _ O
translated -X- _ O
, -X- _ O
please -X- _ O
select -X- _ O
an -X- _ O
explanation -X- _ O
why -X- _ O
the -X- _ O
span -X- _ O
might -X- _ O
have -X- _ O
been -X- _ O
marked -X- _ O
as -X- _ O
badly -X- _ O
translated -X- _ O
in -X- _ O
the -X- _ O
first -X- _ O
place -X- _ O
. -X- _ O

On -X- _ O
the -X- _ O
one -X- _ O
hand -X- _ O
, -X- _ O
if -X- _ O
you -X- _ O
agree -X- _ O
that -X- _ O
the -X- _ O
highlighted -X- _ O
span -X- _ O
is -X- _ O
translated -X- _ O
badly -X- _ O
, -X- _ O
please -X- _ O
explain -X- _ O
your -X- _ O
reasoning -X- _ O
by -X- _ O
selecting -X- _ O
your -X- _ O
explanation -X- _ O
. -X- _ O

In -X- _ O
a -X- _ O
second -X- _ O
step -X- _ O
, -X- _ O
you -X- _ O
are -X- _ O
asked -X- _ O
to -X- _ O
select -X- _ O
an -X- _ O
explanation -X- _ O
. -X- _ O

In -X- _ O
that -X- _ O
case -X- _ O
, -X- _ O
focus -X- _ O
your -X- _ O
answer -X- _ O
on -X- _ O
the -X- _ O
span -X- _ O
that -X- _ O
is -X- _ O
most -X- _ O
problematic -X- _ O
for -X- _ O
the -X- _ O
translation -X- _ O
. -X- _ O

Sometimes -X- _ O
, -X- _ O
multiple -X- _ O
spans -X- _ O
are -X- _ O
highlighted -X- _ O
. -X- _ O

If -X- _ O
a -X- _ O
span -X- _ O
is -X- _ O
in -X- _ O
the -X- _ O
translation -X- _ O
, -X- _ O
check -X- _ O
whether -X- _ O
it -X- _ O
correctly -X- _ O
conveys -X- _ O
the -X- _ O
source -X- _ O
. -X- _ O

If -X- _ O
a -X- _ O
span -X- _ O
is -X- _ O
in -X- _ O
the -X- _ O
source -X- _ O
sentence -X- _ O
, -X- _ O
check -X- _ O
whether -X- _ O
it -X- _ O
has -X- _ O
been -X- _ O
correctly -X- _ O
translated -X- _ O
. -X- _ O

The -X- _ O
highlighted -X- _ O
spans -X- _ O
can -X- _ O
be -X- _ O
either -X- _ O
in -X- _ O
the -X- _ O
source -X- _ O
sequence -X- _ O
or -X- _ O
in -X- _ O
the -X- _ O
translation -X- _ O
. -X- _ O

You -X- _ O
are -X- _ O
asked -X- _ O
to -X- _ O
determine -X- _ O
whether -X- _ O
the -X- _ O
claim -X- _ O
is -X- _ O
true -X- _ O
. -X- _ O

One -X- _ O
or -X- _ O
several -X- _ O
spans -X- _ O
in -X- _ O
the -X- _ O
text -X- _ O
are -X- _ O
highlighted -X- _ O
and -X- _ O
it -X- _ O
is -X- _ O
claimed -X- _ O
that -X- _ O
the -X- _ O
spans -X- _ O
are -X- _ O
translated -X- _ O
badly -X- _ O
. -X- _ O

A -X- _ O
Annotator -X- _ O
Guidelines -X- _ O
You -X- _ O
will -X- _ O
be -X- _ O
shown -X- _ O
a -X- _ O
series -X- _ O
of -X- _ O
source -X- _ O
sentences -X- _ O
and -X- _ O
translations -X- _ O
. -X- _ O

Moses -X- _ B-MethodName
: -X- _ O
Open -X- _ O
source -X- _ O
toolkit -X- _ O
for -X- _ O
statistical -X- _ B-TaskName
machine -X- _ I-TaskName
translation -X- _ I-TaskName
. -X- _ O

Predictor -X- _ O
- -X- _ O
estimator -X- _ O
using -X- _ O
multilevel -X- _ B-TaskName
task -X- _ I-TaskName
learning -X- _ I-TaskName
with -X- _ O
stack -X- _ O
propagation -X- _ O
for -X- _ O
neural -X- _ O
quality -X- _ O
estimation -X- _ O
. -X- _ O

Unsupervised -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
representation -X- _ O
learning -X- _ O
at -X- _ O
scale -X- _ O
. -X- _ O

A -X- _ O
comparative -X- _ O
quality -X- _ O
evaluation -X- _ O
of -X- _ O
PBSMT -X- _ B-MethodName
and -X- _ O
NMT -X- _ B-MethodName
using -X- _ O
professional -X- _ O
translators -X- _ O
. -X- _ O

We -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
thank -X- _ O
Xin -X- _ O
Sennrich -X- _ O
for -X- _ O
facilitating -X- _ O
the -X- _ O
recruitment -X- _ O
of -X- _ O
annotators -X- _ O
, -X- _ O
and -X- _ O
Chantal -X- _ O
Amrhein -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
anonymous -X- _ O
reviewers -X- _ O
for -X- _ O
helpful -X- _ O
feedback -X- _ O
. -X- _ O

Acknowledgments -X- _ O
This -X- _ O
work -X- _ O
was -X- _ O
funded -X- _ O
by -X- _ O
the -X- _ O
Swiss -X- _ O
National -X- _ O
Science -X- _ O
Foundation -X- _ O
( -X- _ O
project -X- _ O
MUTAMUR -X- _ O
; -X- _ O
no -X- _ O
. -X- _ O

Future -X- _ O
work -X- _ O
could -X- _ O
address -X- _ O
the -X- _ O
low -X- _ O
precision -X- _ O
on -X- _ O
addition -X- _ O
errors -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
relatively -X- _ O
rare -X- _ O
in -X- _ O
the -X- _ O
datasets -X- _ O
we -X- _ O
used -X- _ O
for -X- _ O
evaluation -X- _ O
. -X- _ O

Evaluation -X- _ O
on -X- _ O
real -X- _ O
machine -X- _ B-TaskName
translations -X- _ I-TaskName
shows -X- _ O
that -X- _ O
our -X- _ O
approach -X- _ O
outperforms -X- _ O
a -X- _ O
supervised -X- _ O
baseline -X- _ O
in -X- _ O
the -X- _ O
detection -X- _ O
of -X- _ O
omissions -X- _ O
. -X- _ O

Since -X- _ O
any -X- _ O
off -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
shelf -X- _ O
NMT -X- _ B-MethodName
model -X- _ I-MethodName
can -X- _ O
be -X- _ O
used -X- _ O
to -X- _ O
estimate -X- _ O
conditional -X- _ O
likelihood -X- _ O
, -X- _ O
no -X- _ O
access -X- _ O
to -X- _ O
the -X- _ O
original -X- _ O
translation -X- _ O
system -X- _ O
or -X- _ O
to -X- _ O
a -X- _ O
quality -X- _ O
estimation -X- _ O
model -X- _ O
is -X- _ O
needed -X- _ O
. -X- _ O

Derived -X- _ O
from -X- _ O
contrastive -X- _ O
conditioning -X- _ O
, -X- _ O
our -X- _ O
method -X- _ O
relies -X- _ O
on -X- _ O
hypothetical -X- _ O
reasoning -X- _ O
over -X- _ O
the -X- _ O
likelihood -X- _ B-MetricName
of -X- _ O
partial -X- _ O
sequences -X- _ O
. -X- _ O

7 -X- _ O
Conclusion -X- _ O
We -X- _ O
have -X- _ O
proposed -X- _ O
a -X- _ O
reference -X- _ O
- -X- _ O
free -X- _ O
method -X- _ O
to -X- _ O
automatically -X- _ O
detect -X- _ O
coverage -X- _ O
errors -X- _ O
in -X- _ O
translations -X- _ O
. -X- _ O

In -X- _ O
addition -X- _ O
, -X- _ O
restricting -X- _ O
the -X- _ O
potential -X- _ O
error -X- _ O
spans -X- _ O
that -X- _ O
are -X- _ O
considered -X- _ O
could -X- _ O
further -X- _ O
improve -X- _ O
efficiency -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
this -X- _ O
is -X- _ O
still -X- _ O
a -X- _ O
fraction -X- _ O
of -X- _ O
the -X- _ O
time -X- _ O
needed -X- _ O
for -X- _ O
generating -X- _ O
a -X- _ O
translation -X- _ O
in -X- _ O
the -X- _ O
first -X- _ O
place -X- _ O
. -X- _ O

In -X- _ O
Appendix -X- _ O
C -X- _ O
we -X- _ O
perform -X- _ O
a -X- _ O
comparison -X- _ O
, -X- _ O
finding -X- _ O
that -X- _ O
on -X- _ O
a -X- _ O
long -X- _ O
sentence -X- _ O
pair -X- _ O
contrastive -X- _ O
conditioning -X- _ O
can -X- _ O
take -X- _ O
up -X- _ O
to -X- _ O
ten -X- _ O
times -X- _ O
longer -X- _ O
than -X- _ O
a -X- _ O
forward -X- _ O
pass -X- _ O
of -X- _ O
the -X- _ O
baseline -X- _ O
. -X- _ O

Inference -X- _ O
time -X- _ O
should -X- _ O
also -X- _ O
be -X- _ O
discussed -X- _ O
. -X- _ O

Higher -X- _ O
accuracy -X- _ B-MetricName
would -X- _ O
be -X- _ O
necessary -X- _ O
for -X- _ O
word -X- _ B-MethodName
- -X- _ I-MethodName
level -X- _ I-MethodName
QE -X- _ I-MethodName
to -X- _ O
be -X- _ O
helpful -X- _ O
( -X- _ O
Shenoy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
so -X- _ O
with -X- _ O
regard -X- _ O
to -X- _ O
detecting -X- _ O
addition -X- _ O
errors -X- _ B-MetricName
, -X- _ O
the -X- _ O
practical -X- _ O
utility -X- _ O
of -X- _ O
both -X- _ O
the -X- _ O
baseline -X- _ O
and -X- _ O
of -X- _ O
our -X- _ O
approach -X- _ O
remains -X- _ O
limited -X- _ O
. -X- _ O

Further -X- _ O
work -X- _ O
needs -X- _ O
to -X- _ O
be -X- _ O
done -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
detection -X- _ O
of -X- _ O
additions -X- _ O
, -X- _ O
of -X- _ O
which -X- _ O
the -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
data -X- _ O
contain -X- _ O
few -X- _ O
examples -X- _ O
. -X- _ O

Our -X- _ O
results -X- _ O
on -X- _ O
omissions -X- _ O
are -X- _ O
encouraging -X- _ O
, -X- _ O
and -X- _ O
user -X- _ O
studies -X- _ O
are -X- _ O
recommended -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
validate -X- _ O
the -X- _ O
usefulness -X- _ O
of -X- _ O
the -X- _ O
predictions -X- _ O
to -X- _ O
practitioners -X- _ O
. -X- _ O

USD -X- _ O
30 -X- _ O
per -X- _ O
hour.6 -X- _ O
Limitations -X- _ O
and -X- _ O
Future -X- _ O
Work -X- _ O
We -X- _ O
hope -X- _ O
that -X- _ O
the -X- _ O
automatic -X- _ O
detection -X- _ O
of -X- _ O
coverage -X- _ O
errors -X- _ O
could -X- _ O
be -X- _ O
an -X- _ O
aid -X- _ O
to -X- _ O
translators -X- _ O
and -X- _ O
posteditors -X- _ O
, -X- _ O
given -X- _ O
that -X- _ O
manually -X- _ O
detecting -X- _ O
such -X- _ O
errors -X- _ O
is -X- _ O
tedious -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
more -X- _ O
than -X- _ O
10% -X- _ O
of -X- _ O
the -X- _ O
spans -X- _ O
marked -X- _ O
in -X- _ O
ChineseEnglish -X- _ O
translations -X- _ O
were -X- _ O
classified -X- _ O
by -X- _ O
our -X- _ O
raters -X- _ O
as -X- _ O
a -X- _ O
different -X- _ O
type -X- _ O
of -X- _ O
accuracy -X- _ O
error -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
mistranslation -X- _ O
. -X- _ O

Finally -X- _ O
, -X- _ O
Table -X- _ O
2 -X- _ O
shows -X- _ O
that -X- _ O
many -X- _ O
of -X- _ O
the -X- _ O
predicted -X- _ O
error -X- _ O
spans -X- _ O
are -X- _ O
in -X- _ O
fact -X- _ O
translation -X- _ O
errors -X- _ O
, -X- _ O
but -X- _ O
not -X- _ O
coverage -X- _ O
errors -X- _ O
in -X- _ O
a -X- _ O
narrow -X- _ O
sense -X- _ O
. -X- _ O

Example -X- _ O
predictions -X- _ O
are -X- _ O
provided -X- _ O
in -X- _ O
Appendix -X- _ O
F -X- _ O
, -X- _ O
which -X- _ O
include -X- _ O
cases -X- _ O
where -X- _ O
all -X- _ O
three -X- _ O
raters -X- _ O
of -X- _ O
Freitag -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
had -X- _ O
overlooked -X- _ O
the -X- _ O
coverage -X- _ B-MetricName
error -X- _ I-MetricName
. -X- _ O

The -X- _ O
distribution -X- _ O
of -X- _ O
the -X- _ O
detailed -X- _ O
answers -X- _ O
( -X- _ O
Figures -X- _ O
3 -X- _ O
and -X- _ O
4 -X- _ O
in -X- _ O
the -X- _ O
Appendix -X- _ O
) -X- _ O
suggests -X- _ O
that -X- _ O
syntactical -X- _ O
differences -X- _ O
between -X- _ O
the -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
language -X- _ O
contribute -X- _ O
to -X- _ O
the -X- _ O
false -X- _ O
positives -X- _ O
regarding -X- _ O
additions -X- _ O
. -X- _ O

Precision -X- _ B-MetricName
is -X- _ O
higher -X- _ O
than -X- _ O
expected -X- _ O
when -X- _ O
detecting -X- _ O
omission -X- _ O
errors -X- _ O
in -X- _ O
EnglishGerman -X- _ O
translations -X- _ O
, -X- _ O
but -X- _ O
is -X- _ O
still -X- _ O
low -X- _ O
for -X- _ O
additions -X- _ O
. -X- _ O

Results -X- _ O
The -X- _ O
fine -X- _ O
- -X- _ O
grained -X- _ O
answers -X- _ O
allow -X- _ O
us -X- _ O
to -X- _ O
quantify -X- _ O
the -X- _ O
word -X- _ O
- -X- _ O
level -X- _ O
precision -X- _ O
of -X- _ O
the -X- _ O
spans -X- _ O
highlighted -X- _ O
by -X- _ O
our -X- _ O
approach -X- _ O
, -X- _ O
both -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
coverage -X- _ O
errors -X- _ O
in -X- _ O
particular -X- _ O
and -X- _ O
to -X- _ O
translation -X- _ O
errors -X- _ O
in -X- _ O
general -X- _ O
( -X- _ O
Table -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O

Agreement -X- _ O
on -X- _ O
the -X- _ O
more -X- _ O
subjective -X- _ O
follow -X- _ O
- -X- _ O
up -X- _ O
question -X- _ O
was -X- _ O
lower -X- _ O
( -X- _ O
0.32 -X- _ O
/ -X- _ O
0.13 -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
agreement -X- _ O
was -X- _ O
moderate -X- _ O
for -X- _ O
the -X- _ O
main -X- _ O
question -X- _ O
, -X- _ O
with -X- _ O
a -X- _ O
Cohens -X- _ O
kappa -X- _ O
of -X- _ O
0.54 -X- _ O
for -X- _ O
EnglishGerman -X- _ O
and -X- _ O
0.45 -X- _ O
for -X- _ O
ChineseEnglish -X- _ O
. -X- _ O

A -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
samples -X- _ O
were -X- _ O
annotated -X- _ O
by -X- _ O
both -X- _ O
raters -X- _ O
. -X- _ O

They -X- _ O
were -X- _ O
asked -X- _ O
whether -X- _ O
the -X- _ O
highlighted -X- _ O
span -X- _ O
was -X- _ O
indeed -X- _ O
translated -X- _ O
badly -X- _ O
, -X- _ O
and -X- _ O
were -X- _ O
asked -X- _ O
to -X- _ O
perform -X- _ O
a -X- _ O
fine -X- _ O
- -X- _ O
grained -X- _ O
analysis -X- _ O
based -X- _ O
on -X- _ O
a -X- _ O
list -X- _ O
of -X- _ O
predefined -X- _ O
answer -X- _ O
options -X- _ O
( -X- _ O
Figures -X- _ O
3 -X- _ O
and -X- _ O
4 -X- _ O
in -X- _ O
the -X- _ O
Appendix -X- _ O
) -X- _ O
. -X- _ O

Raters -X- _ O
were -X- _ O
shown -X- _ O
the -X- _ O
source -X- _ O
sequence -X- _ O
, -X- _ O
the -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
, -X- _ O
and -X- _ O
the -X- _ O
predicted -X- _ O
error -X- _ O
span -X- _ O
. -X- _ O

Evaluation -X- _ O
Design -X- _ O
We -X- _ O
employed -X- _ O
two -X- _ O
linguistic -X- _ O
experts -X- _ O
per -X- _ O
language -X- _ O
pair -X- _ O
as -X- _ O
raters.8Each -X- _ O
rater -X- _ O
was -X- _ O
shown -X- _ O
around -X- _ O
700 -X- _ O
randomly -X- _ O
sampled -X- _ O
positive -X- _ O
predictions -X- _ O
across -X- _ O
both -X- _ O
types -X- _ O
of -X- _ O
coverage -X- _ O
errors -X- _ O
. -X- _ O

7We -X- _ O
perform -X- _ O
a -X- _ O
segment -X- _ O
- -X- _ O
level -X- _ O
evaluation -X- _ O
and -X- _ O
do -X- _ O
not -X- _ O
quantify -X- _ O
word -X- _ O
- -X- _ O
level -X- _ O
accuracy -X- _ B-MetricName
in -X- _ O
this -X- _ O
section -X- _ O
since -X- _ O
the -X- _ O
dataset -X- _ O
does -X- _ O
not -X- _ O
contain -X- _ O
consistently -X- _ O
annotated -X- _ O
spans -X- _ O
for -X- _ O
coverage -X- _ O
errors.493 -X- _ O
. -X- _ O

Our -X- _ O
human -X- _ O
raters -X- _ O
were -X- _ O
presented -X- _ O
segments -X- _ O
that -X- _ O
had -X- _ O
been -X- _ O
marked -X- _ O
as -X- _ O
true -X- _ O
or -X- _ O
false -X- _ O
positives -X- _ O
in -X- _ O
the -X- _ O
above -X- _ O
evaluation -X- _ O
, -X- _ O
allowing -X- _ O
us -X- _ O
to -X- _ O
quantify -X- _ O
word -X- _ O
- -X- _ O
level -X- _ O
precision -X- _ O
. -X- _ O

5.2 -X- _ O
Human -X- _ O
Evaluation -X- _ O
of -X- _ O
Precision -X- _ O
We -X- _ O
perform -X- _ O
an -X- _ O
additional -X- _ O
word -X- _ O
- -X- _ O
level -X- _ O
human -X- _ O
evaluation -X- _ O
to -X- _ O
analyze -X- _ O
the -X- _ O
predictions -X- _ O
obtained -X- _ O
via -X- _ O
our -X- _ O
approach -X- _ O
in -X- _ O
more -X- _ O
detail -X- _ O
. -X- _ O

Considering -X- _ O
its -X- _ O
high -X- _ O
performance -X- _ O
on -X- _ O
a -X- _ O
synthetic -X- _ O
test -X- _ O
set -X- _ O
( -X- _ O
Table -X- _ O
A1 -X- _ O
in -X- _ O
the -X- _ O
Appendix -X- _ O
) -X- _ O
, -X- _ O
it -X- _ O
seems -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
does -X- _ O
not -X- _ O
generalize -X- _ O
well -X- _ O
to -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
coverage -X- _ O
errors -X- _ O
, -X- _ O
highlighting -X- _ O
the -X- _ O
challenges -X- _ O
of -X- _ O
training -X- _ O
a -X- _ O
supervised -X- _ B-MethodName
QE -X- _ I-MethodName
model -X- _ I-MethodName
on -X- _ O
purely -X- _ O
synthetic -X- _ O
data -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
both -X- _ O
approaches -X- _ O
recognize -X- _ O
addition -X- _ O
errors -X- _ O
with -X- _ O
low -X- _ O
accuracy -X- _ B-MetricName
, -X- _ O
and -X- _ O
especially -X- _ O
the -X- _ O
supervised -X- _ O
baseline -X- _ O
has -X- _ O
low -X- _ O
recall -X- _ O
. -X- _ O

Our -X- _ O
approach -X- _ O
clearly -X- _ O
surpasses -X- _ O
the -X- _ O
baseline -X- _ O
in -X- _ O
the -X- _ O
detection -X- _ O
of -X- _ O
omission -X- _ O
errors -X- _ O
in -X- _ O
both -X- _ O
language -X- _ O
pairs -X- _ O
. -X- _ O

Results -X- _ O
The -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
gold -X- _ O
- -X- _ O
standard -X- _ O
comparison -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O

For -X- _ O
ease -X- _ O
of -X- _ O
implementation -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
exclude -X- _ O
segments -X- _ O
that -X- _ O
consist -X- _ O
of -X- _ O
multiple -X- _ O
sentences -X- _ O
. -X- _ O

We -X- _ O
count -X- _ O
a -X- _ O
prediction -X- _ O
as -X- _ O
correct -X- _ O
if -X- _ O
any -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
human -X- _ O
raters -X- _ O
has -X- _ O
marked -X- _ O
the -X- _ O
same -X- _ O
error -X- _ O
type -X- _ O
anywhere -X- _ O
in -X- _ O
the -X- _ O
segment.7We -X- _ O
exclude -X- _ O
segments -X- _ O
from -X- _ O
the -X- _ O
evaluation -X- _ O
that -X- _ O
might -X- _ O
have -X- _ O
been -X- _ O
incompletely -X- _ O
annotated -X- _ O
( -X- _ O
because -X- _ O
raters -X- _ O
stopped -X- _ O
after -X- _ O
marking -X- _ O
five -X- _ O
errors -X- _ O
) -X- _ O
. -X- _ O

Still -X- _ O
, -X- _ O
we -X- _ O
expect -X- _ O
that -X- _ O
a -X- _ O
system -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
dataset -X- _ O
will -X- _ O
be -X- _ O
able -X- _ O
to -X- _ O
generalize -X- _ O
to -X- _ O
such -X- _ O
examples -X- _ O
, -X- _ O
especially -X- _ O
if -X- _ O
two -X- _ O
separate -X- _ O
classifiers -X- _ O
are -X- _ O
used -X- _ O
for -X- _ O
additions -X- _ O
and -X- _ O
omissions -X- _ O
. -X- _ O

5Note -X- _ O
that -X- _ O
the -X- _ O
synthetic -X- _ O
dataset -X- _ O
does -X- _ O
not -X- _ O
contain -X- _ O
translations -X- _ O
with -X- _ O
both -X- _ O
an -X- _ O
addition -X- _ O
and -X- _ O
an -X- _ O
omission -X- _ O
error -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
limitation -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
AdamW -X- _ B-MethodName
( -X- _ O
Loshchilov -X- _ O
and -X- _ O
Hutter -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
with -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
1e-5 -X- _ B-HyperparameterValue
, -X- _ O
freezing -X- _ O
the -X- _ O
pretrained -X- _ O
encoder -X- _ O
for -X- _ O
the -X- _ O
first -X- _ O
1000 -X- _ O
steps -X- _ O
. -X- _ O

For -X- _ O
token -X- _ O
classification -X- _ O
we -X- _ O
train -X- _ O
two -X- _ O
linear -X- _ O
layers -X- _ O
, -X- _ O
separately -X- _ O
for -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
language -X- _ O
( -X- _ O
which -X- _ O
corresponds -X- _ O
to -X- _ O
omissions -X- _ O
and -X- _ O
additions -X- _ O
, -X- _ O
respectively -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
train -X- _ O
for -X- _ O
10 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
with -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
32 -X- _ B-HyperparameterValue
, -X- _ O
with -X- _ O
early -X- _ O
stopping -X- _ O
on -X- _ O
the -X- _ O
validation -X- _ O
set -X- _ O
. -X- _ O

We -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
the -X- _ O
large -X- _ O
version -X- _ O
of -X- _ O
XLMRoBERTa -X- _ B-MethodName
, -X- _ O
which -X- _ O
results -X- _ O
in -X- _ O
a -X- _ O
model -X- _ O
of -X- _ O
similar -X- _ O
parameter -X- _ O
count -X- _ O
as -X- _ O
the -X- _ O
mBART50 -X- _ B-MethodName
model -X- _ O
we -X- _ O
use -X- _ O
for -X- _ O
contrastive -X- _ O
conditioning -X- _ O
. -X- _ O

Where -X- _ O
suitable -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
default -X- _ O
settings -X- _ O
of -X- _ O
OpenKiwi -X- _ B-MethodName
. -X- _ O

For -X- _ O
English -X- _ O
and -X- _ O
German -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
Moses -X- _ B-MethodName
tokenizer -X- _ I-MethodName
( -X- _ O
Koehn -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2007 -X- _ O
) -X- _ O
to -X- _ O
separate -X- _ O
the -X- _ O
text -X- _ O
into -X- _ O
labeled -X- _ O
tokens -X- _ O
; -X- _ O
for -X- _ O
Chinese -X- _ O
we -X- _ O
label -X- _ O
the -X- _ O
text -X- _ O
on -X- _ O
the -X- _ O
character -X- _ O
level -X- _ O
. -X- _ O

A -X- _ O
source -X- _ O
token -X- _ O
is -X- _ O
BAD -X- _ O
if -X- _ O
it -X- _ O
is -X- _ O
omitted -X- _ O
in -X- _ O
the -X- _ O
translation -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
token -X- _ O
in -X- _ O
the -X- _ O
translation -X- _ O
is -X- _ O
BAD -X- _ O
if -X- _ O
it -X- _ O
is -X- _ O
part -X- _ O
of -X- _ O
an -X- _ O
addition -X- _ O
error -X- _ O
. -X- _ O

Every -X- _ O
token -X- _ O
is -X- _ O
classified -X- _ O
as -X- _ O
either -X- _ O
OKor -X- _ O
BAD -X- _ O
, -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
word -X- _ O
- -X- _ O
level -X- _ O
labels -X- _ O
used -X- _ O
for -X- _ O
the -X- _ O
QE -X- _ B-TaskName
shared -X- _ I-TaskName
tasks -X- _ I-TaskName
( -X- _ O
Specia -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
supervised -X- _ O
task -X- _ O
can -X- _ O
be -X- _ O
described -X- _ O
as -X- _ O
token -X- _ B-TaskName
- -X- _ I-TaskName
level -X- _ I-TaskName
binary -X- _ I-TaskName
classification -X- _ I-TaskName
. -X- _ O

Supervised -X- _ O
baseline -X- _ O
system -X- _ O
Following -X- _ O
the -X- _ O
approach -X- _ O
outlined -X- _ O
by -X- _ O
Moura -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
OpenKiwi -X- _ B-MethodName
framework -X- _ O
( -X- _ O
Kepler -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
to -X- _ O
train -X- _ O
a -X- _ O
separate -X- _ O
Predictor -X- _ B-MethodName
- -X- _ I-MethodName
Estimator -X- _ I-MethodName
model -X- _ I-MethodName
( -X- _ O
Kim -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
per -X- _ O
language -X- _ O
pair -X- _ O
, -X- _ O
based -X- _ O
on -X- _ O
XLMRoBERTa -X- _ B-MethodName
( -X- _ O
Conneau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

Statistics -X- _ O
are -X- _ O
reported -X- _ O
in -X- _ O
Table -X- _ O
A3 -X- _ O
. -X- _ O

We -X- _ O
average -X- _ O
over -X- _ O
three -X- _ O
baseline -X- _ O
models -X- _ O
trained -X- _ O
with -X- _ O
different -X- _ O
random -X- _ B-HyperparameterName
seeds -X- _ I-HyperparameterName
, -X- _ O
reporting -X- _ O
the -X- _ O
standard -X- _ B-MetricName
deviation -X- _ I-MetricName
. -X- _ O

Negative -X- _ O
examples -X- _ O
are -X- _ O
cre4https://github.com/google/ -X- _ O
wmt -X- _ O
- -X- _ O
mqm -X- _ O
- -X- _ O
human -X- _ O
- -X- _ O
evaluation492 -X- _ O
. -X- _ O

Conversely -X- _ O
, -X- _ O
the -X- _ O
partial -X- _ O
translations -X- _ O
are -X- _ O
treated -X- _ O
as -X- _ O
undertranslations -X- _ O
of -X- _ O
the -X- _ O
original -X- _ O
sources -X- _ O
. -X- _ O

This -X- _ O
allows -X- _ O
us -X- _ O
to -X- _ O
treat -X- _ O
the -X- _ O
full -X- _ O
translations -X- _ O
as -X- _ O
overtranslations -X- _ O
of -X- _ O
the -X- _ O
partial -X- _ O
sources -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
added -X- _ O
words -X- _ O
as -X- _ O
addition -X- _ O
errors -X- _ O
. -X- _ O

We -X- _ O
retain -X- _ O
only -X- _ O
samples -X- _ O
where -X- _ O
the -X- _ O
full -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
is -X- _ O
different -X- _ O
from -X- _ O
the -X- _ O
partial -X- _ O
one -X- _ O
, -X- _ O
and -X- _ O
can -X- _ O
be -X- _ O
constructed -X- _ O
by -X- _ O
addition -X- _ O
. -X- _ O

We -X- _ O
then -X- _ O
machine -X- _ O
- -X- _ O
translate -X- _ O
both -X- _ O
the -X- _ O
original -X- _ O
and -X- _ O
the -X- _ O
partial -X- _ O
sources -X- _ O
, -X- _ O
yielding -X- _ O
fulland -X- _ O
partial -X- _ O
machine -X- _ B-TaskName
translations -X- _ I-TaskName
. -X- _ O

Specifically -X- _ O
, -X- _ O
we -X- _ O
delete -X- _ O
each -X- _ O
constituent -X- _ O
with -X- _ O
a -X- _ O
probability -X- _ B-MetricName
of -X- _ O
15% -X- _ B-MetricValue
. -X- _ O

We -X- _ O
start -X- _ O
from -X- _ O
the -X- _ O
original -X- _ O
source -X- _ O
sentences -X- _ O
and -X- _ O
create -X- _ O
partial -X- _ O
sources -X- _ O
by -X- _ O
deleting -X- _ O
randomly -X- _ O
selected -X- _ O
constituents -X- _ O
. -X- _ O

Figure -X- _ O
2 -X- _ O
illustrates -X- _ O
the -X- _ O
process -X- _ O
. -X- _ O

We -X- _ O
propose -X- _ O
a -X- _ O
data -X- _ O
creation -X- _ O
process -X- _ O
that -X- _ O
is -X- _ O
inspired -X- _ O
by -X- _ O
previous -X- _ O
work -X- _ O
( -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Tuan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
but -X- _ O
is -X- _ O
defined -X- _ O
such -X- _ O
that -X- _ O
it -X- _ O
works -X- _ O
for -X- _ O
both -X- _ O
additions -X- _ O
and -X- _ O
omissions -X- _ O
, -X- _ O
and -X- _ O
produces -X- _ O
uent -X- _ O
translations -X- _ O
. -X- _ O

Synthetic -X- _ O
Data -X- _ O
We -X- _ O
also -X- _ O
create -X- _ O
synthetic -X- _ O
coverage -X- _ O
errors -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
use -X- _ O
for -X- _ O
training -X- _ O
a -X- _ O
supervised -X- _ O
baseline -X- _ O
QE -X- _ B-MethodName
system -X- _ I-MethodName
. -X- _ O

The -X- _ O
development -X- _ O
set -X- _ O
was -X- _ O
used -X- _ O
to -X- _ O
identify -X- _ O
the -X- _ O
typical -X- _ O
parts -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
speech -X- _ O
of -X- _ O
coverage -X- _ O
error -X- _ O
spans -X- _ O
, -X- _ O
listed -X- _ O
in -X- _ O
the -X- _ O
paragraph -X- _ O
above -X- _ O
. -X- _ O

Gold -X- _ O
Standard -X- _ O
Data -X- _ O
We -X- _ O
use -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
EnglishGerman -X- _ O
and -X- _ O
ChineseEnglish -X- _ O
machine -X- _ B-TaskName
translations -X- _ I-TaskName
for -X- _ O
evaluation -X- _ O
, -X- _ O
which -X- _ O
have -X- _ O
been -X- _ O
annotated -X- _ O
by -X- _ O
Freitag -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
with -X- _ O
translation -X- _ O
errors.4We -X- _ B-MetricName
set -X- _ O
aside -X- _ O
translations -X- _ O
by -X- _ O
the -X- _ O
system -X- _ O
Online -X- _ O
- -X- _ O
B -X- _ O
as -X- _ O
a -X- _ O
development -X- _ O
set -X- _ O
, -X- _ O
and -X- _ O
use -X- _ O
the -X- _ O
other -X- _ O
systems -X- _ O
as -X- _ O
a -X- _ O
test -X- _ O
set -X- _ O
, -X- _ O
excluding -X- _ O
translations -X- _ O
by -X- _ O
humans -X- _ O
. -X- _ O

Specifically -X- _ O
, -X- _ O
we -X- _ O
treat -X- _ O
common -X- _ O
nouns -X- _ O
, -X- _ O
proper -X- _ O
nouns -X- _ O
, -X- _ O
main -X- _ O
verbs -X- _ O
, -X- _ O
adjectives -X- _ O
, -X- _ O
numerals -X- _ O
, -X- _ O
adverbs -X- _ O
, -X- _ O
and -X- _ O
interjections -X- _ O
as -X- _ O
relevant -X- _ O
parts -X- _ O
of -X- _ O
speech -X- _ O
. -X- _ O

parts -X- _ O
of -X- _ O
speech -X- _ O
that -X- _ O
might -X- _ O
constitute -X- _ O
potential -X- _ O
error -X- _ O
spans -X- _ O
. -X- _ O

The -X- _ O
full -X- _ O
translation -X- _ O
contains -X- _ O
an -X- _ O
addition -X- _ O
error -X- _ O
with -X- _ O
regard -X- _ O
to -X- _ O
the -X- _ O
partial -X- _ O
source -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
partial -X- _ O
translation -X- _ O
contains -X- _ O
an -X- _ O
omission -X- _ O
error -X- _ O
with -X- _ O
regard -X- _ O
to -X- _ O
the -X- _ O
original -X- _ O
source -X- _ O
sequence -X- _ O
. -X- _ O

Original -X- _ O
source -X- _ O
Partial -X- _ O
sourceFull -X- _ O
translation -X- _ O
Partial -X- _ O
translation -X- _ O
translateDelete -X- _ O
random -X- _ O
constituentsCheck -X- _ O
addition -X- _ O
property -X- _ O
translate -X- _ O
Figure -X- _ O
2 -X- _ O
: -X- _ O
Process -X- _ O
designed -X- _ O
for -X- _ O
creating -X- _ O
machine -X- _ O
translations -X- _ O
with -X- _ O
synthetic -X- _ O
coverage -X- _ O
errors -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
the -X- _ O
scores -X- _ O
might -X- _ O
be -X- _ O
confounded -X- _ O
by -X- _ O
a -X- _ O
lack -X- _ O
of -X- _ O
uency -X- _ O
in -X- _ O
the -X- _ O
partial -X- _ O
translations -X- _ O
. -X- _ O

We -X- _ O
make -X- _ O
use -X- _ O
of -X- _ O
universal -X- _ B-MethodName
part -X- _ I-MethodName
- -X- _ I-MethodName
of -X- _ I-MethodName
- -X- _ I-MethodName
speech -X- _ I-MethodName
tags -X- _ I-MethodName
( -X- _ I-MethodName
UPOS -X- _ I-MethodName
) -X- _ I-MethodName
to -X- _ O
define -X- _ O
ditioned -X- _ O
on -X- _ O
the -X- _ O
source -X- _ O
. -X- _ O

Error -X- _ O
spans -X- _ O
We -X- _ O
use -X- _ O
Stanza -X- _ B-MethodName
( -X- _ O
Qi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
for -X- _ O
dependency -X- _ O
parsing -X- _ O
, -X- _ O
a -X- _ O
neural -X- _ O
pipeline -X- _ O
for -X- _ O
various -X- _ O
languages -X- _ O
trained -X- _ O
on -X- _ O
data -X- _ O
from -X- _ O
Universal -X- _ O
Dependencies -X- _ O
( -X- _ O
de -X- _ O
Marneffe -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
one -X- _ B-MethodName
- -X- _ I-MethodName
to -X- _ I-MethodName
- -X- _ I-MethodName
many -X- _ I-MethodName
mBART50 -X- _ I-MethodName
model -X- _ I-MethodName
if -X- _ O
English -X- _ O
is -X- _ O
the -X- _ O
source -X- _ O
language -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
many -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
one -X- _ O
model -X- _ O
if -X- _ O
English -X- _ O
is -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
. -X- _ O

Sequence -X- _ B-MetricName
- -X- _ I-MetricName
level -X- _ I-MetricName
probability -X- _ I-MetricName
scores -X- _ I-MetricName
are -X- _ O
computed -X- _ O
by -X- _ O
averaging -X- _ O
the -X- _ O
log -X- _ O
- -X- _ O
probabilities -X- _ O
of -X- _ O
all -X- _ O
target -X- _ O
tokens -X- _ O
. -X- _ O

Scoring -X- _ O
model -X- _ O
We -X- _ O
use -X- _ O
mBART50 -X- _ B-MethodName
( -X- _ O
Tang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
sequence -X- _ B-MethodName
- -X- _ I-MethodName
to -X- _ I-MethodName
- -X- _ I-MethodName
sequence -X- _ I-MethodName
Transformer -X- _ I-MethodName
pre -X- _ O
- -X- _ O
trained -X- _ O
on -X- _ O
monolingual -X- _ O
corpora -X- _ O
in -X- _ O
many -X- _ O
languages -X- _ O
using -X- _ O
the -X- _ O
BART -X- _ B-MethodName
objective -X- _ O
( -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
that -X- _ O
was -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
English -X- _ B-DatasetName
- -X- _ I-DatasetName
centric -X- _ I-DatasetName
multilingual -X- _ I-DatasetName
MT -X- _ I-DatasetName
in -X- _ O
50 -X- _ O
languages -X- _ O
. -X- _ O

4 -X- _ O
Experimental -X- _ O
Setup -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
we -X- _ O
describe -X- _ O
the -X- _ O
data -X- _ O
and -X- _ O
tools -X- _ O
that -X- _ O
we -X- _ O
use -X- _ O
to -X- _ O
implement -X- _ O
and -X- _ O
evaluate -X- _ O
our -X- _ O
approach -X- _ O
. -X- _ O

Our -X- _ O
assumption -X- _ O
is -X- _ O
that -X- _ O
NMT -X- _ B-MethodName
models -X- _ I-MethodName
can -X- _ O
produce -X- _ O
reliable -X- _ O
probability -X- _ O
estimates -X- _ O
despite -X- _ O
the -X- _ O
ungrammatical -X- _ O
input -X- _ O
. -X- _ O

This -X- _ O
is -X- _ O
still -X- _ O
a -X- _ O
simplified -X- _ O
notion -X- _ O
of -X- _ O
constituency -X- _ O
, -X- _ O
since -X- _ O
some -X- _ O
partial -X- _ O
sequences -X- _ O
will -X- _ O
be -X- _ O
ungrammatical -X- _ O
. -X- _ O

For -X- _ O
every -X- _ O
potential -X- _ O
error -X- _ O
span -X- _ O
, -X- _ O
we -X- _ O
create -X- _ O
a -X- _ O
partial -X- _ O
sequence -X- _ O
by -X- _ O
deleting -X- _ O
the -X- _ O
span -X- _ O
from -X- _ O
the -X- _ O
original -X- _ O
sequence -X- _ O
. -X- _ O

It -X- _ O
contains -X- _ O
a -X- _ O
part -X- _ O
of -X- _ O
speech -X- _ O
of -X- _ O
interest -X- _ O
. -X- _ O

It -X- _ O
covers -X- _ O
a -X- _ O
contiguous -X- _ O
subsequence -X- _ O
. -X- _ O

Formally -X- _ O
, -X- _ O
we -X- _ O
consider -X- _ O
word -X- _ O
spans -X- _ O
that -X- _ O
satisfy -X- _ O
the -X- _ O
following -X- _ O
conditions -X- _ O
: -X- _ O
1.A -X- _ O
potential -X- _ O
error -X- _ O
span -X- _ O
is -X- _ O
a -X- _ O
complete -X- _ O
subtree -X- _ O
of -X- _ O
the -X- _ O
dependency -X- _ O
tree -X- _ O
. -X- _ O

This -X- _ O
allows -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
to -X- _ O
skip -X- _ O
function -X- _ O
words -X- _ O
and -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
to -X- _ O
include -X- _ O
a -X- _ O
reasonable -X- _ O
number -X- _ O
of -X- _ O
multiword -X- _ O
spans -X- _ O
in -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
potential -X- _ O
error -X- _ O
spans -X- _ O
. -X- _ O

We -X- _ O
thus -X- _ O
propose -X- _ O
to -X- _ O
extract -X- _ O
potential -X- _ O
error -X- _ O
spans -X- _ O
from -X- _ O
parse -X- _ O
trees -X- _ O
, -X- _ O
specifically -X- _ O
from -X- _ O
dependency -X- _ O
trees -X- _ O
predicted -X- _ O
by -X- _ O
Universal -X- _ B-MethodName
Dependency -X- _ I-MethodName
parsers -X- _ I-MethodName
( -X- _ O
de -X- _ O
Marneffe -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
widely -X- _ O
available -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
such -X- _ O
an -X- _ O
approach -X- _ O
would -X- _ O
rely -X- _ O
on -X- _ O
a -X- _ O
radical -X- _ O
assumption -X- _ O
of -X- _ O
compositionality -X- _ O
, -X- _ O
treating -X- _ O
all -X- _ O
tokens -X- _ O
as -X- _ O
independent -X- _ O
constituents -X- _ O
. -X- _ O

For -X- _ O
a -X- _ O
source -X- _ O
sentence -X- _ O
of -X- _ O
ntokens -X- _ O
one -X- _ O
could -X- _ O
create -X- _ O
npartial -X- _ O
source -X- _ O
sequences -X- _ O
with -X- _ O
the -X- _ O
ith -X- _ O
token -X- _ O
deleted -X- _ O
. -X- _ O

Potential -X- _ O
Error -X- _ O
Spans -X- _ O
In -X- _ O
its -X- _ O
most -X- _ O
basic -X- _ O
form -X- _ O
, -X- _ O
our -X- _ O
algorithm -X- _ O
does -X- _ O
not -X- _ O
require -X- _ O
any -X- _ O
linguistic -X- _ O
resources -X- _ O
apart -X- _ O
from -X- _ O
tokenization -X- _ O
. -X- _ O

Namely -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
an -X- _ O
NMT -X- _ B-MethodName
model -X- _ I-MethodName
for -X- _ O
the -X- _ O
reverse -X- _ O
translation -X- _ O
direction -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
score -X- _ O
the -X- _ O
source -X- _ O
sequence -X- _ O
conditioned -X- _ O
on -X- _ O
the -X- _ O
full -X- _ O
translation -X- _ O
and -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
partial -X- _ O
translations.3 -X- _ O
3Another -X- _ O
possibility -X- _ O
would -X- _ O
be -X- _ O
to -X- _ O
leave -X- _ O
the -X- _ O
translation -X- _ O
direction -X- _ O
unreversed -X- _ O
and -X- _ O
to -X- _ O
score -X- _ O
the -X- _ O
partial -X- _ O
translations -X- _ O
con-491 -X- _ O
. -X- _ O

To -X- _ O
compute -X- _ O
the -X- _ O
probability -X- _ O
score -X- _ O
for -X- _ O
a -X- _ O
translationYgiven -X- _ O
a -X- _ O
source -X- _ O
sequence -X- _ O
X -X- _ O
, -X- _ O
we -X- _ O
sum -X- _ O
up -X- _ O
the -X- _ O
log -X- _ O
- -X- _ O
probabilities -X- _ O
for -X- _ O
every -X- _ O
target -X- _ O
token -X- _ O
and -X- _ O
normalize -X- _ O
the -X- _ O
sum -X- _ O
by -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
target -X- _ O
tokens -X- _ O
: -X- _ O
score -X- _ O
( -X- _ O
YjX -X- _ O
) -X- _ O
= -X- _ O
1 -X- _ O
jYjjYjX -X- _ O
i=0logp(yijX -X- _ O
; -X- _ O
y -X- _ O
< -X- _ O
i -X- _ O
) -X- _ O
Application -X- _ O
to -X- _ O
Addition -X- _ O
Errors -X- _ O
We -X- _ O
apply -X- _ O
the -X- _ O
same -X- _ O
method -X- _ O
to -X- _ O
addition -X- _ O
detection -X- _ O
, -X- _ O
but -X- _ O
swap -X- _ O
the -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
languages -X- _ O
. -X- _ O

If -X- _ O
the -X- _ O
probability -X- _ B-MetricName
score -X- _ I-MetricName
of -X- _ O
the -X- _ O
translation -X- _ O
( -X- _ O
average -X- _ O
token -X- _ O
logprobability -X- _ O
) -X- _ O
is -X- _ O
higher -X- _ O
when -X- _ O
conditioned -X- _ O
on -X- _ O
such -X- _ O
a -X- _ O
partial -X- _ O
source -X- _ O
, -X- _ O
the -X- _ O
deleted -X- _ O
constituent -X- _ O
is -X- _ O
taken -X- _ O
to -X- _ O
be -X- _ O
missing -X- _ O
from -X- _ O
the -X- _ O
translation -X- _ O
. -X- _ O

We -X- _ O
construct -X- _ O
partial -X- _ O
source -X- _ O
sequences -X- _ O
by -X- _ O
systematically -X- _ O
deleting -X- _ O
constituents -X- _ O
from -X- _ O
the -X- _ O
source -X- _ O
. -X- _ O

Application -X- _ O
to -X- _ O
Omission -X- _ O
Errors -X- _ O
Figure -X- _ O
1 -X- _ O
illustrates -X- _ O
how -X- _ O
contrastive -X- _ O
conditioning -X- _ O
can -X- _ O
be -X- _ O
directly -X- _ O
applied -X- _ O
to -X- _ O
the -X- _ O
detection -X- _ O
of -X- _ O
omission -X- _ O
errors -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
if -X- _ O
a -X- _ O
certain -X- _ O
translation -X- _ O
is -X- _ O
more -X- _ O
probable -X- _ O
under -X- _ O
an -X- _ O
NMT -X- _ B-MethodName
model -X- _ I-MethodName
when -X- _ O
conditioned -X- _ O
on -X- _ O
a -X- _ O
counterfactual -X- _ O
source -X- _ O
sequence -X- _ O
, -X- _ O
the -X- _ O
translation -X- _ O
might -X- _ O
be -X- _ O
inadequate -X- _ O
. -X- _ O

3 -X- _ O
Approach -X- _ O
Contrastive -X- _ O
Conditioning -X- _ O
Properties -X- _ O
of -X- _ O
a -X- _ O
translation -X- _ O
can -X- _ O
be -X- _ O
inferred -X- _ O
by -X- _ O
estimating -X- _ O
its -X- _ O
probability -X- _ O
conditioned -X- _ O
on -X- _ O
contrastive -X- _ O
source -X- _ O
sequences -X- _ O
( -X- _ O
Vamvas -X- _ O
and -X- _ O
Sennrich -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

MQM -X- _ B-MethodName
reserves -X- _ O
these -X- _ O
terms -X- _ O
for -X- _ O
errors -X- _ O
where -X- _ O
the -X- _ O
translation -X- _ O
is -X- _ O
too -X- _ O
specific -X- _ O
or -X- _ O
too -X- _ O
unspecific.references -X- _ O
with -X- _ O
synthetic -X- _ O
omissions -X- _ O
reduces -X- _ O
coverage -X- _ O
errors -X- _ O
produced -X- _ O
by -X- _ O
an -X- _ O
NMT -X- _ B-MethodName
system -X- _ I-MethodName
. -X- _ O

More -X- _ O
recently -X- _ O
, -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
found -X- _ O
that -X- _ O
contrastive -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
on -X- _ O
2The -X- _ O
terms -X- _ O
overtranslation -X- _ O
andundertranslation -X- _ O
have -X- _ O
been -X- _ O
used -X- _ O
in -X- _ O
the -X- _ O
literature -X- _ O
as -X- _ O
well -X- _ O
. -X- _ O

Other -X- _ O
related -X- _ O
work -X- _ O
has -X- _ O
focused -X- _ O
on -X- _ O
improving -X- _ O
coverage -X- _ O
during -X- _ O
decoding -X- _ O
or -X- _ O
training -X- _ O
, -X- _ O
for -X- _ O
example -X- _ O
via -X- _ O
attention -X- _ O
( -X- _ O
Tu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
among -X- _ O
others -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
method -X- _ O
that -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
off -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
shelf -X- _ O
NMT -X- _ B-MethodName
models -X- _ O
only -X- _ O
. -X- _ O

Similarly -X- _ O
, -X- _ O
Tuan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
train -X- _ O
a -X- _ O
QE -X- _ B-MethodName
model -X- _ I-MethodName
on -X- _ O
synthetically -X- _ B-TaskName
noisy -X- _ I-TaskName
translations -X- _ I-TaskName
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
insert -X- _ O
synthetic -X- _ O
hallucinations -X- _ O
and -X- _ O
train -X- _ O
a -X- _ O
Transformer -X- _ B-MethodName
to -X- _ O
predict -X- _ O
the -X- _ O
inserted -X- _ O
spans -X- _ O
. -X- _ O

Previous -X- _ O
work -X- _ O
has -X- _ O
employed -X- _ O
custom -X- _ O
QE -X- _ B-MethodName
models -X- _ I-MethodName
trained -X- _ O
on -X- _ O
labeled -X- _ O
parallel -X- _ O
data -X- _ O
. -X- _ O

Detecting -X- _ O
and -X- _ O
reducing -X- _ O
coverage -X- _ O
errors -X- _ O
While -X- _ O
reference -X- _ O
- -X- _ O
based -X- _ O
approaches -X- _ O
include -X- _ O
measuring -X- _ O
the -X- _ O
n -X- _ O
- -X- _ O
gram -X- _ O
overlap -X- _ O
to -X- _ O
the -X- _ O
reference -X- _ O
( -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
and -X- _ O
analyzing -X- _ O
word -X- _ O
alignment -X- _ O
to -X- _ O
the -X- _ O
source -X- _ O
( -X- _ O
Kong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
this -X- _ O
work -X- _ O
focuses -X- _ O
on -X- _ O
the -X- _ O
reference -X- _ O
- -X- _ O
free -X- _ O
detection -X- _ O
of -X- _ O
coverage -X- _ O
errors -X- _ O
. -X- _ O

Similar -X- _ O
patterns -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
EnglishFrench -X- _ B-TaskName
machine -X- _ I-TaskName
translations -X- _ I-TaskName
that -X- _ O
have -X- _ O
been -X- _ O
annotated -X- _ O
with -X- _ O
fine -X- _ O
- -X- _ O
grained -X- _ O
MQM -X- _ O
labels -X- _ O
for -X- _ O
the -X- _ O
document -X- _ B-TaskName
- -X- _ I-TaskName
level -X- _ I-TaskName
QE -X- _ I-TaskName
shared -X- _ I-TaskName
task -X- _ I-TaskName
( -X- _ O
Specia -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Fonseca -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Specia -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

Their -X- _ O
findings -X- _ O
confirm -X- _ O
that -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
NMT -X- _ B-MethodName
systems -X- _ I-MethodName
still -X- _ O
erroneously -X- _ O
add -X- _ O
and -X- _ O
omit -X- _ O
target -X- _ O
words -X- _ O
, -X- _ O
and -X- _ O
that -X- _ O
omission -X- _ O
occurs -X- _ O
more -X- _ O
often -X- _ O
than -X- _ O
addition -X- _ O
. -X- _ O

issue -X- _ O
where -X- _ O
content -X- _ O
is -X- _ O
missing -X- _ O
from -X- _ O
the -X- _ O
translation -X- _ O
but -X- _ O
is -X- _ O
present -X- _ O
in -X- _ O
the -X- _ O
source.2 -X- _ O
Freitag -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
used -X- _ O
MQM -X- _ B-MethodName
to -X- _ O
manually -X- _ O
re -X- _ O
- -X- _ O
annotate -X- _ O
EnglishGerman -X- _ B-TaskName
and -X- _ I-TaskName
ChineseEnglish -X- _ I-TaskName
machine -X- _ I-TaskName
translations -X- _ I-TaskName
submitted -X- _ O
to -X- _ O
the -X- _ O
WMT -X- _ B-TaskName
2020 -X- _ I-TaskName
news -X- _ I-TaskName
translation -X- _ I-TaskName
task -X- _ I-TaskName
( -X- _ O
Barrault -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

This -X- _ O
indicates -X- _ O
that -X- _ O
there -X- _ O
is -X- _ O
an -X- _ O
omission -X- _ O
error -X- _ O
( -X- _ O
Step -X- _ O
4 -X- _ O
) -X- _ O
. -X- _ O

An -X- _ O
NMT -X- _ B-MethodName
model -X- _ I-MethodName
such -X- _ O
as -X- _ O
mBART50 -X- _ B-MethodName
assigns -X- _ O
a -X- _ O
higher -X- _ O
probability -X- _ B-MetricName
score -X- _ I-MetricName
to -X- _ O
Y -X- _ O
conditioned -X- _ O
on -X- _ O
the -X- _ O
source -X- _ O
with -X- _ O
after -X- _ O
landing -X- _ O
deleted -X- _ O
than -X- _ O
to -X- _ O
Y -X- _ O
conditioned -X- _ O
on -X- _ O
the -X- _ O
full -X- _ O
source -X- _ O
( -X- _ O
Step -X- _ O
3 -X- _ O
) -X- _ O
. -X- _ O

Potential -X- _ O
error -X- _ O
spans -X- _ O
are -X- _ O
derived -X- _ O
from -X- _ O
a -X- _ O
parse -X- _ O
tree -X- _ O
( -X- _ O
Step -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O

German -X- _ O
translation -X- _ O
Y -X- _ O
leaves -X- _ O
after -X- _ O
landing -X- _ O
erroneously -X- _ O
untranslated -X- _ O
( -X- _ O
Step -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O

Addition -X- _ O
is -X- _ O
defined -X- _ O
as -X- _ O
an -X- _ O
accuracy -X- _ O
issue -X- _ O
where -X- _ O
the -X- _ O
target -X- _ O
text -X- _ O
includes -X- _ O
text -X- _ O
not -X- _ O
present -X- _ O
in -X- _ O
the -X- _ O
source -X- _ O
, -X- _ O
and -X- _ O
omission -X- _ O
is -X- _ O
defined -X- _ O
as -X- _ O
an -X- _ O
accuracy -X- _ O
1https://github.com/ZurichNLP/ -X- _ O
coverage -X- _ O
- -X- _ O
contrastive -X- _ O
- -X- _ O
conditioning490 -X- _ O
. -X- _ O

They -X- _ O
are -X- _ O
included -X- _ O
as -X- _ O
typical -X- _ O
translation -X- _ O
issues -X- _ O
in -X- _ O
the -X- _ O
Multidimensional -X- _ B-MethodName
Quality -X- _ I-MethodName
Metrics -X- _ I-MethodName
( -X- _ I-MethodName
MQM -X- _ I-MethodName
) -X- _ I-MethodName
framework -X- _ I-MethodName
( -X- _ O
Lommel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
release -X- _ O
the -X- _ O
code -X- _ O
and -X- _ O
data -X- _ O
to -X- _ O
reproduce -X- _ O
our -X- _ O
findings -X- _ O
, -X- _ O
including -X- _ O
a -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
dataset -X- _ O
of -X- _ O
synthetic -X- _ O
coverage -X- _ O
errors -X- _ O
in -X- _ O
EnglishGerman -X- _ O
and -X- _ O
ChineseEnglish -X- _ O
machine -X- _ B-TaskName
translations.1 -X- _ I-TaskName
2 -X- _ O
Related -X- _ O
Work -X- _ O
Coverage -X- _ O
errors -X- _ O
in -X- _ O
NMT -X- _ B-MethodName
Addition -X- _ I-MethodName
and -X- _ O
omission -X- _ O
of -X- _ O
target -X- _ O
words -X- _ O
have -X- _ O
been -X- _ O
observed -X- _ O
by -X- _ O
human -X- _ O
evaluation -X- _ O
studies -X- _ O
in -X- _ O
various -X- _ O
languages -X- _ O
, -X- _ O
with -X- _ O
omission -X- _ O
as -X- _ O
the -X- _ O
more -X- _ O
frequent -X- _ O
error -X- _ O
type -X- _ O
( -X- _ O
Castilho -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Zheng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
believe -X- _ O
our -X- _ O
algorithm -X- _ O
could -X- _ O
be -X- _ O
a -X- _ O
useful -X- _ O
aid -X- _ O
whenever -X- _ O
humans -X- _ O
remain -X- _ O
in -X- _ O
the -X- _ O
loop -X- _ O
, -X- _ O
for -X- _ O
example -X- _ O
in -X- _ O
a -X- _ O
post -X- _ O
- -X- _ O
editing -X- _ O
workow -X- _ O
. -X- _ O

False -X- _ B-MetricName
positive -X- _ I-MetricName
predictions -X- _ O
can -X- _ O
occur -X- _ O
especially -X- _ O
in -X- _ O
cases -X- _ O
where -X- _ O
the -X- _ O
translation -X- _ B-TaskName
has -X- _ O
different -X- _ O
syntax -X- _ O
than -X- _ O
the -X- _ O
source -X- _ O
. -X- _ O

Human -X- _ O
raters -X- _ O
find -X- _ O
that -X- _ O
word -X- _ O
- -X- _ O
level -X- _ O
precision -X- _ O
is -X- _ O
higher -X- _ O
for -X- _ O
omissions -X- _ O
than -X- _ O
additions -X- _ O
, -X- _ O
with -X- _ O
39% -X- _ B-MetricValue
of -X- _ O
predicted -X- _ O
error -X- _ B-MetricName
spans -X- _ O
being -X- _ O
precise -X- _ O
for -X- _ O
EnglishGerman -X- _ O
translations -X- _ O
, -X- _ O
and -X- _ O
20% -X- _ B-MetricValue
for -X- _ O
ChineseEnglish -X- _ O
. -X- _ O

When -X- _ O
comparing -X- _ O
the -X- _ O
detected -X- _ O
errors -X- _ O
to -X- _ O
human -X- _ O
annotations -X- _ O
of -X- _ O
coverage -X- _ O
errors -X- _ O
on -X- _ O
the -X- _ O
segment -X- _ O
level -X- _ O
( -X- _ O
Freitag -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
our -X- _ O
approach -X- _ O
surpasses -X- _ O
a -X- _ O
supervised -X- _ O
QE -X- _ O
baseline -X- _ O
that -X- _ O
was -X- _ O
trained -X- _ O
on -X- _ O
a -X- _ O
large -X- _ O
number -X- _ O
of -X- _ O
synthetic -X- _ O
coverage -X- _ O
errors -X- _ O
. -X- _ O

We -X- _ O
apply -X- _ O
the -X- _ O
same -X- _ O
principle -X- _ O
to -X- _ O
the -X- _ O
detection -X- _ O
of -X- _ O
addition -X- _ O
errors -X- _ O
by -X- _ O
swapping -X- _ O
the -X- _ O
source -X- _ O
and -X- _ O
the -X- _ O
target -X- _ O
sequence -X- _ O
. -X- _ O

If -X- _ O
the -X- _ O
probability -X- _ B-MetricName
score -X- _ I-MetricName
is -X- _ O
higher -X- _ O
than -X- _ O
when -X- _ O
the -X- _ O
translation -X- _ O
is -X- _ O
conditioned -X- _ O
on -X- _ O
the -X- _ O
full -X- _ O
source -X- _ O
, -X- _ O
the -X- _ O
deleted -X- _ O
constituent -X- _ O
might -X- _ O
have -X- _ O
no -X- _ O
counterpart -X- _ O
in -X- _ O
the -X- _ O
translation -X- _ B-TaskName
( -X- _ O
Figure -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O

Omission -X- _ B-MetricName
errors -X- _ I-MetricName
are -X- _ O
detected -X- _ O
by -X- _ O
systematically -X- _ O
deletingconstituents -X- _ O
from -X- _ O
the -X- _ O
source -X- _ O
and -X- _ O
by -X- _ O
estimating -X- _ O
the -X- _ O
probability -X- _ O
of -X- _ O
the -X- _ O
translation -X- _ O
conditioned -X- _ O
on -X- _ O
such -X- _ O
a -X- _ O
partial -X- _ O
source -X- _ O
sequence -X- _ O
. -X- _ O

We -X- _ O
create -X- _ O
parse -X- _ B-MethodName
trees -X- _ I-MethodName
for -X- _ O
both -X- _ O
the -X- _ O
source -X- _ B-TaskName
sequence -X- _ I-TaskName
and -X- _ I-TaskName
the -X- _ I-TaskName
translation -X- _ I-TaskName
, -X- _ O
and -X- _ O
treat -X- _ O
their -X- _ O
constituents -X- _ O
as -X- _ O
units -X- _ O
of -X- _ O
information -X- _ O
. -X- _ O

Adapting -X- _ O
our -X- _ O
contrastive -X- _ O
conditioning -X- _ O
approach -X- _ O
( -X- _ O
Vamvas -X- _ O
and -X- _ O
Sennrich -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
probability -X- _ B-MetricName
scores -X- _ I-MetricName
of -X- _ O
NMT -X- _ B-MethodName
models -X- _ I-MethodName
to -X- _ O
approximate -X- _ O
this -X- _ O
concept -X- _ O
of -X- _ O
coverage -X- _ O
. -X- _ O

Conversely -X- _ O
, -X- _ O
an -X- _ O
omission -X- _ B-MetricName
error -X- _ I-MetricName
means -X- _ O
that -X- _ O
the -X- _ O
translation -X- _ O
would -X- _ O
be -X- _ O
more -X- _ O
adequate -X- _ O
for -X- _ O
a -X- _ O
less -X- _ O
informative -X- _ O
source -X- _ O
sequence -X- _ O
. -X- _ O

Therefore -X- _ O
, -X- _ O
an -X- _ O
addition -X- _ O
error -X- _ O
means -X- _ O
that -X- _ O
the -X- _ O
source -X- _ O
would -X- _ O
be -X- _ O
better -X- _ O
conveyed -X- _ O
by -X- _ O
a -X- _ O
translation -X- _ O
containing -X- _ O
less -X- _ O
information -X- _ O
. -X- _ O

Our -X- _ O
premise -X- _ O
is -X- _ O
that -X- _ O
a -X- _ O
translation -X- _ O
has -X- _ O
optimal -X- _ O
coverage -X- _ O
if -X- _ O
it -X- _ O
uses -X- _ O
as -X- _ O
little -X- _ O
information -X- _ O
as -X- _ O
possible -X- _ O
and -X- _ O
as -X- _ O
much -X- _ O
information -X- _ O
as -X- _ O
necessary -X- _ O
to -X- _ O
convey -X- _ O
the -X- _ O
source -X- _ O
sequence -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
reference -X- _ O
- -X- _ O
free -X- _ O
algorithm -X- _ O
based -X- _ O
on -X- _ O
hypothetical -X- _ O
reasoning -X- _ O
. -X- _ O

Previous -X- _ O
approaches -X- _ O
to -X- _ O
detecting -X- _ O
such -X- _ O
errors -X- _ O
make -X- _ O
use -X- _ O
of -X- _ O
reference -X- _ O
translations -X- _ O
( -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
or -X- _ O
employ -X- _ O
a -X- _ O
separate -X- _ O
quality -X- _ B-MethodName
estimation -X- _ I-MethodName
( -X- _ I-MethodName
QE -X- _ I-MethodName
) -X- _ I-MethodName
model -X- _ I-MethodName
trained -X- _ O
on -X- _ O
synthetic -X- _ O
data -X- _ O
for -X- _ O
a -X- _ O
language -X- _ O
pair -X- _ O
( -X- _ O
Tuan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

1 -X- _ O
Introduction -X- _ O
Neural -X- _ B-TaskName
machine -X- _ I-TaskName
translation -X- _ I-TaskName
( -X- _ I-TaskName
NMT -X- _ I-TaskName
) -X- _ I-TaskName
is -X- _ O
susceptible -X- _ O
to -X- _ O
coverage -X- _ O
errors -X- _ O
such -X- _ O
as -X- _ O
the -X- _ O
addition -X- _ O
of -X- _ O
superuous -X- _ O
target -X- _ O
words -X- _ O
or -X- _ O
the -X- _ O
omission -X- _ O
of -X- _ O
important -X- _ O
source -X- _ O
content -X- _ O
. -X- _ O

The -X- _ O
accuracy -X- _ B-MetricName
of -X- _ O
our -X- _ O
method -X- _ O
is -X- _ O
comparable -X- _ O
to -X- _ O
a -X- _ O
supervised -X- _ O
method -X- _ O
that -X- _ O
requires -X- _ O
a -X- _ O
custom -X- _ O
quality -X- _ O
estimation -X- _ O
model -X- _ O
. -X- _ O

This -X- _ O
allows -X- _ O
to -X- _ O
pinpoint -X- _ O
superuous -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
translation -X- _ O
and -X- _ O
untranslated -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
source -X- _ O
even -X- _ O
in -X- _ O
the -X- _ O
absence -X- _ O
of -X- _ O
a -X- _ O
reference -X- _ B-TaskName
translation -X- _ I-TaskName
. -X- _ O

Using -X- _ O
contrastive -X- _ O
conditioning -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
the -X- _ O
likelihood -X- _ O
of -X- _ O
a -X- _ O
full -X- _ O
sequence -X- _ O
under -X- _ O
a -X- _ O
translation -X- _ O
model -X- _ O
to -X- _ O
the -X- _ O
likelihood -X- _ O
of -X- _ O
its -X- _ O
parts -X- _ O
, -X- _ O
given -X- _ O
the -X- _ O
corresponding -X- _ O
source -X- _ O
or -X- _ O
target -X- _ O
sequence -X- _ O
. -X- _ O

We -X- _ O
propose -X- _ O
a -X- _ O
method -X- _ O
for -X- _ O
detecting -X- _ O
such -X- _ O
phenomena -X- _ O
with -X- _ O
off -X- _ B-MethodName
- -X- _ I-MethodName
the -X- _ I-MethodName
- -X- _ I-MethodName
shelf -X- _ I-MethodName
translation -X- _ I-MethodName
models -X- _ I-MethodName
. -X- _ O

Get -X- _ O
to -X- _ O
the -X- _ O
point -X- _ O
: -X- _ O
Summarization -X- _ B-TaskName
with -X- _ O
pointergenerator -X- _ B-MethodName
networks -X- _ I-MethodName
. -X- _ O

SQuAD -X- _ B-DatasetName
: -X- _ O
100,000 -X- _ O
+ -X- _ O
questions -X- _ O
for -X- _ O
machine -X- _ B-TaskName
comprehension -X- _ I-TaskName
of -X- _ O
text -X- _ O
. -X- _ O

Addressing -X- _ O
the -X- _ O
rare -X- _ O
word -X- _ O
problem -X- _ O
in -X- _ O
neural -X- _ B-TaskName
machine -X- _ I-TaskName
translation -X- _ I-TaskName
. -X- _ O

Dense -X- _ O
passage -X- _ O
retrieval -X- _ O
for -X- _ O
opendomain -X- _ B-TaskName
question -X- _ I-TaskName
answering -X- _ I-TaskName
. -X- _ O

TriviaQA -X- _ B-DatasetName
: -X- _ O
A -X- _ O
large -X- _ O
scale -X- _ O
distantly -X- _ O
supervised -X- _ O
challenge -X- _ O
dataset -X- _ O
for -X- _ O
reading -X- _ B-TaskName
comprehension -X- _ I-TaskName
. -X- _ O

Leveraging -X- _ O
passage -X- _ O
retrieval -X- _ O
with -X- _ O
generative -X- _ O
models -X- _ O
for -X- _ O
open -X- _ B-TaskName
domain -X- _ I-TaskName
question -X- _ I-TaskName
answering -X- _ I-TaskName
. -X- _ O

Learning -X- _ O
to -X- _ O
retrieve -X- _ O
reasoning -X- _ O
paths -X- _ O
over -X- _ O
wikipedia -X- _ O
graphfor -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
. -X- _ O

Experimental -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
outperforms -X- _ O
FiD -X- _ B-MethodName
- -X- _ I-MethodName
KD -X- _ I-MethodName
on -X- _ O
two -X- _ O
benchmark -X- _ O
datasets -X- _ O
under -X- _ O
the -X- _ O
same -X- _ O
setting -X- _ O
, -X- _ O
demonstrating -X- _ O
the -X- _ O
advantages -X- _ O
of -X- _ O
our -X- _ O
method -X- _ O
. -X- _ O

Specifically -X- _ O
, -X- _ O
we -X- _ O
integrate -X- _ O
a -X- _ O
pointer -X- _ O
network -X- _ O
into -X- _ O
the -X- _ O
FiD -X- _ B-MethodName
reader -X- _ I-MethodName
to -X- _ O
allow -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
directly -X- _ O
select -X- _ O
words -X- _ O
from -X- _ O
the -X- _ O
retrieved -X- _ O
passages -X- _ O
. -X- _ O

6 -X- _ O
Conclusion -X- _ O
In -X- _ O
this -X- _ O
article -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
FiD -X- _ B-MethodName
- -X- _ I-MethodName
PGN -X- _ I-MethodName
approach -X- _ O
for -X- _ O
the -X- _ O
reader -X- _ O
module -X- _ O
of -X- _ O
ODQA -X- _ B-TaskName
under -X- _ O
the -X- _ O
standard -X- _ O
retriever -X- _ B-MethodName
- -X- _ I-MethodName
reader -X- _ I-MethodName
framework -X- _ I-MethodName
. -X- _ O

Moreover -X- _ O
, -X- _ O
the -X- _ O
two -X- _ O
models -X- _ O
show -X- _ O
comparative -X- _ O
performance -X- _ O
when -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
training -X- _ O
passages -X- _ O
is -X- _ O
small -X- _ O
, -X- _ O
but -X- _ O
when -X- _ O
more -X- _ O
passages -X- _ O
are -X- _ O
included -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
outperforms -X- _ O
FiD -X- _ B-MethodName
, -X- _ O
especially -X- _ O
on -X- _ O
the -X- _ O
NQ -X- _ B-DatasetName
dataset -X- _ I-DatasetName
. -X- _ O

We -X- _ O
can -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
matching -X- _ O
scores -X- _ O
of -X- _ O
both -X- _ O
models -X- _ O
increase -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
passages -X- _ O
used -X- _ O
in -X- _ O
training -X- _ O
, -X- _ O
consistent -X- _ O
with -X- _ O
the -X- _ O
findings -X- _ O
in -X- _ O
Izacard -X- _ O
and -X- _ O
Grave -X- _ O
( -X- _ O
2021b -X- _ O
) -X- _ O
that -X- _ O
sequence -X- _ B-MethodName
- -X- _ I-MethodName
tosequence -X- _ I-MethodName
model -X- _ I-MethodName
is -X- _ O
capable -X- _ O
of -X- _ O
gathering -X- _ O
information -X- _ O
across -X- _ O
multiple -X- _ O
retrieved -X- _ O
passages -X- _ O
. -X- _ O

Exact -X- _ B-MetricName
match -X- _ I-MetricName
( -X- _ I-MetricName
EM -X- _ I-MetricName
) -X- _ I-MetricName
scores -X- _ I-MetricName
are -X- _ O
measured -X- _ O
on -X- _ O
the -X- _ O
development -X- _ O
sets -X- _ O
of -X- _ O
NQ -X- _ B-DatasetName
and -X- _ O
TriviaQA -X- _ B-DatasetName
. -X- _ O

Figure -X- _ O
3 -X- _ O
: -X- _ O
The -X- _ O
variation -X- _ O
of -X- _ O
performance -X- _ O
with -X- _ O
different -X- _ O
number -X- _ O
of -X- _ O
retrieved -X- _ O
passages -X- _ O
used -X- _ O
in -X- _ O
reader -X- _ O
training -X- _ O
. -X- _ O

Exact -X- _ B-MetricName
match -X- _ I-MetricName
( -X- _ I-MetricName
EM -X- _ I-MetricName
) -X- _ I-MetricName
scores -X- _ I-MetricName
are -X- _ O
reported -X- _ O
. -X- _ O

We -X- _ O
train -X- _ O
both -X- _ O
models -X- _ O
with -X- _ O
topk -X- _ O
passages -X- _ O
( -X- _ O
k2f1;5;10;25 -X- _ O
g -X- _ O
) -X- _ O
and -X- _ O
evaluate -X- _ O
on -X- _ O
the -X- _ O
development -X- _ O
sets -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
number -X- _ O
of -X- _ O
pas-438 -X- _ O
. -X- _ O

Figure -X- _ O
3 -X- _ O
shows -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
and -X- _ O
FiD -X- _ B-MethodName
reader -X- _ I-MethodName
with -X- _ O
regard -X- _ O
to -X- _ O
different -X- _ O
number -X- _ O
of -X- _ O
retrieved -X- _ O
training -X- _ O
passages -X- _ O
. -X- _ O

Training -X- _ O
with -X- _ O
Varying -X- _ O
Number -X- _ O
of -X- _ O
Passages -X- _ O
. -X- _ O

It -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
that -X- _ O
our -X- _ O
approach -X- _ O
improves -X- _ O
most -X- _ O
over -X- _ O
FiD -X- _ B-MethodName
reader -X- _ I-MethodName
on -X- _ O
" -X- _ O
No -X- _ O
Overlap -X- _ O
" -X- _ O
category -X- _ O
, -X- _ O
the -X- _ O
most -X- _ O
challenging -X- _ O
setting -X- _ O
, -X- _ O
indicating -X- _ O
a -X- _ O
better -X- _ O
generalization -X- _ O
ability -X- _ O
to -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
. -X- _ O

Table -X- _ O
4 -X- _ O
reports -X- _ O
the -X- _ O
results -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
three -X- _ O
kinds -X- _ O
of -X- _ O
test -X- _ O
- -X- _ O
train -X- _ O
overlaps -X- _ O
. -X- _ O

We -X- _ O
evaluate -X- _ O
our -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
same -X- _ O
test -X- _ O
data -X- _ O
splits -X- _ O
as -X- _ O
in -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
study -X- _ O
of -X- _ O
test -X- _ O
- -X- _ O
train -X- _ O
overlap -X- _ O
( -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
provides -X- _ O
valuable -X- _ O
insights -X- _ O
into -X- _ O
the -X- _ O
models -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
behavior -X- _ O
. -X- _ O

2.9 -X- _ O
EM -X- _ B-MethodName
for -X- _ O
TriviaQA -X- _ B-DatasetName
and -X- _ O
NQ -X- _ B-DatasetName
, -X- _ O
respectively -X- _ O
) -X- _ O
. -X- _ O

Moreover -X- _ O
, -X- _ O
this -X- _ O
observation -X- _ O
is -X- _ O
also -X- _ O
consistent -X- _ O
with -X- _ O
the -X- _ O
results -X- _ O
that -X- _ O
the -X- _ O
improvements -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
over -X- _ O
FiD -X- _ B-MethodName
reader -X- _ I-MethodName
is -X- _ O
smaller -X- _ O
in -X- _ O
TriviaQA -X- _ B-DatasetName
than -X- _ O
the -X- _ O
one -X- _ O
in -X- _ O
NQ -X- _ B-DatasetName
( -X- _ O
0.9 -X- _ O
vs -X- _ O
. -X- _ O

Compared -X- _ O
to -X- _ O
the -X- _ O
information -X- _ O
- -X- _ O
seeking -X- _ O
questions -X- _ O
in -X- _ O
NQ -X- _ B-DatasetName
, -X- _ O
probing -X- _ O
questions -X- _ O
tend -X- _ O
to -X- _ O
need -X- _ O
more -X- _ O
complex -X- _ O
reasoning -X- _ O
, -X- _ O
and -X- _ O
thus -X- _ O
it -X- _ O
is -X- _ O
difficult -X- _ O
to -X- _ O
directly -X- _ O
extract -X- _ O
relevant -X- _ O
tokens -X- _ O
from -X- _ O
input -X- _ O
texts -X- _ O
. -X- _ O

As -X- _ O
stated -X- _ O
in -X- _ O
Rogers -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
Trivia -X- _ O
questions -X- _ O
are -X- _ O
more -X- _ O
like -X- _ O
probing -X- _ O
questions -X- _ O
. -X- _ O

We -X- _ O
conjecture -X- _ O
that -X- _ O
this -X- _ O
phenomenon -X- _ O
is -X- _ O
caused -X- _ O
by -X- _ O
the -X- _ O
different -X- _ O
Figure -X- _ O
2 -X- _ O
: -X- _ O
Generation -X- _ O
probability -X- _ O
pgenover -X- _ O
training -X- _ O
steps -X- _ O
on -X- _ O
NQ -X- _ B-DatasetName
and -X- _ O
TriviaQA -X- _ B-DatasetName
. -X- _ O

Note -X- _ O
that -X- _ O
a -X- _ O
higher -X- _ O
generation -X- _ O
probability -X- _ O
means -X- _ O
that -X- _ O
more -X- _ O
tokens -X- _ O
are -X- _ O
produced -X- _ O
from -X- _ O
the -X- _ O
vocabulary -X- _ O
instead -X- _ O
of -X- _ O
copying -X- _ O
from -X- _ O
the -X- _ O
input -X- _ O
. -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
, -X- _ O
the -X- _ O
generation -X- _ O
probability -X- _ O
pgen -X- _ O
in -X- _ O
TriviaQA -X- _ B-DatasetName
is -X- _ O
always -X- _ O
higher -X- _ O
than -X- _ O
the -X- _ O
one -X- _ O
in -X- _ O
NQ -X- _ B-DatasetName
. -X- _ O

We -X- _ O
explore -X- _ O
the -X- _ O
probability -X- _ O
of -X- _ O
generation -X- _ O
during -X- _ O
training -X- _ O
to -X- _ O
further -X- _ O
investigate -X- _ O
the -X- _ O
effects -X- _ O
of -X- _ O
the -X- _ O
pointer -X- _ O
module -X- _ O
. -X- _ O

5 -X- _ O
Analysis -X- _ O
Generation -X- _ O
Probability -X- _ O
. -X- _ O

It -X- _ O
is -X- _ O
worth -X- _ O
noting -X- _ O
that -X- _ O
, -X- _ O
compared -X- _ O
with -X- _ O
FiDKD -X- _ B-MethodName
trained -X- _ O
with -X- _ O
the -X- _ O
top-100 -X- _ O
retrieved -X- _ O
passages -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
achieves -X- _ O
comparative -X- _ O
or -X- _ O
even -X- _ O
better -X- _ O
results -X- _ O
with -X- _ O
only -X- _ O
1/4 -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
data -X- _ O
and -X- _ O
without -X- _ O
introducing -X- _ O
many -X- _ O
parameters -X- _ O
( -X- _ O
only -X- _ O
1537 -X- _ O
extra -X- _ O
parameters -X- _ O
are -X- _ O
added -X- _ O
) -X- _ O
, -X- _ O
indicating -X- _ O
the -X- _ O
efficiency -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
. -X- _ O

This -X- _ O
demonstrates -X- _ O
that -X- _ O
the -X- _ O
pointer -X- _ O
network -X- _ O
could -X- _ O
help -X- _ O
to -X- _ O
generate -X- _ O
answers -X- _ O
more -X- _ O
accurately -X- _ O
. -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
outperforms -X- _ O
FiD -X- _ B-MethodName
- -X- _ I-MethodName
KD -X- _ I-MethodName
on -X- _ O
both -X- _ O
NQ -X- _ B-DatasetName
and -X- _ O
TriviaQA -X- _ B-DatasetName
datasets -X- _ O
under -X- _ O
the -X- _ O
same -X- _ O
setting -X- _ O
. -X- _ O

For -X- _ O
a -X- _ O
fair -X- _ O
comparison -X- _ O
, -X- _ O
we -X- _ O
retrained -X- _ O
the -X- _ O
FiD -X- _ B-MethodName
reader -X- _ O
on -X- _ O
the -X- _ O
top-25 -X- _ O
retrieved -X- _ O
passages -X- _ O
to -X- _ O
match -X- _ O
our -X- _ O
experimental -X- _ O
settings -X- _ O
. -X- _ O

4.3 -X- _ O
Results -X- _ O
Table -X- _ O
3 -X- _ O
shows -X- _ O
the -X- _ O
experimental -X- _ O
results -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
and -X- _ O
other -X- _ O
approaches -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
sets -X- _ O
, -X- _ O
evaluated -X- _ O
with -X- _ O
the -X- _ O
standard -X- _ O
exact -X- _ B-MetricName
match -X- _ I-MetricName
( -X- _ I-MetricName
EM -X- _ I-MetricName
) -X- _ I-MetricName
score -X- _ I-MetricName
( -X- _ O
Rajpurkar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O

All -X- _ O
experiments -X- _ O
are -X- _ O
run -X- _ O
on -X- _ O
eight -X- _ O
Nvidia -X- _ O
V100 -X- _ O
32 -X- _ O
GB -X- _ O
GPUs -X- _ O
. -X- _ O

Moreover -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
our -X- _ O
model -X- _ O
using -X- _ O
the -X- _ O
top-25 -X- _ O
retrieved -X- _ O
passages -X- _ O
for -X- _ O
each -X- _ O
question -X- _ O
and -X- _ O
set -X- _ O
the -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
as -X- _ O
64 -X- _ B-HyperparameterValue
due -X- _ O
to -X- _ O
computational -X- _ O
limitation -X- _ O
. -X- _ O

Our -X- _ O
model -X- _ O
is -X- _ O
initialized -X- _ O
with -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
T5 -X- _ B-MethodName
- -X- _ I-MethodName
base -X- _ I-MethodName
model -X- _ I-MethodName
, -X- _ O
and -X- _ O
trained -X- _ O
using -X- _ O
AdamW -X- _ B-MethodName
( -X- _ O
Loshchilov -X- _ O
and -X- _ O
Hutter -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
algorithm -X- _ O
with -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
10 4 -X- _ B-HyperparameterValue
, -X- _ O
linear -X- _ O
scheduling -X- _ O
with -X- _ B-HyperparameterValue
15k -X- _ I-HyperparameterValue
total -X- _ B-HyperparameterName
steps -X- _ I-HyperparameterName
and -X- _ B-HyperparameterValue
1k -X- _ I-HyperparameterValue
warm -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
up -X- _ I-HyperparameterName
steps -X- _ I-HyperparameterName
. -X- _ O

4.2 -X- _ O
Implementation -X- _ O
Details -X- _ O
We -X- _ O
follow -X- _ O
the -X- _ O
experimental -X- _ O
settings -X- _ O
as -X- _ O
in -X- _ O
FiD -X- _ B-MethodName
. -X- _ O

The -X- _ O
performance -X- _ O
of -X- _ O
SOTA -X- _ B-MethodName
model -X- _ O
is -X- _ O
in -X- _ O
bold -X- _ O
and -X- _ O
the -X- _ O
second -X- _ O
best -X- _ O
model -X- _ O
is -X- _ O
in -X- _ O
underline -X- _ O
. -X- _ O

Topkindicates -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
retrieved -X- _ O
passages -X- _ O
used -X- _ O
during -X- _ O
reader -X- _ O
training -X- _ O
. -X- _ O

Alen -X- _ O
denote -X- _ O
the -X- _ O
average -X- _ O
number -X- _ O
of -X- _ O
tokens -X- _ O
per -X- _ O
question -X- _ O
and -X- _ O
answer -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
data -X- _ O
released -X- _ O
on -X- _ O
the -X- _ O
repository -X- _ O
of -X- _ O
FiD1 -X- _ B-MethodName
, -X- _ O
containing -X- _ O
question -X- _ O
- -X- _ O
answer -X- _ O
pairs -X- _ O
and -X- _ O
top-100 -X- _ O
passages -X- _ O
retrieved -X- _ O
by -X- _ O
FiD -X- _ B-MethodName
- -X- _ I-MethodName
KD -X- _ I-MethodName
. -X- _ O

It -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
that -X- _ O
TriviaQA -X- _ B-TaskName
has -X- _ O
on -X- _ O
average -X- _ O
longer -X- _ O
question -X- _ O
length -X- _ O
than -X- _ O
NQ -X- _ B-TaskName
, -X- _ O
indicating -X- _ O
that -X- _ O
questions -X- _ O
in -X- _ O
TriviaQA -X- _ B-TaskName
are -X- _ O
relatively -X- _ O
more -X- _ O
complex -X- _ O
. -X- _ O

The -X- _ O
details -X- _ O
of -X- _ O
data -X- _ O
statistics -X- _ O
are -X- _ O
listed -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
. -X- _ O

The -X- _ O
TriviaQA -X- _ B-DatasetName
dataset -X- _ I-DatasetName
consists -X- _ O
of -X- _ O
question -X- _ O
- -X- _ O
answer -X- _ O
pairs -X- _ O
collected -X- _ O
from -X- _ O
trivia -X- _ O
and -X- _ O
quiz -X- _ O
- -X- _ O
league -X- _ O
websites -X- _ O
. -X- _ O

The -X- _ O
NQ -X- _ B-DatasetName
dataset -X- _ I-DatasetName
comprises -X- _ O
real -X- _ O
queries -X- _ O
that -X- _ O
user -X- _ O
issued -X- _ O
on -X- _ O
Google -X- _ O
search -X- _ O
engine -X- _ O
along -X- _ O
with -X- _ O
answers -X- _ O
. -X- _ O

The -X- _ O
final -X- _ O
prediction -X- _ O
probability -X- _ O
is -X- _ O
defined -X- _ O
as -X- _ O
P(yt -X- _ O
) -X- _ O
= -X- _ O
pgenPvocab(yt -X- _ O
) -X- _ O
+ -X- _ O
( -X- _ O
1 pgen)Pctx(yt):(4 -X- _ O
) -X- _ O
4 -X- _ O
Experiments -X- _ O
4.1 -X- _ O
Datasets -X- _ O
We -X- _ O
evaluate -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
approach -X- _ O
on -X- _ O
two -X- _ O
standard -X- _ B-DatasetName
ODQA -X- _ I-DatasetName
datasets -X- _ O
, -X- _ B-DatasetName
NQ -X- _ I-DatasetName
and -X- _ B-DatasetName
TriviaQA -X- _ I-DatasetName
. -X- _ O

Finally -X- _ O
, -X- _ O
put -X- _ O
all -X- _ O
the -X- _ O
above -X- _ O
together -X- _ O
, -X- _ O
the -X- _ O
target -X- _ O
tokenytcould -X- _ O
both -X- _ O
be -X- _ O
generated -X- _ O
from -X- _ O
vocabulary -X- _ O
with -X- _ O
probability -X- _ O
pgen -X- _ O
, -X- _ O
and -X- _ O
copy -X- _ O
from -X- _ O
the -X- _ O
source -X- _ O
passages -X- _ O
. -X- _ O

Ifytis -X- _ O
not -X- _ O
present -X- _ O
in -X- _ O
the -X- _ O
topkretrieved -X- _ O
passages -X- _ O
, -X- _ O
Pctx(yt -X- _ O
) -X- _ O
will -X- _ O
be -X- _ O
zero -X- _ O
. -X- _ O

Then -X- _ O
the -X- _ O
probability -X- _ O
of -X- _ O
selectingytin -X- _ O
source -X- _ O
sequence -X- _ O
is -X- _ O
calculated -X- _ O
as -X- _ O
, -X- _ O
Pctx(yt -X- _ O
) -X- _ O
= -X- _ O
X -X- _ O
j -X- _ O
: -X- _ O
x1 -X- _ O
: -X- _ O
k;j -X- _ O
= -X- _ O
yt -X- _ O
L -X- _ O
t;j -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
wherex1 -X- _ O
: -X- _ O
kdenotes -X- _ O
the -X- _ O
concatenation -X- _ O
of -X- _ O
the -X- _ O
topk -X- _ O
retrieved -X- _ O
passages -X- _ O
, -X- _ O
x1 -X- _ O
: -X- _ O
k;jis -X- _ O
thej -X- _ O
- -X- _ O
th -X- _ O
token -X- _ O
of -X- _ O
x1 -X- _ O
: -X- _ O
k -X- _ O
, -X- _ O
and -X- _ O
L -X- _ O
t;jis -X- _ O
thej -X- _ O
- -X- _ O
th -X- _ O
element -X- _ O
of -X- _ O
L -X- _ O
t -X- _ O
. -X- _ O

Then -X- _ O
at -X- _ O
step -X- _ O
t -X- _ O
, -X- _ O
the -X- _ O
probability -X- _ O
distribution -X- _ O
of -X- _ O
words -X- _ O
generation -X- _ O
over -X- _ O
the -X- _ O
vocabulary -X- _ O
is -X- _ O
computed -X- _ O
as -X- _ O
, -X- _ O
Pvocab= -X- _ O
softmax -X- _ O
( -X- _ O
WEsL -X- _ O
t -X- _ O
) -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
whereWE2RjVjdis -X- _ O
a -X- _ O
learnable -X- _ O
weight -X- _ O
matrix -X- _ O
. -X- _ O
Benefiting -X- _ O
from -X- _ O
the -X- _ O
encoder -X- _ B-MethodName
- -X- _ I-MethodName
decoder -X- _ I-MethodName
attention -X- _ I-MethodName
layer -X- _ O
in -X- _ O
transformer -X- _ O
architecture -X- _ O
, -X- _ O
we -X- _ O
directly -X- _ O
utilize -X- _ O
the -X- _ O
cross -X- _ B-MethodName
- -X- _ I-MethodName
attention -X- _ I-MethodName
score -X- _ I-MethodName
L -X- _ O
tof -X- _ O
the -X- _ O
last -X- _ O
decoder -X- _ O
layerLover -X- _ O
the -X- _ O
source -X- _ O
tokens -X- _ O
for -X- _ O
the -X- _ O
target -X- _ O
token -X- _ O
ytas -X- _ O
copy -X- _ O
distribution -X- _ O
. -X- _ O

Next -X- _ O
, -X- _ O
letVdenote -X- _ O
the -X- _ O
vocabulary -X- _ O
containing -X- _ O
words -X- _ O
for -X- _ O
the -X- _ O
generative -X- _ O
model -X- _ O
and -X- _ O
jVjbe -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
vocabulary -X- _ O
. -X- _ O

In -X- _ O
addition -X- _ O
, -X- _ O
the -X- _ O
probability -X- _ O
of -X- _ O
copying -X- _ O
is -X- _ O
1 pgen -X- _ O
. -X- _ O

Our -X- _ O
approach -X- _ O
mainly -X- _ O
differs -X- _ O
from -X- _ O
FiD -X- _ B-MethodName
reader -X- _ I-MethodName
in -X- _ O
the -X- _ O
decoder -X- _ O
module -X- _ O
by -X- _ O
adding -X- _ O
a -X- _ O
pointer -X- _ O
network -X- _ O
. -X- _ O

Finally -X- _ O
, -X- _ O
we -X- _ O
concatenate -X- _ O
all -X- _ O
the -X- _ O
hidden -X- _ O
representations -X- _ O
of -X- _ O
topkpassagesfh1;:::;h -X- _ O
kgas -X- _ O
input -X- _ O
to -X- _ O
the -X- _ O
decoder -X- _ O
. -X- _ O

Next -X- _ O
, -X- _ O
we -X- _ O
pass -X- _ O
each -X- _ O
xiindividually -X- _ O
to -X- _ O
the -X- _ O
reader -X- _ O
encoder -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
the -X- _ O
encoder -X- _ O
of -X- _ O
T5 -X- _ B-MethodName
or -X- _ O
BART -X- _ B-MethodName
model -X- _ O
, -X- _ O
and -X- _ O
obtain -X- _ O
the -X- _ O
hidden -X- _ O
representationshi= -X- _ O
( -X- _ O
hi;1;hi;2;:::;h -X- _ O
i;n)of -X- _ O
the -X- _ O
questionpassage -X- _ O
pair -X- _ O
where -X- _ O
hi;j2Rdanddis -X- _ O
the -X- _ O
model -X- _ O
dimension -X- _ O
. -X- _ O

We -X- _ O
firstly -X- _ O
concatenate -X- _ O
the -X- _ O
given -X- _ O
question -X- _ O
qwith -X- _ O
each -X- _ O
retrieved -X- _ O
passagepiasxi= -X- _ O
[ -X- _ O
q;pi -X- _ O
] -X- _ O
. -X- _ O

The -X- _ O
reader -X- _ B-MethodName
encoder -X- _ I-MethodName
of -X- _ O
our -X- _ O
model -X- _ O
is -X- _ O
identical -X- _ O
to -X- _ O
the -X- _ O
one -X- _ O
of -X- _ O
FiD -X- _ B-MethodName
reader -X- _ I-MethodName
. -X- _ O

The -X- _ O
overall -X- _ O
reader -X- _ O
architecture -X- _ O
is -X- _ O
depicted -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
. -X- _ O

A -X- _ O
pointer -X- _ O
network -X- _ O
is -X- _ O
integrated -X- _ O
into -X- _ O
the -X- _ O
FiD -X- _ B-MethodName
reader -X- _ O
to -X- _ O
facilitate -X- _ O
copying -X- _ O
words -X- _ O
from -X- _ O
the -X- _ O
retrieved -X- _ O
passages -X- _ O
. -X- _ O

We -X- _ O
adopt -X- _ O
the -X- _ O
retriever -X- _ O
results -X- _ O
of -X- _ O
FiD -X- _ B-MethodName
- -X- _ I-MethodName
KD -X- _ I-MethodName
, -X- _ O
where -X- _ O
a -X- _ O
dense -X- _ O
retriever -X- _ O
similar -X- _ O
to -X- _ O
DPR -X- _ B-MethodName
( -X- _ O
Karpukhin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
is -X- _ O
used -X- _ O
. -X- _ O

3 -X- _ O
Method -X- _ O
Our -X- _ O
model -X- _ O
follows -X- _ O
the -X- _ O
standard -X- _ O
two -X- _ O
- -X- _ O
stage -X- _ O
retrieverreader -X- _ O
framework -X- _ O
with -X- _ O
a -X- _ O
focus -X- _ O
on -X- _ O
the -X- _ O
enhancement -X- _ O
of -X- _ O
the -X- _ O
reader -X- _ O
module -X- _ O
built -X- _ O
upon -X- _ O
the -X- _ O
FiD -X- _ B-MethodName
reader -X- _ O
. -X- _ O

summarization -X- _ B-TaskName
( -X- _ O
Gu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
See -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Gehrmann -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
and -X- _ O
neural -X- _ B-TaskName
machine -X- _ I-TaskName
translation -X- _ I-TaskName
( -X- _ O
Luong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Gu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
its -X- _ O
application -X- _ O
to -X- _ O
ODQA -X- _ B-TaskName
has -X- _ O
been -X- _ O
less -X- _ O
explored -X- _ O
. -X- _ O

It -X- _ O
has -X- _ O
been -X- _ O
frequently -X- _ O
used -X- _ O
in -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
tasks -X- _ I-TaskName
like436 -X- _ O
. -X- _ O

At -X- _ O
each -X- _ O
decoding -X- _ O
stage -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
either -X- _ O
directly -X- _ O
copy -X- _ O
a -X- _ O
word -X- _ O
from -X- _ O
the -X- _ O
input -X- _ O
or -X- _ O
generate -X- _ O
one -X- _ O
with -X- _ O
certain -X- _ O
probability -X- _ O
, -X- _ O
and -X- _ O
thus -X- _ O
can -X- _ O
be -X- _ O
viewed -X- _ O
as -X- _ O
a -X- _ O
combination -X- _ O
of -X- _ O
extractive -X- _ O
and -X- _ O
generative -X- _ O
approaches -X- _ O
. -X- _ O

2.3 -X- _ O
Pointer -X- _ B-MethodName
- -X- _ I-MethodName
Generator -X- _ I-MethodName
Network -X- _ I-MethodName
Pointer -X- _ B-MethodName
- -X- _ I-MethodName
Generator -X- _ I-MethodName
Network -X- _ I-MethodName
( -X- _ O
See -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
is -X- _ O
an -X- _ O
extension -X- _ O
of -X- _ O
the -X- _ O
sequence -X- _ B-MethodName
- -X- _ I-MethodName
to -X- _ I-MethodName
- -X- _ I-MethodName
sequence -X- _ I-MethodName
model -X- _ I-MethodName
by -X- _ O
integrating -X- _ O
a -X- _ O
copy -X- _ O
mechanism -X- _ O
( -X- _ O
Vinyals -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
into -X- _ O
the -X- _ O
generator -X- _ O
. -X- _ O

FiDKD -X- _ B-MethodName
( -X- _ O
Izacard -X- _ O
and -X- _ O
Grave -X- _ O
, -X- _ O
2021a -X- _ O
) -X- _ O
is -X- _ O
an -X- _ O
extension -X- _ O
of -X- _ O
FiD -X- _ B-MethodName
model -X- _ O
that -X- _ O
increases -X- _ O
the -X- _ O
accuracy -X- _ B-MetricName
of -X- _ O
passage -X- _ O
retrieval -X- _ O
by -X- _ O
training -X- _ O
the -X- _ O
dense -X- _ O
retriever -X- _ O
with -X- _ O
the -X- _ O
guidance -X- _ O
of -X- _ O
the -X- _ O
FiD -X- _ B-MethodName
reader -X- _ O
iteratively -X- _ O
. -X- _ O

Their -X- _ O
method -X- _ O
provide -X- _ O
a -X- _ O
way -X- _ O
to -X- _ O
better -X- _ O
aggregate -X- _ O
evidence -X- _ O
from -X- _ O
multiple -X- _ O
passages -X- _ O
and -X- _ O
improve -X- _ O
the -X- _ O
performance -X- _ O
significantly -X- _ O
. -X- _ O

Izacard -X- _ O
and -X- _ O
Grave -X- _ O
( -X- _ O
2021b -X- _ O
) -X- _ O
separately -X- _ O
encodes -X- _ O
the -X- _ O
question -X- _ O
with -X- _ O
each -X- _ O
top -X- _ O
retrieved -X- _ O
passage -X- _ O
, -X- _ O
then -X- _ O
takes -X- _ O
the -X- _ O
concatenation -X- _ O
of -X- _ O
the -X- _ O
encoder -X- _ O
outputs -X- _ O
as -X- _ O
input -X- _ O
to -X- _ O
the -X- _ O
decoder -X- _ O
. -X- _ O

Min -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020b -X- _ O
) -X- _ O
concatenate -X- _ O
the -X- _ O
given -X- _ O
question -X- _ O
with -X- _ O
top -X- _ O
retrieved -X- _ O
passages -X- _ O
and -X- _ O
feed -X- _ O
the -X- _ O
concatenation -X- _ O
to -X- _ O
the -X- _ O
BART -X- _ B-MethodName
model -X- _ I-MethodName
( -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
. -X- _ O

2.2 -X- _ O
Generative -X- _ O
Readers -X- _ O
Compared -X- _ O
to -X- _ O
extractive -X- _ O
models -X- _ O
which -X- _ O
extract -X- _ O
spans -X- _ O
from -X- _ O
the -X- _ O
retrieved -X- _ O
passages -X- _ O
, -X- _ O
generative -X- _ O
models -X- _ O
are -X- _ O
able -X- _ O
to -X- _ O
produce -X- _ O
new -X- _ O
words -X- _ O
out -X- _ O
of -X- _ O
the -X- _ O
retrieved -X- _ O
passages -X- _ O
, -X- _ O
and -X- _ O
thus -X- _ O
provide -X- _ O
a -X- _ O
more -X- _ O
exible -X- _ O
modeling -X- _ O
framework -X- _ O
. -X- _ O

Later -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
emergence -X- _ O
of -X- _ O
large -X- _ B-MethodName
- -X- _ I-MethodName
scale -X- _ I-MethodName
pre -X- _ I-MethodName
- -X- _ I-MethodName
trained -X- _ I-MethodName
language -X- _ I-MethodName
models -X- _ I-MethodName
, -X- _ O
readers -X- _ O
based -X- _ O
on -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
suchas -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
T5 -X- _ B-MethodName
( -X- _ O
Raffel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
have -X- _ O
become -X- _ O
a -X- _ O
common -X- _ O
approach -X- _ O
( -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Izacard -X- _ O
and -X- _ O
Grave -X- _ O
, -X- _ O
2021b -X- _ O
; -X- _ O
Karpukhin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

Early -X- _ O
work -X- _ O
of -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
adapts -X- _ O
a -X- _ O
BiLSTM -X- _ B-MethodName
architecture -X- _ O
with -X- _ O
various -X- _ O
lexical -X- _ O
and -X- _ O
semantic -X- _ O
features -X- _ O
from -X- _ O
the -X- _ O
question -X- _ O
and -X- _ O
passages -X- _ O
as -X- _ O
inputs -X- _ O
. -X- _ O

The -X- _ O
reader -X- _ O
intends -X- _ O
to -X- _ O
find -X- _ O
answer -X- _ O
of -X- _ O
the -X- _ O
question -X- _ O
from -X- _ O
the -X- _ O
first -X- _ O
stage -X- _ O
retrieved -X- _ O
passages -X- _ O
. -X- _ O

The -X- _ O
retriever -X- _ O
aims -X- _ O
at -X- _ O
retrieving -X- _ O
supportive -X- _ O
passages -X- _ O
to -X- _ O
the -X- _ O
given -X- _ O
question -X- _ O
from -X- _ O
a -X- _ O
large -X- _ O
document -X- _ O
corpus -X- _ O
. -X- _ O

Following -X- _ O
the -X- _ O
work -X- _ O
of -X- _ O
DrQA -X- _ B-TaskName
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
most -X- _ O
recent -X- _ O
works -X- _ O
build -X- _ O
a -X- _ O
two -X- _ O
- -X- _ O
stage -X- _ O
retriever -X- _ O
- -X- _ O
reader -X- _ O
system -X- _ O
to -X- _ O
tackle -X- _ O
the -X- _ O
problem -X- _ O
. -X- _ O

2 -X- _ O
Related -X- _ O
Work -X- _ O
2.1 -X- _ O
Open -X- _ B-TaskName
- -X- _ I-TaskName
Domain -X- _ I-TaskName
Question -X- _ I-TaskName
Answering -X- _ I-TaskName
In -X- _ O
this -X- _ O
era -X- _ O
of -X- _ O
data -X- _ O
explosion -X- _ O
, -X- _ O
ODQA -X- _ B-TaskName
offers -X- _ O
a -X- _ O
way -X- _ O
to -X- _ O
rapidly -X- _ O
and -X- _ O
accurately -X- _ O
fulfill -X- _ O
users -X- _ O
information -X- _ O
needs -X- _ O
, -X- _ O
and -X- _ O
hence -X- _ O
has -X- _ O
recently -X- _ O
received -X- _ O
significant -X- _ O
attention -X- _ O
from -X- _ O
both -X- _ O
industry -X- _ O
and -X- _ O
academia -X- _ O
( -X- _ O
Min -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021a -X- _ O
) -X- _ O
. -X- _ O

Our -X- _ O
experiments -X- _ O
results -X- _ O
show -X- _ O
the -X- _ O
effectiveness -X- _ O
and -X- _ O
efficiency -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
. -X- _ O

Compared -X- _ O
to -X- _ O
FiD -X- _ B-MethodName
, -X- _ O
we -X- _ O
achieve -X- _ O
comparative -X- _ O
or -X- _ O
even -X- _ O
better -X- _ O
accuracy -X- _ B-MetricName
on -X- _ O
the -X- _ O
NaturalQuestions -X- _ B-DatasetName
( -X- _ I-DatasetName
NQ -X- _ I-DatasetName
) -X- _ I-DatasetName
( -X- _ O
Kwiatkowski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
TriviaQA -X- _ B-DatasetName
( -X- _ O
Joshi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
benchmarks -X- _ O
, -X- _ O
with -X- _ O
less -X- _ O
passages -X- _ O
used -X- _ O
in -X- _ O
training -X- _ O
. -X- _ O

We -X- _ O
reuse -X- _ O
the -X- _ O
encoder -X- _ B-MethodName
- -X- _ I-MethodName
decoder -X- _ I-MethodName
attention -X- _ I-MethodName
scores -X- _ O
as -X- _ O
the -X- _ O
copy -X- _ O
distribution -X- _ O
to -X- _ O
reduce -X- _ O
the -X- _ O
computational -X- _ B-MetricName
cost -X- _ I-MetricName
. -X- _ O

To -X- _ O
be -X- _ O
more -X- _ O
specific -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
fusion -X- _ B-MethodName
- -X- _ I-MethodName
in -X- _ I-MethodName
- -X- _ I-MethodName
decoder -X- _ I-MethodName
pointer -X- _ I-MethodName
- -X- _ I-MethodName
generator -X- _ I-MethodName
network -X- _ I-MethodName
( -X- _ I-MethodName
FiDPGN -X- _ I-MethodName
) -X- _ I-MethodName
is -X- _ O
built -X- _ O
upon -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
model -X- _ O
FiD -X- _ B-MethodName
. -X- _ O

work -X- _ O
( -X- _ O
Vinyals -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
, -X- _ O
that -X- _ O
enables -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
directly -X- _ O
copy -X- _ O
text -X- _ O
from -X- _ O
the -X- _ O
retrieved -X- _ O
passages -X- _ O
while -X- _ O
retains -X- _ O
the -X- _ O
ability -X- _ O
of -X- _ O
generating -X- _ O
new -X- _ O
words -X- _ O
when -X- _ O
the -X- _ O
true -X- _ O
answers -X- _ O
are -X- _ O
not -X- _ O
explicitly -X- _ O
present -X- _ O
in -X- _ O
the -X- _ O
input -X- _ O
. -X- _ O

We -X- _ O
add -X- _ O
a -X- _ O
linear -X- _ O
layer -X- _ O
to -X- _ O
calculate -X- _ O
the -X- _ O
generation -X- _ O
probability -X- _ O
, -X- _ O
which -X- _ O
decides -X- _ O
the -X- _ O
weights -X- _ O
of -X- _ O
generating -X- _ O
words -X- _ O
from -X- _ O
vocabulary -X- _ O
or -X- _ O
copying -X- _ O
from -X- _ O
source -X- _ O
passages -X- _ O
. -X- _ O

Inspired -X- _ O
by -X- _ O
the -X- _ O
work -X- _ O
of -X- _ O
See -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
enhance -X- _ O
the -X- _ O
generative -X- _ B-MethodName
model -X- _ I-MethodName
with -X- _ O
a -X- _ O
pointer -X- _ O
net-435 -X- _ O
. -X- _ O

Thus -X- _ O
, -X- _ O
we -X- _ O
hypothesize -X- _ O
that -X- _ O
if -X- _ O
we -X- _ O
could -X- _ O
put -X- _ O
a -X- _ O
constraint -X- _ O
on -X- _ O
the -X- _ O
produced -X- _ O
words -X- _ O
to -X- _ O
the -X- _ O
input -X- _ O
text -X- _ O
, -X- _ O
the -X- _ O
generated -X- _ O
answer -X- _ O
will -X- _ O
be -X- _ O
more -X- _ O
faithful -X- _ O
. -X- _ O

While -X- _ O
in -X- _ O
both -X- _ O
cases -X- _ O
, -X- _ O
the -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
answers -X- _ O
are -X- _ O
present -X- _ O
in -X- _ O
the -X- _ O
retrieved -X- _ O
passages -X- _ O
. -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
, -X- _ O
the -X- _ O
answer -X- _ O
" -X- _ O
Dubai -X- _ O
in -X- _ O
Germany -X- _ O
" -X- _ O
produced -X- _ O
by -X- _ O
the -X- _ O
generative -X- _ O
model -X- _ O
FiD -X- _ B-MethodName
( -X- _ O
Izacard -X- _ O
and -X- _ O
Grave -X- _ O
, -X- _ O
2021b -X- _ O
) -X- _ O
is -X- _ O
factual -X- _ O
incorrect -X- _ O
and -X- _ O
the -X- _ O
answer -X- _ O
" -X- _ O
33 -X- _ O
" -X- _ O
in -X- _ O
the -X- _ O
second -X- _ O
example -X- _ O
is -X- _ O
not -X- _ O
coherent -X- _ O
to -X- _ O
the -X- _ O
question -X- _ O
. -X- _ O

We -X- _ O
found -X- _ O
that -X- _ O
the -X- _ O
phenomenon -X- _ O
also -X- _ O
happens -X- _ O
in -X- _ O
ODQA -X- _ B-TaskName
. -X- _ O

This -X- _ O
problem -X- _ O
has -X- _ O
been -X- _ O
addressed -X- _ O
in -X- _ O
tasks -X- _ O
like -X- _ O
text -X- _ B-TaskName
summarization -X- _ I-TaskName
( -X- _ O
Maynez -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
( -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

Compared -X- _ O
to -X- _ O
extractive -X- _ O
models -X- _ O
, -X- _ O
generative -X- _ O
models -X- _ O
generate -X- _ O
text -X- _ O
more -X- _ O
freely -X- _ O
, -X- _ O
which -X- _ O
makes -X- _ O
it -X- _ O
often -X- _ O
suffer -X- _ O
from -X- _ O
the -X- _ O
problem -X- _ O
of -X- _ O
producing -X- _ O
hallucinated -X- _ O
text -X- _ O
that -X- _ O
is -X- _ O
factual -X- _ O
inaccuracy -X- _ O
or -X- _ O
inconsistent -X- _ O
to -X- _ O
the -X- _ O
input -X- _ O
. -X- _ O

The -X- _ O
orange -X- _ O
text -X- _ O
represents -X- _ O
supportive -X- _ O
sentences -X- _ O
. -X- _ O

Nine -X- _ O
teams -X- _ O
have -X- _ O
been -X- _ O
crowned -X- _ O
champions -X- _ O
, -X- _ O
with -X- _ O
Real -X- _ O
Madrid -X- _ O
winning -X- _ O
the -X- _ O
title -X- _ O
a -X- _ O
record -X- _ O
33 -X- _ O
times -X- _ O
and -X- _ O
Barcelona -X- _ O
25 -X- _ O
times -X- _ O
. -X- _ O

Shooting -X- _ O
wrapped -X- _ O
in -X- _ O
June -X- _ O
2014 -X- _ O
. -X- _ O

Filming -X- _ O
also -X- _ O
took -X- _ O
place -X- _ O
in -X- _ O
Hurghada -X- _ O
in -X- _ O
Egypt -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
in -X- _ O
Berlin -X- _ O
and -X- _ O
Dsseldorf -X- _ O
in -X- _ O
Germany -X- _ O
. -X- _ O

Principal -X- _ O
photography -X- _ O
commenced -X- _ O
on -X- _ O
March -X- _ O
6 -X- _ O
, -X- _ O
2014 -X- _ O
in -X- _ O
Morocco -X- _ O
. -X- _ O

Recently -X- _ O
, -X- _ O
benefiting -X- _ O
from -X- _ O
the -X- _ O
powerful -X- _ O
ability -X- _ O
of -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
encoderdecoder -X- _ O
language -X- _ O
models -X- _ O
( -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
; -X- _ O
Raffel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
capability -X- _ O
of -X- _ O
aggregating -X- _ O
information -X- _ O
from -X- _ O
multiple -X- _ O
passages -X- _ O
( -X- _ O
Izacard -X- _ O
This -X- _ O
work -X- _ O
was -X- _ O
done -X- _ O
when -X- _ O
she -X- _ O
was -X- _ O
at -X- _ O
AARC.Question -X- _ O
: -X- _ O
where -X- _ O
was -X- _ O
a -X- _ O
hologram -X- _ O
for -X- _ O
the -X- _ O
king -X- _ O
filmed -X- _ O
? -X- _ O
Passages -X- _ O
( -X- _ O
Truncated -X- _ O
): -X- _ O
title -X- _ O
: -X- _ O
A -X- _ O
Hologram -X- _ O
for -X- _ O
the -X- _ O
King -X- _ O
( -X- _ O
film -X- _ O
) -X- _ O
context -X- _ O
: -X- _ O
Production -X- _ O
was -X- _ O
set -X- _ O
to -X- _ O
begin -X- _ O
in -X- _ O
first -X- _ O
quarter -X- _ O
of -X- _ O
2014 -X- _ O
. -X- _ O

The -X- _ O
reader -X- _ O
models -X- _ O
can -X- _ O
be -X- _ O
broadly -X- _ O
categorized -X- _ O
into -X- _ O
two -X- _ O
classes -X- _ O
: -X- _ O
extractive -X- _ O
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Asai -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Karpukhin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
generative -X- _ O
( -X- _ O
Izacard -X- _ O
and -X- _ O
Grave -X- _ O
, -X- _ O
2021b -X- _ O
; -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
; -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

With -X- _ O
the -X- _ O
pioneering -X- _ O
work -X- _ O
of -X- _ O
DrQA -X- _ B-TaskName
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
modern -X- _ O
approaches -X- _ O
to -X- _ O
ODQA -X- _ B-TaskName
commonly -X- _ O
adopt -X- _ O
a -X- _ O
simple -X- _ O
two -X- _ O
- -X- _ O
stage -X- _ O
retriever -X- _ O
- -X- _ O
reader -X- _ O
pipeline -X- _ O
, -X- _ O
that -X- _ O
firstly -X- _ O
retrieve -X- _ O
a -X- _ O
relatively -X- _ O
small -X- _ O
number -X- _ O
of -X- _ O
support -X- _ O
passages -X- _ O
( -X- _ O
Karpukhin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Min -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021b -X- _ O
; -X- _ O
Yamada -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
followed -X- _ O
by -X- _ O
the -X- _ O
reader -X- _ O
identifying -X- _ O
the -X- _ O
answer -X- _ O
. -X- _ O

1 -X- _ O
Introduction -X- _ O
Open -X- _ B-TaskName
- -X- _ I-TaskName
domain -X- _ I-TaskName
question -X- _ I-TaskName
answering -X- _ I-TaskName
( -X- _ I-TaskName
ODQA -X- _ I-TaskName
) -X- _ I-TaskName
focuses -X- _ O
on -X- _ O
providing -X- _ O
highly -X- _ O
precise -X- _ O
answers -X- _ O
to -X- _ O
natural -X- _ O
language -X- _ O
questions -X- _ O
from -X- _ O
a -X- _ O
large -X- _ O
collection -X- _ O
of -X- _ O
unstructured -X- _ O
text -X- _ O
data -X- _ O
( -X- _ O
V -X- _ O
oorhees -X- _ O
, -X- _ O
1999 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
conduct -X- _ O
experiments -X- _ O
on -X- _ O
the -X- _ O
two -X- _ O
benchmark -X- _ O
datasets -X- _ O
, -X- _ O
NaturalQuestions -X- _ B-DatasetName
and -X- _ O
TriviaQA -X- _ B-DatasetName
, -X- _ O
and -X- _ O
the -X- _ O
empirical -X- _ O
results -X- _ O
demonstrate -X- _ O
the -X- _ O
performance -X- _ O
gains -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
approach -X- _ O
. -X- _ O

We -X- _ O
enhance -X- _ O
the -X- _ O
original -X- _ O
generative -X- _ O
reader -X- _ O
by -X- _ O
incorporating -X- _ O
a -X- _ O
pointer -X- _ B-MethodName
network -X- _ I-MethodName
to -X- _ O
encourage -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
directly -X- _ O
copy -X- _ O
words -X- _ O
from -X- _ O
the -X- _ O
retrieved -X- _ O
passages -X- _ O
. -X- _ O

In -X- _ O
particular -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
is -X- _ O
built -X- _ O
upon -X- _ O
the -X- _ O
powerful -X- _ O
generative -X- _ O
model -X- _ O
FiD -X- _ B-MethodName
( -X- _ O
Izacard -X- _ O
and -X- _ O
Grave -X- _ O
, -X- _ O
2021b -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
article -X- _ O
, -X- _ O
we -X- _ O
focus -X- _ O
on -X- _ O
improving -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
the -X- _ O
reader -X- _ O
module -X- _ O
and -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
copy -X- _ O
- -X- _ O
augmented -X- _ O
generative -X- _ O
approach -X- _ O
that -X- _ O
integrates -X- _ O
the -X- _ O
merits -X- _ O
of -X- _ O
both -X- _ O
extractive -X- _ O
and -X- _ O
generative -X- _ O
readers -X- _ O
. -X- _ O

Existing -X- _ O
modern -X- _ O
approaches -X- _ O
mostly -X- _ O
follow -X- _ O
a -X- _ O
standard -X- _ O
two -X- _ O
- -X- _ O
stage -X- _ O
paradigm -X- _ O
: -X- _ O
retriever -X- _ O
then -X- _ O
reader -X- _ O
. -X- _ O

Task -X- _ O
Template -X- _ O
Label -X- _ O
words -X- _ O
SST-2 -X- _ B-MethodName
It -X- _ O
was -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
. -X- _ O

A -X- _ O
T5 -X- _ B-MethodName
- -X- _ O
large -X- _ O
and -X- _ O
beam -X- _ B-MethodName
search -X- _ I-MethodName
( -X- _ O
e.g. -X- _ O
, -X- _ O
beam -X- _ O
width -X- _ O
: -X- _ O
30 -X- _ O
) -X- _ O
were -X- _ O
used -X- _ O
to -X- _ O
generate -X- _ O
phrase -X- _ B-MethodName
- -X- _ I-MethodName
level -X- _ I-MethodName
verbalizers -X- _ I-MethodName
automatically -X- _ O
in -X- _ O
a -X- _ O
zero -X- _ B-MethodName
- -X- _ I-MethodName
shot -X- _ I-MethodName
manner -X- _ I-MethodName
. -X- _ O

The -X- _ O
gradients -X- _ O
are -X- _ O
clipped -X- _ O
if -X- _ O
their -X- _ O
norms -X- _ B-MetricName
exceed -X- _ O
1.0 -X- _ B-MetricValue
. -X- _ O

The -X- _ O
warmup -X- _ O
proportion -X- _ O
is -X- _ O
0.6 -X- _ B-HyperparameterValue
. -X- _ O

All -X- _ O
optimizations -X- _ O
were -X- _ O
performed -X- _ O
using -X- _ O
the -X- _ O
AdamW -X- _ B-MethodName
optimizer -X- _ I-MethodName
with -X- _ O
a -X- _ O
linear -X- _ O
warm -X- _ O
- -X- _ O
up -X- _ O
of -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
. -X- _ O

Experiments -X- _ O
were -X- _ O
conducted -X- _ O
with -X- _ O
Nvidia -X- _ O
Quadro -X- _ O
RTX -X- _ O
8000 -X- _ O
GPU -X- _ O
. -X- _ O

B.2 -X- _ O
Implementation -X- _ O
This -X- _ O
proposed -X- _ O
approach -X- _ O
was -X- _ O
implemented -X- _ O
using -X- _ O
PyTorch -X- _ B-MethodName
( -X- _ O
Paszke -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
HuggingFace -X- _ B-MethodName
Transformers -X- _ I-MethodName
( -X- _ O
Wolf -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

This -X- _ O
study -X- _ O
followed -X- _ O
the -X- _ O
same -X- _ O
experimental -X- _ O
setting -X- _ O
from -X- _ O
LM -X- _ B-MethodName
- -X- _ I-MethodName
BFF -X- _ I-MethodName
( -X- _ O
Gao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

B -X- _ O
Implementation -X- _ O
Details -X- _ O
B.1 -X- _ O
Datasets -X- _ O
& -X- _ O
Setting -X- _ O
We -X- _ O
used -X- _ O
the -X- _ O
following -X- _ O
datasetsSNLI -X- _ B-DatasetName
( -X- _ O
Bowman -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
, -X- _ O
MNLI -X- _ B-DatasetName
( -X- _ O
Williams -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
SST-2 -X- _ B-DatasetName
( -X- _ O
Socher -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
MRPC -X- _ B-DatasetName
( -X- _ O
Dolan -X- _ O
and -X- _ O
Brockett -X- _ O
, -X- _ O
2005 -X- _ O
) -X- _ O
, -X- _ O
MR -X- _ B-DatasetName
( -X- _ O
Pang -X- _ O
and -X- _ O
Lee -X- _ O
, -X- _ O
2005 -X- _ O
) -X- _ O
, -X- _ O
CR -X- _ B-DatasetName
( -X- _ O
Hu -X- _ O
and -X- _ O
Liu -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
, -X- _ O
MPQA -X- _ B-DatasetName
( -X- _ O
Wiebe -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2005 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
Subj -X- _ B-DatasetName
( -X- _ O
Pang -X- _ O
and -X- _ O
Lee -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
leave -X- _ O
this -X- _ O
topic -X- _ O
as -X- _ O
a -X- _ O
subject -X- _ O
for -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O

We -X- _ O
believe -X- _ O
that -X- _ O
this -X- _ O
is -X- _ O
strongly -X- _ O
related -X- _ O
to -X- _ O
automatic -X- _ B-TaskName
phraselevel -X- _ I-TaskName
generation -X- _ I-TaskName
and -X- _ O
is -X- _ O
bounded -X- _ O
by -X- _ O
the -X- _ O
maximum -X- _ O
input -X- _ O
length -X- _ O
. -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
, -X- _ O
despite -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
LM -X- _ B-MethodName
- -X- _ I-MethodName
BFFMS -X- _ I-MethodName
, -X- _ O
it -X- _ O
shows -X- _ O
a -X- _ O
lower -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
performance -X- _ O
than -X- _ O
previous -X- _ O
studies -X- _ O
on -X- _ O
SNLI -X- _ B-DatasetName
and -X- _ O
MNLI -X- _ B-DatasetName
. -X- _ O

Furthermore -X- _ O
, -X- _ O
unlike -X- _ O
the -X- _ O
GPT-3 -X- _ B-MethodName
model -X- _ I-MethodName
, -X- _ O
the -X- _ O
maximum -X- _ O
input -X- _ O
length -X- _ O
of -X- _ O
PLMs -X- _ B-MethodName
is -X- _ O
usually -X- _ O
512 -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
not -X- _ O
sufficient -X- _ O
to -X- _ O
deal -X- _ O
with -X- _ O
more -X- _ O
difficult -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
SNLI -X- _ B-TaskName
and -X- _ O
MNLI -X- _ B-TaskName
. -X- _ O

A -X- _ O
Limitation -X- _ O
The -X- _ O
main -X- _ O
contribution -X- _ O
of -X- _ O
this -X- _ O
work -X- _ O
is -X- _ O
the -X- _ O
multiple -X- _ O
soft -X- _ O
demonstration -X- _ O
memory -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
the -X- _ O
numberof -X- _ O
available -X- _ O
demonstrations -X- _ O
is -X- _ O
bounded -X- _ O
by -X- _ O
the -X- _ O
maximum -X- _ O
input -X- _ O
length -X- _ O
. -X- _ O

Transformers -X- _ B-MethodName
: -X- _ O
State -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
. -X- _ O

A -X- _ O
broad -X- _ O
- -X- _ O
coverage -X- _ O
challenge -X- _ O
corpus -X- _ O
for -X- _ O
sentence -X- _ B-TaskName
understanding -X- _ I-TaskName
through -X- _ O
inference -X- _ O
. -X- _ O

NSP -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
: -X- _ O
A -X- _ O
prompt -X- _ O
- -X- _ O
based -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
learner -X- _ O
through -X- _ O
an -X- _ O
original -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
task -X- _ O
- -X- _ O
next -X- _ B-TaskName
sentence -X- _ I-TaskName
prediction -X- _ I-TaskName
. -X- _ O

Recursive -X- _ B-MethodName
deep -X- _ I-MethodName
models -X- _ I-MethodName
for -X- _ O
semantic -X- _ B-TaskName
compositionality -X- _ I-TaskName
over -X- _ O
a -X- _ O
sentiment -X- _ O
treebank -X- _ O
. -X- _ O

Its -X- _ O
not -X- _ O
just -X- _ O
size -X- _ O
that -X- _ O
matters -X- _ O
: -X- _ O
Small -X- _ O
language -X- _ O
models -X- _ O
are -X- _ O
also -X- _ O
fewshot -X- _ O
learners -X- _ O
. -X- _ O

Exploiting -X- _ O
cloze -X- _ B-TaskName
- -X- _ I-TaskName
questions -X- _ I-TaskName
for -X- _ O
few -X- _ B-TaskName
- -X- _ I-TaskName
shot -X- _ I-TaskName
text -X- _ I-TaskName
classification -X- _ I-TaskName
and -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
inference -X- _ I-TaskName
. -X- _ O

Pytorch -X- _ B-MethodName
: -X- _ O
An -X- _ O
imperative -X- _ O
style -X- _ O
, -X- _ O
high -X- _ O
- -X- _ O
performance -X- _ O
deep -X- _ O
learning -X- _ O
library -X- _ O
. -X- _ O

Seeing -X- _ O
stars -X- _ O
: -X- _ O
Exploiting -X- _ O
class -X- _ O
relationships -X- _ O
for -X- _ O
sentiment -X- _ B-TaskName
categorization -X- _ I-TaskName
with -X- _ O
respect -X- _ O
to -X- _ O
rating -X- _ O
scales -X- _ O
. -X- _ O

A -X- _ O
sentimental -X- _ O
education -X- _ O
: -X- _ O
Sentiment -X- _ B-TaskName
analysis -X- _ I-TaskName
using -X- _ O
subjectivity -X- _ O
summarization -X- _ O
based -X- _ O
on -X- _ O
minimum -X- _ O
cuts -X- _ O
. -X- _ O

Roberta -X- _ B-MethodName
: -X- _ O
A -X- _ O
robustly -X- _ O
optimized -X- _ O
bert -X- _ O
pretraining -X- _ O
approach -X- _ O
. -X- _ O
Robert -X- _ O
Logan -X- _ O
, -X- _ O
Ivana -X- _ O
Balaevi -X- _ O
c -X- _ O
, -X- _ O
Eric -X- _ O
Wallace -X- _ O
, -X- _ O
Fabio -X- _ O
Petroni -X- _ O
, -X- _ O
Sameer -X- _ O
Singh -X- _ O
, -X- _ O
and -X- _ O
Sebastian -X- _ O
Riedel -X- _ O
. -X- _ O

A -X- _ O
large -X- _ O
annotated -X- _ O
corpus -X- _ O
for -X- _ O
learning -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
inference -X- _ I-TaskName
. -X- _ O

Acknowledgements -X- _ O
We -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
thank -X- _ O
all -X- _ O
anonymous -X- _ O
reviewers -X- _ O
for -X- _ O
their -X- _ O
valuable -X- _ O
comments -X- _ O
and -X- _ O
suggestions.314 -X- _ O
. -X- _ O

Extending -X- _ O
our -X- _ O
work -X- _ O
to -X- _ O
a -X- _ O
large -X- _ O
soft -X- _ O
demonstration -X- _ O
memory -X- _ O
and -X- _ O
a -X- _ O
combination -X- _ O
of -X- _ O
local -X- _ O
and -X- _ O
global -X- _ O
memory -X- _ O
is -X- _ O
valuable -X- _ O
for -X- _ O
future -X- _ O
investigations -X- _ O
. -X- _ O

Experiments -X- _ O
showed -X- _ O
that -X- _ O
the -X- _ O
proposed -X- _ O
method -X- _ O
outperforms -X- _ O
prior -X- _ O
works -X- _ O
on -X- _ O
five -X- _ O
tasks -X- _ O
: -X- _ O
SST-2 -X- _ B-TaskName
, -X- _ O
MR -X- _ B-TaskName
, -X- _ O
Subj -X- _ B-TaskName
, -X- _ O
MRPC -X- _ B-TaskName
, -X- _ O
and -X- _ O
MPQA -X- _ B-TaskName
. -X- _ O

5 -X- _ O
Conclusion -X- _ O
This -X- _ O
study -X- _ O
proposed -X- _ O
LM -X- _ B-MethodName
- -X- _ I-MethodName
BFF -X- _ I-MethodName
- -X- _ I-MethodName
MSmanual -X- _ I-MethodName
prompts -X- _ O
with -X- _ O
multiple -X- _ O
soft -X- _ O
demonstration -X- _ O
memory -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
automatic -X- _ O
generation -X- _ O
of -X- _ O
multiple -X- _ O
label -X- _ O
words -X- _ O
and -X- _ O
an -X- _ O
auxiliary -X- _ O
NDP -X- _ B-TaskName
task -X- _ I-TaskName
. -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2a -X- _ O
and -X- _ O
2b -X- _ O
, -X- _ O
the -X- _ O
representation -X- _ O
learned -X- _ O
using -X- _ O
the -X- _ O
NDP -X- _ B-TaskName
task -X- _ I-TaskName
is -X- _ O
more -X- _ O
discriminative -X- _ O
than -X- _ O
that -X- _ O
learned -X- _ O
without -X- _ O
the -X- _ O
NDP -X- _ B-TaskName
task -X- _ I-TaskName
, -X- _ O
suggesting -X- _ O
that -X- _ O
the -X- _ O
NDP -X- _ B-TaskName
task -X- _ I-TaskName
provides -X- _ O
an -X- _ O
effective -X- _ O
additional -X- _ O
loss -X- _ O
for -X- _ O
learning -X- _ O
representations -X- _ O
of -X- _ O
soft -X- _ O
demonstration -X- _ O
memory -X- _ O
. -X- _ O

To -X- _ O
further -X- _ O
analyze -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
auxiliary -X- _ O
NDP -X- _ B-TaskName
task -X- _ I-TaskName
, -X- _ O
Figure -X- _ O
2 -X- _ O
visualizes -X- _ O
the -X- _ O
representation -X- _ O
of -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
tokens -X- _ O
on -X- _ O
SST-2 -X- _ B-DatasetName
using -X- _ O
t -X- _ B-MethodName
- -X- _ I-MethodName
SNE -X- _ I-MethodName
( -X- _ O
van -X- _ O
der -X- _ O
Maaten -X- _ O
and -X- _ O
Hinton -X- _ O
, -X- _ O
2008 -X- _ O
) -X- _ O
compared -X- _ O
, -X- _ O
with -X- _ O
and -X- _ O
without -X- _ O
the -X- _ O
NDP -X- _ B-TaskName
task -X- _ I-TaskName
. -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
7Here -X- _ O
, -X- _ O
pis -X- _ O
fixed -X- _ O
to -X- _ O
be -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
tokens -X- _ O
used -X- _ O
in -X- _ O
the -X- _ O
multiple -X- _ O
demonstrations -X- _ O
of -X- _ O
the -X- _ O
LM -X- _ B-MethodName
- -X- _ I-MethodName
BFF -X- _ I-MethodName
- -X- _ I-MethodName
MS.3 -X- _ I-MethodName
, -X- _ O
LM -X- _ B-MethodName
- -X- _ I-MethodName
BFF -X- _ I-MethodName
- -X- _ I-MethodName
MS -X- _ I-MethodName
with -X- _ O
NDP -X- _ B-MetricName
loss -X- _ I-MetricName
shows -X- _ O
improved -X- _ O
performance -X- _ O
compared -X- _ O
to -X- _ O
that -X- _ O
without -X- _ O
NDP -X- _ B-MetricName
loss -X- _ I-MetricName
, -X- _ O
providing -X- _ O
positive -X- _ O
evidence -X- _ O
for -X- _ O
our -X- _ O
motivating -X- _ O
hypothesis -X- _ O
that -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
the -X- _ O
NDP -X- _ B-MetricName
loss -X- _ I-MetricName
is -X- _ O
helpful -X- _ O
in -X- _ O
enhancing -X- _ O
the -X- _ O
representation -X- _ O
of -X- _ O
soft -X- _ O
demonstration -X- _ O
memory -X- _ O
. -X- _ O

To -X- _ O
examine -X- _ O
whether -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
the -X- _ O
NDP -X- _ B-TaskName
task -X- _ I-TaskName
is -X- _ O
indeed -X- _ O
effective -X- _ O
in -X- _ O
LM -X- _ B-MethodName
- -X- _ I-MethodName
BFF -X- _ I-MethodName
- -X- _ I-MethodName
MS -X- _ I-MethodName
, -X- _ O
Table -X- _ O
3 -X- _ O
compares -X- _ O
results -X- _ O
of -X- _ O
LM -X- _ B-MethodName
- -X- _ I-MethodName
BFF -X- _ I-MethodName
- -X- _ I-MethodName
MS -X- _ I-MethodName
with -X- _ O
and -X- _ O
without -X- _ O
the -X- _ O
NDP -X- _ B-TaskName
task -X- _ I-TaskName
on -X- _ O
the -X- _ O
SST-2 -X- _ B-DatasetName
dataset -X- _ I-DatasetName
. -X- _ O

The -X- _ O
results -X- _ O
confirm -X- _ O
that -X- _ O
the -X- _ O
gain -X- _ O
of -X- _ O
soft -X- _ O
demonstration -X- _ O
memory -X- _ O
is -X- _ O
not -X- _ O
merely -X- _ O
obtained -X- _ O
by -X- _ O
using -X- _ O
additional -X- _ O
parameters -X- _ O
of -X- _ O
soft -X- _ O
vectors -X- _ O
, -X- _ O
but -X- _ O
by -X- _ O
effectively -X- _ O
modeling -X- _ O
the -X- _ O
demonstration -X- _ O
- -X- _ O
aware -X- _ O
context -X- _ O
. -X- _ O

Table -X- _ O
2 -X- _ O
compares -X- _ O
soft -X- _ O
prompting -X- _ O
with -X- _ O
LM -X- _ B-MethodName
- -X- _ I-MethodName
BFFMS -X- _ I-MethodName
on -X- _ O
SST-2 -X- _ B-DatasetName
and -X- _ O
shows -X- _ O
that -X- _ O
LM -X- _ B-MethodName
- -X- _ I-MethodName
BFF -X- _ I-MethodName
- -X- _ I-MethodName
MS -X- _ I-MethodName
outperforms -X- _ O
soft -X- _ O
prompting -X- _ O
under -X- _ O
the -X- _ O
setting -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
length -X- _ O
of -X- _ O
soft -X- _ O
token -X- _ O
. -X- _ O

We -X- _ O
further -X- _ O
evaluate -X- _ O
the -X- _ O
soft -X- _ O
prompting -X- _ O
of -X- _ O
( -X- _ O
Lester -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
by -X- _ O
prepending -X- _ O
psoft -X- _ O
vectors -X- _ O
to -X- _ O
the -X- _ O
main -X- _ O
template -X- _ O
Tlabel(xin -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
pis -X- _ O
the -X- _ O
length -X- _ O
of -X- _ O
the -X- _ O
additional -X- _ O
soft -X- _ O
prompt7 -X- _ O
. -X- _ O

Soft -X- _ O
Prompting -X- _ O
To -X- _ O
validate -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
soft -X- _ O
demonstration -X- _ O
memory -X- _ O
, -X- _ O
instead -X- _ O
of -X- _ O
inserting -X- _ O
soft -X- _ O
vectors -X- _ O
into -X- _ O
the -X- _ O
demonstration -X- _ O
parts -X- _ O
. -X- _ O

We -X- _ O
believe -X- _ O
that -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
global -X- _ O
demonstration -X- _ O
memory -X- _ O
is -X- _ O
task -X- _ O
sensitive -X- _ O
, -X- _ O
suggesting -X- _ O
that -X- _ O
the -X- _ O
local -X- _ O
method -X- _ O
of -X- _ O
sampling -X- _ O
similar -X- _ O
demonstrations -X- _ O
as -X- _ O
in -X- _ O
LM -X- _ B-MethodName
- -X- _ I-MethodName
BFF -X- _ I-MethodName
often -X- _ O
needs -X- _ O
to -X- _ O
be -X- _ O
employed -X- _ O
for -X- _ O
some -X- _ O
tasks -X- _ O
or -X- _ O
specific -X- _ O
input -X- _ O
sentences.313 -X- _ O
. -X- _ O

On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ B-MethodName
LM -X- _ I-MethodName
- -X- _ I-MethodName
BFFMS -X- _ I-MethodName
is -X- _ O
weaker -X- _ O
than -X- _ O
LM -X- _ B-MethodName
- -X- _ I-MethodName
BFF -X- _ I-MethodName
on -X- _ O
SNLI -X- _ B-DatasetName
, -X- _ O
although -X- _ O
it -X- _ O
shows -X- _ O
comparable -X- _ O
results -X- _ O
to -X- _ O
DART -X- _ B-MethodName
. -X- _ O

Moreover -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
observed -X- _ O
that -X- _ O
the -X- _ O
performance -X- _ O
variation -X- _ O
of -X- _ O
LMBFF -X- _ B-MethodName
- -X- _ I-MethodName
MS -X- _ I-MethodName
are -X- _ O
mostly -X- _ O
lower -X- _ O
than -X- _ O
that -X- _ O
of -X- _ O
the -X- _ O
prior -X- _ O
methods -X- _ O
except -X- _ O
for -X- _ O
the -X- _ O
MNLI -X- _ B-TaskName
, -X- _ O
SNLI -X- _ B-TaskName
, -X- _ O
and -X- _ O
CR -X- _ B-TaskName
tasks -X- _ O
, -X- _ O
implying -X- _ O
that -X- _ O
our -X- _ O
approach -X- _ O
is -X- _ O
more -X- _ O
stable -X- _ O
than -X- _ O
the -X- _ O
existing -X- _ O
models -X- _ O
. -X- _ O

In -X- _ O
particular -X- _ O
, -X- _ O
LM -X- _ B-MethodName
- -X- _ I-MethodName
BFF -X- _ I-MethodName
- -X- _ I-MethodName
MS -X- _ I-MethodName
achieves -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
performance -X- _ O
on -X- _ O
SST-2 -X- _ B-TaskName
and -X- _ O
MRPC -X- _ B-TaskName
tasks -X- _ O
, -X- _ O
with -X- _ O
94.0 -X- _ B-MetricValue
and -X- _ O
80.4 -X- _ B-MetricValue
, -X- _ O
respectively -X- _ O
. -X- _ O

4.1 -X- _ O
Main -X- _ O
Results -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
noticed -X- _ O
that -X- _ O
the -X- _ O
proposed -X- _ O
approach -X- _ O
achieves -X- _ O
a -X- _ O
better -X- _ O
and -X- _ O
stable -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
performance -X- _ O
than -X- _ O
the -X- _ O
prior -X- _ O
methods -X- _ O
and -X- _ O
the -X- _ O
LM -X- _ B-MethodName
- -X- _ I-MethodName
BFF -X- _ I-MethodName
on -X- _ O
five -X- _ O
tasks -X- _ O
. -X- _ O

For -X- _ O
a -X- _ O
fair -X- _ O
comparison -X- _ O
, -X- _ O
the -X- _ O
same -X- _ O
manual -X- _ O
prompts -X- _ O
for -X- _ O
Tlabel -X- _ O
in -X- _ O
LM -X- _ B-MethodName
- -X- _ I-MethodName
BFF -X- _ I-MethodName
and -X- _ O
LM -X- _ B-MethodName
- -X- _ I-MethodName
BFF -X- _ I-MethodName
- -X- _ I-MethodName
MS -X- _ I-MethodName
are -X- _ O
used -X- _ O
. -X- _ O

4 -X- _ O
Experiments -X- _ O
The -X- _ O
implementation -X- _ O
details -X- _ O
are -X- _ O
provided -X- _ O
in -X- _ O
Appendix -X- _ O
B -X- _ O
. -X- _ O

Section -X- _ O
4.3 -X- _ O
presents -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
using -X- _ O
the -X- _ O
NDP -X- _ B-MetricName
loss -X- _ I-MetricName
compared -X- _ O
to -X- _ O
that -X- _ O
without -X- _ O
it -X- _ O
. -X- _ O

To -X- _ O
be -X- _ O
more -X- _ O
specific -X- _ O
, -X- _ O
the -X- _ O
NDP -X- _ B-TaskName
task -X- _ I-TaskName
trains -X- _ O
PNDP(y|xprompt -X- _ O
) -X- _ O
= -X- _ O
softmax -X- _ O
( -X- _ O
W[MLM -X- _ O
] -X- _ O
h[CLS -X- _ O
] -X- _ O
+ -X- _ O
b -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
W[MLM]R|Y| -X- _ O
dare -X- _ O
the -X- _ O
output -X- _ O
embedding -X- _ O
weights -X- _ O
of -X- _ O
the -X- _ O
label -X- _ O
words -X- _ O
in -X- _ O
an -X- _ O
MLM -X- _ B-MethodName
decoder -X- _ I-MethodName
. -X- _ O

An -X- _ O
illustration -X- _ O
of -X- _ O
the -X- _ O
incorporated -X- _ O
soft -X- _ O
demonstration -X- _ O
memory -X- _ O
is -X- _ O
described -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
. -X- _ O

To -X- _ O
create -X- _ O
mdemonstrations -X- _ O
, -X- _ O
all -X- _ O
examples -X- _ O
of -X- _ O
global -X- _ O
memory -X- _ O
are -X- _ O
chosen -X- _ O
without -X- _ O
requiring -X- _ O
a -X- _ O
sample -X- _ O
of -X- _ O
similar -X- _ O
examples -X- _ O
. -X- _ O

3.3 -X- _ O
Soft -X- _ O
Demonstration -X- _ O
Memory -X- _ O
Different -X- _ O
from -X- _ O
LM -X- _ B-MethodName
- -X- _ I-MethodName
BFF -X- _ I-MethodName
which -X- _ O
explicitly -X- _ O
finds -X- _ O
similar -X- _ O
training -X- _ O
examples -X- _ O
N(xin -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
, -X- _ O
soft -X- _ O
demonstration -X- _ O
memory -X- _ O
is -X- _ O
used -X- _ O
, -X- _ O
which -X- _ O
consists -X- _ O
of -X- _ O
globally -X- _ O
shared -X- _ O
soft -X- _ O
examples -X- _ O
as -X- _ O
demonstrations -X- _ O
, -X- _ O
assuming -X- _ O
that -X- _ O
each -X- _ O
demonstration -X- _ O
uses -X- _ O
nsoft -X- _ O
tokens -X- _ O
for -X- _ O
a -X- _ O
sentence -X- _ O
as -X- _ O
[ -X- _ O
T1][Tn -X- _ O
] -X- _ O
. -X- _ O

Our -X- _ O
generation -X- _ O
results -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
. -X- _ O

The -X- _ O
input -X- _ O
for -X- _ O
T5s -X- _ B-MethodName
encoder -X- _ O
is -X- _ O
merely -X- _ O
the -X- _ O
prompted -X- _ O
sequence -X- _ O
Tlabel(xin -X- _ O
) -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
with -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
as -X- _ O
the -X- _ O
span -X- _ O
- -X- _ O
corrupted -X- _ O
token -X- _ O
, -X- _ O
the -X- _ O
decoder -X- _ O
then -X- _ O
fills -X- _ O
in -X- _ O
the -X- _ O
placeholders -X- _ O
, -X- _ O
removes -X- _ O
duplicated -X- _ O
results -X- _ O
, -X- _ O
and -X- _ O
chooses -X- _ O
the -X- _ O
top -X- _ O
mmost -X- _ O
likely -X- _ O
generated -X- _ O
sequences -X- _ O
for -X- _ O
phrase -X- _ O
- -X- _ O
level -X- _ O
mapping -X- _ O
functions -X- _ O
of -X- _ O
the -X- _ O
corresponding -X- _ O
label -X- _ O
as -X- _ O
described -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
. -X- _ O

To -X- _ O
this -X- _ O
end -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
T5 -X- _ B-MethodName
to -X- _ O
generate -X- _ O
label -X- _ O
phrases -X- _ O
using -X- _ O
a -X- _ O
properly -X- _ O
designed -X- _ O
span -X- _ O
- -X- _ O
corrupted -X- _ O
input -X- _ O
in -X- _ O
the -X- _ O
reverse -X- _ O
manner -X- _ O
of -X- _ O
( -X- _ O
Gao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
which -X- _ O
exploits -X- _ O
T5 -X- _ B-MethodName
to -X- _ O
automatically -X- _ O
generate -X- _ O
templates -X- _ O
. -X- _ O

The -X- _ O
remaining -X- _ O
part -X- _ O
describes -X- _ O
how -X- _ O
to -X- _ O
obtain -X- _ O
the -X- _ O
mphrase -X- _ O
- -X- _ O
level -X- _ O
mapping -X- _ O
functions -X- _ O
in -X- _ O
Eq -X- _ O
. -X- _ O

3.2 -X- _ O
Automatically -X- _ O
Generating -X- _ O
Phrase -X- _ O
- -X- _ O
Level -X- _ O
Verbalizers -X- _ O
In -X- _ O
contrast -X- _ O
to -X- _ O
the -X- _ O
LM -X- _ B-MethodName
- -X- _ I-MethodName
BFF -X- _ I-MethodName
, -X- _ O
we -X- _ O
employ -X- _ O
phrase -X- _ O
-level -X- _ O
mapping -X- _ O
function -X- _ O
, -X- _ O
as -X- _ O
it -X- _ O
is -X- _ O
theorized -X- _ O
that -X- _ O
it -X- _ O
would -X- _ O
enable -X- _ O
a -X- _ O
better -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
demonstration -X- _ O
than -X- _ O
a -X- _ O
word -X- _ O
- -X- _ O
level -X- _ O
mapping -X- _ O
function -X- _ O
. -X- _ O

Note -X- _ O
that -X- _ O
this -X- _ O
setting -X- _ O
includes -X- _ O
the -X- _ B-MethodName
LM -X- _ I-MethodName
- -X- _ I-MethodName
BFF -X- _ I-MethodName
as -X- _ O
a -X- _ O
specific -X- _ O
case -X- _ O
with -X- _ O
|N(xin -X- _ O
, -X- _ O
y)|= -X- _ O
1per -X- _ O
label -X- _ O
and -X- _ O
M={M -X- _ O
wo}in -X- _ O
Eq -X- _ O
. -X- _ O

Note -X- _ O
that -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
use -X- _ O
auto -X- _ O
- -X- _ O
generated -X- _ O
templates -X- _ O
and -X- _ O
label -X- _ O
words.a -X- _ O
total -X- _ O
waste -X- _ O
of -X- _ O
my -X- _ O
time -X- _ O
. -X- _ O

To -X- _ O
define -X- _ O
Tdemon -X- _ O
, -X- _ O
suppose -X- _ O
that -X- _ O
VandYare -X- _ O
the -X- _ O
vocabulary -X- _ O
and -X- _ O
label -X- _ O
space -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O

The -X- _ O
mean -X- _ B-MetricName
( -X- _ O
and -X- _ O
standard -X- _ B-MetricName
deviation -X- _ I-MetricName
) -X- _ O
performance -X- _ O
over -X- _ O
five -X- _ O
different -X- _ O
splits -X- _ O
is -X- _ O
reported -X- _ O
. -X- _ O

: -X- _ O
no -X- _ O
training -X- _ O
examples -X- _ O
are -X- _ O
used -X- _ O
. -X- _ O

: -X- _ O
the -X- _ O
full -X- _ O
training -X- _ O
set -X- _ O
is -X- _ O
used -X- _ O
. -X- _ O

4Here -X- _ O
, -X- _ O
the -X- _ O
soft -X- _ O
prompting -X- _ O
method -X- _ O
refers -X- _ O
to -X- _ O
the -X- _ O
methods -X- _ O
of -X- _ O
using -X- _ O
unknown -X- _ O
prompt -X- _ O
- -X- _ O
specific -X- _ O
token -X- _ O
embedding -X- _ O
or -X- _ O
hidden -X- _ O
representations -X- _ O
at -X- _ O
prompt -X- _ O
positions.311 -X- _ O
. -X- _ O

In -X- _ O
addition -X- _ O
, -X- _ O
inspired -X- _ O
by -X- _ O
the -X- _ O
method -X- _ O
of -X- _ O
soft -X- _ O
prompting -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
soft -X- _ O
demonstration -X- _ O
memory -X- _ O
based -X- _ O
on -X- _ O
globally -X- _ O
shared -X- _ O
soft -X- _ O
vectors -X- _ O
for -X- _ O
prompt -X- _ O
tokens -X- _ O
, -X- _ O
without -X- _ O
using -X- _ O
hard -X- _ O
tokens -X- _ O
of -X- _ O
the -X- _ O
similar -X- _ O
context -X- _ O
. -X- _ O

Unlike -X- _ O
LM -X- _ B-MethodName
- -X- _ I-MethodName
BFF -X- _ I-MethodName
, -X- _ O
which -X- _ O
uses -X- _ O
a -X- _ O
single -X- _ O
demonstration -X- _ O
per -X- _ O
label -X- _ O
, -X- _ O
our -X- _ O
work -X- _ O
uses -X- _ O
multiple -X- _ O
demonstrations -X- _ O
that -X- _ O
are -X- _ O
provided -X- _ O
for -X- _ O
automatically -X- _ O
generated -X- _ O
label -X- _ O
phrases -X- _ O
. -X- _ O

The -X- _ O
demonstration -X- _ O
- -X- _ O
aware -X- _ O
prompt -X- _ O
has -X- _ O
also -X- _ O
been -X- _ O
explored -X- _ O
by -X- _ O
( -X- _ O
Gao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
with -X- _ O
their -X- _ O
proposed -X- _ O
LM -X- _ B-MethodName
- -X- _ I-MethodName
BFF -X- _ I-MethodName
, -X- _ O
where -X- _ O
a -X- _ O
demonstration -X- _ O
is -X- _ O
constructed -X- _ O
by -X- _ O
unmasking -X- _ O
the -X- _ O
masked -X- _ O
prompt -X- _ O
on -X- _ O
a -X- _ O
similar -X- _ O
input -X- _ O
example -X- _ O
. -X- _ O

Instead -X- _ O
of -X- _ O
using -X- _ O
hard -X- _ O
prompts -X- _ O
, -X- _ O
there -X- _ O
have -X- _ O
also -X- _ O
been -X- _ O
works -X- _ O
of -X- _ O
using -X- _ O
continuous -X- _ O
vectors -X- _ O
of -X- _ O
prompt -X- _ O
tokens -X- _ O
, -X- _ O
called -X- _ O
soft -X- _ O
prompting4 -X- _ O
, -X- _ O
including -X- _ O
the -X- _ O
work -X- _ O
of -X- _ O
Lester -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
proposes -X- _ O
soft -X- _ O
prompts -X- _ O
composed -X- _ O
of -X- _ O
learnable -X- _ O
continuous -X- _ O
embeddings -X- _ O
while -X- _ O
freezing -X- _ O
the -X- _ O
weight -X- _ O
of -X- _ O
PLMs -X- _ B-MethodName
; -X- _ O
and -X- _ O
Gu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
proposes -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
prompts -X- _ O
by -X- _ O
adding -X- _ O
soft -X- _ O
prompts -X- _ O
into -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
stage -X- _ O
to -X- _ O
obtain -X- _ O
a -X- _ O
better -X- _ O
initialization -X- _ O
. -X- _ O

Null -X- _ O
Prompts -X- _ O
simple -X- _ O
concatenations -X- _ O
of -X- _ O
the -X- _ O
inputs -X- _ O
and -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
tokenachieve -X- _ O
a -X- _ O
free -X- _ O
of -X- _ O
prompt -X- _ O
engineering -X- _ O
( -X- _ O
Logan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

AutoPrompt -X- _ B-MethodName
creates -X- _ O
appropriate -X- _ O
prompts -X- _ O
for -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
discrete -X- _ O
tokens -X- _ O
using -X- _ O
a -X- _ O
gradient -X- _ B-MethodName
- -X- _ I-MethodName
guided -X- _ I-MethodName
search -X- _ I-MethodName
( -X- _ O
Shin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
PET -X- _ B-MethodName
reformulates -X- _ O
downstream -X- _ O
tasks -X- _ O
as -X- _ O
a -X- _ O
masked -X- _ O
language -X- _ O
modeling -X- _ O
problem -X- _ O
and -X- _ O
performs -X- _ O
gradient -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
fine -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
( -X- _ O
Schick -X- _ O
and -X- _ O
Schtze -X- _ O
, -X- _ O
2021a -X- _ O
, -X- _ O
b -X- _ O
) -X- _ O
. -X- _ O

2 -X- _ O
Related -X- _ O
Work -X- _ O
Prompt -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
few -X- _ I-MethodName
- -X- _ I-MethodName
shot -X- _ I-MethodName
fine -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
, -X- _ O
which -X- _ O
finetunes -X- _ O
based -X- _ O
on -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
examples -X- _ O
under -X- _ O
a -X- _ O
prompting -X- _ O
setting -X- _ O
, -X- _ O
has -X- _ O
been -X- _ O
widely -X- _ O
studied -X- _ O
for -X- _ O
moderately -X- _ O
sized -X- _ O
PLMs -X- _ B-MethodName
such -X- _ O
as -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
andRoBERTa -X- _ B-MethodName
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
present -X- _ O
promising -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
proposed -X- _ O
method -X- _ O
on -X- _ O
eight -X- _ O
NLP -X- _ O
tasks -X- _ O
by -X- _ O
showing -X- _ O
improved -X- _ O
results -X- _ O
on -X- _ O
some -X- _ O
datasets -X- _ O
, -X- _ O
particularly -X- _ O
achieving -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
performance -X- _ O
on -X- _ O
SST-2 -X- _ B-DatasetName
and -X- _ O
MRPC -X- _ B-DatasetName
. -X- _ O

The -X- _ O
contributions -X- _ O
of -X- _ O
this -X- _ O
study -X- _ O
are -X- _ O
summarized -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
We -X- _ O
propose -X- _ O
prompts -X- _ O
with -X- _ O
multiple -X- _ O
soft -X- _ O
demonstration -X- _ O
memory -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
automatic -X- _ O
generation -X- _ O
of -X- _ O
multiple -X- _ O
label -X- _ O
phrases -X- _ O
and -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
soft -X- _ O
demonstration -X- _ O
memory -X- _ O
that -X- _ O
is -X- _ O
armed -X- _ O
with -X- _ O
an -X- _ O
auxiliary -X- _ O
NDP -X- _ B-TaskName
task -X- _ O
. -X- _ O

Following -X- _ O
the -X- _ O
previous -X- _ O
setting -X- _ O
of -X- _ O
the -X- _ O
LM -X- _ B-MethodName
- -X- _ I-MethodName
BFF -X- _ I-MethodName
, -X- _ O
the -X- _ O
experimental -X- _ O
results -X- _ O
on -X- _ O
eight -X- _ O
NLP -X- _ O
datasets -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
proposed -X- _ O
LM -X- _ B-MethodName
- -X- _ I-MethodName
BFF -X- _ I-MethodName
- -X- _ I-MethodName
MS -X- _ I-MethodName
leads -X- _ O
to -X- _ O
a -X- _ O
better -X- _ O
and -X- _ O
more -X- _ O
stable -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
performance -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
previous -X- _ O
models -X- _ O
. -X- _ O

To -X- _ O
train -X- _ O
the -X- _ O
soft -X- _ O
demonstration -X- _ O
memory -X- _ O
effectively -X- _ O
, -X- _ O
we -X- _ O
further -X- _ O
introduce -X- _ O
an -X- _ O
auxiliary -X- _ O
task -X- _ O
, -X- _ O
named -X- _ B-TaskName
next -X- _ I-TaskName
demonstrations -X- _ I-TaskName
prediction -X- _ I-TaskName
( -X- _ I-TaskName
NDP -X- _ I-TaskName
) -X- _ I-TaskName
task -X- _ I-TaskName
, -X- _ O
inspired -X- _ O
by -X- _ O
NSP -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
( -X- _ O
Sun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
our -X- _ O
approach -X- _ O
, -X- _ O
soft -X- _ O
vectors -X- _ O
are -X- _ O
considered -X- _ O
as -X- _ O
automatically -X- _ O
generated -X- _ O
demonstration -X- _ O
that -X- _ O
matches -X- _ O
well -X- _ O
for -X- _ O
each -X- _ O
label -X- _ O
phrase -X- _ O
, -X- _ O
capturing -X- _ O
the -X- _ O
common -X- _ O
context -X- _ O
for -X- _ O
the -X- _ O
corresponding -X- _ O
phrase -X- _ O
. -X- _ O

The -X- _ O
subfigure -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
shows -X- _ O
the -X- _ O
span -X- _ O
- -X- _ O
corrupted -X- _ O
input -X- _ O
and -X- _ O
output -X- _ O
of -X- _ O
T5 -X- _ B-MethodName
used -X- _ O
for -X- _ O
automatic -X- _ O
generation -X- _ O
of -X- _ O
phrase -X- _ O
- -X- _ O
level -X- _ O
verbalizers -X- _ O
as -X- _ O
in -X- _ O
Section -X- _ O
3.2 -X- _ O
. -X- _ O

& -X- _ O
" -X- _ O
# -X- _ O
, -X- _ O
, -X- _ O
! -X- _ O
It -X- _ O
was -X- _ O
an -X- _ O
instant -X- _ O
hit -X- _ O
. -X- _ O

It -X- _ O
was -X- _ O
great -X- _ O
. -X- _ O

A -X- _ O
fun -X- _ O
ride -X- _ O
. -X- _ O

It -X- _ O
was -X- _ O
terrible -X- _ O
. -X- _ O

3Here -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
assumed -X- _ O
that -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
label -X- _ O
words -X- _ O
is -X- _ O
different -X- _ O
from -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
label -X- _ O
phrases.310 -X- _ O
. -X- _ O

Unlike -X- _ B-MethodName
LM -X- _ I-MethodName
- -X- _ I-MethodName
BFF -X- _ I-MethodName
, -X- _ O
which -X- _ O
directly -X- _ O
uses -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
hard -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
demonstration -X- _ O
, -X- _ O
inspired -X- _ O
by -X- _ O
thesoft -X- _ O
prompts -X- _ O
of -X- _ O
Lester -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
replace -X- _ O
them -X- _ O
with -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
soft -X- _ O
vectors -X- _ O
as -X- _ O
a -X- _ O
proper -X- _ O
context -X- _ O
for -X- _ O
each -X- _ O
label -X- _ O
phrase -X- _ O
, -X- _ O
where -X- _ O
soft -X- _ O
vectors -X- _ O
are -X- _ O
globally -X- _ O
shared -X- _ O
soft -X- _ O
examples -X- _ O
for -X- _ O
each -X- _ O
label -X- _ O
phrase -X- _ O
but -X- _ O
are -X- _ O
not -X- _ O
sensitive -X- _ O
to -X- _ O
2Note -X- _ O
that -X- _ O
LM -X- _ B-MethodName
- -X- _ I-MethodName
BFF -X- _ I-MethodName
also -X- _ O
explored -X- _ O
sampling -X- _ O
multiple -X- _ O
demonstrations -X- _ O
per -X- _ O
label -X- _ O
, -X- _ O
but -X- _ O
did -X- _ O
not -X- _ O
observe -X- _ O
any -X- _ O
improvement -X- _ O
. -X- _ O

2.Soft -X- _ O
demonstration -X- _ O
memory -X- _ O
based -X- _ O
on -X- _ O
multiple -X- _ O
sequences -X- _ O
of -X- _ O
word -X- _ O
embeddings -X- _ O
. -X- _ O

Given -X- _ O
that -X- _ O
label -X- _ O
phrases -X- _ O
are -X- _ O
semantically -X- _ O
related -X- _ O
or -X- _ O
similar -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
expected -X- _ O
that -X- _ O
resulting -X- _ O
demonstrations -X- _ O
indirectly -X- _ O
augment -X- _ O
the -X- _ O
vocabulary -X- _ O
of -X- _ O
the -X- _ O
verbalizer -X- _ O
with -X- _ O
label -X- _ O
phrases3 -X- _ O
. -X- _ O

While -X- _ O
LM -X- _ B-MethodName
- -X- _ I-MethodName
BFF -X- _ I-MethodName
uses -X- _ O
single -X- _ O
demonstration2 -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
uses -X- _ O
multiple -X- _ O
demonstrations -X- _ O
with -X- _ O
different -X- _ O
label -X- _ O
phrases -X- _ O
, -X- _ O
where -X- _ O
each -X- _ O
demonstration -X- _ O
is -X- _ O
constructed -X- _ O
per -X- _ O
label -X- _ O
phrase -X- _ O
. -X- _ O

To -X- _ O
improve -X- _ O
LMBFF -X- _ B-MethodName
, -X- _ O
we -X- _ O
propose -X- _ O
LM -X- _ B-MethodName
- -X- _ I-MethodName
BFF -X- _ I-MethodName
- -X- _ I-MethodName
MS -X- _ I-MethodName
, -X- _ O
better -X- _ O
few -X- _ B-MethodName
- -X- _ I-MethodName
shot -X- _ I-MethodName
fine -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
of -X- _ O
language -X- _ O
models -X- _ O
with -X- _ O
multiple -X- _ O
soft -X- _ O
demonstration -X- _ O
memory -X- _ O
, -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
following -X- _ O
two -X- _ O
extensions -X- _ O
: -X- _ O
1.Prompts -X- _ O
with -X- _ O
multiple -X- _ O
demonstrations -X- _ O
. -X- _ O

With -X- _ O
demonstration -X- _ O
- -X- _ O
aware -X- _ O
prompts -X- _ O
, -X- _ O
the -X- _ O
LM -X- _ B-MethodName
- -X- _ I-MethodName
BFF -X- _ I-MethodName
outperforms -X- _ O
the -X- _ O
conventional -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
approach -X- _ O
and -X- _ O
GPT-3s -X- _ B-MethodName
in -X- _ O
- -X- _ O
context -X- _ B-TaskName
learning -X- _ I-TaskName
. -X- _ O

Among -X- _ O
the -X- _ O
various -X- _ O
methods -X- _ O
of -X- _ O
prompt -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
fine -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
, -X- _ O
this -X- _ O
study -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
LMBFF -X- _ B-MethodName
method -X- _ O
( -X- _ O
Gao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
uses -X- _ O
a -X- _ O
demonstration -X- _ O
- -X- _ O
aware -X- _ O
prompt -X- _ O
where -X- _ O
a -X- _ O
demonstration -X- _ O
is -X- _ O
produced -X- _ O
by -X- _ O
unmasking -X- _ O
the -X- _ O
example -X- _ O
prompt -X- _ O
in -X- _ O
contexts -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
input -X- _ O
, -X- _ O
inspired -X- _ O
by -X- _ O
the -X- _ O
findings -X- _ O
from -X- _ O
the -X- _ O
GPT-3 -X- _ B-MethodName
model -X- _ O
( -X- _ O
Brown -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

Prompt -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
fine -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
reformulates -X- _ O
downstream -X- _ O
tasks -X- _ O
as -X- _ O
a -X- _ O
masked -X- _ O
language -X- _ O
modeling -X- _ O
problem -X- _ O
, -X- _ O
where -X- _ O
a -X- _ O
token -X- _ O
( -X- _ O
label -X- _ O
word -X- _ O
) -X- _ O
is -X- _ O
generated -X- _ O
on -X- _ O
a -X- _ O
given -X- _ O
prompt -X- _ O
with -X- _ O
a -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
template -X- _ O
. -X- _ O

To -X- _ O
enable -X- _ O
task -X- _ B-MethodName
- -X- _ I-MethodName
specific -X- _ I-MethodName
fine -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
, -X- _ O
promptbased -X- _ O
few -X- _ B-MethodName
- -X- _ I-MethodName
shot -X- _ I-MethodName
fine -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
has -X- _ O
been -X- _ O
widely -X- _ O
studied -X- _ O
to -X- _ O
encourage -X- _ O
the -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
capabilities -X- _ O
of -X- _ O
pretrained -X- _ B-MethodName
language -X- _ I-MethodName
models -X- _ I-MethodName
( -X- _ I-MethodName
PLMs -X- _ I-MethodName
) -X- _ I-MethodName
equipped -X- _ O
with -X- _ O
label -X- _ O
- -X- _ O
specific -X- _ O
verbalizers -X- _ O
andprompts -X- _ O
that -X- _ O
are -X- _ O
compatible -X- _ O
with -X- _ O
language -X- _ O
models -X- _ O
( -X- _ O
Schick -X- _ O
and -X- _ O
Schtze -X- _ O
, -X- _ O
2021a -X- _ O
, -X- _ O
b -X- _ O
) -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
the -X- _ O
GPT-3 -X- _ B-MethodName
model -X- _ I-MethodName
consists -X- _ O
of -X- _ O
175B -X- _ O
parameters -X- _ O
, -X- _ O
making -X- _ O
it -X- _ O
challenging -X- _ O
to -X- _ O
perform -X- _ O
task -X- _ B-MethodName
- -X- _ I-MethodName
specific -X- _ I-MethodName
fine -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
, -X- _ O
which -X- _ O
is -X- _ O
often -X- _ O
required -X- _ O
in -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
applications -X- _ O
. -X- _ O

1 -X- _ O
Introduction -X- _ O
The -X- _ O
GPT-3 -X- _ B-MethodName
model -X- _ I-MethodName
( -X- _ O
Brown -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
has -X- _ O
achieved -X- _ O
remarkable -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
performance -X- _ O
on -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
understanding -X- _ I-TaskName
tasks -X- _ O
given -X- _ O
a -X- _ O
natural -X- _ O
language -X- _ O
prompt -X- _ O
and|K|labeled -X- _ O
samples -X- _ O
as -X- _ O
demonstrations -X- _ O
in -X- _ O
the -X- _ O
inputs -X- _ O
without -X- _ O
updating -X- _ O
the -X- _ O
models -X- _ O
weights -X- _ O
. -X- _ O

Experiments -X- _ O
conducted -X- _ O
on -X- _ O
eight -X- _ O
NLP -X- _ O
tasks -X- _ O
show -X- _ O
that -X- _ O
LM -X- _ B-MethodName
- -X- _ I-MethodName
BFF -X- _ I-MethodName
- -X- _ I-MethodName
MS -X- _ I-MethodName
leads -X- _ O
to -X- _ O
improvements -X- _ O
over -X- _ O
LMBFF -X- _ B-MethodName
on -X- _ O
five -X- _ O
tasks -X- _ O
, -X- _ O
particularly -X- _ O
achieving -X- _ O
94.0 -X- _ B-MetricValue
and -X- _ O
90.4 -X- _ B-MetricValue
on -X- _ O
SST-2 -X- _ B-DatasetName
and -X- _ O
MRPC -X- _ B-DatasetName
, -X- _ O
respectively1 -X- _ O
. -X- _ O

To -X- _ O
improve -X- _ O
the -X- _ O
approach -X- _ O
of -X- _ O
LM -X- _ B-MethodName
- -X- _ I-MethodName
BFF -X- _ I-MethodName
, -X- _ O
this -X- _ O
paper -X- _ O
proposes -X- _ O
LM -X- _ B-MethodName
- -X- _ I-MethodName
BFFMSbetter -X- _ I-MethodName
few -X- _ B-MethodName
- -X- _ I-MethodName
shot -X- _ I-MethodName
fine -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
of -X- _ O
language -X- _ O
models -X- _ O
with -X- _ O
multiple -X- _ O
soft -X- _ O
demonstrations -X- _ O
by -X- _ O
making -X- _ O
its -X- _ O
further -X- _ O
extensions -X- _ O
, -X- _ O
which -X- _ O
include -X- _ O
1 -X- _ O
) -X- _ O
prompts -X- _ O
with -X- _ O
multiple -X- _ O
demonstrations -X- _ O
based -X- _ O
on -X- _ O
automatic -X- _ O
generation -X- _ O
of -X- _ O
multiple -X- _ O
label -X- _ O
words -X- _ O
; -X- _ O
and -X- _ O
2 -X- _ O
) -X- _ O
soft -X- _ O
demonstration -X- _ O
memory -X- _ O
which -X- _ O
consists -X- _ O
of -X- _ O
multiple -X- _ O
sequences -X- _ O
of -X- _ O
globally -X- _ O
shared -X- _ O
word -X- _ O
embeddings -X- _ O
for -X- _ O
a -X- _ O
similar -X- _ O
context -X- _ O
. -X- _ O

Usr -X- _ O
: -X- _ O
Thank -X- _ O
you -X- _ O
, -X- _ O
that -X- _ O
should -X- _ O
be -X- _ O
all -X- _ O
for -X- _ O
today -X- _ O
. -X- _ O

Which -X- _ O
day -X- _ O
would -X- _ O
you -X- _ O
be -X- _ O
traveling -X- _ O
? -X- _ O
Usr -X- _ O
: -X- _ O
I -X- _ O
will -X- _ O
be -X- _ O
traveling -X- _ O
on -X- _ O
Tuesday -X- _ O
. -X- _ O

MultiWOZ -X- _ B-DatasetName
2.1 -X- _ I-DatasetName
: -X- _ O
A -X- _ O
consolidated -X- _ O
multi -X- _ O
- -X- _ O
domain -X- _ O
dialogue -X- _ O
dataset -X- _ O
with -X- _ O
state -X- _ O
corrections -X- _ O
and -X- _ O
state -X- _ O
tracking -X- _ O
baselines -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O
Mihail -X- _ O
Eric -X- _ O
, -X- _ O
Rahul -X- _ O
Goel -X- _ O
, -X- _ O
Shachi -X- _ O
Paul -X- _ O
, -X- _ O
Abhishek -X- _ O
Sethi -X- _ O
, -X- _ O
Sanchit -X- _ O
Agarwal -X- _ O
, -X- _ O
Shuyang -X- _ O
Gao -X- _ O
, -X- _ O
Adarsh -X- _ O
Kumar -X- _ O
, -X- _ O
Anuj -X- _ O
Goyal -X- _ O
, -X- _ O
Peter -X- _ O
Ku -X- _ O
, -X- _ O
and -X- _ O
Dilek -X- _ O
Hakkani -X- _ O
- -X- _ O
Tur -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
22nd -X- _ O
Annual -X- _ O
Meeting -X- _ O
of -X- _ O
the -X- _ O
Special -X- _ O
Interest -X- _ O
Group -X- _ O
on -X- _ O
Discourse -X- _ O
and -X- _ O
Dialogue -X- _ O
, -X- _ O
pages -X- _ O
218 -X- _ O
227 -X- _ O
, -X- _ O
Singapore -X- _ O
and -X- _ O
Online -X- _ O
. -X- _ O

Hi -X- _ B-MethodName
- -X- _ I-MethodName
DST -X- _ I-MethodName
: -X- _ O
A -X- _ O
hierarchical -X- _ O
approach -X- _ O
for -X- _ O
scalable -X- _ O
and -X- _ O
extensible -X- _ O
dialogue -X- _ O
state -X- _ O
tracking -X- _ O
. -X- _ O

Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
2018 -X- _ O
Conference -X- _ O
on -X- _ O
Empirical -X- _ O
Methods -X- _ O
in -X- _ O
Natural -X- _ O
Language -X- _ O
Processing -X- _ O
, -X- _ O
pages -X- _ O
50165026 -X- _ O
, -X- _ O
Brussels -X- _ O
, -X- _ O
Belgium -X- _ O
. -X- _ O

MultiWOZ -X- _ B-DatasetName
- -X- _ O
a -X- _ O
largescale -X- _ O
multi -X- _ O
- -X- _ O
domain -X- _ O
wizard -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
Oz -X- _ O
dataset -X- _ O
for -X- _ O
taskoriented -X- _ O
dialogue -X- _ O
modelling -X- _ O
. -X- _ O

References -X- _ O
Pawe -X- _ O
Budzianowski -X- _ O
, -X- _ O
Tsung -X- _ O
- -X- _ O
Hsien -X- _ O
Wen -X- _ O
, -X- _ O
Bo -X- _ O
- -X- _ O
Hsiang -X- _ O
Tseng -X- _ O
, -X- _ O
Iigo -X- _ O
Casanueva -X- _ O
, -X- _ O
Stefan -X- _ O
Ultes -X- _ O
, -X- _ O
Osman -X- _ O
Ramadan -X- _ O
, -X- _ O
and -X- _ O
Milica -X- _ O
Gai -X- _ O
c -X- _ O
. -X- _ O

In -X- _ O
conclusion -X- _ O
, -X- _ O
FGA -X- _ B-MetricName
is -X- _ O
a -X- _ O
practical -X- _ O
and -X- _ O
insightful -X- _ O
metric -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
useful -X- _ O
to -X- _ O
evaluate -X- _ O
future -X- _ O
DST -X- _ B-MethodName
models -X- _ I-MethodName
. -X- _ O

We -X- _ O
justified -X- _ O
that -X- _ O
FGA -X- _ B-MetricName
provides -X- _ O
a -X- _ O
relatively -X- _ O
balanced -X- _ O
estimation -X- _ O
of -X- _ O
DST -X- _ B-TaskName
performance -X- _ O
along -X- _ O
with -X- _ O
better -X- _ O
discrimination -X- _ O
property -X- _ O
. -X- _ O

We -X- _ O
addressed -X- _ O
the -X- _ O
issues -X- _ O
of -X- _ O
joint -X- _ B-MetricName
accuracy -X- _ I-MetricName
by -X- _ O
introducing -X- _ O
Flexible -X- _ B-MetricName
goal -X- _ I-MetricName
accuracy -X- _ I-MetricName
( -X- _ I-MetricName
FGA -X- _ I-MetricName
) -X- _ I-MetricName
which -X- _ O
tries -X- _ O
to -X- _ O
give -X- _ O
partial -X- _ O
credit -X- _ O
to -X- _ O
mispredictions -X- _ O
that -X- _ O
are -X- _ O
locally -X- _ O
correct -X- _ O
. -X- _ O

We -X- _ O
argued -X- _ O
that -X- _ O
joint -X- _ B-MetricName
accuracy -X- _ I-MetricName
can -X- _ O
underestimate -X- _ O
the -X- _ O
power -X- _ O
of -X- _ O
a -X- _ O
DST -X- _ B-TaskName
algorithm -X- _ O
, -X- _ O
whereas -X- _ O
slot -X- _ B-MetricName
and -X- _ I-MetricName
average -X- _ I-MetricName
goal -X- _ I-MetricName
accuracy -X- _ I-MetricName
can -X- _ O
overestimate -X- _ O
it -X- _ O
. -X- _ O

5 -X- _ O
Conclusion -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
analyzed -X- _ O
the -X- _ O
limitations -X- _ O
of -X- _ O
existing -X- _ O
DST -X- _ O
metrics -X- _ O
. -X- _ O

This -X- _ O
shows -X- _ O
that -X- _ O
FGA -X- _ B-MetricName
is -X- _ O
slightly -X- _ O
better -X- _ O
correlated -X- _ O
than -X- _ O
JGA -X- _ B-MetricName
with -X- _ O
human -X- _ O
evaluation -X- _ O
. -X- _ O

Pearson -X- _ B-MetricName
correlation -X- _ I-MetricName
coefficient -X- _ I-MetricName
of -X- _ O
JGA -X- _ B-MetricName
and -X- _ O
FGA -X- _ B-MetricName
( -X- _ O
with -X- _ O
= -X- _ O
0.5 -X- _ O
) -X- _ O
with -X- _ O
human -X- _ O
ratings -X- _ O
came -X- _ O
out -X- _ O
to -X- _ O
be -X- _ O
0.33 -X- _ B-MetricValue
and -X- _ O
0.37 -X- _ B-MetricValue
respectively -X- _ O
. -X- _ O

For -X- _ O
each -X- _ O
conversation -X- _ O
, -X- _ O
the -X- _ O
evaluators -X- _ O
were -X- _ O
asked -X- _ O
to -X- _ O
report -X- _ O
their -X- _ O
satisfaction -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
or -X- _ O
dissatisfaction -X- _ O
( -X- _ O
0 -X- _ O
) -X- _ O
with -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
in -X- _ O
keeping -X- _ O
track -X- _ O
of -X- _ O
user -X- _ O
intent -X- _ O
throughout -X- _ O
the -X- _ O
conversation -X- _ O
. -X- _ O

The -X- _ O
predictions -X- _ O
were -X- _ O
generated -X- _ O
using -X- _ O
SOM -X- _ B-MethodName
- -X- _ I-MethodName
DST -X- _ I-MethodName
. -X- _ O

For -X- _ O
each -X- _ O
turn -X- _ O
in -X- _ O
a -X- _ O
conversation -X- _ O
, -X- _ O
we -X- _ O
provided -X- _ O
the -X- _ O
system -X- _ O
and -X- _ O
user -X- _ O
utterances -X- _ O
along -X- _ O
with -X- _ O
the -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
and -X- _ O
predicted -X- _ O
belief -X- _ O
states -X- _ O
. -X- _ O

evaluation -X- _ O
involving -X- _ O
11 -X- _ O
evaluators -X- _ O
on -X- _ O
100 -X- _ O
randomly -X- _ O
picked -X- _ O
conversations -X- _ O
from -X- _ O
the -X- _ O
MultiWOZ -X- _ B-DatasetName
2.1 -X- _ I-DatasetName
test -X- _ I-DatasetName
data -X- _ I-DatasetName
. -X- _ O

FGA -X- _ B-MetricName
x -X- _ O
indicates -X- _ O
the -X- _ O
FGA -X- _ O
value -X- _ O
calcualated -X- _ O
using -X- _ O
= -X- _ O
x -X- _ O
. -X- _ O

M1 -X- _ O
and -X- _ O
M2 -X- _ O
represents -X- _ O
exact -X- _ O
and -X- _ O
turn -X- _ O
- -X- _ O
level -X- _ O
matches -X- _ O
respectively -X- _ O
. -X- _ O

Human -X- _ O
Evaluation -X- _ O
: -X- _ O
We -X- _ O
conducted -X- _ O
a -X- _ O
human321 -X- _ O
. -X- _ O

Moreover -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
also -X- _ O
notice -X- _ O
that -X- _ O
FGA -X- _ B-MetricName
acts -X- _ O
as -X- _ O
a -X- _ O
better -X- _ O
discriminator -X- _ O
of -X- _ O
DST -X- _ B-MethodName
models -X- _ I-MethodName
in -X- _ O
comparison -X- _ O
to -X- _ O
the -X- _ O
existing -X- _ O
metrics -X- _ O
. -X- _ O

Now -X- _ O
, -X- _ O
by -X- _ O
comparing -X- _ O
the -X- _ O
numbers -X- _ O
of -X- _ O
Table -X- _ O
1 -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
infer -X- _ O
that -X- _ O
FGA -X- _ B-MetricName
does -X- _ O
a -X- _ O
better -X- _ O
job -X- _ O
in -X- _ O
providing -X- _ O
a -X- _ O
fair -X- _ O
estimate -X- _ O
while -X- _ O
considering -X- _ O
both -X- _ O
exact -X- _ O
and -X- _ O
turn -X- _ O
- -X- _ O
level -X- _ O
matches -X- _ O
. -X- _ O

Among -X- _ O
the -X- _ O
four -X- _ O
models -X- _ O
, -X- _ O
SOM -X- _ B-MethodName
- -X- _ I-MethodName
DST -X- _ I-MethodName
performs -X- _ O
well -X- _ O
for -X- _ O
both -X- _ O
objectives -X- _ O
because -X- _ O
of -X- _ O
their -X- _ O
sophisticated -X- _ O
selective -X- _ O
overwrite -X- _ O
mechanism -X- _ O
. -X- _ O

In -X- _ O
contrast -X- _ O
, -X- _ O
Hi -X- _ B-MethodName
- -X- _ I-MethodName
DST -X- _ I-MethodName
optimizes -X- _ O
explicitly -X- _ O
for -X- _ O
turn -X- _ O
- -X- _ O
level -X- _ O
non -X- _ O
- -X- _ O
cumulative -X- _ O
belief -X- _ O
states -X- _ O
, -X- _ O
thereby -X- _ O
achieving -X- _ O
better -X- _ O
turn -X- _ O
- -X- _ O
level -X- _ O
accuracy -X- _ O
at -X- _ O
the -X- _ O
expense -X- _ O
of -X- _ O
JGA -X- _ B-MetricName
. -X- _ O

This -X- _ O
behavior -X- _ O
of -X- _ O
Trippy -X- _ B-MethodName
can -X- _ O
be -X- _ O
a -X- _ O
sideeffect -X- _ O
of -X- _ O
boosting -X- _ O
the -X- _ O
JGA -X- _ B-MetricName
using -X- _ O
its -X- _ O
intricate -X- _ O
featurization -X- _ O
. -X- _ O

It -X- _ O
has -X- _ O
lesser -X- _ O
turn -X- _ O
- -X- _ O
level -X- _ O
matches -X- _ O
than -X- _ O
SOM -X- _ B-MethodName
- -X- _ I-MethodName
DST -X- _ I-MethodName
and -X- _ O
Hi -X- _ B-MethodName
- -X- _ I-MethodName
DST -X- _ I-MethodName
. -X- _ O

However -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
notice -X- _ O
that -X- _ O
Trippy -X- _ B-MethodName
does -X- _ O
not -X- _ O
have -X- _ O
the -X- _ O
same -X- _ O
performance -X- _ O
gain -X- _ O
for -X- _ O
turn -X- _ O
- -X- _ O
level -X- _ O
matches -X- _ O
. -X- _ O

Currently -X- _ O
, -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
DST -X- _ B-TaskName
performances -X- _ O
are -X- _ O
shown -X- _ O
using -X- _ O
Trippy -X- _ B-MethodName
. -X- _ O

From -X- _ O
Table -X- _ O
1 -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
observe -X- _ O
that -X- _ O
Trippy -X- _ B-MethodName
has -X- _ O
the -X- _ O
best -X- _ O
JGA -X- _ B-MetricName
. -X- _ O

For -X- _ O
the -X- _ O
same -X- _ O
reason -X- _ O
, -X- _ O
we -X- _ O
did -X- _ O
not -X- _ O
try -X- _ O
to -X- _ O
find -X- _ O
the -X- _ O
best -X- _ O
for -X- _ O
evaluating -X- _ O
the -X- _ O
MultiWOZ -X- _ B-DatasetName
dataset -X- _ I-DatasetName
. -X- _ O

Hence -X- _ O
, -X- _ O
we -X- _ O
reported -X- _ O
the -X- _ O
FGA -X- _ B-MetricName
score -X- _ I-MetricName
for -X- _ O
multiple -X- _ O
values -X- _ O
of -X- _ O
hyper -X- _ O
- -X- _ O
parameter -X- _ O
rather -X- _ O
than -X- _ O
showing -X- _ O
the -X- _ O
result -X- _ O
for -X- _ O
a -X- _ O
single -X- _ O
value -X- _ O
. -X- _ O

Since -X- _ O
the -X- _ O
MultiWOZ -X- _ B-DatasetName
dataset -X- _ I-DatasetName
covers -X- _ O
many -X- _ O
domains -X- _ O
( -X- _ O
hotel -X- _ O
, -X- _ O
restaurant -X- _ O
, -X- _ O
taxi -X- _ O
, -X- _ O
train -X- _ O
, -X- _ O
attraction -X- _ O
) -X- _ O
where -X- _ O
each -X- _ O
domain -X- _ O
may -X- _ O
have -X- _ O
different -X- _ O
levels -X- _ O
of -X- _ O
tolerance -X- _ O
( -X- _ O
intuitively -X- _ O
train -X- _ O
, -X- _ O
taxi -X- _ O
booking -X- _ O
may -X- _ O
be -X- _ O
strict -X- _ O
whereas -X- _ O
information -X- _ O
seeking -X- _ O
about -X- _ O
attraction -X- _ O
, -X- _ O
restaurant -X- _ O
domains -X- _ O
may -X- _ O
be -X- _ O
lenient -X- _ O
) -X- _ O
, -X- _ O
an -X- _ O
overall -X- _ O
common -X- _ O
/ -X- _ O
single -X- _ O
strictness -X- _ O
setting -X- _ O
for -X- _ O
the -X- _ O
entire -X- _ O
dataset -X- _ O
may -X- _ O
be -X- _ O
difficult -X- _ O
to -X- _ O
reach -X- _ O
at -X- _ O
. -X- _ O

The -X- _ O
results -X- _ O
are -X- _ O
reported -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
MultiWOZ -X- _ B-TaskName
2.1 -X- _ I-TaskName
dataset -X- _ I-TaskName
( -X- _ O
Eric -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
as -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
recent -X- _ O
progress -X- _ O
in -X- _ O
DST -X- _ B-TaskName
are -X- _ O
showcased -X- _ O
on -X- _ O
this -X- _ O
dataset -X- _ O
. -X- _ O

4 -X- _ O
Result -X- _ O
and -X- _ O
Analysis -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
report -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
FGA -X- _ B-MetricName
along -X- _ O
with -X- _ O
the -X- _ O
other -X- _ O
metrics -X- _ O
on -X- _ O
four -X- _ O
different -X- _ O
DST -X- _ B-MethodName
models -X- _ I-MethodName
: -X- _ O
TRADE -X- _ B-MethodName
( -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
Hi -X- _ B-MethodName
- -X- _ I-MethodName
DST -X- _ I-MethodName
( -X- _ O
Dey -X- _ O
and -X- _ O
Desarkar -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
SOM -X- _ B-MethodName
- -X- _ I-MethodName
DST -X- _ I-MethodName
( -X- _ O
Kim -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
Trippy -X- _ B-MethodName
( -X- _ O
Heck -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

Hence -X- _ O
, -X- _ O
FGA -X- _ B-MetricName
can -X- _ O
provide -X- _ O
a -X- _ O
relatively -X- _ O
balanced -X- _ O
estimate -X- _ O
than -X- _ O
the -X- _ O
existing -X- _ O
metrics -X- _ O
even -X- _ O
in -X- _ O
the -X- _ O
presence -X- _ O
of -X- _ O
annotation -X- _ O
errors -X- _ O
and -X- _ O
inconsistencies -X- _ O
. -X- _ O

Secondly -X- _ O
, -X- _ O
it -X- _ O
gives -X- _ O
a -X- _ O
better -X- _ O
estimate -X- _ O
than -X- _ O
JGA -X- _ B-MetricName
in -X- _ O
keeping -X- _ O
track -X- _ O
of -X- _ O
both -X- _ O
exact -X- _ O
and -X- _ O
turn -X- _ O
- -X- _ O
level -X- _ O
matches -X- _ O
simultaneously -X- _ O
. -X- _ O

Firstly -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
overestimating -X- _ O
in -X- _ O
comparison -X- _ O
to -X- _ O
SA -X- _ B-MetricName
and -X- _ O
AGA -X- _ B-MetricName
. -X- _ O

We -X- _ O
can -X- _ O
observe -X- _ O
two -X- _ O
things -X- _ O
from -X- _ O
these -X- _ O
numbers -X- _ O
. -X- _ O

1 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
FGA -X- _ B-MetricName
score -X- _ I-MetricName
for -X- _ O
each -X- _ O
turn -X- _ O
with -X- _ O
= -X- _ O
0.5is -X- _ O
{ -X- _ O
1 -X- _ O
, -X- _ O
1 -X- _ O
, -X- _ O
0 -X- _ O
, -X- _ O
0.39 -X- _ O
, -X- _ O
0 -X- _ O
, -X- _ O
0.39 -X- _ O
} -X- _ O
which -X- _ O
results -X- _ O
in -X- _ O
a -X- _ O
FGA -X- _ B-MetricName
score -X- _ I-MetricName
of -X- _ O
46.33% -X- _ B-MetricValue
for -X- _ O
theentire -X- _ O
conversation -X- _ O
. -X- _ O

In -X- _ O
our -X- _ O
running -X- _ O
example -X- _ O
( -X- _ O
Fig -X- _ O
. -X- _ O

Hence -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
flexibly -X- _ O
set -X- _ O
the -X- _ O
strictness -X- _ O
criteria -X- _ O
of -X- _ O
FGA -X- _ B-MetricName
through -X- _ O
the -X- _ O
hyper -X- _ O
- -X- _ O
parameter -X- _ O
according -X- _ O
to -X- _ O
our -X- _ O
requirement -X- _ O
. -X- _ O

If -X- _ O
the -X- _ O
dataset -X- _ O
is -X- _ O
clean -X- _ O
, -X- _ O
one -X- _ O
can -X- _ O
alternatively -X- _ O
find -X- _ O
the -X- _ O
best -X- _ O
through -X- _ O
a -X- _ O
human -X- _ O
evaluation -X- _ O
, -X- _ O
although -X- _ O
it -X- _ O
would -X- _ O
require -X- _ O
additional -X- _ O
human -X- _ O
effort -X- _ O
. -X- _ O

So -X- _ O
, -X- _ O
the -X- _ O
strictness -X- _ O
of -X- _ O
FGA -X- _ B-MetricName
is -X- _ O
directly -X- _ O
proportional -X- _ O
to -X- _ O
tfand -X- _ O
inversely -X- _ O
proportional -X- _ O
to -X- _ O
p -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
if -X- _ O
tf=6 -X- _ O
and -X- _ O
p=0.95 -X- _ O
, -X- _ O
then -X- _ O
= -X- _ O
0.499 -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
take -X- _ O
a -X- _ O
theoretical -X- _ O
stand -X- _ O
and -X- _ O
approximate -X- _ O
the -X- _ O
hyper -X- _ O
- -X- _ O
parameter -X- _ O
value -X- _ O
as -X- _ O
= -X- _ O
ln(1p)/tfwhere -X- _ O
tfis -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
turns -X- _ O
that -X- _ O
it -X- _ O
will -X- _ O
take -X- _ O
to -X- _ O
forget -X- _ O
a -X- _ O
mistake -X- _ O
by -X- _ O
factor -X- _ O
pwhere -X- _ O
( -X- _ O
0p -X- _ O
< -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O

Finding -X- _ O
the -X- _ O
appropriate -X- _ O
for -X- _ O
a -X- _ O
specific -X- _ O
DST -X- _ B-TaskName
task -X- _ I-TaskName
should -X- _ O
be -X- _ O
done -X- _ O
carefully -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
match -X- _ O
the -X- _ O
desired -X- _ O
evaluation -X- _ O
criteria -X- _ O
. -X- _ O

Note -X- _ O
that= -X- _ O
0will -X- _ O
reduce -X- _ O
FGA -X- _ B-MetricName
to -X- _ O
JGA -X- _ B-MetricName
( -X- _ O
strict -X- _ O
metric -X- _ O
) -X- _ O
whereas -X- _ O
will -X- _ O
report -X- _ O
only -X- _ O
the -X- _ O
accuracy -X- _ O
on -X- _ O
turn -X- _ O
- -X- _ O
level -X- _ O
matches -X- _ O
( -X- _ O
relaxed -X- _ O
metric -X- _ O
) -X- _ O
. -X- _ O

Clearly -X- _ O
, -X- _ O
the -X- _ O
strictness -X- _ O
of -X- _ O
FGA -X- _ B-MetricName
is -X- _ O
inversely -X- _ O
proportional -X- _ O
to -X- _ O
. -X- _ O

1 -X- _ O
) -X- _ O
parameterized -X- _ O
by -X- _ O
where -X- _ O
0 -X- _ O
. -X- _ O

Algorithm -X- _ O
1 -X- _ O
: -X- _ O
FGA -X- _ B-MetricName
for -X- _ O
single -X- _ O
conversation -X- _ O
Input -X- _ O
: -X- _ O
B -X- _ O
= -X- _ O
list -X- _ O
of -X- _ O
groun -X- _ O
- -X- _ O
truth -X- _ O
belief -X- _ O
states -X- _ O
, -X- _ O
B= -X- _ O
list -X- _ O
of -X- _ O
predicted -X- _ O
belief -X- _ O
states -X- _ O
, -X- _ O
N= -X- _ O
# -X- _ O
turns -X- _ O
Output -X- _ O
: -X- _ O
Flexible -X- _ B-MetricName
goal -X- _ I-MetricName
accuracy -X- _ I-MetricName
1T={0,1 -X- _ O
, -X- _ O
. -X- _ O

Just -X- _ O
comparing -X- _ O
TtandT -X- _ O
tto -X- _ O
check -X- _ O
a -X- _ O
turn -X- _ O
- -X- _ O
level -X- _ O
or -X- _ O
local -X- _ O
match -X- _ O
can -X- _ O
be -X- _ O
erroneous -X- _ O
because -X- _ O
it -X- _ O
will -X- _ O
not -X- _ O
credit -X- _ O
the -X- _ O
model -X- _ O
for -X- _ O
error -X- _ O
corrections.320 -X- _ O
. -X- _ O

In -X- _ O
other -X- _ O
words -X- _ O
, -X- _ O
a -X- _ O
turn -X- _ O
- -X- _ O
level -X- _ O
or -X- _ O
local -X- _ O
match -X- _ O
indicates -X- _ O
that -X- _ O
all -X- _ O
the -X- _ O
intents -X- _ O
shown -X- _ O
by -X- _ O
the -X- _ O
user -X- _ O
in -X- _ O
a -X- _ O
particular -X- _ O
turn -X- _ O
have -X- _ O
been -X- _ O
correctly -X- _ O
detected -X- _ O
without -X- _ O
any -X- _ O
false -X- _ O
positives -X- _ O
. -X- _ O

A -X- _ O
turn -X- _ O
t -X- _ O
> -X- _ O
0is -X- _ O
locally -X- _ O
correct -X- _ O
if -X- _ O
( -X- _ O
T -X- _ O
tBtandTtB -X- _ O
t -X- _ O
) -X- _ O
where -X- _ O
Tt -X- _ O
= -X- _ O
Bt\Bt1andT -X- _ O
t -X- _ O
= -X- _ O
B -X- _ O
t\B -X- _ O
t1 -X- _ O
. -X- _ O

We -X- _ O
decide -X- _ O
the -X- _ O
correctness -X- _ O
of -X- _ O
a -X- _ O
turn -X- _ O
- -X- _ O
level -X- _ O
match -X- _ O
using -X- _ O
the -X- _ O
logic -X- _ O
shown -X- _ O
in -X- _ O
line -X- _ O
10 -X- _ O
of -X- _ O
Algo -X- _ O
. -X- _ O

The -X- _ O
main -X- _ O
idea -X- _ O
is -X- _ O
to -X- _ O
forget -X- _ O
the -X- _ O
mistakes -X- _ O
with -X- _ O
time -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
attain -X- _ O
a -X- _ O
fair -X- _ O
judgment -X- _ O
of -X- _ O
a -X- _ O
DST -X- _ B-MethodName
model -X- _ I-MethodName
offline -X- _ O
. -X- _ O

It -X- _ O
assigns -X- _ O
a -X- _ O
penalized -X- _ O
score -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
distance -X- _ O
between -X- _ O
the -X- _ O
error -X- _ O
turn -X- _ O
( -X- _ O
terr -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
current -X- _ O
turn -X- _ O
( -X- _ O
t -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
penalty -X- _ O
is -X- _ O
inversely -X- _ O
proportional -X- _ O
to -X- _ O
this -X- _ O
distance -X- _ O
( -X- _ O
tterr -X- _ O
) -X- _ O
. -X- _ O

Unlike -X- _ O
JGA -X- _ B-MetricName
, -X- _ O
FGA -X- _ B-MetricName
does -X- _ O
not -X- _ O
penalize -X- _ O
type -X- _ O
2 -X- _ O
errors -X- _ O
completely -X- _ O
. -X- _ O

FGA -X- _ B-MetricName
works -X- _ O
differently -X- _ O
from -X- _ O
JGA -X- _ B-MetricName
only -X- _ O
for -X- _ O
type -X- _ O
2 -X- _ O
errors -X- _ O
. -X- _ O

the -X- _ O
turn -X- _ O
- -X- _ O
level -X- _ O
prediction -X- _ O
is -X- _ O
wrong -X- _ O
, -X- _ O
2 -X- _ O
) -X- _ O
the -X- _ O
turn -X- _ O
- -X- _ O
level -X- _ O
prediction -X- _ O
of -X- _ O
turntis -X- _ O
correct -X- _ O
but -X- _ O
the -X- _ O
source -X- _ O
of -X- _ O
the -X- _ O
error -X- _ O
is -X- _ O
some -X- _ O
earlier -X- _ O
turn -X- _ O
terrt -X- _ O
. -X- _ O

Bt -X- _ O
= -X- _ O
B -X- _ O
t -X- _ O
) -X- _ O
can -X- _ O
occur -X- _ O
in -X- _ O
two -X- _ O
ways -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
the -X- _ O
source -X- _ O
of -X- _ O
the -X- _ O
error -X- _ O
is -X- _ O
turn -X- _ O
titself -X- _ O
i.e -X- _ O
. -X- _ O

For -X- _ O
a -X- _ O
given -X- _ O
a -X- _ O
turn -X- _ O
t -X- _ O
, -X- _ O
an -X- _ O
error -X- _ O
in -X- _ O
belief -X- _ O
state -X- _ O
prediction -X- _ O
( -X- _ O
i.e -X- _ O
. -X- _ O

The -X- _ O
description -X- _ O
of -X- _ O
FGA -X- _ B-MetricName
is -X- _ O
presented -X- _ O
in -X- _ O
the -X- _ O
next -X- _ O
part -X- _ O
of -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
whereas -X- _ O
its -X- _ O
working -X- _ O
is -X- _ O
described -X- _ O
as -X- _ O
a -X- _ O
pseudo -X- _ O
- -X- _ O
code -X- _ O
in -X- _ O
Algo -X- _ O
. -X- _ O

This -X- _ O
is -X- _ O
why -X- _ O
with -X- _ O
the -X- _ O
objective -X- _ O
to -X- _ O
obtain -X- _ O
a -X- _ O
better -X- _ O
evaluation -X- _ O
metric -X- _ O
for -X- _ O
DST -X- _ B-TaskName
, -X- _ O
we -X- _ O
address -X- _ O
the -X- _ O
shortcomings -X- _ O
of -X- _ O
JGA -X- _ B-MetricName
by -X- _ O
proposing -X- _ O
a -X- _ O
new -X- _ O
metric -X- _ O
called -X- _ O
Flexible -X- _ B-MetricName
goal -X- _ I-MetricName
accuracy -X- _ I-MetricName
( -X- _ I-MetricName
FGA -X- _ I-MetricName
) -X- _ I-MetricName
. -X- _ O

3 -X- _ O
Flexible -X- _ B-MetricName
Goal -X- _ I-MetricName
Accuracy -X- _ I-MetricName
From -X- _ O
the -X- _ O
previous -X- _ O
discussion -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
evident -X- _ O
that -X- _ O
despite -X- _ O
a -X- _ O
few -X- _ O
limitations -X- _ O
, -X- _ O
joint -X- _ B-MetricName
goal -X- _ I-MetricName
accuracy -X- _ I-MetricName
is -X- _ O
superior -X- _ O
to -X- _ O
the -X- _ O
other -X- _ O
two -X- _ O
metrics -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
even -X- _ O
if -X- _ O
turn -X- _ O
2 -X- _ O
and -X- _ O
4 -X- _ O
are -X- _ O
incorrect -X- _ O
, -X- _ O
we -X- _ O
get -X- _ O
an -X- _ O
AGA -X- _ B-MetricName
of -X- _ O
4/6 -X- _ B-MetricValue
and -X- _ O
5/7 -X- _ B-MetricValue
respectively -X- _ O
which -X- _ O
clearly -X- _ O
indicates -X- _ O
an -X- _ O
overestimation -X- _ O
. -X- _ O

Note -X- _ O
that -X- _ O
even -X- _ O
if -X- _ O
a -X- _ O
turn -X- _ O
is -X- _ O
completely -X- _ O
wrong -X- _ O
, -X- _ O
AGA -X- _ B-MetricName
for -X- _ O
that -X- _ O
turn -X- _ O
can -X- _ O
still -X- _ O
be -X- _ O
higher -X- _ O
because -X- _ O
of -X- _ O
the -X- _ O
correct -X- _ O
predictions -X- _ O
in -X- _ O
the -X- _ O
previous -X- _ O
turns -X- _ O
. -X- _ O

But -X- _ O
there -X- _ O
still -X- _ O
exists -X- _ O
a -X- _ O
second -X- _ O
major -X- _ O
problem -X- _ O
with -X- _ O
AGA -X- _ B-MetricName
. -X- _ O

However -X- _ O
, -X- _ O
this -X- _ O
issue -X- _ O
can -X- _ O
be -X- _ O
easily -X- _ O
addressed -X- _ O
by -X- _ O
redefining -X- _ O
AGA -X- _ B-MetricName
as|NtB -X- _ O
t| -X- _ O
|NtB -X- _ O
t| -X- _ O
. -X- _ O

Ignoring -X- _ O
the -X- _ O
false -X- _ B-MetricName
positives -X- _ I-MetricName
makes -X- _ O
this -X- _ O
metric -X- _ O
insensitive -X- _ O
to -X- _ O
extraneous -X- _ O
triplets -X- _ O
in -X- _ O
the -X- _ O
predicted -X- _ O
belief -X- _ O
state -X- _ O
. -X- _ O

Firstly -X- _ O
, -X- _ O
AGA -X- _ B-MetricName
is -X- _ O
only -X- _ O
recall -X- _ O
- -X- _ O
oriented -X- _ O
and -X- _ O
thereby -X- _ O
does -X- _ O
not -X- _ O
consider -X- _ O
the -X- _ O
false -X- _ O
positives -X- _ O
. -X- _ O

This -X- _ O
metric -X- _ O
has -X- _ O
mainly -X- _ O
two -X- _ O
limitations -X- _ O
. -X- _ O

1 -X- _ O
, -X- _ O
AGA -X- _ B-MetricName
for -X- _ O
turn -X- _ O
2 -X- _ O
is -X- _ O
4/6 -X- _ B-MetricValue
, -X- _ O
and -X- _ B-MetricValue
76.19% -X- _ I-MetricValue
for -X- _ O
the -X- _ O
entire -X- _ O
conversation -X- _ O
. -X- _ O

The -X- _ O
turns -X- _ O
having -X- _ O
Nt -X- _ O
= -X- _ O
are -X- _ O
ignored -X- _ O
during -X- _ O
the -X- _ O
computation -X- _ O
of -X- _ O
AGA -X- _ B-MetricName
. -X- _ O

Then -X- _ O
AGA -X- _ B-MetricName
is -X- _ O
computed -X- _ O
as -X- _ O
|NtB -X- _ O
t| -X- _ O
|Nt|where -X- _ O
B -X- _ O
tis -X- _ O
the -X- _ O
predicted -X- _ O
belief -X- _ O
state -X- _ O
forturnt -X- _ O
. -X- _ O

Let -X- _ O
NtBtbe -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
triplets -X- _ O
having -X- _ O
non -X- _ O
- -X- _ O
empty -X- _ O
slot -X- _ O
- -X- _ O
values -X- _ O
. -X- _ O

Here -X- _ O
, -X- _ O
the -X- _ O
slots -X- _ O
that -X- _ O
have -X- _ O
a -X- _ O
nonempty -X- _ O
assignment -X- _ O
in -X- _ O
the -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
dialogue -X- _ O
state -X- _ O
are -X- _ O
only -X- _ O
considered -X- _ O
during -X- _ O
evaluation -X- _ O
. -X- _ O

2.3 -X- _ O
Average -X- _ B-MetricName
Goal -X- _ I-MetricName
accuracy -X- _ I-MetricName
Average -X- _ B-MetricName
goal -X- _ I-MetricName
accuracy -X- _ I-MetricName
( -X- _ I-MetricName
AGA -X- _ I-MetricName
) -X- _ I-MetricName
is -X- _ O
a -X- _ O
relatively -X- _ O
newer -X- _ O
metric -X- _ O
proposed -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
SGD -X- _ B-DatasetName
dataset -X- _ I-DatasetName
( -X- _ O
Rastogi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

Thus -X- _ O
, -X- _ O
slot -X- _ B-MetricName
accuracy -X- _ I-MetricName
is -X- _ O
a -X- _ O
poor -X- _ O
metric -X- _ O
to -X- _ O
evaluate -X- _ O
DST -X- _ B-TaskName
. -X- _ O

For -X- _ O
datasets -X- _ O
with -X- _ O
a -X- _ O
larger -X- _ O
number -X- _ O
of -X- _ O
domain -X- _ O
/ -X- _ O
slots -X- _ O
, -X- _ O
since -X- _ O
|S|is -X- _ O
large -X- _ O
, -X- _ O
slot -X- _ B-MetricName
accuracy -X- _ I-MetricName
will -X- _ O
be -X- _ O
close -X- _ O
to -X- _ O
1 -X- _ B-MetricValue
for -X- _ O
almost -X- _ O
all -X- _ O
scenarios -X- _ O
. -X- _ O

As -X- _ O
a -X- _ O
result -X- _ O
, -X- _ O
slot -X- _ B-MetricName
accuracy -X- _ I-MetricName
remains -X- _ O
on -X- _ O
the -X- _ O
higher -X- _ O
side -X- _ O
( -X- _ O
81% -X- _ B-MetricValue
for -X- _ O
MultiWOZ -X- _ B-DatasetName
2.1 -X- _ I-DatasetName
) -X- _ O
even -X- _ O
if -X- _ O
we -X- _ O
predict -X- _ O
nothing -X- _ O
. -X- _ O

It -X- _ O
is -X- _ O
natural -X- _ O
that -X- _ O
|Bt|<<|S|because -X- _ O
a -X- _ O
conversation -X- _ O
will -X- _ O
typically -X- _ O
have -X- _ O
only -X- _ O
a -X- _ O
small -X- _ O
number -X- _ O
of -X- _ O
domain -X- _ O
- -X- _ O
slot -X- _ O
pairs -X- _ O
live -X- _ O
at -X- _ O
any -X- _ O
time -X- _ O
. -X- _ O

Then -X- _ O
, -X- _ O
slot -X- _ B-MetricName
accuracy -X- _ I-MetricName
simplifies -X- _ O
to|S||Bt| -X- _ O
|S| -X- _ O
. -X- _ O

Let -X- _ O
us -X- _ O
exhibit -X- _ O
this -X- _ O
fact -X- _ O
by -X- _ O
considering -X- _ O
the -X- _ O
case -X- _ O
where -X- _ O
we -X- _ O
predict -X- _ O
nothing -X- _ O
for -X- _ O
all -X- _ O
turns -X- _ O
i.e -X- _ O
. -X- _ O

Basically -X- _ O
, -X- _ O
slot -X- _ B-MetricName
accuracy -X- _ I-MetricName
overestimates -X- _ O
the -X- _ O
DST -X- _ B-TaskName
performance -X- _ O
. -X- _ O

1 -X- _ O
, -X- _ O
we -X- _ O
get -X- _ O
a -X- _ O
slot -X- _ B-MetricName
accuracy -X- _ I-MetricName
of -X- _ O
93.33% -X- _ B-MetricValue
which -X- _ O
is -X- _ O
extremely -X- _ O
high -X- _ O
. -X- _ O

For -X- _ O
instance -X- _ O
, -X- _ O
even -X- _ O
if -X- _ O
the -X- _ O
prediction -X- _ O
of -X- _ O
Turn -X- _ O
2 -X- _ O
is -X- _ O
wrong -X- _ O
in -X- _ O
Fig -X- _ O
. -X- _ O

The -X- _ O
value -X- _ O
of -X- _ O
slot -X- _ B-MetricName
accuracy -X- _ I-MetricName
can -X- _ O
be -X- _ O
very -X- _ O
misleading -X- _ O
. -X- _ O

Slot -X- _ B-MetricName
accuracy -X- _ I-MetricName
for -X- _ O
the -X- _ O
entire -X- _ O
conversation -X- _ O
in -X- _ O
Fig -X- _ O
. -X- _ O

For -X- _ O
Turn -X- _ O
2 -X- _ O
in -X- _ O
our -X- _ O
running -X- _ O
example -X- _ O
, -X- _ O
since -X- _ O
|B1\B -X- _ O
1|= -X- _ O
2and|B -X- _ O
1\B1|= -X- _ O
0 -X- _ O
, -X- _ O
slot -X- _ O
accuracy -X- _ O
is -X- _ O
equal -X- _ O
to(30200 -X- _ O
) -X- _ O
30i.e -X- _ O
. -X- _ O

In -X- _ O
MultiWOZ -X- _ B-DatasetName
, -X- _ O
the -X- _ O
value -X- _ O
of -X- _ O
|S| -X- _ O
is -X- _ O
30 -X- _ O
. -X- _ O

The -X- _ O
term|PQ|in -X- _ O
the -X- _ O
above -X- _ O
equation -X- _ O
helps -X- _ O
to -X- _ O
rectify -X- _ O
this -X- _ O
overcounting -X- _ O
. -X- _ O

Note -X- _ O
that -X- _ O
if -X- _ O
the -X- _ O
value -X- _ O
of -X- _ O
a -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
domain -X- _ O
- -X- _ O
slot -X- _ O
pair -X- _ O
is -X- _ O
wrongly -X- _ O
predicted -X- _ O
then -X- _ O
this -X- _ O
misprediction -X- _ O
will -X- _ O
be -X- _ O
counted -X- _ O
twice -X- _ O
( -X- _ O
once -X- _ O
in -X- _ O
both -X- _ O
XandY -X- _ O
) -X- _ O
. -X- _ O

Basically -X- _ O
, -X- _ O
in -X- _ O
Equation -X- _ O
1 -X- _ O
, -X- _ O
|X|and|Y|represent -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
false -X- _ O
negatives -X- _ O
and -X- _ O
false -X- _ O
positives -X- _ O
respectively -X- _ O
. -X- _ O

Then -X- _ O
slot -X- _ B-MetricName
accuracy -X- _ I-MetricName
at -X- _ O
turn -X- _ O
tis -X- _ O
defined -X- _ O
as -X- _ O
SA=|S| -X- _ O
|X| -X- _ O
|Y|+|PQ| -X- _ O
|S| -X- _ O
, -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
where -X- _ O
X= -X- _ O
( -X- _ O
Bt\B -X- _ O
t),Y= -X- _ O
( -X- _ O
B -X- _ O
t\Bt),Pis -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
unique -X- _ O
domain -X- _ O
- -X- _ O
slot -X- _ O
pairs -X- _ O
from -X- _ O
X -X- _ O
, -X- _ O
andQis -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
unique -X- _ O
domain -X- _ O
- -X- _ O
slot -X- _ O
pairs -X- _ O
from -X- _ O
Y -X- _ O
. -X- _ O

Let -X- _ O
BtandB -X- _ O
tbe -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
and -X- _ O
predicted -X- _ O
belief -X- _ O
states -X- _ O
respectively -X- _ O
. -X- _ O

Let -X- _ O
Sbe -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
unique -X- _ O
domainslot -X- _ O
pairs -X- _ O
in -X- _ O
the -X- _ O
dataset -X- _ O
. -X- _ O

2.2 -X- _ O
Slot -X- _ B-MetricName
Accuracy -X- _ I-MetricName
Slot -X- _ B-MetricName
accuracy -X- _ I-MetricName
( -X- _ I-MetricName
SA -X- _ I-MetricName
) -X- _ I-MetricName
is -X- _ O
a -X- _ O
relaxed -X- _ O
version -X- _ O
of -X- _ O
JGA -X- _ B-MetricName
that -X- _ O
compares -X- _ O
each -X- _ O
predicted -X- _ O
( -X- _ O
domain -X- _ O
, -X- _ O
slot -X- _ O
, -X- _ O
slot -X- _ O
- -X- _ O
value -X- _ O
) -X- _ O
triplet -X- _ O
to -X- _ O
its -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
label -X- _ O
individually -X- _ O
( -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

Otherwise -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
need -X- _ O
to -X- _ O
include -X- _ O
turn -X- _ O
- -X- _ O
level -X- _ O
performance -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
obtain -X- _ O
a -X- _ O
fair -X- _ O
evaluation -X- _ O
of -X- _ O
a -X- _ O
DST -X- _ B-TaskName
model.319 -X- _ O
. -X- _ O

Hence -X- _ O
, -X- _ O
using -X- _ O
joint -X- _ O
goal -X- _ O
accuracy -X- _ O
for -X- _ O
evaluating -X- _ O
DST -X- _ B-TaskName
works -X- _ O
fine -X- _ O
if -X- _ O
there -X- _ O
are -X- _ O
no -X- _ O
annotation -X- _ O
errors -X- _ O
and -X- _ O
the -X- _ O
sole -X- _ O
purpose -X- _ O
is -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
prediction -X- _ O
of -X- _ O
cumulative -X- _ O
belief -X- _ O
state -X- _ O
. -X- _ O

So -X- _ O
, -X- _ O
if -X- _ O
a -X- _ O
mismatch -X- _ O
occurs -X- _ O
due -X- _ O
to -X- _ O
an -X- _ O
annotation -X- _ O
error -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
highly -X- _ O
probable -X- _ O
that -X- _ O
all -X- _ O
the -X- _ O
subsequent -X- _ O
turns -X- _ O
will -X- _ O
be -X- _ O
marked -X- _ O
incorrect -X- _ O
leading -X- _ O
to -X- _ O
an -X- _ O
underestimated -X- _ O
performance -X- _ O
. -X- _ O

Although -X- _ O
the -X- _ O
prediction -X- _ O
looks -X- _ O
rational -X- _ O
, -X- _ O
the -X- _ O
triplet -X- _ O
is -X- _ O
absent -X- _ O
in -X- _ O
the -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
in -X- _ O
turn -X- _ O
4 -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
has -X- _ O
predicted -X- _ O
the -X- _ O
intent -X- _ O
( -X- _ O
attraction -X- _ O
, -X- _ O
name -X- _ O
, -X- _ O
all -X- _ O
saints -X- _ O
church -X- _ O
) -X- _ O
. -X- _ O

Besides -X- _ O
, -X- _ O
the -X- _ O
available -X- _ O
DST -X- _ B-DatasetName
datasets -X- _ I-DatasetName
( -X- _ O
like -X- _ O
MultiWOZ -X- _ B-DatasetName
) -X- _ O
contain -X- _ O
a -X- _ O
lot -X- _ O
of -X- _ O
annotation -X- _ O
errors -X- _ O
( -X- _ O
Zang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

using -X- _ O
only -X- _ O
joint -X- _ B-MetricName
accuracy -X- _ I-MetricName
for -X- _ O
model -X- _ O
selection -X- _ O
. -X- _ O

Arrows -X- _ O
represent -X- _ O
the -X- _ O
propagation -X- _ O
of -X- _ O
errors -X- _ O
. -X- _ O

Turn -X- _ O
Match -X- _ O
indicates -X- _ O
the -X- _ O
correctness -X- _ O
of -X- _ O
turn -X- _ O
- -X- _ O
level -X- _ O
noncumulative -X- _ O
belief -X- _ O
state -X- _ O
prediction -X- _ O
. -X- _ O

Exact -X- _ O
Match -X- _ O
compares -X- _ O
Ground -X- _ O
truth -X- _ O
belief -X- _ O
state -X- _ O
Btand -X- _ O
Predicted -X- _ O
belief -X- _ O
state -X- _ O
B -X- _ O
t -X- _ O
. -X- _ O

B5 -X- _ O
{ -X- _ O
attraction -X- _ O
: -X- _ O
{ -X- _ O
area -X- _ O
: -X- _ O
centre -X- _ O
} -X- _ O
, -X- _ O
hotel -X- _ O
: -X- _ O
{ -X- _ O
area -X- _ O
: -X- _ O
centre -X- _ O
, -X- _ O
day -X- _ O
: -X- _ O
wednesday -X- _ O
, -X- _ O
people -X- _ O
: -X- _ O
4 -X- _ O
, -X- _ O
stay -X- _ O
: -X- _ O
2 -X- _ O
, -X- _ O
name -X- _ O
: -X- _ O
cityroomz -X- _ O
, -X- _ O
stars -X- _ O
: -X- _ O
0 -X- _ O
} -X- _ O
} -X- _ O
B'5 -X- _ O
{ -X- _ O
attraction -X- _ O
: -X- _ O
{ -X- _ O
area -X- _ O
: -X- _ O
centre -X- _ O
, -X- _ O
name -X- _ O
: -X- _ O
all -X- _ O
saints -X- _ O
church -X- _ O
} -X- _ O
, -X- _ O
hotel -X- _ O
: -X- _ O
{ -X- _ O
day -X- _ O
: -X- _ O
wednesday -X- _ O
, -X- _ O
people -X- _ O
: -X- _ O
4 -X- _ O
, -X- _ O
stay -X- _ O
: -X- _ O
2 -X- _ O
, -X- _ O
name -X- _ O
: -X- _ O
cityroomz -X- _ O
} -X- _ O
} -X- _ O
Figure -X- _ O
1 -X- _ O
: -X- _ O
Illustration -X- _ O
of -X- _ O
DST -X- _ B-TaskName
task -X- _ I-TaskName
. -X- _ O

Goodbye -X- _ O
. -X- _ O

That -X- _ O
's -X- _ O
all -X- _ O
I -X- _ O
need -X- _ O
. -X- _ O

Thanks -X- _ O
! -X- _ O
B4 -X- _ O
{ -X- _ O
attraction -X- _ O
: -X- _ O
{ -X- _ O
area -X- _ O
: -X- _ O
centre -X- _ O
} -X- _ O
, -X- _ O
hotel -X- _ O
: -X- _ O
{ -X- _ O
area -X- _ O
: -X- _ O
centre -X- _ O
, -X- _ O
day -X- _ O
: -X- _ O
wednesday -X- _ O
, -X- _ O
people -X- _ O
: -X- _ O
4 -X- _ O
, -X- _ O
stay -X- _ O
: -X- _ O
2 -X- _ O
, -X- _ O
name -X- _ O
: -X- _ O
cityroomz -X- _ O
, -X- _ O
stars -X- _ O
: -X- _ O
0 -X- _ O
} -X- _ O
} -X- _ O
B'4 -X- _ O
{ -X- _ O
attraction -X- _ O
: -X- _ O
{ -X- _ O
area -X- _ O
: -X- _ O
centre -X- _ O
, -X- _ O
name -X- _ O
: -X- _ O
all -X- _ O
saints -X- _ O
church -X- _ O
} -X- _ O
, -X- _ O
hotel -X- _ O
: -X- _ O
{ -X- _ O
day -X- _ O
: -X- _ O
wednesday -X- _ O
, -X- _ O
people -X- _ O
: -X- _ O
4 -X- _ O
, -X- _ O
stay -X- _ O
: -X- _ O
2 -X- _ O
, -X- _ O
name -X- _ O
: -X- _ O
cityroomz -X- _ O
} -X- _ O
} -X- _ O
5 -X- _ O
S5 -X- _ O
Can -X- _ O
I -X- _ O
help -X- _ O
you -X- _ O
with -X- _ O
anything -X- _ O
else -X- _ O
? -X- _ O
U5 -X- _ O
No -X- _ O
thanks -X- _ O
. -X- _ O

U4 -X- _ O
That -X- _ O
sounds -X- _ O
perfect -X- _ O
. -X- _ O

B3 -X- _ O
{ -X- _ O
attraction -X- _ O
: -X- _ O
{ -X- _ O
area -X- _ O
: -X- _ O
centre -X- _ O
} -X- _ O
, -X- _ O
hotel -X- _ O
: -X- _ O
{ -X- _ O
area -X- _ O
: -X- _ O
centre -X- _ O
, -X- _ O
day -X- _ O
: -X- _ O
wednesday -X- _ O
, -X- _ O
people -X- _ O
: -X- _ O
4 -X- _ O
, -X- _ O
stay -X- _ O
: -X- _ O
2 -X- _ O
, -X- _ O
name -X- _ O
: -X- _ O
cityroomz -X- _ O
, -X- _ O
stars -X- _ O
: -X- _ O
0 -X- _ O
} -X- _ O
} -X- _ O
B'3 -X- _ O
{ -X- _ O
attraction -X- _ O
: -X- _ O
{ -X- _ O
area -X- _ O
: -X- _ O
centre -X- _ O
} -X- _ O
, -X- _ O
hotel -X- _ O
: -X- _ O
{ -X- _ O
day -X- _ O
: -X- _ O
wednesday -X- _ O
, -X- _ O
people -X- _ O
: -X- _ O
4 -X- _ O
, -X- _ O
stay -X- _ O
: -X- _ O
2 -X- _ O
, -X- _ O
name -X- _ O
: -X- _ O
cityroomz -X- _ O
} -X- _ O
} -X- _ O
4 -X- _ O
S4 -X- _ O
I -X- _ O
have -X- _ O
the -X- _ O
all -X- _ O
saints -X- _ O
church -X- _ O
located -X- _ O
at -X- _ O
jesus -X- _ O
lane -X- _ O
and -X- _ O
it -X- _ O
's -X- _ O
free -X- _ O
entrance -X- _ O
. -X- _ O

Perhaps -X- _ O
an -X- _ O
attraction -X- _ O
in -X- _ O
the -X- _ O
city -X- _ O
centre -X- _ O
. -X- _ O

I -X- _ O
am -X- _ O
also -X- _ O
looking -X- _ O
for -X- _ O
places -X- _ O
to -X- _ O
go -X- _ O
in -X- _ O
town -X- _ O
. -X- _ O

U2 -X- _ O
Can -X- _ O
you -X- _ O
please -X- _ O
book -X- _ O
a -X- _ O
room -X- _ O
for -X- _ O
4 -X- _ O
people -X- _ O
for -X- _ O
2 -X- _ O
nights -X- _ O
starting -X- _ O
on -X- _ O
wednesday -X- _ O
? -X- _ O
B2 -X- _ O
{ -X- _ O
hotel -X- _ O
: -X- _ O
{ -X- _ O
area -X- _ O
: -X- _ O
centre -X- _ O
, -X- _ O
day -X- _ O
: -X- _ O
wednesday -X- _ O
, -X- _ O
people -X- _ O
: -X- _ O
4 -X- _ O
, -X- _ O
stay -X- _ O
: -X- _ O
2 -X- _ O
, -X- _ O
name -X- _ O
: -X- _ O
cityroomz -X- _ O
, -X- _ O
stars -X- _ O
: -X- _ O
0 -X- _ O
} -X- _ O
} -X- _ O
B'2 -X- _ O
{ -X- _ O
hotel -X- _ O
: -X- _ O
{ -X- _ O
day -X- _ O
: -X- _ O
wednesday -X- _ O
, -X- _ O
people -X- _ O
: -X- _ O
4 -X- _ O
, -X- _ O
stay -X- _ O
: -X- _ O
2 -X- _ O
, -X- _ O
name -X- _ O
: -X- _ O
cityroomz -X- _ O
} -X- _ O
} -X- _ O
3 -X- _ O
S3 -X- _ O
Booking -X- _ O
was -X- _ O
successful -X- _ O
. -X- _ O
Reference -X- _ O
number -X- _ O
is -X- _ O
: -X- _ O
WGUYAGN2 -X- _ O
anything -X- _ O
else -X- _ O
i -X- _ O
can -X- _ O
help -X- _ O
? -X- _ O
U3 -X- _ O
Thanks -X- _ O
. -X- _ O

Its -X- _ O
address -X- _ O
is -X- _ O
Sleeperz -X- _ O
Hotel -X- _ O
, -X- _ O
Station -X- _ O
Road -X- _ O
. -X- _ O

B0 -X- _ O
{ -X- _ O
} -X- _ O
B'0 -X- _ O
{ -X- _ O
} -X- _ O
1 -X- _ O
S1 -X- _ O
We -X- _ O
have -X- _ O
79 -X- _ O
attractions -X- _ O
to -X- _ O
choose -X- _ O
from -X- _ O
, -X- _ O
anything -X- _ O
specific -X- _ O
that -X- _ O
you -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
tell -X- _ O
us -X- _ O
to -X- _ O
help -X- _ O
narrow -X- _ O
it -X- _ O
down -X- _ O
? -X- _ O
U1 -X- _ O
I -X- _ O
'm -X- _ O
looking -X- _ O
for -X- _ O
a -X- _ O
hotel -X- _ O
called -X- _ O
cityroomz -X- _ O
. -X- _ O

I -X- _ O
am -X- _ O
so -X- _ O
excited -X- _ O
to -X- _ O
see -X- _ O
some -X- _ O
local -X- _ O
tourist -X- _ O
attractions -X- _ O
. -X- _ O

So -X- _ O
, -X- _ O
one -X- _ O
should -X- _ O
be -X- _ O
careful -X- _ O
while -X- _ O
1Code -X- _ O
is -X- _ O
available -X- _ O
at -X- _ O
github.com/SuvodipDey/FGA -X- _ B-MetricName
Turn -X- _ O
Conversation -X- _ O
Details -X- _ O
Exact -X- _ O
match -X- _ O
Turn -X- _ O
match -X- _ O
0 -X- _ O
U0 -X- _ O
Hi -X- _ O
, -X- _ O
I -X- _ O
am -X- _ O
traveling -X- _ O
to -X- _ O
Cambridge -X- _ O
and -X- _ O
could -X- _ O
use -X- _ O
some -X- _ O
help -X- _ O
for -X- _ O
sure -X- _ O
. -X- _ O

But -X- _ O
we -X- _ O
observed -X- _ O
that -X- _ O
sometimes -X- _ O
increasing -X- _ O
exact -X- _ O
matches -X- _ O
can -X- _ O
decrease -X- _ O
turn -X- _ O
- -X- _ O
level -X- _ O
matches -X- _ O
mainly -X- _ O
due -X- _ O
to -X- _ O
annotation -X- _ O
inconsistencies -X- _ O
. -X- _ O

Normally -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
expected -X- _ O
that -X- _ O
increasing -X- _ O
the -X- _ O
exact -X- _ O
matches -X- _ O
will -X- _ O
also -X- _ O
reflect -X- _ O
in -X- _ O
turn -X- _ O
- -X- _ O
level -X- _ O
matches -X- _ O
. -X- _ O

1 -X- _ O
, -X- _ O
Turn -X- _ O
3 -X- _ O
and5are -X- _ O
locally -X- _ O
correct -X- _ O
but -X- _ O
JGA -X- _ B-MetricName
will -X- _ O
mark -X- _ O
them -X- _ O
0 -X- _ O
sinceBtandB -X- _ O
thas -X- _ O
not -X- _ O
matched -X- _ O
exactly -X- _ O
. -X- _ O

In -X- _ O
addition -X- _ O
, -X- _ O
JGA -X- _ B-MetricName
does -X- _ O
not -X- _ O
take -X- _ O
into -X- _ O
account -X- _ O
turnlevel -X- _ O
performances -X- _ O
. -X- _ O

Therefore -X- _ O
, -X- _ O
JGA -X- _ B-MetricName
can -X- _ O
undermine -X- _ O
the -X- _ O
true -X- _ O
potential -X- _ O
of -X- _ O
a -X- _ O
DST -X- _ B-MethodName
model -X- _ I-MethodName
and -X- _ O
provide -X- _ O
an -X- _ O
underestimated -X- _ O
performance -X- _ O
. -X- _ O

So -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
very -X- _ O
likely -X- _ O
to -X- _ O
get -X- _ O
a -X- _ O
JGA -X- _ B-MetricName
of -X- _ O
zero -X- _ O
if -X- _ O
the -X- _ O
model -X- _ O
somehow -X- _ O
mispredicts -X- _ O
the -X- _ O
first -X- _ O
turn -X- _ O
. -X- _ O

1 -X- _ O
, -X- _ O
the -X- _ O
prediction -X- _ O
goes -X- _ O
wrong -X- _ O
in -X- _ O
Turn -X- _ O
2which -X- _ O
affects -X- _ O
all -X- _ O
the -X- _ O
later -X- _ O
predictions -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
in -X- _ O
Fig -X- _ O
. -X- _ O

As -X- _ O
a -X- _ O
result -X- _ O
, -X- _ O
once -X- _ O
a -X- _ O
misprediction -X- _ O
has -X- _ O
occurred -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
difficult -X- _ O
to -X- _ O
get -X- _ O
back -X- _ O
a -X- _ O
correct -X- _ O
prediction -X- _ O
in -X- _ O
subsequent -X- _ O
turns -X- _ O
. -X- _ O

The -X- _ O
main -X- _ O
source -X- _ O
of -X- _ O
the -X- _ O
issue -X- _ O
is -X- _ O
the -X- _ O
cumulative -X- _ O
nature -X- _ O
of -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
Bt -X- _ O
. -X- _ O

Although -X- _ O
joint -X- _ B-MetricName
goal -X- _ I-MetricName
accuracy -X- _ I-MetricName
is -X- _ O
a -X- _ O
convenient -X- _ O
metric -X- _ O
to -X- _ O
evaluate -X- _ O
DST -X- _ B-TaskName
, -X- _ O
it -X- _ O
has -X- _ O
certain -X- _ O
limitations -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
example -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
2 -X- _ O
out -X- _ O
of -X- _ O
6 -X- _ O
correct -X- _ O
predictions -X- _ O
ofB -X- _ O
tthat -X- _ O
result -X- _ O
in -X- _ O
a -X- _ O
JGA -X- _ B-MetricName
score -X- _ I-MetricName
of -X- _ O
33.33% -X- _ B-MetricValue
for -X- _ O
the -X- _ O
whole -X- _ O
conversation -X- _ O
. -X- _ O

1 -X- _ O
shows -X- _ O
an -X- _ O
illustration -X- _ O
of -X- _ O
the -X- _ O
predicted -X- _ O
belief -X- _ O
state -X- _ O
where -X- _ O
the -X- _ O
predictions -X- _ O
of -X- _ O
B -X- _ O
tare -X- _ O
generated -X- _ O
using -X- _ O
SOM -X- _ B-MethodName
- -X- _ I-MethodName
DST -X- _ I-MethodName
( -X- _ O
Kim -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

Then -X- _ O
the -X- _ O
prediction -X- _ O
of -X- _ O
turn -X- _ O
tis -X- _ O
considered -X- _ O
to -X- _ O
be -X- _ O
correct -X- _ O
if -X- _ O
and -X- _ O
only -X- _ O
if -X- _ O
Btexactly -X- _ O
matches -X- _ O
B -X- _ O
t -X- _ O
. -X- _ O

Let -X- _ O
Btand -X- _ O
B -X- _ O
tbe -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
and -X- _ O
predicted -X- _ O
belief -X- _ O
states -X- _ O
at -X- _ O
turn -X- _ O
t -X- _ O
. -X- _ O

2 -X- _ O
Discussion -X- _ O
on -X- _ O
existing -X- _ O
DST -X- _ B-MetricName
metrics -X- _ I-MetricName
2.1 -X- _ O
Joint -X- _ B-MetricName
goal -X- _ I-MetricName
accuracy -X- _ I-MetricName
Joint -X- _ B-MetricName
accuracy -X- _ I-MetricName
or -X- _ O
joint -X- _ B-MetricName
goal -X- _ I-MetricName
accuracy -X- _ I-MetricName
( -X- _ I-MetricName
JGA -X- _ I-MetricName
) -X- _ I-MetricName
checks -X- _ O
whether -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
predicted -X- _ O
belief -X- _ O
states -X- _ O
exactly -X- _ O
matches -X- _ O
the -X- _ O
ground -X- _ O
truth -X- _ O
for -X- _ O
a -X- _ O
given -X- _ O
user -X- _ O
turn -X- _ O
( -X- _ O
Henderson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
; -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

Justification -X- _ O
of -X- _ O
FGA -X- _ B-MetricName
along -X- _ O
with -X- _ O
performance -X- _ O
comparison -X- _ O
on -X- _ O
the -X- _ O
MultiWOZ -X- _ B-DatasetName
dataset -X- _ I-DatasetName
. -X- _ O

Proposal -X- _ O
of -X- _ O
Flexible -X- _ B-MetricName
Goal -X- _ I-MetricName
Accuracy -X- _ I-MetricName
( -X- _ I-MetricName
FGA -X- _ I-MetricName
) -X- _ I-MetricName
than -X- _ O
can -X- _ O
keep -X- _ O
track -X- _ O
of -X- _ O
both -X- _ O
joint -X- _ O
and -X- _ O
turnlevel -X- _ O
performances -X- _ O
simultaneously -X- _ O
. -X- _ O

The -X- _ O
main -X- _ O
contributions -X- _ O
of -X- _ O
our -X- _ O
work -X- _ O
are -X- _ O
as -X- _ O
follows1 -X- _ O
: -X- _ O
Detailed -X- _ O
analysis -X- _ O
of -X- _ O
the -X- _ O
existing -X- _ O
DST -X- _ B-TaskName
metrics -X- _ O
. -X- _ O

the -X- _ O
source -X- _ O
of -X- _ O
the -X- _ O
misprediction -X- _ O
is -X- _ O
some -X- _ O
earlier -X- _ O
turn -X- _ O
. -X- _ O

FGA -X- _ B-MetricName
is -X- _ O
to -X- _ O
partially -X- _ O
penalize -X- _ O
a -X- _ O
misprediction -X- _ O
which -X- _ O
is -X- _ O
locally -X- _ O
correct -X- _ O
i.e -X- _ O
. -X- _ O

The -X- _ O
central -X- _ O
idea -X- _ O
of318 -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
address -X- _ O
these -X- _ O
issues -X- _ O
of -X- _ O
JGA -X- _ B-MetricName
by -X- _ O
proposing -X- _ O
a -X- _ O
novel -X- _ O
evaluation -X- _ O
metric -X- _ O
for -X- _ O
DST -X- _ B-TaskName
called -X- _ O
Flexible -X- _ B-MetricName
GoalAccuracy -X- _ I-MetricName
( -X- _ I-MetricName
FGA -X- _ I-MetricName
) -X- _ I-MetricName
. -X- _ O

Hence -X- _ O
, -X- _ O
to -X- _ O
provide -X- _ O
a -X- _ O
fair -X- _ O
estimate -X- _ O
, -X- _ O
it -X- _ O
requires -X- _ O
not -X- _ O
only -X- _ O
track -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
cumulative -X- _ O
belief -X- _ O
state -X- _ O
but -X- _ O
also -X- _ O
turn -X- _ O
- -X- _ O
level -X- _ O
belief -X- _ O
state -X- _ O
as -X- _ O
well -X- _ O
. -X- _ O

Annotation -X- _ O
inconsistencies -X- _ O
and -X- _ O
errors -X- _ O
are -X- _ O
common -X- _ O
in -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
datasets -X- _ O
. -X- _ O

So -X- _ O
, -X- _ O
the -X- _ O
generalization -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
may -X- _ O
get -X- _ O
compromised -X- _ O
if -X- _ O
the -X- _ O
model -X- _ O
selection -X- _ O
is -X- _ O
done -X- _ O
only -X- _ O
using -X- _ O
JGA -X- _ B-MetricName
. -X- _ O

1 -X- _ O
, -X- _ O
the -X- _ O
presence -X- _ O
of(hotel -X- _ O
, -X- _ O
area -X- _ O
, -X- _ O
centre -X- _ O
) -X- _ O
and -X- _ O
absence -X- _ O
of -X- _ O
( -X- _ O
attraction -X- _ O
, -X- _ O
name -X- _ O
, -X- _ O
all -X- _ O
saints -X- _ O
church -X- _ O
) -X- _ O
in -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
B2and -X- _ O
B4shows -X- _ O
such -X- _ O
inconsistencies -X- _ O
. -X- _ O

But -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
improving -X- _ O
JGA -X- _ B-MetricName
can -X- _ O
sometimes -X- _ O
degrade -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
predicting -X- _ O
Ttmainly -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
presence -X- _ O
of -X- _ O
annotation -X- _ O
inconsistencies -X- _ O
in -X- _ O
the -X- _ O
available -X- _ O
datasets -X- _ O
. -X- _ O

Ideally -X- _ O
, -X- _ O
a -X- _ O
model -X- _ O
with -X- _ O
higher -X- _ O
JGA -X- _ B-MetricName
should -X- _ O
also -X- _ O
perform -X- _ O
equally -X- _ O
well -X- _ O
to -X- _ O
predict -X- _ O
Tt -X- _ O
. -X- _ O

Let -X- _ O
Ttbe -X- _ O
the -X- _ O
turn -X- _ O
- -X- _ O
level -X- _ O
belief -X- _ O
state -X- _ O
that -X- _ O
contains -X- _ O
all -X- _ O
the -X- _ O
intents -X- _ O
or -X- _ O
( -X- _ O
domain -X- _ O
, -X- _ O
slot -X- _ O
, -X- _ O
slot -X- _ O
- -X- _ O
value -X- _ O
) -X- _ O
triplets -X- _ O
expressed -X- _ O
by -X- _ O
the -X- _ O
user -X- _ O
only -X- _ O
at -X- _ O
turnt -X- _ O
. -X- _ O

Besides -X- _ O
, -X- _ O
JGA -X- _ B-MetricName
completely -X- _ O
ignores -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
turn -X- _ O
- -X- _ O
specific -X- _ O
local -X- _ O
predictions -X- _ O
. -X- _ O

This -X- _ O
is -X- _ O
why -X- _ O
it -X- _ O
can -X- _ O
provide -X- _ O
an -X- _ O
underestimated -X- _ O
performance -X- _ O
in -X- _ O
certain -X- _ O
cases -X- _ O
. -X- _ O

As -X- _ O
the -X- _ O
belief -X- _ O
state -X- _ O
is -X- _ O
cumulative -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
very -X- _ O
unlikely -X- _ O
for -X- _ O
a -X- _ O
model -X- _ O
to -X- _ O
get -X- _ O
back -X- _ O
a -X- _ O
correct -X- _ O
prediction -X- _ O
after -X- _ O
a -X- _ O
misprediction -X- _ O
. -X- _ O

It -X- _ O
compares -X- _ O
the -X- _ O
predicted -X- _ O
dialogue -X- _ O
states -X- _ O
to -X- _ O
the -X- _ O
ground -X- _ O
truth -X- _ O
Btat -X- _ O
each -X- _ O
dialogue -X- _ O
turn -X- _ O
t(Henderson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
primary -X- _ O
metric -X- _ O
for -X- _ O
evaluating -X- _ O
DST -X- _ B-TaskName
is -X- _ O
Joint -X- _ B-MetricName
Goal -X- _ I-MetricName
Accuracy -X- _ I-MetricName
( -X- _ I-MetricName
JGA -X- _ I-MetricName
) -X- _ I-MetricName
. -X- _ O

The -X- _ O
objective -X- _ O
of -X- _ O
DST -X- _ B-TaskName
is -X- _ O
to -X- _ O
predict -X- _ O
Btgiven -X- _ O
the -X- _ O
dialogue -X- _ O
history -X- _ O
till -X- _ O
turn -X- _ O
t -X- _ O
. -X- _ O

Belief -X- _ O
state -X- _ O
Btfor -X- _ O
turn -X- _ O
tis -X- _ O
defined -X- _ O
as -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
( -X- _ O
domain -X- _ O
, -X- _ O
slot -X- _ O
, -X- _ O
slot -X- _ O
- -X- _ O
value -X- _ O
) -X- _ O
triplets -X- _ O
that -X- _ O
have -X- _ O
been -X- _ O
extracted -X- _ O
till -X- _ O
turn -X- _ O
t -X- _ O
, -X- _ O
thereby -X- _ O
it -X- _ O
is -X- _ O
cumulative -X- _ O
in -X- _ O
nature -X- _ O
. -X- _ O

The -X- _ O
commonly -X- _ O
used -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
dialogue -X- _ O
state -X- _ O
for -X- _ O
DST -X- _ B-TaskName
is -X- _ O
the -X- _ O
belief -X- _ O
state -X- _ O
. -X- _ O

Then -X- _ O
a -X- _ O
typical -X- _ O
conversation -X- _ O
can -X- _ O
be -X- _ O
expressed -X- _ O
as -X- _ O
D={U0,(S1 -X- _ O
, -X- _ O
U1 -X- _ O
) -X- _ O
, -X- _ O
... -X- _ O
( -X- _ O
Sn -X- _ O
, -X- _ O
Un -X- _ O
) -X- _ O
} -X- _ O
. -X- _ O

Let -X- _ O
Ut -X- _ O
andStbe -X- _ O
the -X- _ O
user -X- _ O
and -X- _ O
system -X- _ O
utterances -X- _ O
respectively -X- _ O
at -X- _ O
turn -X- _ O
t -X- _ O
. -X- _ O

1 -X- _ O
Introduction -X- _ O
Dialogue -X- _ B-TaskName
State -X- _ I-TaskName
Tracking -X- _ I-TaskName
( -X- _ I-TaskName
DST -X- _ I-TaskName
) -X- _ I-TaskName
is -X- _ O
at -X- _ O
the -X- _ O
core -X- _ O
of -X- _ O
task -X- _ B-MethodName
- -X- _ I-MethodName
oriented -X- _ I-MethodName
dialogue -X- _ I-MethodName
systems -X- _ I-MethodName
. -X- _ O

With -X- _ O
the -X- _ O
growing -X- _ O
popularity -X- _ O
of -X- _ O
task -X- _ O
- -X- _ O
based -X- _ O
conversational -X- _ O
agents -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
essential -X- _ O
to -X- _ O
review -X- _ O
the -X- _ O
evaluation -X- _ O
of -X- _ O
DST -X- _ B-TaskName
to -X- _ O
appropriately -X- _ O
measure -X- _ O
the -X- _ O
progress -X- _ O
in -X- _ O
this -X- _ O
evolving -X- _ O
area -X- _ O
. -X- _ O

The -X- _ O
task -X- _ O
of -X- _ O
DST -X- _ B-TaskName
is -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
user -X- _ O
intent -X- _ O
through -X- _ O
dialogue -X- _ O
states -X- _ O
( -X- _ O
Henderson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O

1 -X- _ O
shows -X- _ O
an -X- _ O
example -X- _ O
DST -X- _ B-TaskName
task -X- _ I-TaskName
from -X- _ O
Multi -X- _ B-DatasetName
- -X- _ I-DatasetName
WOZ -X- _ I-DatasetName
( -X- _ O
Budzianowski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
dataset -X- _ O
. -X- _ O

It -X- _ O
is -X- _ O
responsible -X- _ O
for -X- _ O
keeping -X- _ O
track -X- _ O
of -X- _ O
the -X- _ O
key -X- _ O
information -X- _ O
exchanged -X- _ O
during -X- _ O
a -X- _ O
conversation -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
show -X- _ O
that -X- _ O
FGA -X- _ B-MetricName
is -X- _ O
a -X- _ O
better -X- _ O
discriminator -X- _ O
of -X- _ O
DST -X- _ B-MethodName
model -X- _ I-MethodName
performance -X- _ O
. -X- _ O

By -X- _ O
doing -X- _ O
so -X- _ O
, -X- _ O
FGA -X- _ B-MetricName
considers -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
both -X- _ O
cumulative -X- _ O
and -X- _ O
turn -X- _ O
- -X- _ O
level -X- _ O
prediction -X- _ O
flexibly -X- _ O
and -X- _ O
provides -X- _ O
a -X- _ O
better -X- _ O
insight -X- _ O
than -X- _ O
the -X- _ O
existing -X- _ O
metrics -X- _ O
. -X- _ O

the -X- _ O
root -X- _ O
cause -X- _ O
of -X- _ O
the -X- _ O
error -X- _ O
is -X- _ O
an -X- _ O
earlier -X- _ O
turn -X- _ O
. -X- _ O

But -X- _ O
unlike -X- _ O
JGA -X- _ B-MetricName
, -X- _ O
it -X- _ O
tries -X- _ O
to -X- _ O
give -X- _ O
penalized -X- _ O
rewards -X- _ O
to -X- _ O
mispredictions -X- _ O
that -X- _ O
are -X- _ O
locally -X- _ O
correct -X- _ O
i.e -X- _ O
. -X- _ O

FGA -X- _ B-MetricName
is -X- _ O
a -X- _ O
generalized -X- _ O
version -X- _ O
of -X- _ O
JGA -X- _ B-MetricName
. -X- _ O

To -X- _ O
address -X- _ O
the -X- _ O
existing -X- _ O
issues -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
new -X- _ O
evaluation -X- _ O
metric -X- _ O
named -X- _ O
Flexible -X- _ B-MetricName
GoalAccuracy -X- _ I-MetricName
( -X- _ I-MetricName
FGA -X- _ I-MetricName
) -X- _ I-MetricName
. -X- _ O

In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
discuss -X- _ O
various -X- _ O
evaluation -X- _ O
metrics -X- _ O
used -X- _ O
for -X- _ O
DST -X- _ B-MethodName
along -X- _ O
with -X- _ O
their -X- _ O
shortcomings -X- _ O
. -X- _ O

So -X- _ O
, -X- _ O
using -X- _ O
JGA -X- _ B-MetricName
as -X- _ O
the -X- _ O
only -X- _ O
metric -X- _ O
for -X- _ O
model -X- _ O
selection -X- _ O
may -X- _ O
not -X- _ O
be -X- _ O
ideal -X- _ O
for -X- _ O
all -X- _ O
scenarios -X- _ O
. -X- _ O

Moreover -X- _ O
, -X- _ O
an -X- _ O
improvement -X- _ O
in -X- _ O
JGA -X- _ B-MetricName
can -X- _ O
sometimes -X- _ O
decrease -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
turn -X- _ O
- -X- _ O
level -X- _ O
or -X- _ O
non -X- _ O
- -X- _ O
cumulative -X- _ O
belief -X- _ O
state -X- _ O
prediction -X- _ O
due -X- _ O
to -X- _ O
inconsistency -X- _ O
in -X- _ O
annotations -X- _ O
. -X- _ O

Thus -X- _ O
, -X- _ O
although -X- _ O
being -X- _ O
a -X- _ O
useful -X- _ O
metric -X- _ O
, -X- _ O
it -X- _ O
can -X- _ O
be -X- _ O
harsh -X- _ O
at -X- _ O
times -X- _ O
and -X- _ O
underestimate -X- _ O
the -X- _ O
true -X- _ O
potential -X- _ O
of -X- _ O
a -X- _ O
DST -X- _ B-MethodName
model -X- _ I-MethodName
. -X- _ O

Due -X- _ O
to -X- _ O
this -X- _ O
cumulative -X- _ O
nature -X- _ O
of -X- _ O
the -X- _ O
belief -X- _ O
state -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
difficult -X- _ O
to -X- _ O
get -X- _ O
a -X- _ O
correct -X- _ O
prediction -X- _ O
once -X- _ O
a -X- _ O
misprediction -X- _ O
has -X- _ O
occurred -X- _ O
. -X- _ O

This -X- _ O
case -X- _ O
intuitively -X- _ O
shows -X- _ O
our -X- _ O
HCL -X- _ B-MethodName
framework -X- _ I-MethodName
can -X- _ O
help -X- _ O
the -X- _ O
model -X- _ O
better -X- _ O
handle -X- _ O
the -X- _ O
hard -X- _ O
instance -X- _ O
with -X- _ O
complex -X- _ O
structure.339 -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
the -X- _ O
AMR -X- _ B-MethodName
parsed -X- _ O
by -X- _ O
the -X- _ O
SPRING -X- _ B-MethodName
model -X- _ I-MethodName
( -X- _ O
depth:5 -X- _ O
) -X- _ O
is -X- _ O
shallower -X- _ O
than -X- _ O
the -X- _ O
gold -X- _ O
AMR -X- _ B-MethodName
( -X- _ O
depth:9 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
their -X- _ O
structures -X- _ O
are -X- _ O
also -X- _ O
different -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
the -X- _ O
root -X- _ O
of -X- _ O
the -X- _ O
gold -X- _ O
AMR -X- _ B-MethodName
and -X- _ O
the -X- _ O
SPRING -X- _ B-MethodName
parsed -X- _ O
AMR -X- _ B-MethodName
are -X- _ O
possible01 -X- _ O
and -X- _ O
and -X- _ O
, -X- _ O
respectively -X- _ O
) -X- _ O
. -X- _ O

As -X- _ O
is -X- _ O
illustrated -X- _ O
, -X- _ O
our -X- _ O
method -X- _ O
achieves -X- _ O
the -X- _ O
right -X- _ O
AMR -X- _ B-MethodName
for -X- _ O
the -X- _ O
input -X- _ O
sentence -X- _ O
. -X- _ O

Figure -X- _ O
6 -X- _ O
shows -X- _ O
a -X- _ O
case -X- _ O
study -X- _ O
( -X- _ O
we -X- _ O
omit -X- _ O
some -X- _ O
details -X- _ O
of -X- _ O
AMR -X- _ B-MethodName
graphs -X- _ O
for -X- _ O
a -X- _ O
more -X- _ O
clear -X- _ O
description -X- _ O
) -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
input -X- _ O
sentence -X- _ O
, -X- _ O
our -X- _ O
method -X- _ O
achieves -X- _ O
the -X- _ O
right -X- _ O
AMR -X- _ B-MethodName
, -X- _ O
while -X- _ O
the -X- _ O
baseline -X- _ O
model -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
SPRING -X- _ O
( -X- _ O
Bevilacqua -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
) -X- _ O
gets -X- _ O
a -X- _ O
shallower -X- _ O
and -X- _ O
wrong -X- _ O
structure -X- _ O
AMR -X- _ B-MethodName
. -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
5 -X- _ O
, -X- _ O
following -X- _ O
Bevilacqua -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
AMR -X- _ B-MethodName
graph -X- _ O
is -X- _ O
linearized -X- _ O
by -X- _ O
the -X- _ B-MethodName
DFSbased -X- _ I-MethodName
linearization -X- _ I-MethodName
method -X- _ I-MethodName
according -X- _ O
to -X- _ O
the -X- _ O
edge -X- _ O
order -X- _ O
(: -X- _ O
ARG0!:ARG1!:ARG2 -X- _ O
) -X- _ O
. -X- _ O

This -X- _ O
paper -X- _ O
is -X- _ O
supported -X- _ O
by -X- _ O
the -X- _ O
National -X- _ O
Key -X- _ O
Research -X- _ O
and -X- _ O
Development -X- _ O
Program -X- _ O
of -X- _ O
China -X- _ O
under -X- _ O
Grant -X- _ O
No -X- _ O
. -X- _ O

Acknowledgement -X- _ O
The -X- _ O
authors -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
thank -X- _ O
the -X- _ O
anonymous -X- _ O
reviewers -X- _ O
for -X- _ O
their -X- _ O
thoughtful -X- _ O
and -X- _ O
constructive -X- _ O
comments -X- _ O
, -X- _ O
and -X- _ O
Bevilacqua -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
for -X- _ O
their -X- _ O
highquality -X- _ O
open -X- _ O
codebase -X- _ O
. -X- _ O

Extensive -X- _ O
experiments -X- _ O
on -X- _ O
AMR2.0 -X- _ B-DatasetName
, -X- _ O
AMR3.0 -X- _ B-DatasetName
, -X- _ O
structure -X- _ O
- -X- _ O
complex -X- _ O
and -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
distribution -X- _ O
situations -X- _ O
verify -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
HCL.336 -X- _ B-MethodName
. -X- _ O

SC -X- _ B-MethodName
and -X- _ O
IC -X- _ B-MethodName
train -X- _ O
the -X- _ O
model -X- _ O
on -X- _ O
different -X- _ O
hierarchies -X- _ O
( -X- _ O
AMR -X- _ B-MethodName
sub -X- _ I-MethodName
- -X- _ I-MethodName
graphs -X- _ I-MethodName
and -X- _ O
AMR -X- _ B-MethodName
full -X- _ I-MethodName
graphs -X- _ I-MethodName
) -X- _ O
. -X- _ O

inspired -X- _ O
by -X- _ O
human -X- _ O
cognition -X- _ O
, -X- _ O
SC -X- _ B-MethodName
follows -X- _ O
the -X- _ O
principle -X- _ O
of -X- _ O
learning -X- _ O
the -X- _ O
core -X- _ O
concepts -X- _ O
of -X- _ O
AMR -X- _ B-MethodName
first -X- _ O
, -X- _ O
and -X- _ O
IC -X- _ B-MethodName
obeys -X- _ O
the -X- _ O
rule -X- _ O
of -X- _ O
learning -X- _ O
easy -X- _ O
instances -X- _ O
first -X- _ O
. -X- _ O

5 -X- _ O
Conclusion -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
Hierarchical -X- _ B-MethodName
Curriculum -X- _ I-MethodName
Learning -X- _ I-MethodName
( -X- _ I-MethodName
HCL -X- _ I-MethodName
) -X- _ I-MethodName
framework -X- _ I-MethodName
for -X- _ O
sequenceto -X- _ B-TaskName
- -X- _ I-TaskName
sequence -X- _ I-TaskName
AMR -X- _ I-TaskName
parsing -X- _ I-TaskName
, -X- _ O
which -X- _ O
consists -X- _ O
of -X- _ O
Structure -X- _ B-MethodName
- -X- _ I-MethodName
level -X- _ I-MethodName
Curriculum -X- _ I-MethodName
( -X- _ I-MethodName
SC -X- _ I-MethodName
) -X- _ I-MethodName
and -X- _ O
Instance -X- _ B-MethodName
- -X- _ I-MethodName
level -X- _ I-MethodName
Curriculum -X- _ I-MethodName
( -X- _ I-MethodName
IC -X- _ I-MethodName
) -X- _ I-MethodName
. -X- _ O

We -X- _ O
think -X- _ O
the -X- _ O
reason -X- _ O
is -X- _ O
that -X- _ O
SC -X- _ B-MethodName
constructs -X- _ O
AMR -X- _ B-MethodName
subgraphs -X- _ O
for -X- _ O
training -X- _ O
, -X- _ O
which -X- _ O
enhances -X- _ O
the -X- _ O
models -X- _ O
ability -X- _ O
to -X- _ O
perceive -X- _ O
the -X- _ O
AMR -X- _ B-MethodName
hierarchy -X- _ O
. -X- _ O

Specifically -X- _ O
, -X- _ O
the -X- _ O
structure -X- _ B-MethodName
- -X- _ I-MethodName
level -X- _ I-MethodName
curriculum -X- _ I-MethodName
( -X- _ I-MethodName
SC -X- _ I-MethodName
) -X- _ I-MethodName
is -X- _ O
more -X- _ O
effective -X- _ O
than -X- _ O
the -X- _ O
instance -X- _ B-MethodName
- -X- _ I-MethodName
level -X- _ I-MethodName
curriculum -X- _ I-MethodName
( -X- _ I-MethodName
IC -X- _ I-MethodName
) -X- _ I-MethodName
. -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
see -X- _ O
both -X- _ O
curricula -X- _ O
are -X- _ O
conducive -X- _ O
to -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
, -X- _ O
and -X- _ O
they -X- _ O
are -X- _ O
complementary -X- _ O
to -X- _ O
each -X- _ O
other -X- _ O
. -X- _ O

Table -X- _ O
2 -X- _ O
shows -X- _ O
theSMATCH -X- _ B-MetricName
scores -X- _ I-MetricName
on -X- _ O
both -X- _ O
AMR2.0 -X- _ B-DatasetName
and -X- _ O
AMR3.0 -X- _ B-DatasetName
. -X- _ O

We -X- _ O
conduct -X- _ O
ablation -X- _ O
studies -X- _ O
by -X- _ O
removing -X- _ O
one -X- _ O
curriculum -X- _ O
at -X- _ O
a -X- _ O
time -X- _ O
. -X- _ O

Ablation -X- _ O
Study -X- _ O
To -X- _ O
illustrate -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
curricula -X- _ O
. -X- _ O

performs -X- _ O
Bevilacqua -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
on -X- _ O
all -X- _ O
3 -X- _ O
OOD -X- _ O
datasets -X- _ O
, -X- _ O
which -X- _ O
shows -X- _ O
our -X- _ O
HCL -X- _ B-MethodName
framework -X- _ O
can -X- _ O
also -X- _ O
improve -X- _ O
the -X- _ O
generalization -X- _ O
ability -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O

Please -X- _ O
refer -X- _ O
to -X- _ O
Appendix -X- _ O
B -X- _ O
for -X- _ O
details -X- _ O
of -X- _ O
OOD -X- _ O
datasets -X- _ O
. -X- _ O

Following -X- _ O
Bevilacqua -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
our -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
training -X- _ O
dataset -X- _ O
of -X- _ O
AMR2.0 -X- _ B-DatasetName
, -X- _ O
and -X- _ O
then -X- _ O
evaluate -X- _ O
it -X- _ O
on -X- _ O
3 -X- _ O
OOD -X- _ O
test -X- _ O
datasets -X- _ O
, -X- _ O
BIO -X- _ B-DatasetName
, -X- _ O
TLP -X- _ B-DatasetName
and -X- _ O
News3 -X- _ B-DatasetName
. -X- _ O

Bevilacqua -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
propose -X- _ O
the -X- _ O
OOD -X- _ O
evaluation -X- _ O
for -X- _ O
AMR -X- _ B-MethodName
parsers -X- _ O
. -X- _ O

As -X- _ O
is -X- _ O
shown -X- _ O
, -X- _ O
as -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
layers -X- _ O
increases -X- _ O
, -X- _ O
HCL -X- _ B-MethodName
exceeds -X- _ O
SPRING -X- _ O
greater -X- _ O
, -X- _ O
which -X- _ O
shows -X- _ O
our -X- _ O
HCL -X- _ B-MethodName
helps -X- _ O
the -X- _ O
model -X- _ O
better -X- _ O
handle -X- _ O
hard -X- _ O
instances.4In -X- _ O
addition -X- _ O
, -X- _ O
to -X- _ O
some -X- _ O
extend -X- _ O
, -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
distribution -X- _ O
( -X- _ O
OOD -X- _ O
) -X- _ O
instances -X- _ O
can -X- _ O
be -X- _ O
regarded -X- _ O
as -X- _ O
hard -X- _ O
instances -X- _ O
, -X- _ O
thus -X- _ O
we -X- _ O
also -X- _ O
consider -X- _ O
the -X- _ O
OOD -X- _ O
situation -X- _ O
. -X- _ O

Hard -X- _ O
Instances -X- _ O
Benefit -X- _ O
Figure -X- _ O
4 -X- _ O
shows -X- _ O
the -X- _ O
performances -X- _ O
of -X- _ O
our -X- _ O
HCL -X- _ B-MethodName
and -X- _ O
Bevilacqua -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
( -X- _ O
SPRING -X- _ O
) -X- _ O
at -X- _ O
different -X- _ O
layers -X- _ O
. -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
, -X- _ O
compared -X- _ O
with -X- _ O
Bevilacqua -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
( -X- _ O
also -X- _ O
a -X- _ O
sequence -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
sequence -X- _ O
model -X- _ O
based -X- _ O
on -X- _ O
BART -X- _ O
- -X- _ O
large -X- _ O
) -X- _ O
, -X- _ O
our -X- _ O
method -X- _ O
achieves -X- _ O
2:97and -X- _ B-MetricValue
2:83average -X- _ B-MetricValue
F1 -X- _ B-MetricName
scores -X- _ I-MetricName
improvement -X- _ O
on -X- _ O
3structure -X- _ O
- -X- _ O
dependent -X- _ O
metrics -X- _ O
on -X- _ O
AMR2.0 -X- _ B-DatasetName
and -X- _ O
AMR3.0 -X- _ B-DatasetName
, -X- _ O
respectively -X- _ O
, -X- _ O
which -X- _ O
proves -X- _ O
HCL -X- _ B-MethodName
helps -X- _ O
the -X- _ O
at -X- _ O
sequence -X- _ B-MethodName
- -X- _ I-MethodName
to -X- _ I-MethodName
- -X- _ I-MethodName
sequence -X- _ I-MethodName
model -X- _ O
better -X- _ O
adapt -X- _ O
to -X- _ O
AMR -X- _ B-MethodName
with -X- _ O
the -X- _ O
hierarchical -X- _ O
and -X- _ O
complex -X- _ O
structure -X- _ O
. -X- _ O

Please -X- _ O
refer -X- _ O
to -X- _ O
Appendix -X- _ O
C -X- _ O
for -X- _ O
the -X- _ O
reason -X- _ O
for -X- _ O
this -X- _ O
division -X- _ O
. -X- _ O

We -X- _ O
divide -X- _ O
the -X- _ O
fine -X- _ B-MetricName
- -X- _ I-MetricName
grained -X- _ I-MetricName
F1 -X- _ I-MetricName
scores -X- _ I-MetricName
into -X- _ O
2categories -X- _ O
, -X- _ O
structure -X- _ O
- -X- _ O
dependent -X- _ O
( -X- _ O
unlabelled -X- _ O
, -X- _ O
re -X- _ O
- -X- _ O
entrancy -X- _ O
and -X- _ O
SRL -X- _ O
) -X- _ O
and -X- _ O
structureindependen -X- _ O
( -X- _ O
the -X- _ O
left -X- _ O
5metrics -X- _ O
) -X- _ O
. -X- _ O

4 -X- _ O
Analysis -X- _ O
Structure -X- _ O
Benefit -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
explore -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
HCL -X- _ B-MethodName
framework -X- _ O
for -X- _ O
the -X- _ O
structured -X- _ O
AMR -X- _ B-MethodName
parsing -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
these -X- _ O
metrics -X- _ O
are -X- _ O
unrelated -X- _ O
to -X- _ O
the -X- _ O
AMR -X- _ B-MethodName
structure -X- _ O
that -X- _ O
our -X- _ O
HCL -X- _ B-MethodName
focuses -X- _ O
on -X- _ O
. -X- _ O

Bevilacqua -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
outperforms -X- _ O
slightly -X- _ O
our -X- _ O
model -X- _ O
in -X- _ O
Conc -X- _ O
. -X- _ O

on -X- _ O
AMR2.0 -X- _ B-DatasetName
, -X- _ O
they -X- _ O
adopt -X- _ O
a -X- _ O
complex -X- _ O
process -X- _ O
, -X- _ O
which -X- _ O
may -X- _ O
hurt -X- _ O
the -X- _ O
model -X- _ O
generalization -X- _ O
ability -X- _ O
. -X- _ O

Although -X- _ O
Cai -X- _ O
and -X- _ O
Lam -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
outperforms -X- _ O
our -X- _ O
model -X- _ O
in -X- _ O
Neg -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
fine -X- _ O
- -X- _ O
grained -X- _ O
results -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
achieves -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
in -X- _ O
6out -X- _ O
of -X- _ O
8metrics -X- _ O
on -X- _ O
both -X- _ O
AMR2.0 -X- _ B-DatasetName
and -X- _ O
AMR3.0 -X- _ B-DatasetName
, -X- _ O
which -X- _ O
shows -X- _ O
the -X- _ O
effective2https://github.com/mdtux89/amr-evaluation -X- _ O
3https://github.com/SapienzaNLP/spring335 -X- _ O
. -X- _ O

As -X- _ O
is -X- _ O
shown -X- _ O
, -X- _ O
on -X- _ O
AMR2.0 -X- _ B-DatasetName
and -X- _ O
AMR3.0 -X- _ B-DatasetName
, -X- _ O
our -X- _ O
hierarchical -X- _ O
curriculum -X- _ O
learning -X- _ O
model -X- _ O
achieves -X- _ O
84:30:1and83:70:1 -X- _ B-MetricValue
SMATCH -X- _ B-MetricName
scores -X- _ I-MetricName
, -X- _ O
and -X- _ O
outperforms -X- _ O
Bevilacqua -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
0:5and -X- _ B-MetricValue
0:7SMATCH -X- _ B-MetricValue
scores -X- _ B-MetricName
, -X- _ O
respectively -X- _ O
. -X- _ O

Main -X- _ O
Results -X- _ O
We -X- _ O
compare -X- _ O
our -X- _ O
method -X- _ O
with -X- _ O
previous -X- _ O
approaches -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O

Our -X- _ O
code -X- _ O
and -X- _ O
model -X- _ O
are -X- _ O
available -X- _ O
at -X- _ O
https://github.com/ -X- _ O
Wangpeiyi9979 -X- _ O
/ -X- _ O
HCL -X- _ O
- -X- _ O
Text2AMR -X- _ O
. -X- _ O

We -X- _ O
adopt -X- _ O
the -X- _ O
same -X- _ O
post -X- _ B-MethodName
- -X- _ I-MethodName
processing -X- _ I-MethodName
process -X- _ I-MethodName
as -X- _ O
Bevilacqua -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
train -X- _ O
our -X- _ O
model -X- _ O
on -X- _ O
a -X- _ O
single -X- _ O
NVIDIA -X- _ O
TESLA -X- _ O
V -X- _ O
100GPU -X- _ O
with -X- _ O
32 -X- _ O
GB -X- _ O
memory -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
cross -X- _ B-MetricName
- -X- _ I-MetricName
entropy -X- _ I-MetricName
as -X- _ O
our -X- _ O
loss -X- _ O
function -X- _ O
. -X- _ O

After -X- _ O
the -X- _ O
curriculum -X- _ O
training -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
for -X- _ O
30 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
on -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
. -X- _ O

The -X- _ O
training -X- _ B-HyperparameterName
steps -X- _ I-HyperparameterName
Tscis1000 -X- _ I-HyperparameterName
andTicis500 -X- _ B-HyperparameterName
. -X- _ O

Dropout -X- _ B-HyperparameterName
is -X- _ O
set -X- _ O
to -X- _ O
0:25and -X- _ B-HyperparameterValue
beam -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
is -X- _ O
5 -X- _ B-HyperparameterValue
. -X- _ O

The -X- _ B-HyperparameterName
batch -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
is -X- _ O
2048 -X- _ B-HyperparameterValue
graph -X- _ O
linearization -X- _ O
tokens -X- _ O
with -X- _ O
the -X- _ O
gradient -X- _ B-HyperparameterName
accumulation -X- _ I-HyperparameterName
10 -X- _ B-HyperparameterValue
. -X- _ O

We -X- _ O
utilizes -X- _ O
RAdam -X- _ B-MetricName
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
as -X- _ O
our -X- _ O
optimizer -X- _ O
with -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
3e5 -X- _ B-HyperparameterValue
. -X- _ O

We -X- _ O
use -X- _ O
BART -X- _ B-MethodName
- -X- _ I-MethodName
large -X- _ I-MethodName
as -X- _ O
our -X- _ O
sequence -X- _ B-MethodName
- -X- _ I-MethodName
to -X- _ I-MethodName
- -X- _ I-MethodName
sequence -X- _ I-MethodName
model -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
Bevilacqua -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

Experiment -X- _ O
Setups -X- _ O
Our -X- _ O
implementation -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
Huggingfaces -X- _ B-MethodName
transformers -X- _ I-MethodName
library -X- _ O
( -X- _ O
Wolf -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
open -X- _ O
codebase -X- _ O
of -X- _ O
Bevilacqua -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021)3 -X- _ O
. -X- _ O

Following -X- _ O
Bevilacqua -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
SMATCH -X- _ B-MetricName
scores -X- _ I-MetricName
( -X- _ O
Cai -X- _ O
and -X- _ O
Knight -X- _ O
, -X- _ O
2013)and -X- _ O
the -X- _ O
fine -X- _ B-MetricName
- -X- _ I-MetricName
grained -X- _ I-MetricName
evaluation -X- _ I-MetricName
metrics -X- _ I-MetricName
( -X- _ O
Damonte -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017)2to -X- _ O
evaluate -X- _ O
the -X- _ O
performances -X- _ O
. -X- _ O

Please -X- _ O
refer -X- _ O
to -X- _ O
the -X- _ O
Appendix -X- _ O
B -X- _ O
for -X- _ O
details -X- _ O
of -X- _ O
two -X- _ O
benchmarks -X- _ O
. -X- _ O

3 -X- _ O
Experiments -X- _ O
Datasets -X- _ O
and -X- _ O
Evaluation -X- _ O
Metrics -X- _ O
We -X- _ O
evaluate -X- _ O
our -X- _ O
hierarchical -X- _ B-MethodName
curriculum -X- _ I-MethodName
learning -X- _ I-MethodName
framework -X- _ I-MethodName
on -X- _ O
two -X- _ O
popular -X- _ O
AMR -X- _ B-DatasetName
benchmarks -X- _ I-DatasetName
, -X- _ O
AMR2.0 -X- _ B-DatasetName
( -X- _ O
LDC2017T10 -X- _ O
) -X- _ O
and -X- _ O
AMR3.0 -X- _ B-DatasetName
( -X- _ O
LDC2020T02 -X- _ O
) -X- _ O
. -X- _ O

Specifically -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
use -X- _ O
SC -X- _ B-MethodName
and -X- _ O
then -X- _ O
IC -X- _ B-MethodName
to -X- _ O
train -X- _ O
the -X- _ O
model -X- _ O
, -X- _ O
since -X- _ O
SC -X- _ B-MethodName
( -X- _ O
follows -X- _ O
learning -X- _ O
core -X- _ O
semantics -X- _ O
first -X- _ O
) -X- _ O
is -X- _ O
for -X- _ O
AMR -X- _ B-MethodName
sub -X- _ O
- -X- _ O
graphs -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
regarded -X- _ O
as -X- _ O
a -X- _ O
warmingup -X- _ O
stage -X- _ O
of -X- _ O
IC -X- _ B-MethodName
( -X- _ O
obeys -X- _ O
learning -X- _ O
easy -X- _ O
instances -X- _ O
first -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
for -X- _ O
AMR -X- _ B-MethodName
full -X- _ O
graphs -X- _ O
. -X- _ O

In -X- _ O
each -X- _ O
step -X- _ O
of -X- _ O
the -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
episode -X- _ O
, -X- _ O
the -X- _ O
training -X- _ O
scheduler -X- _ O
samples -X- _ O
a -X- _ O
batch -X- _ O
of -X- _ O
examples -X- _ O
from -X- _ O
buckets -X- _ O
fIj -X- _ O
: -X- _ O
jigto -X- _ O
train -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2(b -X- _ O
) -X- _ O
, -X- _ O
IC -X- _ B-MethodName
has -X- _ O
Mtraining -X- _ O
episodes -X- _ O
, -X- _ O
and -X- _ O
each -X- _ O
episode -X- _ O
consists -X- _ O
of -X- _ O
Ticsteps -X- _ O
. -X- _ O

Figure -X- _ O
3 -X- _ O
shows -X- _ O
AMR -X- _ B-MethodName
graphs -X- _ O
with -X- _ O
deeper -X- _ O
layers -X- _ O
can -X- _ O
be -X- _ O
regarded -X- _ O
as -X- _ O
harder -X- _ O
instances -X- _ O
for -X- _ O
the -X- _ O
at -X- _ O
pretrained -X- _ O
model -X- _ O
, -X- _ O
thus -X- _ O
IC -X- _ B-MethodName
divides -X- _ O
all -X- _ O
AMR -X- _ B-MethodName
graphs -X- _ O
into -X- _ O
M -X- _ O
buckets -X- _ O
according -X- _ O
to -X- _ O
their -X- _ O
depths -X- _ O
fIi -X- _ O
: -X- _ O
i= -X- _ O
1 -X- _ O
; -X- _ O
: -X- _ O
: -X- _ O
: -X- _ O
; -X- _ O
Mg -X- _ O
, -X- _ O
where -X- _ O
Iicontains -X- _ O
AMR -X- _ B-MethodName
graphs -X- _ O
with -X- _ O
the -X- _ O
depth -X- _ O
i -X- _ O
. -X- _ O

2.2 -X- _ O
Instance -X- _ B-MethodName
- -X- _ I-MethodName
level -X- _ I-MethodName
Curriculum -X- _ I-MethodName
Inspired -X- _ O
by -X- _ O
learning -X- _ O
easy -X- _ O
instances -X- _ O
first -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
Instance -X- _ B-MethodName
- -X- _ I-MethodName
level -X- _ I-MethodName
Curriculum -X- _ I-MethodName
( -X- _ I-MethodName
IC -X- _ I-MethodName
) -X- _ I-MethodName
. -X- _ O

a -X- _ O
sentence -X- _ O
into -X- _ O
a -X- _ O
sub -X- _ O
- -X- _ O
graph -X- _ O
with -X- _ O
the -X- _ O
depth -X- _ O
d -X- _ O
, -X- _ O
we -X- _ O
append -X- _ O
a -X- _ O
special -X- _ O
string -X- _ O
parse -X- _ O
to -X- _ O
dlayers -X- _ O
to -X- _ O
the -X- _ O
input -X- _ O
sentence -X- _ O
, -X- _ O
and -X- _ O
replace -X- _ O
the -X- _ O
start -X- _ O
token -X- _ O
of -X- _ O
the -X- _ O
decoder -X- _ O
with -X- _ O
an -X- _ O
artificial -X- _ O
token -X- _ O
< -X- _ O
d -X- _ O
> -X- _ O
, -X- _ O
so -X- _ O
the -X- _ O
model -X- _ O
can -X- _ O
perceive -X- _ O
layers -X- _ O
that -X- _ O
need -X- _ O
to -X- _ O
be -X- _ O
parsed -X- _ O
. -X- _ O

ModelsGindicate -X- _ O
models -X- _ O
with -X- _ O
graph -X- _ O
re -X- _ O
- -X- _ O
categorization -X- _ O
( -X- _ O
a -X- _ O
data -X- _ O
processing -X- _ O
method -X- _ O
that -X- _ O
may -X- _ O
hurt -X- _ O
the -X- _ O
model -X- _ O
generalization -X- _ O
ability -X- _ O
Bevilacqua -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
) -X- _ O
. -X- _ O

Our -X- _ O
results -X- _ O
are -X- _ O
the -X- _ O
average -X- _ O
of -X- _ O
3 -X- _ O
runs -X- _ O
with -X- _ O
different -X- _ O
random -X- _ O
seeds -X- _ O
. -X- _ O

In -X- _ O
each -X- _ O
step -X- _ O
of -X- _ O
the -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
episode -X- _ O
, -X- _ O
the -X- _ O
training -X- _ O
scheduler -X- _ O
samples -X- _ O
a -X- _ O
batch -X- _ O
of -X- _ O
examples -X- _ O
from -X- _ O
buckets -X- _ O
fSj -X- _ O
: -X- _ O
jigto -X- _ O
train -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2(a -X- _ O
) -X- _ O
, -X- _ O
SC -X- _ B-MethodName
has -X- _ O
Ntraining -X- _ O
episodes -X- _ O
, -X- _ O
and -X- _ O
each -X- _ O
episode -X- _ O
consists -X- _ O
of -X- _ O
Tscsteps -X- _ O
. -X- _ O

AMR -X- _ B-MethodName
graphs -X- _ I-MethodName
are -X- _ O
organized -X- _ O
in -X- _ O
a -X- _ O
hierarchy -X- _ O
where -X- _ O
the -X- _ O
core -X- _ O
semantics -X- _ O
stay -X- _ O
closely -X- _ O
to -X- _ O
the -X- _ O
root -X- _ O
( -X- _ O
Cai -X- _ O
and -X- _ O
Lam -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
thus -X- _ O
SC -X- _ B-MethodName
divides -X- _ O
all -X- _ O
AMR -X- _ B-MethodName
sub -X- _ O
- -X- _ O
graphs -X- _ O
into -X- _ O
Nbuckets -X- _ O
according -X- _ O
to -X- _ O
their -X- _ O
depths -X- _ O
fSi -X- _ O
: -X- _ O
i= -X- _ O
1;2 -X- _ O
; -X- _ O
: -X- _ O
: -X- _ O
: -X- _ O
; -X- _ O
Ng -X- _ O
, -X- _ O
where -X- _ O
Sicontains -X- _ O
AMR -X- _ B-MethodName
sub -X- _ O
- -X- _ O
graphs -X- _ O
with -X- _ O
the -X- _ O
depth -X- _ O
i -X- _ O
. -X- _ O

2.1 -X- _ B-MethodName
Structure -X- _ I-MethodName
- -X- _ I-MethodName
level -X- _ I-MethodName
Curriculum -X- _ I-MethodName
Motivated -X- _ O
by -X- _ O
learning -X- _ O
core -X- _ O
concepts -X- _ O
first -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
Structure -X- _ B-MethodName
- -X- _ I-MethodName
level -X- _ I-MethodName
Curriculum -X- _ I-MethodName
( -X- _ I-MethodName
SC -X- _ I-MethodName
) -X- _ I-MethodName
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
hierarchical -X- _ B-MethodName
curriculum -X- _ I-MethodName
learning -X- _ I-MethodName
framework -X- _ I-MethodName
( -X- _ O
Figure -X- _ O
2 -X- _ O
) -X- _ O
with -X- _ O
the -X- _ O
structureand -X- _ O
instance -X- _ O
- -X- _ O
level -X- _ O
curricula -X- _ O
to -X- _ O
help -X- _ O
the -X- _ O
at -X- _ O
model -X- _ O
progressively -X- _ O
adapt -X- _ O
to -X- _ O
the -X- _ O
structured -X- _ B-MethodName
AMR -X- _ I-MethodName
graph -X- _ I-MethodName
. -X- _ O

Specifically -X- _ O
, -X- _ O
variables -X- _ O
of -X- _ O
AMR -X- _ B-MethodName
nodes -X- _ O
are -X- _ O
set -X- _ O
to -X- _ O
a -X- _ O
series -X- _ O
of -X- _ O
special -X- _ O
tokens -X- _ O
< -X- _ O
R0 -X- _ O
> -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
< -X- _ O
Rk -X- _ O
> -X- _ O
( -X- _ O
more -X- _ O
details -X- _ O
of -X- _ O
linearization -X- _ O
are -X- _ O
included -X- _ O
in -X- _ O
Appendix -X- _ O
A -X- _ O
) -X- _ O
. -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1(a -X- _ O
) -X- _ O
, -X- _ O
following -X- _ O
Bevilacqua -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
AMR -X- _ B-MethodName
graph -X- _ O
is -X- _ O
linearized -X- _ O
by -X- _ O
the -X- _ O
DFS -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
linearization -X- _ I-MethodName
method -X- _ I-MethodName
with -X- _ O
special -X- _ O
tokens -X- _ O
to -X- _ O
indicate -X- _ O
variables -X- _ O
and -X- _ O
parentheses -X- _ O
to -X- _ O
mark -X- _ O
visit -X- _ O
depth -X- _ O
. -X- _ O

Given -X- _ O
a -X- _ O
sentence -X- _ O
x= -X- _ O
( -X- _ O
x1 -X- _ O
; -X- _ O
: -X- _ O
: -X- _ O
: -X- _ O
; -X- _ O
x -X- _ O
N -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
aims -X- _ O
to -X- _ O
generate -X- _ O
a -X- _ O
linearized -X- _ O
AMR -X- _ B-MethodName
graph -X- _ O
y= -X- _ O
( -X- _ O
y1 -X- _ O
; -X- _ O
: -X- _ O
: -X- _ O
: -X- _ O
; -X- _ O
y -X- _ O
M -X- _ O
) -X- _ O
. -X- _ O

2 -X- _ O
Methodology -X- _ O
We -X- _ O
formulate -X- _ O
AMR -X- _ B-MethodName
parsing -X- _ O
as -X- _ O
a -X- _ O
sequence -X- _ B-MethodName
- -X- _ I-MethodName
tosequence -X- _ I-MethodName
transformation -X- _ I-MethodName
. -X- _ O

( -X- _ O
2 -X- _ O
) -X- _ O
Extensive -X- _ O
experiments -X- _ O
on -X- _ O
AMR2.0 -X- _ B-MethodName
, -X- _ O
AMR3.0 -X- _ B-MethodName
, -X- _ O
structure -X- _ O
- -X- _ O
complex -X- _ O
and -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
distribution -X- _ O
situations -X- _ O
verify -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
HCL -X- _ B-MethodName
. -X- _ O

To -X- _ O
sum -X- _ O
up -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
Inspired -X- _ O
by -X- _ O
the -X- _ O
human -X- _ O
learning -X- _ O
process -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
core -X- _ O
concepts -X- _ O
first -X- _ O
andeasy -X- _ O
in -X- _ O
- -X- _ O
stances -X- _ O
first -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
hierarchical -X- _ B-MethodName
curriculum -X- _ I-MethodName
learning -X- _ I-MethodName
( -X- _ I-MethodName
HCL -X- _ I-MethodName
) -X- _ I-MethodName
framework -X- _ I-MethodName
to -X- _ O
help -X- _ O
the -X- _ O
sequence -X- _ B-MethodName
- -X- _ I-MethodName
tosequence -X- _ I-MethodName
model -X- _ I-MethodName
progressively -X- _ O
adapt -X- _ O
to -X- _ O
the -X- _ O
AMR -X- _ B-MethodName
hierarchy -X- _ O
. -X- _ O

Inspired -X- _ O
by -X- _ O
the -X- _ O
human -X- _ O
cognition -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
easy -X- _ O
ones -X- _ O
first -X- _ O
, -X- _ O
then -X- _ O
hard -X- _ O
ones -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
IC -X- _ B-MethodName
which -X- _ O
trains -X- _ O
the -X- _ O
model -X- _ O
by -X- _ O
starting -X- _ O
from -X- _ O
easy -X- _ O
instances -X- _ O
with -X- _ O
a -X- _ O
shallower -X- _ O
AMR -X- _ B-MethodName
structure -X- _ O
and -X- _ O
then -X- _ O
handling -X- _ O
hard -X- _ O
instances -X- _ O
. -X- _ O

Our -X- _ O
preliminary -X- _ O
study -X- _ O
in -X- _ O
Figure -X- _ O
3 -X- _ O
shows -X- _ O
that -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
vanilla -X- _ O
BART -X- _ B-MethodName
baseline -X- _ O
would -X- _ O
drop -X- _ O
rapidly -X- _ O
as -X- _ O
the -X- _ O
depth -X- _ O
of -X- _ O
AMR -X- _ B-MethodName
graph -X- _ O
grows -X- _ O
, -X- _ O
which -X- _ O
indicates -X- _ O
that -X- _ O
handing -X- _ O
deeper -X- _ O
AMR -X- _ B-MethodName
hierarchy -X- _ O
is -X- _ O
more -X- _ O
difficult -X- _ O
for -X- _ O
pretrained -X- _ O
models -X- _ O
. -X- _ O

( -X- _ O
2 -X- _ O
) -X- _ O
Instance -X- _ B-MethodName
- -X- _ I-MethodName
level -X- _ I-MethodName
Curriculum -X- _ I-MethodName
( -X- _ I-MethodName
IC -X- _ I-MethodName
) -X- _ I-MethodName
. -X- _ O

Motivated -X- _ O
by -X- _ O
the -X- _ O
human -X- _ O
learning -X- _ O
process -X- _ O
, -X- _ O
i.e. -X- _ O
,core -X- _ O
concepts -X- _ O
first -X- _ O
, -X- _ O
then -X- _ O
details -X- _ O
, -X- _ O
SC -X- _ B-MethodName
enumerates -X- _ O
all -X- _ O
AMR -X- _ B-MethodName
sub -X- _ I-MethodName
- -X- _ I-MethodName
graphs -X- _ I-MethodName
with -X- _ O
different -X- _ O
depths -X- _ O
, -X- _ O
and -X- _ O
deals -X- _ O
with -X- _ O
them -X- _ O
in -X- _ O
order -X- _ O
from -X- _ O
shallow -X- _ O
to -X- _ O
deep -X- _ O
. -X- _ O

As -X- _ O
depicted -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
, -X- _ O
the -X- _ O
concepts -X- _ O
and -X- _ O
relations -X- _ O
that -X- _ O
locate -X- _ O
in -X- _ O
the -X- _ O
different -X- _ O
layers -X- _ O
of -X- _ O
the -X- _ B-MethodName
AMR -X- _ I-MethodName
graph -X- _ I-MethodName
correspond -X- _ O
to -X- _ O
different -X- _ O
levels -X- _ O
of -X- _ O
abstraction -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
the -X- _ O
semantic -X- _ B-TaskName
representation -X- _ I-TaskName
. -X- _ O

AMR -X- _ B-MethodName
graphs -X- _ I-MethodName
are -X- _ O
organized -X- _ O
in -X- _ O
a -X- _ O
hierarchy -X- _ O
where -X- _ O
the -X- _ O
core -X- _ O
semantic -X- _ O
elements -X- _ O
stay -X- _ O
closely -X- _ O
to -X- _ O
the -X- _ O
root -X- _ O
node -X- _ O
( -X- _ O
Cai -X- _ O
and -X- _ O
Lam -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

( -X- _ O
1 -X- _ O
) -X- _ O
Structure -X- _ B-MethodName
- -X- _ I-MethodName
level -X- _ I-MethodName
Curriculum -X- _ I-MethodName
( -X- _ I-MethodName
SC -X- _ I-MethodName
) -X- _ I-MethodName
. -X- _ O

cal -X- _ O
curriculum -X- _ O
learning -X- _ O
framework -X- _ O
with -X- _ O
two -X- _ O
curricular -X- _ O
strategies -X- _ O
to -X- _ O
help -X- _ O
the -X- _ O
at -X- _ O
pretrained -X- _ O
model -X- _ O
progressively -X- _ O
adapt -X- _ O
to -X- _ O
the -X- _ O
hierarchical -X- _ B-MethodName
AMR -X- _ I-MethodName
graph -X- _ I-MethodName
. -X- _ O

The -X- _ O
AMR -X- _ B-MethodName
graphs -X- _ O
with -X- _ O
at -X- _ O
least -X- _ O
depth -X- _ B-HyperparameterName
7accounted -X- _ B-HyperparameterValue
for -X- _ O
43:6% -X- _ O
in -X- _ O
the -X- _ O
AMR-2.0 -X- _ B-DatasetName
test -X- _ I-DatasetName
set -X- _ I-DatasetName
. -X- _ O

IC -X- _ B-MethodName
follows -X- _ O
the -X- _ O
human -X- _ O
intuition -X- _ O
to -X- _ O
start -X- _ O
with -X- _ O
easy -X- _ O
instances -X- _ O
, -X- _ O
which -X- _ O
transits -X- _ O
from -X- _ O
easy -X- _ O
to -X- _ O
hard -X- _ O
AMR -X- _ B-MethodName
instances -X- _ O
. -X- _ O

During -X- _ O
training -X- _ O
, -X- _ O
SC -X- _ B-MethodName
follows -X- _ O
the -X- _ O
principle -X- _ O
of -X- _ O
learning -X- _ O
core -X- _ O
semantics -X- _ O
first -X- _ O
, -X- _ O
which -X- _ O
switches -X- _ O
progressively -X- _ O
from -X- _ O
shallow -X- _ O
to -X- _ O
deep -X- _ O
AMR -X- _ B-MethodName
sub -X- _ O
- -X- _ O
graphs -X- _ O
. -X- _ O

Sentence -X- _ O
: -X- _ O
Nine -X- _ O
of -X- _ O
the -X- _ O
twenty -X- _ O
soldiers -X- _ O
died -X- _ O
. -X- _ O

Humans -X- _ O
usually -X- _ O
adapt -X- _ O
to -X- _ O
difficult -X- _ O
tasks -X- _ O
by -X- _ O
dealing -X- _ O
with -X- _ O
examples -X- _ O
gradually -X- _ O
from -X- _ O
easy -X- _ O
to -X- _ O
hard -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
Curriculum -X- _ B-TaskName
Learning -X- _ I-TaskName
( -X- _ O
Bengio -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2009 -X- _ O
; -X- _ O
Platanios -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Su -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Xu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
. -X- _ O

Therefore -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
difficult -X- _ O
for -X- _ O
sequential -X- _ B-MethodName
generators -X- _ I-MethodName
to -X- _ O
learn -X- _ O
the -X- _ O
inherent -X- _ O
hierarchical -X- _ O
structure -X- _ O
of -X- _ O
AMR -X- _ B-MethodName
( -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021b -X- _ O
) -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
there -X- _ O
exists -X- _ O
a -X- _ O
gap -X- _ O
between -X- _ O
the -X- _ O
at -X- _ O
sentence -X- _ B-MethodName
- -X- _ I-MethodName
to -X- _ I-MethodName
- -X- _ I-MethodName
AMR -X- _ I-MethodName
training -X- _ I-MethodName
objective1and -X- _ I-MethodName
AMR -X- _ B-MethodName
graphs -X- _ I-MethodName
, -X- _ O
since -X- _ O
sequence -X- _ B-MethodName
- -X- _ I-MethodName
tosequence -X- _ I-MethodName
models -X- _ I-MethodName
deviate -X- _ O
from -X- _ O
the -X- _ O
essence -X- _ O
of -X- _ O
graph -X- _ B-TaskName
representation -X- _ I-TaskName
. -X- _ O

Through -X- _ O
directly -X- _ O
generating -X- _ O
the -X- _ O
linearized -X- _ B-MethodName
AMR -X- _ I-MethodName
graph -X- _ I-MethodName
( -X- _ O
e.g. -X- _ O
, -X- _ O
Figure -X- _ O
1(a -X- _ O
) -X- _ O
) -X- _ O
from -X- _ O
the -X- _ O
sentence -X- _ O
, -X- _ O
these -X- _ O
sequence -X- _ B-MethodName
- -X- _ I-MethodName
tosequence -X- _ I-MethodName
methods -X- _ I-MethodName
( -X- _ O
Xu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
; -X- _ O
Bevilacqua -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
circumvent -X- _ O
the -X- _ O
complex -X- _ O
data -X- _ O
processing -X- _ O
pipeline -X- _ O
and -X- _ O
can -X- _ O
be -X- _ O
easily -X- _ O
optimized -X- _ O
compared -X- _ O
with -X- _ B-MethodName
transition -X- _ I-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
or -X- _ I-MethodName
graph -X- _ I-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
methods -X- _ I-MethodName
( -X- _ O
Naseem -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Lee -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Lyu -X- _ O
and -X- _ O
Titov -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019a -X- _ O
, -X- _ O
b -X- _ O
; -X- _ O
Cai -X- _ O
and -X- _ O
Lam -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021b -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
deeper -X- _ O
sub -X- _ O
- -X- _ O
graphs -X- _ O
contain -X- _ O
more -X- _ O
sophisticated -X- _ O
semantics -X- _ O
compared -X- _ O
with -X- _ O
shallower -X- _ O
ones -X- _ O
. -X- _ O

Sentence -X- _ O
: -X- _ O
Nine -X- _ O
of -X- _ O
soldiers -X- _ O
died -X- _ O
.Sentence -X- _ O
: -X- _ O
Nine -X- _ O
of -X- _ O
the -X- _ O
twenty -X- _ O
soldiers -X- _ O
died -X- _ O
. -X- _ O

The -X- _ O
powerful -X- _ O
pretrained -X- _ O
encoder -X- _ B-MethodName
- -X- _ I-MethodName
decoder -X- _ I-MethodName
models -X- _ I-MethodName
, -X- _ O
e.g. -X- _ O
, -X- _ O
BART -X- _ B-MethodName
( -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
have -X- _ O
been -X- _ O
successfully -X- _ O
adapted -X- _ O
to -X- _ O
the -X- _ O
AMR -X- _ B-MethodName
parsing -X- _ O
and -X- _ O
became -X- _ O
the -X- _ O
mainstream -X- _ O
and -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
meth* -X- _ O
Equal -X- _ O
Contribution -X- _ O
. -X- _ O

AMR -X- _ B-MethodName
has -X- _ O
been -X- _ O
exploited -X- _ O
in -X- _ O
the -X- _ O
downstream -X- _ O
NLP -X- _ O
tasks -X- _ O
, -X- _ O
including -X- _ O
information -X- _ B-TaskName
extraction -X- _ I-TaskName
( -X- _ O
Rao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Zhang -X- _ O
and -X- _ O
Ji -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
text -X- _ B-TaskName
summarization -X- _ I-TaskName
( -X- _ O
Liao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Hardy -X- _ O
and -X- _ O
Vlachos -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
and -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
( -X- _ O
Mitra -X- _ O
and -X- _ O
Baral -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Sachan -X- _ O
and -X- _ O
Xing -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O

Figure -X- _ O
1(a -X- _ O
) -X- _ O
illustrates -X- _ O
an -X- _ O
AMR -X- _ B-MethodName
graph -X- _ O
where -X- _ O
nodes -X- _ O
represent -X- _ O
concepts -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
die-01 -X- _ O
and -X- _ O
soldier -X- _ O
, -X- _ O
and -X- _ O
edges -X- _ O
represent -X- _ O
relations -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
: -X- _ O
ARG1 -X- _ O
and -X- _ O
: -X- _ O
quant -X- _ O
. -X- _ O

1 -X- _ O
Introduction -X- _ O
Abstract -X- _ B-HyperparameterName
Meaning -X- _ I-HyperparameterName
Representation -X- _ I-HyperparameterName
( -X- _ I-HyperparameterName
AMR -X- _ I-HyperparameterName
) -X- _ I-HyperparameterName
( -X- _ O
Banarescu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
parsing -X- _ O
aims -X- _ O
to -X- _ O
translate -X- _ O
a -X- _ O
natural -X- _ O
sentence -X- _ O
into -X- _ O
a -X- _ O
directed -X- _ O
acyclic -X- _ O
graph -X- _ O
. -X- _ O

Extensive -X- _ O
experiments -X- _ O
on -X- _ O
AMR2.0 -X- _ B-MethodName
, -X- _ O
AMR3.0 -X- _ B-MethodName
, -X- _ O
structurecomplex -X- _ O
and -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
distribution -X- _ O
situations -X- _ O
verify -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
HCL -X- _ B-MethodName
. -X- _ O

Through -X- _ O
these -X- _ O
two -X- _ O
warming -X- _ O
- -X- _ O
up -X- _ O
processes -X- _ O
, -X- _ O
HCL -X- _ B-MethodName
reduces -X- _ O
the -X- _ O
difficulty -X- _ O
of -X- _ O
learning -X- _ O
complex -X- _ O
structures -X- _ O
, -X- _ O
thus -X- _ O
the -X- _ O
at -X- _ O
model -X- _ O
can -X- _ O
better -X- _ O
adapt -X- _ O
to -X- _ O
the -X- _ O
AMR -X- _ B-MethodName
hierarchy -X- _ O
. -X- _ O

SC -X- _ B-MethodName
switches -X- _ O
progressively -X- _ O
from -X- _ O
core -X- _ O
to -X- _ O
detail -X- _ O
AMR -X- _ B-MethodName
semantic -X- _ O
elements -X- _ O
while -X- _ O
IC -X- _ B-MethodName
transits -X- _ O
from -X- _ O
structuresimple -X- _ O
to -X- _ O
-complex -X- _ O
AMR -X- _ B-MethodName
instances -X- _ O
during -X- _ O
training -X- _ O
. -X- _ O

To -X- _ O
bridge -X- _ O
this -X- _ O
gap -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
Hierarchical -X- _ B-MethodName
Curriculum -X- _ I-MethodName
Learning -X- _ I-MethodName
( -X- _ I-MethodName
HCL -X- _ I-MethodName
) -X- _ I-MethodName
framework -X- _ I-MethodName
with -X- _ O
Structure -X- _ B-MethodName
- -X- _ I-MethodName
level -X- _ I-MethodName
( -X- _ I-MethodName
SC -X- _ I-MethodName
) -X- _ I-MethodName
and -X- _ O
Instance -X- _ B-MethodName
- -X- _ I-MethodName
level -X- _ I-MethodName
Curricula -X- _ I-MethodName
( -X- _ I-MethodName
IC -X- _ I-MethodName
) -X- _ I-MethodName
. -X- _ O

However -X- _ O
, -X- _ O
there -X- _ O
exists -X- _ O
a -X- _ O
gap -X- _ O
between -X- _ O
their -X- _ O
at -X- _ O
training -X- _ O
objective -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
equally -X- _ O
treats -X- _ O
all -X- _ O
output -X- _ O
tokens -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
hierarchical -X- _ O
AMR -X- _ B-MethodName
structure -X- _ O
, -X- _ O
which -X- _ O
limits -X- _ O
the -X- _ O
model -X- _ O
generalization -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
bottom -X- _ O
three -X- _ O
where -X- _ O
the -X- _ O
model -X- _ O
fails -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
target -X- _ O
words -X- _ O
have -X- _ O
very -X- _ O
similar -X- _ O
or -X- _ O
close -X- _ O
senses -X- _ O
, -X- _ O
making -X- _ O
them -X- _ O
really -X- _ O
hard -X- _ O
to -X- _ O
distinguish.331 -X- _ O
. -X- _ O

The -X- _ O
most -X- _ O
probable -X- _ O
predicted -X- _ O
words -X- _ O
for -X- _ O
the -X- _ O
top -X- _ O
three -X- _ O
examples -X- _ O
indicate -X- _ O
that -X- _ O
the -X- _ O
PLM -X- _ B-MethodName
has -X- _ O
spotted -X- _ O
the -X- _ O
correct -X- _ O
senses -X- _ O
in -X- _ O
both -X- _ O
contexts -X- _ O
. -X- _ O

The -X- _ O
top -X- _ O
three -X- _ O
examples -X- _ O
are -X- _ O
correctly -X- _ O
predicted -X- _ O
as -X- _ O
negative -X- _ O
with -X- _ O
high -X- _ O
confidence -X- _ O
( -X- _ O
high -X- _ O
similarity -X- _ B-MetricName
score -X- _ I-MetricName
) -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
bottom -X- _ O
three -X- _ O
are -X- _ O
predicted -X- _ O
positive -X- _ O
again -X- _ O
with -X- _ O
high -X- _ O
confidence -X- _ O
. -X- _ O

The -X- _ O
table -X- _ O
presents -X- _ O
our -X- _ O
generated -X- _ O
prompts -X- _ O
, -X- _ O
top-5 -X- _ O
most -X- _ O
probable -X- _ O
words -X- _ O
predicted -X- _ O
by -X- _ O
RoBERTa -X- _ B-MethodName
- -X- _ I-MethodName
Large -X- _ I-MethodName
for -X- _ O
each -X- _ O
prompt -X- _ O
and -X- _ O
the -X- _ O
final -X- _ O
prediction -X- _ O
of -X- _ O
SP -X- _ B-MethodName
. -X- _ O

We -X- _ O
did -X- _ O
not -X- _ O
include -X- _ O
the -X- _ O
positive -X- _ O
examples -X- _ O
, -X- _ O
since -X- _ O
the -X- _ O
observation -X- _ O
that -X- _ O
the -X- _ O
same -X- _ O
words -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
senses -X- _ O
are -X- _ O
treated -X- _ O
similarly -X- _ O
, -X- _ O
might -X- _ O
not -X- _ O
provide -X- _ O
a -X- _ O
useful -X- _ O
insight -X- _ O
. -X- _ O

The -X- _ O
examples -X- _ O
are -X- _ O
those -X- _ O
from -X- _ O
WiC -X- _ B-TaskName
dev -X- _ O
set -X- _ O
which -X- _ O
had -X- _ O
negative -X- _ O
labels -X- _ O
. -X- _ O

Notably -X- _ O
, -X- _ O
this -X- _ O
observation -X- _ O
is -X- _ O
in -X- _ O
line -X- _ O
with -X- _ O
our -X- _ O
previous -X- _ O
experiments -X- _ O
that -X- _ O
in -X- _ O
general -X- _ O
Spearman -X- _ B-MetricName
has -X- _ O
superior -X- _ O
performance -X- _ O
over -X- _ O
Cosine -X- _ B-MetricName
similarity -X- _ I-MetricName
. -X- _ O

The -X- _ O
results -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
generally -X- _ O
confirm -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
SP -X- _ B-MethodName
with -X- _ O
different -X- _ O
PLMs -X- _ B-MethodName
. -X- _ O

Since -X- _ O
our -X- _ O
cloze -X- _ B-MethodName
- -X- _ I-MethodName
style -X- _ I-MethodName
prompt -X- _ I-MethodName
template -X- _ O
is -X- _ O
not -X- _ O
applicable -X- _ O
to -X- _ O
GPT2 -X- _ B-MethodName
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
different -X- _ O
template -X- _ O
for -X- _ O
it -X- _ O
: -X- _ O
sentence -X- _ O
+ -X- _ O
targetword -X- _ O
+ -X- _ O
" -X- _ O
means -X- _ O
" -X- _ O
. -X- _ O

Table -X- _ O
3 -X- _ O
shows -X- _ O
full -X- _ O
test -X- _ O
set -X- _ O
results -X- _ O
of -X- _ O
SP -X- _ B-MethodName
for -X- _ O
different -X- _ O
PLMs -X- _ B-MethodName
and -X- _ O
similarity -X- _ O
measures -X- _ O
to -X- _ O
compare -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
SP -X- _ B-MethodName
in -X- _ O
different -X- _ O
scenarios -X- _ O
. -X- _ O

A -X- _ O
Experiments -X- _ O
with -X- _ O
other -X- _ O
PLMs -X- _ B-MethodName
This -X- _ O
appendix -X- _ O
contains -X- _ O
more -X- _ O
details -X- _ O
on -X- _ O
WiC -X- _ B-DatasetName
experiments -X- _ O
. -X- _ O

SuperGLUE -X- _ B-DatasetName
: -X- _ O
A -X- _ O
stickier -X- _ O
benchmark -X- _ O
for -X- _ O
general -X- _ B-TaskName
- -X- _ I-TaskName
purpose -X- _ I-TaskName
language -X- _ I-TaskName
understanding -X- _ I-TaskName
systems -X- _ O
. -X- _ O

AutoPrompt -X- _ B-MethodName
: -X- _ O
Eliciting -X- _ O
Knowledge -X- _ O
from -X- _ O
Language -X- _ O
Models -X- _ O
with -X- _ O
Automatically -X- _ B-MethodName
Generated -X- _ I-MethodName
Prompts -X- _ I-MethodName
. -X- _ O

WiC -X- _ B-DatasetName
: -X- _ O
the -X- _ O
word -X- _ O
- -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
dataset -X- _ O
for -X- _ O
evaluating -X- _ O
context -X- _ O
- -X- _ O
sensitive -X- _ O
meaning -X- _ O
representations -X- _ O
. -X- _ O

BERT -X- _ B-MethodName
: -X- _ O
Pre -X- _ O
- -X- _ O
training -X- _ O
of -X- _ O
deep -X- _ B-MethodName
bidirectional -X- _ I-MethodName
transformers -X- _ I-MethodName
for -X- _ O
language -X- _ B-TaskName
understanding -X- _ I-TaskName
. -X- _ O

Language -X- _ O
models -X- _ O
are -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
learners -X- _ O
. -X- _ O

As -X- _ O
future -X- _ O
work -X- _ O
, -X- _ O
one -X- _ O
interesting -X- _ O
direction -X- _ O
could -X- _ O
be -X- _ O
to -X- _ O
perform -X- _ O
further -X- _ O
analysis -X- _ O
on -X- _ O
the -X- _ O
behaviour -X- _ O
of -X- _ O
Spearmans -X- _ B-MetricName
correlation -X- _ I-MetricName
compared -X- _ O
to -X- _ O
cosine -X- _ B-MetricName
similarity -X- _ I-MetricName
anywhere -X- _ O
it -X- _ O
is -X- _ O
applicable -X- _ O
as -X- _ O
a -X- _ O
similarity -X- _ O
measure -X- _ O
. -X- _ O

We -X- _ O
hope -X- _ O
that -X- _ O
our -X- _ O
positive -X- _ O
results -X- _ O
inspire -X- _ O
other -X- _ O
prompting -X- _ O
strategies -X- _ O
to -X- _ O
better -X- _ O
exploit -X- _ O
the -X- _ O
encoded -X- _ O
knowledge -X- _ O
in -X- _ O
PLMs -X- _ B-MethodName
. -X- _ O

We -X- _ O
also -X- _ O
showed -X- _ O
that -X- _ O
Spearmans -X- _ B-MetricName
ranking -X- _ I-MetricName
correlation -X- _ I-MetricName
is -X- _ O
a -X- _ O
more -X- _ O
robust -X- _ O
choice -X- _ O
of -X- _ O
similarity -X- _ B-MetricName
measure -X- _ I-MetricName
compared -X- _ O
to -X- _ O
cosine -X- _ B-MetricName
similarityin -X- _ I-MetricName
this -X- _ O
setting -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
work -X- _ O
we -X- _ O
showed -X- _ O
that -X- _ O
similarity -X- _ O
based -X- _ O
approach -X- _ O
to -X- _ O
promptbased -X- _ O
learning -X- _ O
is -X- _ O
capable -X- _ O
of -X- _ O
achieving -X- _ O
comparable -X- _ O
results -X- _ O
to -X- _ O
purely -X- _ O
fine -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
based -X- _ I-MethodName
methods -X- _ I-MethodName
on -X- _ O
Word -X- _ B-TaskName
- -X- _ I-TaskName
in -X- _ I-TaskName
- -X- _ I-TaskName
Context -X- _ I-TaskName
task -X- _ I-TaskName
, -X- _ O
in -X- _ O
which -X- _ O
previous -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
attempts -X- _ O
have -X- _ O
failed -X- _ O
. -X- _ O

4 -X- _ O
Conclusion -X- _ O
We -X- _ O
proposed -X- _ O
an -X- _ O
adaptation -X- _ O
of -X- _ O
prompt -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
learning -X- _ I-MethodName
which -X- _ O
addresses -X- _ O
the -X- _ O
common -X- _ O
failure -X- _ O
of -X- _ O
existing -X- _ O
techniques -X- _ O
on -X- _ O
the -X- _ O
WiC -X- _ B-DatasetName
dataset -X- _ O
. -X- _ O

This -X- _ O
further -X- _ O
supports -X- _ O
the -X- _ O
sensitivity -X- _ O
of -X- _ O
cosine -X- _ O
similarity -X- _ O
for -X- _ O
WiC -X- _ B-TaskName
to -X- _ O
the -X- _ O
noisy -X- _ O
variations -X- _ O
along -X- _ O
the -X- _ O
most -X- _ O
dominant -X- _ O
dimension -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
other -X- _ O
two -X- _ O
tasks -X- _ O
. -X- _ O

The -X- _ O
ratio -X- _ B-MetricName
of -X- _ I-MetricName
variance -X- _ I-MetricName
is -X- _ O
6.5 -X- _ O
times -X- _ O
for -X- _ O
WiC -X- _ B-DatasetName
compared -X- _ O
to -X- _ O
SST -X- _ B-MethodName
and -X- _ O
27.3 -X- _ O
times -X- _ O
compared -X- _ O
to -X- _ O
SICK -X- _ B-MethodName
. -X- _ O

Figure -X- _ O
2 -X- _ O
illustrates -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
values -X- _ O
for -X- _ O
the -X- _ O
most -X- _ O
dominant -X- _ O
dimension -X- _ O
. -X- _ O

To -X- _ O
verify -X- _ O
our -X- _ O
hypothesis -X- _ O
, -X- _ O
we -X- _ O
ran -X- _ O
an -X- _ O
experiment -X- _ O
using -X- _ O
1200 -X- _ O
sample -X- _ O
MASK -X- _ O
embeddings -X- _ O
for -X- _ O
each -X- _ O
of -X- _ O
our -X- _ O
three -X- _ O
tasks -X- _ O
. -X- _ O

It -X- _ O
is -X- _ O
known -X- _ O
that -X- _ O
the -X- _ O
most -X- _ O
dominant -X- _ O
dimensions -X- _ O
in -X- _ O
PLMs -X- _ B-MethodName
often -X- _ O
encode -X- _ O
irrelevant -X- _ O
information -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
word -X- _ O
frequency -X- _ O
( -X- _ O
Gao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
therefore -X- _ O
hampering -X- _ O
performance -X- _ O
for -X- _ O
sensitive -X- _ O
metrics -X- _ O
such -X- _ O
as -X- _ O
cosine -X- _ B-MetricName
similarity -X- _ I-MetricName
. -X- _ O

This -X- _ O
results -X- _ O
in -X- _ O
a -X- _ O
higher -X- _ O
spread -X- _ O
on -X- _ O
the -X- _ O
most -X- _ O
dominant -X- _ O
dimension -X- _ O
in -X- _ O
the -X- _ O
case -X- _ O
of -X- _ O
WiC -X- _ B-DatasetName
. -X- _ O

However -X- _ O
, -X- _ O
in -X- _ O
SST -X- _ O
and -X- _ O
SICK -X- _ O
the -X- _ O
MASK -X- _ B-MethodName
template -X- _ O
embedding -X- _ O
is -X- _ O
more -X- _ O
restricted -X- _ O
, -X- _ O
often -X- _ O
representing -X- _ O
a -X- _ O
closely -X- _ O
related -X- _ O
word -X- _ O
to -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
class -X- _ O
centroid -X- _ O
embeddings -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
in -X- _ O
SST -X- _ O
the -X- _ O
MASK -X- _ B-MethodName
embedding -X- _ O
almost -X- _ O
always -X- _ O
represents -X- _ O
a -X- _ O
positive -X- _ O
or -X- _ O
negative -X- _ O
adjective -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
WiC -X- _ B-DatasetName
, -X- _ O
the -X- _ O
MASK -X- _ B-MethodName
embeddings -X- _ I-MethodName
can -X- _ O
potentially -X- _ O
refer -X- _ O
to -X- _ O
any -X- _ O
word -X- _ O
, -X- _ O
varying -X- _ O
from -X- _ O
sample -X- _ O
to -X- _ O
sample -X- _ O
. -X- _ O

Figure -X- _ O
2 -X- _ O
: -X- _ O
The -X- _ O
distribution -X- _ O
of -X- _ O
values -X- _ O
for -X- _ O
the -X- _ O
most -X- _ O
dominant -X- _ O
dimension -X- _ O
of -X- _ O
the -X- _ O
MASK -X- _ B-MethodName
embedding -X- _ I-MethodName
for -X- _ O
1200 -X- _ O
samples -X- _ O
for -X- _ O
the -X- _ O
three -X- _ O
tasks -X- _ O
. -X- _ O

The -X- _ O
difference -X- _ O
in -X- _ O
the -X- _ O
gain -X- _ O
across -X- _ O
tasks -X- _ O
can -X- _ O
be -X- _ O
explained -X- _ O
by -X- _ O
the -X- _ O
difference -X- _ O
in -X- _ O
their -X- _ O
underlying -X- _ O
nature.328 -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
the -X- _ O
gain -X- _ O
in -X- _ O
the -X- _ O
other -X- _ O
two -X- _ O
tasks -X- _ O
is -X- _ O
negligible -X- _ O
. -X- _ O

The -X- _ O
results -X- _ O
approve -X- _ O
the -X- _ O
assumption -X- _ O
: -X- _ O
pruned -X- _ B-MetricName
cosine -X- _ I-MetricName
similarity -X- _ I-MetricName
gains -X- _ O
around -X- _ O
10% -X- _ B-MetricValue
absolute -X- _ O
performance -X- _ O
boost -X- _ O
on -X- _ O
WiC -X- _ B-DatasetName
, -X- _ O
filling -X- _ O
the -X- _ O
gap -X- _ O
to -X- _ O
Spearman -X- _ B-MetricName
correlation -X- _ I-MetricName
. -X- _ O

To -X- _ O
evaluate -X- _ O
this -X- _ O
hypothesis -X- _ O
, -X- _ O
we -X- _ O
performed -X- _ O
an -X- _ O
experiment -X- _ O
in -X- _ O
which -X- _ O
the -X- _ O
most -X- _ O
dominant -X- _ O
dimension -X- _ O
was -X- _ O
set -X- _ O
to -X- _ O
zero -X- _ O
for -X- _ O
all -X- _ O
the -X- _ O
embeddings -X- _ O
( -X- _ O
the -X- _ O
dominant -X- _ O
dimension -X- _ O
is -X- _ O
identical -X- _ O
across -X- _ O
all -X- _ O
vectors -X- _ O
) -X- _ O
. -X- _ O

This -X- _ O
superiority -X- _ O
can -X- _ O
be -X- _ O
explained -X- _ O
by -X- _ O
the -X- _ O
assumption -X- _ O
that -X- _ O
cosine -X- _ B-MetricName
similarity -X- _ I-MetricName
is -X- _ O
more -X- _ O
susceptible -X- _ O
to -X- _ O
variations -X- _ O
in -X- _ O
the -X- _ O
dominant -X- _ O
dimensions -X- _ O
. -X- _ O

3.5 -X- _ O
Similarity -X- _ B-MetricName
Measures -X- _ I-MetricName
Comparison -X- _ O
Notably -X- _ O
, -X- _ O
the -X- _ O
Spearman -X- _ O
correlation -X- _ B-MetricName
score -X- _ I-MetricName
, -X- _ O
which -X- _ O
is -X- _ O
less -X- _ O
commonly -X- _ O
used -X- _ O
for -X- _ O
comparing -X- _ O
embeddings -X- _ O
, -X- _ O
outperforms -X- _ O
the -X- _ O
cosine -X- _ B-MetricName
similarity -X- _ I-MetricName
on -X- _ O
WiC -X- _ B-DatasetName
by -X- _ O
a -X- _ O
large -X- _ O
margin -X- _ O
while -X- _ O
maintaining -X- _ O
the -X- _ O
same -X- _ O
level -X- _ O
of -X- _ O
performance -X- _ O
on -X- _ O
other -X- _ O
tasks -X- _ O
. -X- _ O

In -X- _ O
fact -X- _ O
, -X- _ O
one -X- _ O
could -X- _ O
argue -X- _ O
that -X- _ O
the -X- _ O
auto -X- _ O
- -X- _ O
generated -X- _ O
prompt -X- _ O
of -X- _ O
AutoPrompt -X- _ B-MethodName
is -X- _ O
sub -X- _ O
- -X- _ O
optimal -X- _ O
for -X- _ O
our -X- _ O
model -X- _ O
, -X- _ O
which -X- _ O
results -X- _ O
in -X- _ O
dropped -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
SICK -X- _ B-DatasetName
- -X- _ I-DatasetName
E -X- _ I-DatasetName
dataset -X- _ I-DatasetName
. -X- _ O

We -X- _ O
note -X- _ O
that -X- _ O
the -X- _ O
goal -X- _ O
of -X- _ O
this -X- _ O
experiment -X- _ O
was -X- _ O
to -X- _ O
showcase -X- _ O
that -X- _ O
our -X- _ O
simple -X- _ O
adaptation -X- _ O
is -X- _ O
also -X- _ O
applicable -X- _ O
to -X- _ O
scenarios -X- _ O
other -X- _ O
than -X- _ O
the -X- _ O
setting -X- _ O
of -X- _ O
WiC -X- _ B-DatasetName
. -X- _ O

SP -X- _ B-MethodName
retains -X- _ O
an -X- _ O
acceptable -X- _ O
level -X- _ O
of -X- _ O
performance -X- _ O
, -X- _ O
particularly -X- _ O
with -X- _ O
the -X- _ O
manual -X- _ O
prompt -X- _ O
, -X- _ O
but -X- _ O
lags -X- _ O
behind -X- _ O
with -X- _ O
the -X- _ O
auto -X- _ O
- -X- _ O
generated -X- _ O
prompt -X- _ O
. -X- _ O

To -X- _ O
compare -X- _ O
our -X- _ O
results -X- _ O
with -X- _ O
AutoPrompt -X- _ B-MethodName
on -X- _ O
the -X- _ O
SICK -X- _ B-TaskName
- -X- _ I-TaskName
E -X- _ I-TaskName
task -X- _ I-TaskName
, -X- _ O
we -X- _ O
report -X- _ O
accuracy -X- _ B-MethodName
score -X- _ I-MethodName
of -X- _ O
SP -X- _ B-MethodName
for -X- _ O
the -X- _ O
standard -X- _ O
test -X- _ O
set -X- _ O
( -X- _ O
with -X- _ O
neutral -X- _ O
majority -X- _ O
) -X- _ O
and -X- _ O
its -X- _ O
balanced -X- _ O
variant -X- _ O
. -X- _ O

improvement -X- _ O
by -X- _ O
simply -X- _ O
exploiting -X- _ O
a -X- _ O
non -X- _ O
- -X- _ O
optimized -X- _ O
manual -X- _ O
prompt -X- _ O
template -X- _ O
. -X- _ O

SP -X- _ B-MethodName
and -X- _ O
AutoPrompt -X- _ B-MethodName
( -X- _ O
Shin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
methods -X- _ O
are -X- _ O
based -X- _ O
on -X- _ O
RoBERTa -X- _ B-MethodName
- -X- _ O
Large -X- _ O
. -X- _ O

For -X- _ O
SST-2 -X- _ B-MethodName
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
SP -X- _ B-MethodName
can -X- _ O
exploit -X- _ O
a -X- _ O
manual -X- _ O
prompt -X- _ O
template -X- _ O
significantly -X- _ O
better -X- _ O
than -X- _ O
AutoPrompt -X- _ B-MethodName
, -X- _ O
while -X- _ O
being -X- _ O
competitive -X- _ O
using -X- _ O
the -X- _ O
best -X- _ O
template -X- _ O
optimized -X- _ O
by -X- _ O
AutoPrompt -X- _ B-MethodName
( -X- _ O
auto -X- _ O
- -X- _ O
generated -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
compare -X- _ O
SP -X- _ B-MethodName
with -X- _ O
AutoPrompt -X- _ B-MethodName
which -X- _ O
searches -X- _ O
for -X- _ O
the -X- _ O
best -X- _ O
template -X- _ O
for -X- _ O
each -X- _ O
task -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
include -X- _ O
some -X- _ O
detailed -X- _ O
examples -X- _ O
of -X- _ O
how -X- _ O
SP -X- _ B-MethodName
works -X- _ O
for -X- _ O
WiC -X- _ B-DatasetName
in -X- _ O
the -X- _ O
Appendix -X- _ O
. -X- _ O

We -X- _ O
report -X- _ O
SPs -X- _ B-MethodName
performance -X- _ O
on -X- _ O
WiC -X- _ B-DatasetName
for -X- _ O
other -X- _ O
PLMs -X- _ B-MethodName
in -X- _ O
the -X- _ O
Appendix -X- _ O
which -X- _ O
shows -X- _ O
our -X- _ O
method -X- _ O
/ -X- _ O
observation -X- _ O
does -X- _ O
not -X- _ O
depend -X- _ O
on -X- _ O
a -X- _ O
specific -X- _ O
PLM -X- _ B-MethodName
. -X- _ O

Therefore -X- _ O
, -X- _ O
using -X- _ O
limited -X- _ O
examples -X- _ O
in -X- _ O
the -X- _ O
fewshot -X- _ O
setting -X- _ O
they -X- _ O
are -X- _ O
able -X- _ O
to -X- _ O
reach -X- _ O
their -X- _ O
maximum -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
potential -X- _ O
on -X- _ O
WiC -X- _ B-DatasetName
. -X- _ O

This -X- _ O
observation -X- _ O
suggests -X- _ O
that -X- _ O
PLMs -X- _ B-MethodName
already -X- _ O
encode -X- _ O
a -X- _ O
certain -X- _ O
amount -X- _ O
of -X- _ O
task -X- _ O
- -X- _ O
related -X- _ O
knowledge -X- _ O
and -X- _ O
the -X- _ O
supervised -X- _ B-MethodName
fine -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
mainly -X- _ O
updates -X- _ O
their -X- _ O
task -X- _ O
description -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
what -X- _ O
the -X- _ O
task -X- _ O
is -X- _ O
, -X- _ O
not -X- _ O
how -X- _ O
to -X- _ O
solve -X- _ O
it -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
performance -X- _ O
of -X- _ O
SP -X- _ B-MethodName
in -X- _ O
the -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
setting -X- _ O
is -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
ballpark -X- _ O
as -X- _ O
supervised -X- _ B-MethodName
fine -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
( -X- _ O
with -X- _ O
nearly -X- _ O
170 -X- _ O
times -X- _ O
the -X- _ O
data -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
2,714 -X- _ O
instances -X- _ O
per -X- _ O
class -X- _ O
) -X- _ O
. -X- _ O

3.4.1 -X- _ O
WiC -X- _ B-DatasetName
Table -X- _ O
1 -X- _ O
summarizes -X- _ O
the -X- _ O
results -X- _ O
on -X- _ O
WiC -X- _ B-DatasetName
with -X- _ O
RoBERTa -X- _ B-MethodName
- -X- _ O
Large -X- _ O
as -X- _ O
SPs -X- _ B-MethodName
PLM -X- _ B-MethodName
. -X- _ O

3.4 -X- _ O
Results -X- _ O
Given -X- _ O
that -X- _ O
our -X- _ O
experiments -X- _ O
are -X- _ O
mainly -X- _ O
focused -X- _ O
on -X- _ O
the -X- _ O
WiC -X- _ B-DatasetName
dataset -X- _ I-DatasetName
, -X- _ O
we -X- _ O
first -X- _ O
report -X- _ O
our -X- _ O
results -X- _ O
on -X- _ O
this -X- _ O
benchmark -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
provide -X- _ O
additional -X- _ O
results -X- _ O
for -X- _ O
the -X- _ O
other -X- _ O
two -X- _ O
tasks -X- _ O
. -X- _ O

For -X- _ O
each -X- _ O
experiment -X- _ O
, -X- _ O
we -X- _ O
report -X- _ O
the -X- _ O
average -X- _ O
performance -X- _ O
along -X- _ O
with -X- _ O
the -X- _ O
standard -X- _ B-MetricName
deviation -X- _ I-MetricName
. -X- _ O

repeated -X- _ O
5 -X- _ O
times -X- _ O
using -X- _ O
different -X- _ O
randomly -X- _ O
sampled -X- _ O
training -X- _ O
examples -X- _ O
. -X- _ O

SP -X- _ B-MethodName
models -X- _ O
are -X- _ O
based -X- _ O
on -X- _ O
RoBERTa -X- _ B-MethodName
- -X- _ O
Large -X- _ O
. -X- _ O

As -X- _ O
for -X- _ O
PLM -X- _ B-MethodName
, -X- _ O
we -X- _ O
opted -X- _ O
for -X- _ O
RoBERTA -X- _ B-MethodName
- -X- _ O
large -X- _ O
to -X- _ O
be -X- _ O
able -X- _ O
to -X- _ O
benchmark -X- _ O
our -X- _ O
results -X- _ O
against -X- _ O
AutoPrompts -X- _ B-MethodName
( -X- _ O
Shin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

3.3 -X- _ O
Setup -X- _ O
To -X- _ O
train -X- _ O
our -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
only -X- _ O
used -X- _ O
16 -X- _ O
examples -X- _ O
per -X- _ O
class -X- _ O
. -X- _ O

Thus -X- _ O
we -X- _ O
define -X- _ O
our -X- _ O
own -X- _ O
manual -X- _ O
template -X- _ O
function -X- _ O
as -X- _ O
: -X- _ O
T(pre -X- _ O
; -X- _ O
hyp -X- _ O
) -X- _ O
= -X- _ O
pre+ -X- _ O
? -X- _ O
Answer -X- _ O
: -X- _ O
, -X- _ O
+ -X- _ O
hyp -X- _ O
, -X- _ O
where -X- _ O
preis -X- _ O
the -X- _ O
premise -X- _ O
and -X- _ O
hypis -X- _ O
the -X- _ O
hypothesis -X- _ O
of -X- _ O
an -X- _ O
input -X- _ O
example -X- _ O
. -X- _ O

In -X- _ O
our -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
only -X- _ O
use -X- _ O
the -X- _ O
former -X- _ O
annotations -X- _ O
( -X- _ O
SICK -X- _ B-MetricName
- -X- _ I-MetricName
E -X- _ I-MetricName
) -X- _ O
to -X- _ O
compare -X- _ O
our -X- _ O
results -X- _ O
with -X- _ O
AutoPrompt -X- _ B-MethodName
, -X- _ O
which -X- _ O
only -X- _ O
reports -X- _ O
results -X- _ O
for -X- _ O
its -X- _ O
optimized -X- _ O
prompt -X- _ O
. -X- _ O

Sentences -X- _ O
Involving -X- _ O
Compositional -X- _ O
Knowledge -X- _ O
( -X- _ O
Marelli -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
collection -X- _ O
of -X- _ O
sentence -X- _ O
pairs -X- _ O
annotated -X- _ O
with -X- _ O
their -X- _ O
entailment -X- _ O
relationship -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
a -X- _ O
quantified -X- _ O
measurement -X- _ O
of -X- _ O
their -X- _ O
semantic -X- _ B-MetricName
similarity -X- _ I-MetricName
. -X- _ O

This -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
manual -X- _ O
prompt -X- _ O
used -X- _ O
in -X- _ O
AutoPrompt -X- _ B-MethodName
. -X- _ O

For -X- _ O
this -X- _ O
task -X- _ O
we -X- _ O
used -X- _ O
the -X- _ O
automatically -X- _ O
- -X- _ O
generated -X- _ O
template -X- _ O
of -X- _ O
AutoPrompt -X- _ B-MethodName
, -X- _ O
along -X- _ O
with -X- _ O
the -X- _ O
following -X- _ O
manual -X- _ O
template -X- _ O
: -X- _ O
T(sent -X- _ O
) -X- _ O
= -X- _ O
sent -X- _ O
+ -X- _ O
this -X- _ O
movie -X- _ O
was -X- _ O
. -X- _ O
, -X- _ O
where -X- _ O
sent -X- _ O
is -X- _ O
the -X- _ O
input -X- _ O
sentence -X- _ O
and -X- _ O
+ -X- _ O
is -X- _ O
concatenation -X- _ O
operator -X- _ O
. -X- _ O

We -X- _ O
follow -X- _ O
the -X- _ O
latter -X- _ O
( -X- _ B-TaskName
SST-2 -X- _ I-TaskName
) -X- _ O
in -X- _ O
our -X- _ O
experiments -X- _ O
. -X- _ O

Systems -X- _ O
are -X- _ O
evaluated -X- _ O
either -X- _ O
on -X- _ O
a -X- _ O
five -X- _ O
- -X- _ O
way -X- _ O
fine -X- _ B-TaskName
- -X- _ I-TaskName
grained -X- _ I-TaskName
or -X- _ O
binary -X- _ B-TaskName
classification -X- _ I-TaskName
task -X- _ I-TaskName
. -X- _ O

Stanford -X- _ B-TaskName
Sentiment -X- _ I-TaskName
Treebank -X- _ I-TaskName
( -X- _ O
Socher -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
contains -X- _ O
fine -X- _ O
- -X- _ O
grained -X- _ O
sentiment -X- _ O
labeled -X- _ O
parse -X- _ O
trees -X- _ O
of -X- _ O
sentences -X- _ O
from -X- _ O
movie -X- _ O
reviews -X- _ O
. -X- _ O

Following -X- _ O
AutoPrompt -X- _ B-MethodName
, -X- _ O
we -X- _ O
report -X- _ O
results -X- _ O
for -X- _ O
the -X- _ O
following -X- _ O
two -X- _ O
task -X- _ O
: -X- _ O
SST -X- _ B-TaskName
. -X- _ O

The -X- _ O
approach -X- _ O
makes -X- _ O
use -X- _ O
of -X- _ O
full -X- _ O
training -X- _ O
set -X- _ O
to -X- _ O
optimize -X- _ O
discrete -X- _ O
prompts -X- _ O
for -X- _ O
each -X- _ O
specific -X- _ O
target -X- _ O
task -X- _ O
. -X- _ O

For -X- _ O
this -X- _ O
experiment -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
against -X- _ O
AutoPrompt -X- _ B-MethodName
( -X- _ O
Shin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
goal -X- _ O
of -X- _ O
this -X- _ O
additional -X- _ O
experiment -X- _ O
is -X- _ O
twofold -X- _ O
: -X- _ O
first -X- _ O
, -X- _ O
to -X- _ O
show -X- _ O
the -X- _ O
applicability -X- _ O
of -X- _ O
SP -X- _ B-MethodName
to -X- _ O
other -X- _ O
settings -X- _ O
, -X- _ O
including -X- _ O
tasks -X- _ O
with -X- _ O
single -X- _ O
input -X- _ O
sequence -X- _ O
; -X- _ O
and -X- _ O
second -X- _ O
, -X- _ O
to -X- _ O
evaluate -X- _ O
if -X- _ O
SP -X- _ B-MethodName
is -X- _ O
effective -X- _ O
when -X- _ O
using -X- _ O
prompt -X- _ O
templates -X- _ O
from -X- _ O
other -X- _ O
techniques -X- _ O
, -X- _ O
including -X- _ O
those -X- _ O
optimized -X- _ O
for -X- _ O
specific -X- _ O
tasks -X- _ O
. -X- _ O

3.2 -X- _ O
Tasks -X- _ O
In -X- _ O
addition -X- _ O
to -X- _ O
WiC -X- _ B-TaskName
, -X- _ O
we -X- _ O
also -X- _ O
carried -X- _ O
out -X- _ O
experiments -X- _ O
on -X- _ O
two -X- _ O
more -X- _ O
tasks -X- _ O
. -X- _ O

GPT3 -X- _ B-MethodName
( -X- _ O
Brown -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
is -X- _ O
different -X- _ O
in -X- _ O
that -X- _ O
it -X- _ O
employs -X- _ O
the -X- _ O
so -X- _ O
- -X- _ O
called -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
learning -X- _ O
which -X- _ O
involves -X- _ O
no -X- _ O
parameter -X- _ B-MethodName
tuning -X- _ I-MethodName
. -X- _ O

P -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
uses -X- _ O
the -X- _ O
same -X- _ O
PLM -X- _ B-MethodName
as -X- _ O
PET -X- _ B-MethodName
, -X- _ O
but -X- _ O
optimizes -X- _ O
a -X- _ O
continuous -X- _ O
prompt -X- _ O
instead -X- _ O
of -X- _ O
tuning -X- _ O
PLM -X- _ B-MethodName
parameters -X- _ O
. -X- _ O

PET -X- _ O
( -X- _ O
Schick -X- _ O
and -X- _ O
Schtze -X- _ O
, -X- _ O
2021b -X- _ O
) -X- _ O
prefers -X- _ O
ALBERT -X- _ O
- -X- _ O
xxlarge -X- _ O
- -X- _ O
v2 -X- _ O
( -X- _ O
Lan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
over -X- _ O
RoBERTa -X- _ B-MethodName
( -X- _ O
with -X- _ O
an -X- _ O
average -X- _ O
gain -X- _ O
of -X- _ O
8 -X- _ O
points -X- _ O
on -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
SuperGLUE -X- _ B-TaskName
tasks -X- _ O
) -X- _ O
and -X- _ O
fine -X- _ O
- -X- _ O
tunes -X- _ O
it -X- _ O
withmanually -X- _ O
engineered -X- _ B-MethodName
cloze -X- _ I-MethodName
- -X- _ I-MethodName
style -X- _ I-MethodName
prompts -X- _ I-MethodName
. -X- _ O

3 -X- _ O
Experiments -X- _ O
3.1 -X- _ O
Comparison -X- _ O
Systems -X- _ O
We -X- _ O
compare -X- _ O
our -X- _ O
results -X- _ O
on -X- _ O
WiC -X- _ B-TaskName
with -X- _ O
three -X- _ O
other -X- _ O
methods -X- _ O
, -X- _ O
all -X- _ O
of -X- _ O
which -X- _ O
use -X- _ O
32 -X- _ O
examples -X- _ O
for -X- _ O
their -X- _ O
training -X- _ O
. -X- _ O

The -X- _ O
latter -X- _ O
is -X- _ O
a -X- _ O
rank -X- _ B-MetricName
- -X- _ I-MetricName
based -X- _ I-MetricName
comparison -X- _ I-MetricName
measure -X- _ I-MetricName
which -X- _ O
is -X- _ O
insensitive -X- _ O
to -X- _ O
the -X- _ O
absolute -X- _ O
values -X- _ O
of -X- _ O
individual -X- _ O
dimensions -X- _ O
( -X- _ O
rather -X- _ O
checks -X- _ O
for -X- _ O
their -X- _ O
relative -X- _ O
rankings -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
opted -X- _ O
for -X- _ O
two -X- _ O
similarity -X- _ B-MetricName
metrics -X- _ I-MetricName
: -X- _ O
cosine -X- _ B-MetricName
similarity -X- _ I-MetricName
and -X- _ O
Spearmans -X- _ B-MetricName
rank -X- _ I-MetricName
correlation -X- _ I-MetricName
. -X- _ O

Similarity -X- _ B-MetricName
Measures -X- _ I-MetricName
. -X- _ O

We -X- _ O
then -X- _ O
train -X- _ O
the -X- _ O
same -X- _ O
linear -X- _ O
model -X- _ O
as -X- _ O
before -X- _ O
on -X- _ O
the -X- _ O
similarity -X- _ B-MetricName
scores -X- _ I-MetricName
of -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
examples -X- _ O
to -X- _ O
find -X- _ O
the -X- _ O
best -X- _ O
discriminating -X- _ O
threshold -X- _ O
. -X- _ O

Finally -X- _ O
, -X- _ O
our -X- _ O
classification -X- _ O
step -X- _ O
reduces -X- _ O
to -X- _ O
that -X- _ O
of -X- _ O
directly -X- _ O
comparing -X- _ O
our -X- _ O
pair -X- _ O
of -X- _ O
embedding -X- _ O
vectors -X- _ O
using -X- _ O
a -X- _ O
similarity -X- _ O
function -X- _ O
, -X- _ O
to -X- _ O
produce -X- _ O
a -X- _ O
single -X- _ O
similarity -X- _ B-MetricName
score -X- _ O
for -X- _ O
each -X- _ O
instance -X- _ O
. -X- _ O

Next -X- _ O
the -X- _ O
prompts -X- _ O
are -X- _ O
separately -X- _ O
fed -X- _ O
to -X- _ O
PLM -X- _ B-MethodName
, -X- _ O
resulting -X- _ O
in -X- _ O
a -X- _ O
pair -X- _ O
of -X- _ O
mask -X- _ O
embeddings -X- _ O
as -X- _ O
PLMs -X- _ B-MethodName
response -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
first -X- _ O
step -X- _ O
of -X- _ O
SP -X- _ B-MethodName
, -X- _ O
we -X- _ O
apply -X- _ O
this -X- _ O
template -X- _ O
function -X- _ O
to -X- _ O
both -X- _ O
input -X- _ O
sentences -X- _ O
which -X- _ O
generates -X- _ O
a -X- _ O
pair -X- _ O
of -X- _ O
prompts -X- _ O
. -X- _ O

Having -X- _ O
an -X- _ O
input -X- _ O
sentence -X- _ O
and -X- _ O
the -X- _ O
target -X- _ O
word -X- _ O
index -X- _ O
, -X- _ O
we -X- _ O
insert -X- _ O
or -X- _ O
after -X- _ O
the -X- _ O
target -X- _ O
word -X- _ O
, -X- _ O
where -X- _ O
indicates -X- _ O
the -X- _ O
MASK -X- _ O
token -X- _ O
. -X- _ O

Therefore -X- _ O
, -X- _ O
we -X- _ O
ask -X- _ O
PLM -X- _ B-MethodName
about -X- _ O
the -X- _ O
triggered -X- _ O
meaning -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
word -X- _ O
, -X- _ O
separately -X- _ O
for -X- _ O
each -X- _ O
context -X- _ O
, -X- _ O
and -X- _ O
leave -X- _ O
the -X- _ O
comparison -X- _ O
to -X- _ O
similarity -X- _ B-MetricName
measures -X- _ O
. -X- _ O

Previous -X- _ O
work -X- _ O
has -X- _ O
fallen -X- _ O
short -X- _ O
of -X- _ O
designing -X- _ O
a -X- _ O
single -X- _ O
prompt -X- _ O
template -X- _ O
which -X- _ O
make -X- _ O
the -X- _ O
PLM -X- _ B-MethodName
answer -X- _ O
about -X- _ O
the -X- _ O
target -X- _ O
word -X- _ O
having -X- _ O
the -X- _ O
same -X- _ O
meaning -X- _ O
or -X- _ O
not -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
with -X- _ O
" -X- _ O
yes -X- _ O
" -X- _ O
or -X- _ O
" -X- _ O
no -X- _ O
" -X- _ O
) -X- _ O
. -X- _ O

Given -X- _ O
an -X- _ O
ambiguous -X- _ O
target -X- _ O
word -X- _ O
in -X- _ O
two -X- _ O
different -X- _ O
contexts -X- _ O
, -X- _ O
the -X- _ O
task -X- _ O
in -X- _ O
WiC -X- _ B-TaskName
is -X- _ O
defined -X- _ O
as -X- _ O
a -X- _ O
simple -X- _ B-TaskName
binary -X- _ I-TaskName
classification -X- _ I-TaskName
problem -X- _ O
to -X- _ O
identify -X- _ O
if -X- _ O
the -X- _ O
triggered -X- _ O
meaning -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
word -X- _ O
differs -X- _ O
in -X- _ O
the -X- _ O
two -X- _ O
contexts -X- _ O
or -X- _ O
not -X- _ O
. -X- _ O

2.1 -X- _ O
Similarity -X- _ B-MethodName
Prompting -X- _ I-MethodName
for -X- _ O
WiC -X- _ B-TaskName
The -X- _ O
surprising -X- _ O
failure -X- _ O
of -X- _ O
existing -X- _ O
prompt -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
techniques -X- _ I-MethodName
on -X- _ O
the -X- _ O
Word -X- _ B-TaskName
- -X- _ I-TaskName
in -X- _ I-TaskName
- -X- _ I-TaskName
Context -X- _ I-TaskName
task -X- _ I-TaskName
( -X- _ O
Pilehvar -X- _ O
and -X- _ O
Camacho -X- _ O
- -X- _ O
Collados -X- _ O
, -X- _ O
2019 -X- _ O
, -X- _ O
WiC -X- _ O
) -X- _ O
, -X- _ O
motivated -X- _ O
us -X- _ O
to -X- _ O
focus -X- _ O
on -X- _ O
filling -X- _ O
this -X- _ O
gap -X- _ O
. -X- _ O

This -X- _ O
linear -X- _ O
model -X- _ O
is -X- _ O
then -X- _ O
used -X- _ O
at -X- _ O
inference -X- _ O
time -X- _ O
to -X- _ O
evaluate -X- _ O
SP -X- _ B-MethodName
on -X- _ O
test -X- _ O
set -X- _ O
. -X- _ O

the -X- _ O
similarity -X- _ B-MetricName
to -X- _ O
each -X- _ O
centroid -X- _ O
as -X- _ O
a -X- _ O
feature -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
train -X- _ O
a -X- _ O
simple -X- _ O
linear -X- _ B-MethodName
classifier -X- _ I-MethodName
. -X- _ O

by -X- _ O
taking326 -X- _ O
. -X- _ O

To -X- _ O
alleviate -X- _ O
the -X- _ O
problem -X- _ O
, -X- _ O
we -X- _ O
perform -X- _ O
a -X- _ O
class -X- _ B-MethodName
centroid -X- _ I-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
dimension -X- _ I-MethodName
reduction -X- _ I-MethodName
( -X- _ O
i.e -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
this -X- _ O
assumes -X- _ O
the -X- _ O
variance -X- _ O
of -X- _ O
different -X- _ O
classes -X- _ O
to -X- _ O
be -X- _ O
equal -X- _ O
in -X- _ O
the -X- _ O
embedding -X- _ O
space -X- _ O
. -X- _ O

To -X- _ O
classify -X- _ O
a -X- _ O
new -X- _ O
sample -X- _ O
at -X- _ O
inference -X- _ O
time -X- _ O
, -X- _ O
a -X- _ O
simple -X- _ O
approach -X- _ O
would -X- _ O
be -X- _ O
to -X- _ O
employ -X- _ O
a -X- _ O
nearest -X- _ B-MethodName
centroid -X- _ I-MethodName
classifier -X- _ I-MethodName
. -X- _ O

Here -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
obtain -X- _ O
class -X- _ O
- -X- _ O
specific -X- _ O
centroids -X- _ O
by -X- _ O
taking -X- _ O
the -X- _ O
average -X- _ O
of -X- _ O
the -X- _ O
MASK -X- _ O
embeddings -X- _ O
of -X- _ O
our -X- _ O
few -X- _ O
training -X- _ O
examples -X- _ O
. -X- _ O

The -X- _ O
third -X- _ O
step -X- _ O
is -X- _ O
where -X- _ O
SP -X- _ B-MethodName
differs -X- _ O
from -X- _ O
existing -X- _ O
prompt -X- _ O
- -X- _ O
based -X- _ O
approaches -X- _ O
. -X- _ O

This -X- _ O
is -X- _ O
done -X- _ O
by -X- _ O
giving -X- _ O
the -X- _ O
generated -X- _ O
prompts -X- _ O
to -X- _ O
the -X- _ O
PLM -X- _ B-MethodName
as -X- _ O
input -X- _ O
and -X- _ O
obtaining -X- _ O
its -X- _ O
contextualized -X- _ O
embedding -X- _ O
at -X- _ O
the -X- _ O
MASK -X- _ O
index -X- _ O
. -X- _ O

The -X- _ O
next -X- _ O
step -X- _ O
is -X- _ O
feature -X- _ B-TaskName
extraction -X- _ I-TaskName
from -X- _ O
a -X- _ O
PLM -X- _ B-MethodName
. -X- _ O

this -X- _ O
movie -X- _ O
was -X- _ O
. -X- _ O
. -X- _ O

For -X- _ O
instance -X- _ O
, -X- _ O
in -X- _ O
sentiment -X- _ B-TaskName
analysis -X- _ I-TaskName
, -X- _ O
for -X- _ O
the -X- _ O
movie -X- _ O
review -X- _ O
Just -X- _ O
give -X- _ O
it -X- _ O
a -X- _ O
chance -X- _ O
. -X- _ O
, -X- _ O
a -X- _ O
valid -X- _ O
template -X- _ O
function -X- _ O
would -X- _ O
generate -X- _ O
as -X- _ O
output -X- _ O
prompt -X- _ O
: -X- _ O
Just -X- _ O
give -X- _ O
it -X- _ O
a -X- _ O
chance -X- _ O
. -X- _ O

Given -X- _ O
a -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
input -X- _ O
consisting -X- _ O
of -X- _ O
one -X- _ O
or -X- _ O
more -X- _ O
text -X- _ O
sequences -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
use -X- _ O
a -X- _ O
template -X- _ O
function -X- _ O
to -X- _ O
generate -X- _ O
a -X- _ O
prompta -X- _ O
sequence -X- _ O
of -X- _ O
tokens -X- _ O
containing -X- _ O
one -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
tokenper -X- _ O
input -X- _ O
sequence -X- _ O
. -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
, -X- _ O
SP -X- _ B-MethodName
consists -X- _ O
of -X- _ O
three -X- _ O
main -X- _ O
steps -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
prompt -X- _ B-MethodName
generation -X- _ I-MethodName
, -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
feature -X- _ B-MethodName
extraction -X- _ I-MethodName
, -X- _ O
and -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
prediction -X- _ B-MethodName
. -X- _ O

In -X- _ O
what -X- _ O
follows -X- _ O
in -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
describe -X- _ O
our -X- _ O
similarity -X- _ O
- -X- _ O
based -X- _ O
prompting -X- _ O
approach -X- _ O
which -X- _ O
we -X- _ O
will -X- _ O
refer -X- _ O
to -X- _ O
as -X- _ O
SP(Similarity -X- _ B-MethodName
Prompting -X- _ I-MethodName
) -X- _ I-MethodName
. -X- _ O

We -X- _ O
propose -X- _ O
a -X- _ O
similarity -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
method -X- _ I-MethodName
that -X- _ O
not -X- _ O
only -X- _ O
better -X- _ O
exploits -X- _ O
the -X- _ O
response -X- _ O
, -X- _ O
but -X- _ O
also -X- _ O
allows -X- _ O
using -X- _ O
multiple -X- _ O
prompts -X- _ O
which -X- _ O
paves -X- _ O
the -X- _ O
way -X- _ O
for -X- _ O
comparisonbased -X- _ O
tasks -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
WiC -X- _ B-TaskName
. -X- _ O

Existing -X- _ O
methods -X- _ O
often -X- _ O
pick -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
one -X- _ O
or -X- _ O
few -X- _ O
word -X- _ O
predictions -X- _ O
as -X- _ O
a -X- _ O
representative -X- _ O
for -X- _ O
each -X- _ O
class -X- _ O
, -X- _ O
utilizing -X- _ O
the -X- _ O
languagemodels -X- _ O
response -X- _ O
in -X- _ O
a -X- _ O
sub -X- _ O
- -X- _ O
optimal -X- _ O
manner -X- _ O
. -X- _ O

For -X- _ O
instance -X- _ O
, -X- _ O
to -X- _ O
ask -X- _ O
about -X- _ O
the -X- _ O
sentiment -X- _ O
of -X- _ O
a -X- _ O
movie -X- _ O
review -X- _ O
, -X- _ O
one -X- _ O
can -X- _ O
augment -X- _ O
the -X- _ O
review -X- _ O
with -X- _ O
a -X- _ O
cloze -X- _ O
question -X- _ O
like -X- _ O
this -X- _ O
movie -X- _ O
was -X- _ O
. -X- _ O
. -X- _ O

The -X- _ O
common -X- _ O
approach -X- _ O
in -X- _ O
prompt -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
learning -X- _ I-MethodName
is -X- _ O
to -X- _ O
reformulate -X- _ O
the -X- _ O
task -X- _ O
as -X- _ O
a -X- _ O
cloze -X- _ O
- -X- _ O
style -X- _ O
question -X- _ O
. -X- _ O

Assuming -X- _ O
that -X- _ O
PLMs -X- _ B-MethodName
know -X- _ O
how -X- _ O
to -X- _ O
solve -X- _ O
some -X- _ O
tasks -X- _ O
( -X- _ O
to -X- _ O
some -X- _ O
extent -X- _ O
) -X- _ O
, -X- _ O
prompt -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
learning -X- _ I-MethodName
focuses -X- _ O
on -X- _ O
the -X- _ O
former -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
teaching -X- _ O
the -X- _ O
model -X- _ O
what -X- _ O
the -X- _ O
task -X- _ O
is -X- _ O
, -X- _ O
without -X- _ O
needing -X- _ O
to -X- _ O
resort -X- _ O
to -X- _ O
large -X- _ O
amounts -X- _ O
of -X- _ O
data -X- _ O
or -X- _ O
additional -X- _ O
parameters -X- _ O
. -X- _ O

2 -X- _ O
Methodology -X- _ O
Fine -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
on -X- _ O
a -X- _ O
specific -X- _ O
task -X- _ O
can -X- _ O
potentially -X- _ O
update -X- _ O
PLMs -X- _ B-MethodName
on -X- _ O
what -X- _ O
the -X- _ O
task -X- _ O
is -X- _ O
and -X- _ O
how -X- _ O
to -X- _ O
solve -X- _ O
it -X- _ O
. -X- _ O

Moreover -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
with -X- _ O
few -X- _ O
adjustments -X- _ O
, -X- _ O
this -X- _ O
simple -X- _ O
approach -X- _ O
can -X- _ O
be -X- _ O
effectively -X- _ O
used -X- _ O
for -X- _ O
other -X- _ O
downstream -X- _ O
tasks -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
work -X- _ O
we -X- _ O
investigate -X- _ O
the -X- _ O
latter -X- _ O
issue -X- _ O
by -X- _ O
Given -X- _ O
an -X- _ O
ambiguous -X- _ O
target -X- _ O
word -X- _ O
in -X- _ O
two -X- _ O
different -X- _ O
contexts -X- _ O
, -X- _ O
the -X- _ O
task -X- _ O
in -X- _ O
WiC -X- _ B-TaskName
is -X- _ O
defined -X- _ O
as -X- _ O
a -X- _ O
simple -X- _ O
binary -X- _ O
classification -X- _ O
problem -X- _ O
to -X- _ O
identify -X- _ O
if -X- _ O
the -X- _ O
triggered -X- _ O
meaning -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
word -X- _ O
differs -X- _ O
in -X- _ O
the -X- _ O
two -X- _ O
contexts -X- _ O
or -X- _ O
not.325 -X- _ O
. -X- _ O

PLM -X- _ B-MethodName
Similarity -X- _ B-MethodName
Classifier -X- _ I-MethodName
Prompt -X- _ O
G -X- _ O
e -X- _ O
n -X- _ O
e -X- _ O
r -X- _ O
a -X- _ O
t -X- _ O
i -X- _ O
o -X- _ O
n -X- _ O
Feature -X- _ O
E -X- _ O
x -X- _ O
t -X- _ O
r -X- _ O
a -X- _ O
c -X- _ O
t -X- _ O
i -X- _ O
o -X- _ O
n -X- _ O
Prediction -X- _ O
Figure -X- _ O
1 -X- _ O
: -X- _ O
An -X- _ O
illustration -X- _ O
of -X- _ O
the -X- _ O
similarity -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
method -X- _ I-MethodName
applied -X- _ O
to -X- _ O
sentiment -X- _ B-TaskName
analysis -X- _ I-TaskName
( -X- _ O
left -X- _ O
) -X- _ O
and -X- _ O
WiC -X- _ B-DatasetName
( -X- _ O
right -X- _ O
) -X- _ O
. -X- _ O

Given -X- _ O
the -X- _ O
comparison -X- _ O
- -X- _ O
based -X- _ O
nature -X- _ O
of -X- _ O
WiC -X- _ B-DatasetName
, -X- _ O
we -X- _ O
hypothesize -X- _ O
that -X- _ O
conventional -X- _ O
prompting -X- _ O
methods -X- _ O
fall -X- _ O
short -X- _ O
since -X- _ O
they -X- _ O
only -X- _ O
utilize -X- _ O
a -X- _ O
single -X- _ O
prompt -X- _ O
response -X- _ O
. -X- _ O

The -X- _ O
experimental -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
WiC -X- _ B-DatasetName
dataset -X- _ I-DatasetName
shows -X- _ O
that -X- _ O
, -X- _ O
with -X- _ O
only -X- _ O
16 -X- _ O
instances -X- _ O
per -X- _ O
class -X- _ O
, -X- _ O
our -X- _ O
proposed -X- _ O
prompt -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
technique -X- _ I-MethodName
can -X- _ O
achieve -X- _ O
comparable -X- _ O
results -X- _ O
to -X- _ O
the -X- _ O
fine -X- _ B-MethodName
- -X- _ I-MethodName
tuned -X- _ I-MethodName
models -X- _ I-MethodName
( -X- _ O
with -X- _ O
access -X- _ O
to -X- _ O
full -X- _ O
training -X- _ O
data -X- _ O
of -X- _ O
2700 -X- _ O
+ -X- _ O
instances -X- _ O
per -X- _ O
class -X- _ O
) -X- _ O
. -X- _ O

Hence -X- _ O
, -X- _ O
instead -X- _ O
of -X- _ O
relying -X- _ O
on -X- _ O
a -X- _ O
single -X- _ O
response -X- _ O
, -X- _ O
we -X- _ O
make -X- _ O
use -X- _ O
of -X- _ O
the -X- _ O
similarity -X- _ O
of -X- _ O
PLMs -X- _ B-MethodName
response -X- _ O
to -X- _ O
the -X- _ O
combination -X- _ O
of -X- _ O
a -X- _ O
pair -X- _ O
of -X- _ O
prompts -X- _ O
. -X- _ O

introducing -X- _ O
a -X- _ O
new -X- _ O
configuration -X- _ O
for -X- _ O
prompting -X- _ O
. -X- _ O

Template -X- _ O
I -X- _ O
had -X- _ O
lots -X- _ O
of -X- _ O
fun -X- _ O
! -X- _ O
I -X- _ O
h -X- _ O
a -X- _ O
d -X- _ O
l -X- _ O
o -X- _ O
t -X- _ O
s -X- _ O
o -X- _ O
f -X- _ O
fun -X- _ O
! -X- _ O
this -X- _ O
movie -X- _ O
w -X- _ O
a -X- _ O
s -X- _ O
[ -X- _ O
m -X- _ O
a -X- _ O
s -X- _ O
k -X- _ O
] -X- _ O
[ -X- _ O
mask -X- _ O
] -X- _ O
e -X- _ O
m -X- _ O
b -X- _ O
e -X- _ O
d -X- _ O
d -X- _ O
i -X- _ O
n -X- _ O
g -X- _ O
class -X- _ O
c -X- _ O
e -X- _ O
n -X- _ O
t -X- _ O
r -X- _ O
o -X- _ O
i -X- _ O
d -X- _ O
s -X- _ O
s -X- _ O
i -X- _ O
m -X- _ O
i -X- _ O
l -X- _ O
a -X- _ O
r -X- _ O
i -X- _ O
ty -X- _ O
scores -X- _ O
PLM -X- _ B-MethodName
Similarity -X- _ O
Classifier -X- _ O
Template -X- _ O
[ -X- _ O
mask -X- _ O
] -X- _ O
e -X- _ O
m -X- _ O
b -X- _ O
e -X- _ O
d -X- _ O
d -X- _ O
i -X- _ O
n -X- _ O
g -X- _ O
s -X- _ O
s -X- _ O
i -X- _ O
m -X- _ O
i -X- _ O
l -X- _ O
a -X- _ O
rity -X- _ O
score -X- _ O
T -X- _ O
h -X- _ O
e -X- _ O
b -X- _ O
o -X- _ O
d -X- _ O
y -X- _ O
o -X- _ O
r -X- _ O
[ -X- _ O
m -X- _ O
a -X- _ O
s -X- _ O
k -X- _ O
] -X- _ O
of -X- _ O
the -X- _ O
c -X- _ O
a -X- _ O
r -X- _ O
w -X- _ O
a -X- _ O
s -X- _ O
b -X- _ O
a -X- _ O
d -X- _ O
l -X- _ O
y -X- _ O
r -X- _ O
u -X- _ O
s -X- _ O
t -X- _ O
e -X- _ O
d -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
none -X- _ O
of -X- _ O
these -X- _ O
have -X- _ O
shown -X- _ O
success -X- _ O
on -X- _ O
the -X- _ O
WiC -X- _ B-TaskName
task -X- _ I-TaskName
. -X- _ O

To -X- _ O
address -X- _ O
the -X- _ O
first -X- _ O
issue -X- _ O
, -X- _ O
there -X- _ O
have -X- _ O
been -X- _ O
proposals -X- _ O
to -X- _ O
automatically -X- _ O
find -X- _ O
a -X- _ O
suitable -X- _ O
prompt -X- _ O
template -X- _ O
using -X- _ O
a -X- _ O
search -X- _ O
in -X- _ O
the -X- _ O
discrete -X- _ O
token -X- _ O
space -X- _ O
( -X- _ O
Shin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
or -X- _ O
in -X- _ O
the -X- _ O
continuous -X- _ O
embedding -X- _ O
space -X- _ O
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

Two -X- _ O
issues -X- _ O
could -X- _ O
be -X- _ O
responsible -X- _ O
for -X- _ O
the -X- _ O
latter -X- _ O
case -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
improper -X- _ O
prompt -X- _ O
, -X- _ O
or -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
inefficient -X- _ O
utilization -X- _ O
of -X- _ O
PLMs -X- _ B-MethodName
response -X- _ O
. -X- _ O

The -X- _ O
natural -X- _ O
question -X- _ O
that -X- _ O
arises -X- _ O
here -X- _ O
is -X- _ O
if -X- _ O
the -X- _ O
failure -X- _ O
of -X- _ O
few -X- _ B-MethodName
- -X- _ I-MethodName
shot -X- _ I-MethodName
techniques -X- _ I-MethodName
on -X- _ O
WiC -X- _ B-DatasetName
is -X- _ O
due -X- _ O
to -X- _ O
lack -X- _ O
of -X- _ O
relevant -X- _ O
encoded -X- _ O
knowledge -X- _ O
in -X- _ O
PLMs -X- _ B-MethodName
or -X- _ O
the -X- _ O
inefficiency -X- _ O
of -X- _ O
the -X- _ O
employed -X- _ O
prompt -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
methods -X- _ I-MethodName
. -X- _ O

The -X- _ O
same -X- _ O
pattern -X- _ O
of -X- _ O
failure -X- _ O
is -X- _ O
also -X- _ O
observed -X- _ O
in -X- _ O
the -X- _ O
more -X- _ O
recent -X- _ O
prompt -X- _ O
based -X- _ O
attempts -X- _ O
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Schick -X- _ O
and -X- _ O
Schtze -X- _ O
, -X- _ O
2021a -X- _ O
) -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
despite -X- _ O
proving -X- _ O
competitive -X- _ O
on -X- _ O
most -X- _ O
tasks -X- _ O
in -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
and -X- _ O
SuperGLUE -X- _ B-DatasetName
benchmarks -X- _ I-DatasetName
, -X- _ O
existing -X- _ O
prompt -X- _ O
- -X- _ O
based -X- _ O
techniques -X- _ O
fail -X- _ O
on -X- _ O
the -X- _ O
semantic -X- _ B-TaskName
distinction -X- _ I-TaskName
task -X- _ I-TaskName
of -X- _ O
the -X- _ O
Word -X- _ B-DatasetName
- -X- _ I-DatasetName
in -X- _ I-DatasetName
- -X- _ I-DatasetName
Context -X- _ I-DatasetName
( -X- _ I-DatasetName
WiC -X- _ I-DatasetName
) -X- _ I-DatasetName
dataset -X- _ I-DatasetName
. -X- _ O

However -X- _ O
, -X- _ O
surprisingly -X- _ O
, -X- _ O
the -X- _ O
Word -X- _ B-TaskName
- -X- _ I-TaskName
in -X- _ I-TaskName
- -X- _ I-TaskName
Context -X- _ I-TaskName
task -X- _ I-TaskName
( -X- _ O
Pilehvar -X- _ O
and -X- _ O
Camacho -X- _ O
- -X- _ O
Collados -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
tasks -X- _ O
in -X- _ O
the -X- _ O
SuperGLUE -X- _ B-DatasetName
benchmark -X- _ I-DatasetName
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
is -X- _ O
one -X- _ O
exception -X- _ O
on -X- _ O
which -X- _ O
these -X- _ O
methods -X- _ O
fail -X- _ O
to -X- _ O
stay -X- _ O
on -X- _ O
par -X- _ O
with -X- _ O
their -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
counterparts -X- _ O
. -X- _ O
While -X- _ O
a -X- _ O
simple -X- _ O
fine -X- _ B-MethodName
- -X- _ I-MethodName
tuned -X- _ I-MethodName
BERT -X- _ I-MethodName
- -X- _ I-MethodName
base -X- _ I-MethodName
model -X- _ I-MethodName
achieves -X- _ O
around -X- _ O
69% -X- _ B-MetricValue
accuracy -X- _ B-MetricName
on -X- _ O
this -X- _ O
task -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
GPT-3 -X- _ B-MethodName
, -X- _ O
with -X- _ O
more -X- _ O
than -X- _ O
100 -X- _ O
times -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
parameters -X- _ O
, -X- _ O
performs -X- _ O
no -X- _ O
better -X- _ O
than -X- _ O
a -X- _ O
random -X- _ O
baseline -X- _ O
by -X- _ O
employing -X- _ O
a -X- _ O
promptbased -X- _ O
approach -X- _ O
( -X- _ O
Brown -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

Prompt -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
techniques -X- _ I-MethodName
have -X- _ O
shown -X- _ O
impressive -X- _ O
performance -X- _ O
in -X- _ O
the -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
setting -X- _ O
, -X- _ O
especially -X- _ O
when -X- _ O
compared -X- _ O
to -X- _ O
standard -X- _ O
fine -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
on -X- _ O
datasets -X- _ O
of -X- _ O
hundreds -X- _ O
of -X- _ O
data -X- _ O
points -X- _ O
( -X- _ O
Le -X- _ O
Scao -X- _ O
and -X- _ O
Rush -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

From -X- _ O
the -X- _ O
practical -X- _ O
point -X- _ O
of -X- _ O
view -X- _ O
, -X- _ O
prompt -X- _ B-TaskName
- -X- _ I-TaskName
based -X- _ I-TaskName
learning -X- _ I-TaskName
is -X- _ O
particularly -X- _ O
well -X- _ O
- -X- _ O
suited -X- _ O
for -X- _ O
massive -X- _ O
models -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
GPT-3 -X- _ B-MethodName
, -X- _ O
since -X- _ O
it -X- _ O
does -X- _ O
not -X- _ O
involve -X- _ O
parameter -X- _ B-MethodName
tuning -X- _ I-MethodName
. -X- _ O

com -X- _ O
/ -X- _ O
tabasy -X- _ O
/ -X- _ O
similarity_prompting2019 -X- _ O
) -X- _ O
and -X- _ O
RoBERTA -X- _ O
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
when -X- _ O
combined -X- _ O
with -X- _ O
ensembling -X- _ B-MethodName
and -X- _ O
fine -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
( -X- _ O
Schick -X- _ O
and -X- _ O
Schtze -X- _ O
, -X- _ O
2021a -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
code -X- _ O
is -X- _ O
freely -X- _ O
available -X- _ O
at -X- _ O
https://github -X- _ O
. -X- _ O

This -X- _ O
paradigm -X- _ O
has -X- _ O
proven -X- _ O
its -X- _ O
effectiveness -X- _ O
in -X- _ O
the -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
setting -X- _ O
, -X- _ O
even -X- _ O
for -X- _ O
relatively -X- _ O
smaller -X- _ O
models -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
* -X- _ O
Work -X- _ O
done -X- _ O
as -X- _ O
a -X- _ O
Masters -X- _ O
student -X- _ O
at -X- _ O
IUST -X- _ O
. -X- _ O

The -X- _ O
core -X- _ O
idea -X- _ O
is -X- _ O
to -X- _ O
extract -X- _ O
knowledge -X- _ O
by -X- _ O
asking -X- _ O
the -X- _ O
right -X- _ O
question -X- _ O
from -X- _ O
the -X- _ B-MethodName
pre -X- _ I-MethodName
- -X- _ I-MethodName
trained -X- _ I-MethodName
language -X- _ I-MethodName
model -X- _ I-MethodName
( -X- _ I-MethodName
PLM -X- _ I-MethodName
) -X- _ I-MethodName
using -X- _ O
a -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
prompting -X- _ O
template -X- _ O
which -X- _ O
directs -X- _ O
the -X- _ O
PLM -X- _ B-MethodName
to -X- _ O
generate -X- _ O
a -X- _ O
textual -X- _ O
output -X- _ O
corresponding -X- _ O
to -X- _ O
a -X- _ O
target -X- _ O
class -X- _ O
. -X- _ O

The -X- _ O
current -X- _ O
dominant -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
approach -X- _ O
is -X- _ O
the -X- _ O
so -X- _ O
- -X- _ O
called -X- _ O
promptbased -X- _ O
learning -X- _ O
which -X- _ O
involves -X- _ O
a -X- _ O
simple -X- _ O
reformulation -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
as -X- _ O
a -X- _ O
cloze -X- _ B-MethodName
- -X- _ I-MethodName
style -X- _ I-MethodName
( -X- _ O
Taylor -X- _ O
, -X- _ O
1953 -X- _ O
) -X- _ O
fill -X- _ B-MethodName
- -X- _ I-MethodName
in -X- _ I-MethodName
- -X- _ I-MethodName
the -X- _ I-MethodName
- -X- _ I-MethodName
blank -X- _ I-MethodName
objective -X- _ O
. -X- _ O

1 -X- _ O
Introduction -X- _ O
Recently -X- _ O
, -X- _ O
there -X- _ O
has -X- _ O
been -X- _ O
a -X- _ O
resurgence -X- _ O
of -X- _ O
interest -X- _ O
in -X- _ O
few -X- _ B-MethodName
- -X- _ I-MethodName
shot -X- _ I-MethodName
learning -X- _ I-MethodName
, -X- _ O
especially -X- _ O
after -X- _ O
the -X- _ O
introduction -X- _ O
of -X- _ O
GPT-3 -X- _ B-MethodName
( -X- _ O
Brown -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
show -X- _ O
that -X- _ O
this -X- _ O
approach -X- _ O
can -X- _ O
be -X- _ O
effectively -X- _ O
extended -X- _ O
to -X- _ O
other -X- _ O
downstream -X- _ O
tasks -X- _ O
for -X- _ O
which -X- _ O
a -X- _ O
single -X- _ O
prompt -X- _ O
is -X- _ O
sufficient -X- _ O
. -X- _ O

Our -X- _ O
simple -X- _ O
adaptation -X- _ O
shows -X- _ O
that -X- _ O
the -X- _ O
failure -X- _ O
of -X- _ O
existing -X- _ O
prompt -X- _ O
- -X- _ O
based -X- _ O
techniques -X- _ O
in -X- _ O
semantic -X- _ B-TaskName
distinction -X- _ I-TaskName
is -X- _ O
due -X- _ O
to -X- _ O
their -X- _ O
improper -X- _ O
configuration -X- _ O
, -X- _ O
rather -X- _ O
than -X- _ O
lack -X- _ O
of -X- _ O
relevant -X- _ O
knowledge -X- _ O
in -X- _ O
the -X- _ O
representations -X- _ O
. -X- _ O

Trying -X- _ O
to -X- _ O
fill -X- _ O
this -X- _ O
gap -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
new -X- _ O
prompting -X- _ O
technique -X- _ O
, -X- _ O
based -X- _ O
on -X- _ O
similarity -X- _ B-MetricValue
metrics -X- _ I-MetricValue
, -X- _ O
which -X- _ O
boosts -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
performance -X- _ O
to -X- _ O
the -X- _ O
level -X- _ O
of -X- _ O
fully -X- _ O
supervised -X- _ O
methods -X- _ O
. -X- _ O

Specifically -X- _ O
, -X- _ O
none -X- _ O
of -X- _ O
the -X- _ O
existing -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
approaches -X- _ O
( -X- _ O
including -X- _ O
the -X- _ O
incontext -X- _ O
learning -X- _ O
of -X- _ O
GPT-3 -X- _ B-MethodName
) -X- _ O
can -X- _ O
attain -X- _ O
a -X- _ O
performance -X- _ O
that -X- _ O
is -X- _ O
meaningfully -X- _ O
different -X- _ O
from -X- _ O
the -X- _ O
random -X- _ O
baseline -X- _ O
. -X- _ O

Relative -X- _ B-MetricName
slot -X- _ I-MetricName
accuracy -X- _ I-MetricName
can -X- _ O
be -X- _ O
calculated -X- _ O
just -X- _ O
using -X- _ O
slot -X- _ O
- -X- _ O
values -X- _ O
appearing -X- _ O
in -X- _ O
the -X- _ O
dialogue -X- _ O
, -X- _ O
not -X- _ O
being -X- _ O
affected -X- _ O
by -X- _ O
unused -X- _ O
information.308 -X- _ O
. -X- _ O

When -X- _ O
calculating -X- _ O
score -X- _ O
, -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
total -X- _ O
slots -X- _ O
is -X- _ O
set -X- _ O
to -X- _ O
30 -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
of -X- _ O
hotel -X- _ O
, -X- _ O
train -X- _ O
, -X- _ O
restaurant -X- _ O
, -X- _ O
attraction -X- _ O
, -X- _ O
andtaxidomains -X- _ O
in -X- _ O
MultiWOZ -X- _ B-DatasetName
2.1 -X- _ O
. -X- _ O

The -X- _ O
joint -X- _ B-MetricName
goal -X- _ I-MetricName
accuracy -X- _ I-MetricName
of -X- _ O
every -X- _ O
turn -X- _ O
is -X- _ O
0 -X- _ B-MetricValue
because -X- _ O
of -X- _ O
belief -X- _ O
states -X- _ O
with -X- _ O
red -X- _ O
color -X- _ O
. -X- _ O

JGA -X- _ B-MetricName
: -X- _ I-MetricName
Joint -X- _ I-MetricName
Goal -X- _ I-MetricName
Accuracy -X- _ I-MetricName
, -X- _ O
SA -X- _ B-MetricName
: -X- _ I-MetricName
Slot -X- _ I-MetricName
Accuracy.307 -X- _ I-MetricName
. -X- _ O

For -X- _ O
convenience -X- _ O
, -X- _ O
the -X- _ O
name -X- _ O
of -X- _ O
each -X- _ O
metric -X- _ O
is -X- _ O
abbreviated -X- _ O
. -X- _ O

We -X- _ O
focused -X- _ O
on -X- _ O
metrics -X- _ O
evaluating -X- _ O
the -X- _ O
belief -X- _ O
state -X- _ O
of -X- _ O
each -X- _ O
turn -X- _ O
. -X- _ O

Turn -X- _ O
Predicted -X- _ O
State -X- _ O
Gold -X- _ O
State -X- _ O
Joint -X- _ B-MetricName
Goal -X- _ I-MetricName
Acc -X- _ I-MetricName
. -X- _ O

Turn -X- _ O
Predicted -X- _ O
State -X- _ O
Gold -X- _ O
State -X- _ O
Joint -X- _ B-MetricName
Goal -X- _ I-MetricName
Acc -X- _ I-MetricName
. -X- _ O

Table -X- _ O
A2 -X- _ O
: -X- _ O
Sample -X- _ O
dialogue -X- _ O
of -X- _ O
MultiWOZ -X- _ B-DatasetName
2.1 -X- _ O
test -X- _ O
set -X- _ O
( -X- _ O
MUL2270.json).304 -X- _ O
. -X- _ O

you -X- _ O
ve -X- _ O
already -X- _ O
helped -X- _ O
me -X- _ O
with -X- _ O
everything -X- _ O
i -X- _ O
needed -X- _ O
today -X- _ O
. -X- _ O

would -X- _ O
you -X- _ O
like -X- _ O
their -X- _ O
address -X- _ O
or -X- _ O
perhaps -X- _ O
to -X- _ O
book -X- _ O
a -X- _ O
room -X- _ O
there -X- _ O
? -X- _ O
User -X- _ O
: -X- _ O
thank -X- _ O
you -X- _ O
, -X- _ O
but -X- _ O
no -X- _ O
. -X- _ O

6System -X- _ O
: -X- _ O
archway -X- _ O
house -X- _ O
is -X- _ O
a -X- _ O
moderate -X- _ O
-ly -X- _ O
priced -X- _ O
guesthouse -X- _ O
. -X- _ O

would -X- _ O
you -X- _ O
like -X- _ O
to -X- _ O
book -X- _ O
a -X- _ O
room -X- _ O
? -X- _ O
User -X- _ O
: -X- _ O
i -X- _ O
would -X- _ O
first -X- _ O
like -X- _ O
to -X- _ O
know -X- _ O
what -X- _ O
their -X- _ O
price -X- _ O
range -X- _ O
and -X- _ O
hotel -X- _ O
type -X- _ O
are -X- _ O
, -X- _ O
thank -X- _ O
you -X- _ O
. -X- _ O

can -X- _ O
you -X- _ O
tell -X- _ O
me -X- _ O
if -X- _ O
they -X- _ O
have -X- _ O
free -X- _ O
wifi -X- _ O
? -X- _ O
5System -X- _ O
: -X- _ O
they -X- _ O
do -X- _ O
. -X- _ O

User -X- _ O
: -X- _ O
thanks -X- _ O
! -X- _ O
i -X- _ O
am -X- _ O
also -X- _ O
looking -X- _ O
for -X- _ O
a -X- _ O
hotel -X- _ O
called -X- _ O
archway -X- _ O
house -X- _ O
. -X- _ O

shall -X- _ O
i -X- _ O
book -X- _ O
you -X- _ O
for -X- _ O
that -X- _ O
train -X- _ O
? -X- _ O
User -X- _ O
: -X- _ O
can -X- _ O
i -X- _ O
get -X- _ O
the -X- _ O
price -X- _ O
for -X- _ O
a -X- _ O
ticket -X- _ O
, -X- _ O
first -X- _ O
? -X- _ O
4System -X- _ O
: -X- _ O
sure -X- _ O
! -X- _ O
the -X- _ O
ticket -X- _ O
is -X- _ O
23.60 -X- _ O
pounds -X- _ O
. -X- _ O

3System -X- _ O
: -X- _ O
take -X- _ O
train -X- _ O
tr1434 -X- _ O
, -X- _ O
which -X- _ O
will -X- _ O
arrive -X- _ O
at -X- _ O
18:08 -X- _ O
. -X- _ O

2System -X- _ O
: -X- _ O
when -X- _ O
would -X- _ O
you -X- _ O
like -X- _ O
to -X- _ O
leave -X- _ O
or -X- _ O
arrive -X- _ O
by -X- _ O
? -X- _ O
User -X- _ O
: -X- _ O
i -X- _ O
need -X- _ O
to -X- _ O
arrive -X- _ O
by -X- _ O
18,30 -X- _ O
. -X- _ O

can -X- _ O
you -X- _ O
tell -X- _ O
me -X- _ O
where -X- _ O
you -X- _ O
will -X- _ O
be -X- _ O
departing -X- _ O
from -X- _ O
? -X- _ O
User -X- _ O
: -X- _ O
departing -X- _ O
from -X- _ O
london -X- _ O
kings -X- _ O
cross -X- _ O
ontuesday -X- _ O
. -X- _ O

1System -X- _ O
: -X- _ O
i -X- _ O
will -X- _ O
be -X- _ O
happy -X- _ O
to -X- _ O
help -X- _ O
you -X- _ O
find -X- _ O
a -X- _ O
train -X- _ O
. -X- _ O

Turn -X- _ O
Dialogue -X- _ O
History -X- _ O
0System -X- _ O
: -X- _ O
User -X- _ O
: -X- _ O
i -X- _ O
would -X- _ O
like -X- _ O
help -X- _ O
finding -X- _ O
a -X- _ O
train -X- _ O
headed -X- _ O
to -X- _ O
cambridge -X- _ O
. -X- _ O

goodbye -X- _ O
Table -X- _ O
A1 -X- _ O
: -X- _ O
Sample -X- _ O
dialogue -X- _ O
of -X- _ O
MultiWOZ -X- _ B-DatasetName
2.1 -X- _ O
test -X- _ O
set -X- _ O
( -X- _ O
PMUL4234.json -X- _ O
) -X- _ O
. -X- _ O

thanks -X- _ O
so -X- _ O
much -X- _ O
for -X- _ O
all -X- _ O
your -X- _ O
help -X- _ O
. -X- _ O

anything -X- _ O
else -X- _ O
i -X- _ O
can -X- _ O
do -X- _ O
? -X- _ O
User -X- _ O
: -X- _ O
that -X- _ O
will -X- _ O
be -X- _ O
all -X- _ O
for -X- _ O
today -X- _ O
. -X- _ O

reference -X- _ O
number -X- _ O
is -X- _ O
lr5i1rzv -X- _ O
. -X- _ O

i -X- _ O
have -X- _ O
booked -X- _ O
6 -X- _ O
seats -X- _ O
. -X- _ O

as -X- _ O
for -X- _ O
the -X- _ O
train -X- _ O
, -X- _ O
what -X- _ O
time -X- _ O
would -X- _ O
you -X- _ O
like -X- _ O
to -X- _ O
depart -X- _ O
? -X- _ O
User -X- _ O
: -X- _ O
it -X- _ O
does -X- _ O
not -X- _ O
matter -X- _ O
as -X- _ O
long -X- _ O
as -X- _ O
i -X- _ O
am -X- _ O
there -X- _ O
by -X- _ O
13:45 -X- _ O
leaving -X- _ O
leicester -X- _ O
going -X- _ O
to -X- _ O
cambridge -X- _ O
, -X- _ O
ill -X- _ O
need -X- _ O
the -X- _ O
reference -X- _ O
number -X- _ O
too -X- _ O
please -X- _ O
5System -X- _ O
: -X- _ O
i -X- _ O
have -X- _ O
found -X- _ O
tr6210 -X- _ O
leaving -X- _ O
leicester -X- _ O
at -X- _ O
11:09 -X- _ O
on -X- _ O
saturday -X- _ O
and -X- _ O
arriving -X- _ O
in -X- _ O
cambridge -X- _ O
at -X- _ O
12:54 -X- _ O
. -X- _ O

i -X- _ O
also -X- _ O
need -X- _ O
a -X- _ O
train -X- _ O
for -X- _ O
the -X- _ O
same -X- _ O
and -X- _ O
should -X- _ O
leave -X- _ O
leicester -X- _ O
forcambridge -X- _ O
4System -X- _ O
: -X- _ O
alright -X- _ O
, -X- _ O
i -X- _ O
have -X- _ O
made -X- _ O
your -X- _ O
requested -X- _ O
booking -X- _ O
at -X- _ O
curry -X- _ O
garden -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
reference -X- _ O
number -X- _ O
is -X- _ O
hk9ycl6z -X- _ O
. -X- _ O

3System -X- _ O
: -X- _ O
would -X- _ O
you -X- _ O
like -X- _ O
to -X- _ O
try -X- _ O
curry -X- _ O
garden -X- _ O
? -X- _ O
User -X- _ O
: -X- _ O
that -X- _ O
is -X- _ O
fine -X- _ O
book -X- _ O
me -X- _ O
a -X- _ O
table -X- _ O
for -X- _ O
6onsatat17:30 -X- _ O
. -X- _ O

i -X- _ O
am -X- _ O
thinking -X- _ O
i -X- _ O
would -X- _ O
like -X- _ O
an -X- _ O
expensive -X- _ O
restaurant -X- _ O
. -X- _ O

2System -X- _ O
: -X- _ O
i -X- _ O
have -X- _ O
22 -X- _ O
indian -X- _ O
restaurant -X- _ O
-s -X- _ O
do -X- _ O
you -X- _ O
have -X- _ O
a -X- _ O
preference -X- _ O
for -X- _ O
area -X- _ O
of -X- _ O
town -X- _ O
? -X- _ O
User -X- _ O
: -X- _ O
no -X- _ O
, -X- _ O
i -X- _ O
do -X- _ O
not -X- _ O
care -X- _ O
where -X- _ O
it -X- _ O
is -X- _ O
. -X- _ O

Turn -X- _ O
Dialogue -X- _ O
History -X- _ O
0System -X- _ O
: -X- _ O
User -X- _ O
: -X- _ O
can -X- _ O
you -X- _ O
help -X- _ O
me -X- _ O
find -X- _ O
a -X- _ O
nice -X- _ O
restaurant -X- _ O
? -X- _ O
1System -X- _ O
: -X- _ O
sure -X- _ O
! -X- _ O
what -X- _ O
kind -X- _ O
of -X- _ O
food -X- _ O
do -X- _ O
you -X- _ O
like -X- _ O
? -X- _ O
User -X- _ O
: -X- _ O
i -X- _ O
was -X- _ O
thinking -X- _ O
some -X- _ O
indian -X- _ O
food -X- _ O
would -X- _ O
be -X- _ O
great -X- _ O
. -X- _ O

Furthermore -X- _ O
, -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
the -X- _ O
starting -X- _ O
point -X- _ O
of -X- _ O
making -X- _ O
the -X- _ O
joint -X- _ B-MetricName
goal -X- _ I-MetricName
accuracy -X- _ I-MetricName
of -X- _ O
subsequent -X- _ O
turns -X- _ O
to -X- _ O
0 -X- _ B-MetricValue
mainly -X- _ O
occurs -X- _ O
at -X- _ O
the -X- _ O
beginning -X- _ O
of -X- _ O
the -X- _ O
dialogue -X- _ O
does -X- _ O
not -X- _ O
change.303 -X- _ O
. -X- _ O

In -X- _ O
conclusion -X- _ O
, -X- _ O
it -X- _ O
can -X- _ O
be -X- _ O
determined -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
does -X- _ O
not -X- _ O
seem -X- _ O
to -X- _ O
accumulate -X- _ O
erroneous -X- _ O
predictions -X- _ O
because -X- _ O
of -X- _ O
an -X- _ O
accidental -X- _ O
situation -X- _ O
or -X- _ O
interpretation -X- _ O
of -X- _ O
annotations -X- _ O
, -X- _ O
but -X- _ O
this -X- _ O
does -X- _ O
not -X- _ O
negate -X- _ O
the -X- _ O
error -X- _ O
accumulation -X- _ O
phenomenon -X- _ O
. -X- _ O

Because -X- _ O
the -X- _ O
correct -X- _ O
belief -X- _ O
state -X- _ O
was -X- _ O
predicted -X- _ O
right -X- _ O
from -X- _ O
turn -X- _ O
5 -X- _ O
, -X- _ O
it -X- _ O
can -X- _ O
not -X- _ O
be -X- _ O
said -X- _ O
to -X- _ O
be -X- _ O
an -X- _ O
error -X- _ O
accumulation -X- _ O
phenomenon -X- _ O
; -X- _ O
however -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
did -X- _ O
not -X- _ O
predict -X- _ O
the -X- _ O
hotel -X- _ O
- -X- _ O
pricerange -X- _ O
slot -X- _ O
at -X- _ O
turn -X- _ O
6 -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
the -X- _ O
last -X- _ O
turn -X- _ O
in -X- _ O
this -X- _ O
case -X- _ O
. -X- _ O

In -X- _ O
other -X- _ O
words -X- _ O
, -X- _ O
because -X- _ O
the -X- _ O
dialogue -X- _ O
about -X- _ O
the -X- _ O
hotel -X- _ O
- -X- _ O
internet -X- _ O
slot -X- _ O
appears -X- _ O
over -X- _ O
turns -X- _ O
4 -X- _ O
and -X- _ O
5 -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
solely -X- _ O
an -X- _ O
error -X- _ B-MetricName
depending -X- _ O
on -X- _ O
the -X- _ O
prediction -X- _ O
timing -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O

The -X- _ O
second -X- _ O
dialogue -X- _ O
presented -X- _ O
in -X- _ O
Table -X- _ O
A2 -X- _ O
, -X- _ O
reports -X- _ O
the -X- _ O
incorrect -X- _ O
prediction -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
interpretation -X- _ O
of -X- _ O
annotations -X- _ O
at -X- _ O
turn -X- _ O
4 -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
in -X- _ O
this -X- _ O
case -X- _ O
, -X- _ O
another -X- _ O
incorrect -X- _ O
prediction -X- _ O
at -X- _ O
turn -X- _ O
3 -X- _ O
will -X- _ O
cause -X- _ O
error -X- _ B-MetricName
accumulation -X- _ O
in -X- _ O
this -X- _ O
dialogue -X- _ O
. -X- _ O

In -X- _ O
a -X- _ O
general -X- _ O
case -X- _ O
, -X- _ O
the -X- _ O
wrong -X- _ O
prediction -X- _ O
of -X- _ O
the -X- _ O
restaurant -X- _ O
- -X- _ O
pricerange -X- _ O
slot -X- _ O
at -X- _ O
turn -X- _ O
0 -X- _ O
will -X- _ O
accumulate -X- _ O
to -X- _ O
the -X- _ O
last -X- _ O
turn -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
case -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
incorrectly -X- _ O
predicted -X- _ O
therestaurant -X- _ O
- -X- _ O
pricerange -X- _ O
slot -X- _ O
at -X- _ O
turns -X- _ O
0 -X- _ O
and -X- _ O
1 -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
the -X- _ O
utterance -X- _ O
about -X- _ O
the -X- _ O
slot -X- _ O
appeared -X- _ O
by -X- _ O
chance -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
first -X- _ O
dialogue -X- _ O
presented -X- _ O
in -X- _ O
Table -X- _ O
A1 -X- _ O
, -X- _ O
the -X- _ O
joint -X- _ B-MetricName
goal -X- _ I-MetricName
accuracy -X- _ I-MetricName
is -X- _ O
measured -X- _ O
as -X- _ O
1 -X- _ B-MetricValue
at -X- _ O
turn -X- _ O
2 -X- _ O
. -X- _ O

Table -X- _ O
A3 -X- _ O
and -X- _ O
Table -X- _ O
A4 -X- _ O
indicate -X- _ O
the -X- _ O
corresponding -X- _ O
belief -X- _ O
states -X- _ O
of -X- _ O
each -X- _ O
dialogue -X- _ O
. -X- _ O

We -X- _ O
sampled -X- _ O
dialogues -X- _ O
of -X- _ O
the -X- _ O
MultiWOZ -X- _ B-DatasetName
2.1 -X- _ I-DatasetName
test -X- _ O
set -X- _ O
in -X- _ O
Table -X- _ O
A1 -X- _ O
and -X- _ O
Table -X- _ O
A2 -X- _ O
, -X- _ O
and -X- _ O
marked -X- _ O
values -X- _ O
appearing -X- _ O
in -X- _ O
the -X- _ O
dialogue -X- _ O
in -X- _ O
bold -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
discuss -X- _ O
a -X- _ O
few -X- _ O
cases -X- _ O
of -X- _ O
59 -X- _ O
dialogues -X- _ O
that -X- _ O
do -X- _ O
not -X- _ O
show -X- _ O
the -X- _ O
trend -X- _ O
among -X- _ O
642 -X- _ O
dialogues -X- _ O
selected -X- _ O
in -X- _ O
Section -X- _ O
2.1 -X- _ O
; -X- _ O
however -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
important -X- _ O
to -X- _ O
note -X- _ O
that -X- _ O
these -X- _ O
few -X- _ O
cases -X- _ O
have -X- _ O
negligible -X- _ O
effect -X- _ O
on -X- _ O
the -X- _ O
trend -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
, -X- _ O
solely -X- _ O
changing -X- _ O
the -X- _ O
position -X- _ O
where -X- _ O
the -X- _ B-MetricName
joint -X- _ I-MetricName
goal -X- _ I-MetricName
accuracy -X- _ I-MetricName
first -X- _ O
becomes -X- _ O
zero -X- _ B-MetricValue
. -X- _ O

Efficient -X- _ O
context -X- _ O
and -X- _ O
schema -X- _ O
fusion -X- _ O
networks -X- _ O
for -X- _ O
multidomain -X- _ B-TaskName
dialogue -X- _ I-TaskName
state -X- _ I-TaskName
tracking -X- _ I-TaskName
. -X- _ O

Word -X- _ O
- -X- _ O
based -X- _ O
dialog -X- _ O
state -X- _ O
tracking -X- _ O
with -X- _ O
recurrent -X- _ B-MethodName
neural -X- _ I-MethodName
networks -X- _ I-MethodName
. -X- _ O

Hyst -X- _ O
: -X- _ O
A -X- _ O
hybrid -X- _ O
approach -X- _ O
for -X- _ O
flexible -X- _ O
and -X- _ O
accurate -X- _ O
dialogue -X- _ B-TaskName
state -X- _ I-TaskName
tracking -X- _ I-TaskName
. -X- _ O

Dialog -X- _ B-MethodName
state -X- _ I-MethodName
tracking -X- _ I-MethodName
: -X- _ O
A -X- _ O
neural -X- _ O
reading -X- _ O
comprehension -X- _ O
approach -X- _ O
. -X- _ O

A -X- _ O
sequenceto -X- _ B-MethodName
- -X- _ I-MethodName
sequence -X- _ I-MethodName
approach -X- _ O
to -X- _ O
dialogue -X- _ B-TaskName
state -X- _ I-TaskName
tracking -X- _ I-TaskName
. -X- _ O

dialogue -X- _ B-TaskName
state -X- _ I-TaskName
tracking -X- _ I-TaskName
with -X- _ O
graph -X- _ B-MethodName
attention -X- _ I-MethodName
neural -X- _ I-MethodName
networks -X- _ I-MethodName
. -X- _ O

BERT -X- _ B-MethodName
- -X- _ I-MethodName
DST -X- _ I-MethodName
: -X- _ O
scalable -X- _ O
end -X- _ B-TaskName
- -X- _ I-TaskName
to -X- _ I-TaskName
- -X- _ I-TaskName
end -X- _ I-TaskName
dialogue -X- _ I-TaskName
state -X- _ I-TaskName
tracking -X- _ I-TaskName
with -X- _ O
bidirectional -X- _ B-MethodName
encoder -X- _ I-MethodName
representations -X- _ O
from -X- _ O
transformer -X- _ B-MethodName
. -X- _ O

MultiWOZ -X- _ B-DatasetName
- -X- _ O
a -X- _ O
largescale -X- _ O
multi -X- _ O
- -X- _ O
domain -X- _ O
Wizard -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
Oz -X- _ O
dataset -X- _ O
for -X- _ O
taskoriented -X- _ B-TaskName
dialogue -X- _ I-TaskName
modelling -X- _ I-TaskName
. -X- _ O

Acknowledgement -X- _ O
This -X- _ O
work -X- _ O
was -X- _ O
supported -X- _ O
by -X- _ O
Institute -X- _ O
of -X- _ O
Information -X- _ O
& -X- _ O
communications -X- _ O
Technology -X- _ O
Planning -X- _ O
& -X- _ O
Evaluation -X- _ O
( -X- _ O
IITP -X- _ O
) -X- _ O
grant -X- _ O
funded -X- _ O
by -X- _ O
the -X- _ O
Korea -X- _ O
government -X- _ O
( -X- _ O
MSIT -X- _ O
) -X- _ O
( -X- _ O
No -X- _ O
. -X- _ O

Moreover -X- _ O
, -X- _ O
we -X- _ O
suggest -X- _ O
reporting -X- _ O
various -X- _ O
evaluation -X- _ O
metrics -X- _ O
to -X- _ O
complement -X- _ O
the -X- _ O
limitations -X- _ O
of -X- _ O
each -X- _ O
metric -X- _ O
in -X- _ O
future -X- _ O
studies -X- _ O
, -X- _ O
not -X- _ O
solely -X- _ O
reporting -X- _ O
the -X- _ B-MetricName
joint -X- _ I-MetricName
goal -X- _ I-MetricName
accuracy -X- _ I-MetricName
. -X- _ O

When -X- _ O
the -X- _ O
DST -X- _ B-TaskName
task -X- _ I-TaskName
is -X- _ O
scaled -X- _ O
up -X- _ O
to -X- _ O
deal -X- _ O
with -X- _ O
more -X- _ O
diverse -X- _ O
conversational -X- _ O
situations -X- _ O
, -X- _ O
a -X- _ O
realistic -X- _ O
model -X- _ O
evaluation -X- _ O
will -X- _ O
be -X- _ O
possible -X- _ O
using -X- _ O
relative -X- _ B-MetricName
slot -X- _ I-MetricName
accuracy -X- _ I-MetricName
. -X- _ O

This -X- _ O
metric -X- _ O
is -X- _ O
not -X- _ O
affected -X- _ O
by -X- _ O
unseen -X- _ O
slots -X- _ O
in -X- _ O
the -X- _ O
current -X- _ O
dialogue -X- _ O
situation -X- _ O
, -X- _ O
and -X- _ O
compensates -X- _ O
for -X- _ O
the -X- _ O
models -X- _ O
correct -X- _ O
predic -X- _ O
- -X- _ O
tion -X- _ O
. -X- _ O

Accordingly -X- _ O
, -X- _ O
the -X- _ O
relative -X- _ B-MetricName
slot -X- _ I-MetricName
accuracy -X- _ I-MetricName
is -X- _ O
proposed -X- _ O
. -X- _ O

5 -X- _ O
Conclusion -X- _ O
This -X- _ O
paper -X- _ O
points -X- _ O
out -X- _ O
the -X- _ O
challenge -X- _ O
that -X- _ O
the -X- _ O
existing -X- _ O
joint -X- _ B-MetricName
goal -X- _ I-MetricName
and -X- _ I-MetricName
slot -X- _ I-MetricName
accuracies -X- _ I-MetricName
can -X- _ O
not -X- _ O
fully -X- _ O
evaluate -X- _ O
the -X- _ O
accumulating -X- _ O
belief -X- _ O
state -X- _ O
of -X- _ O
each -X- _ O
turn -X- _ O
in -X- _ O
the -X- _ O
MultiWOZ -X- _ B-DatasetName
dataset -X- _ I-DatasetName
. -X- _ O

Consequently -X- _ O
, -X- _ O
relative -X- _ B-MetricName
slot -X- _ I-MetricName
accuracy -X- _ I-MetricName
has -X- _ O
a -X- _ O
more -X- _ O
elaborated -X- _ O
discriminative -X- _ O
power -X- _ O
than -X- _ O
the -X- _ O
average -X- _ B-MetricName
goal -X- _ I-MetricName
accuracy -X- _ I-MetricName
. -X- _ O

In -X- _ O
contrast -X- _ O
, -X- _ B-MetricName
relative -X- _ I-MetricName
slot -X- _ I-MetricName
accuracy -X- _ I-MetricName
can -X- _ O
give -X- _ O
a -X- _ O
penalty -X- _ O
proportional -X- _ O
to -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
wrong -X- _ O
predictions -X- _ O
because -X- _ O
it -X- _ O
includes -X- _ O
both -X- _ O
gold -X- _ O
and -X- _ O
predicted -X- _ O
states -X- _ O
when -X- _ O
calculating -X- _ O
the -X- _ O
score -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
example -X- _ O
, -X- _ O
average -X- _ B-MetricName
goal -X- _ I-MetricName
accuracy -X- _ I-MetricName
can -X- _ O
not -X- _ O
consider -X- _ O
additional -X- _ O
belief -X- _ O
states -X- _ O
incorrectly -X- _ O
predicted -X- _ O
by -X- _ O
Model -X- _ O
B -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
score -X- _ O
between -X- _ O
the -X- _ O
two -X- _ O
models -X- _ O
. -X- _ O

Table -X- _ O
3 -X- _ O
describes -X- _ O
how -X- _ O
these -X- _ O
two -X- _ O
metrics -X- _ O
result -X- _ O
in -X- _ O
different -X- _ O
values -X- _ O
for -X- _ O
the -X- _ O
same -X- _ O
model -X- _ O
predictions -X- _ O
. -X- _ O

Comparison -X- _ O
to -X- _ O
Average -X- _ B-MetricName
Goal -X- _ I-MetricName
Accuracy -X- _ I-MetricName
Relative -X- _ B-MetricName
slot -X- _ I-MetricName
accuracy -X- _ I-MetricName
can -X- _ O
compare -X- _ O
DST -X- _ B-MethodName
model -X- _ I-MethodName
performances -X- _ O
more -X- _ O
properly -X- _ O
than -X- _ O
average -X- _ B-MetricName
goal -X- _ I-MetricName
accuracy -X- _ I-MetricName
, -X- _ O
as -X- _ O
mentioned -X- _ O
in -X- _ O
Section -X- _ O
2.3 -X- _ O
. -X- _ O

Therefore -X- _ O
, -X- _ O
relative -X- _ B-MetricName
slot -X- _ I-MetricName
accuracy -X- _ I-MetricName
can -X- _ O
provide -X- _ O
an -X- _ O
intuitive -X- _ O
evaluation -X- _ O
reflecting -X- _ O
the -X- _ O
current -X- _ O
belief -X- _ O
state -X- _ O
recording -X- _ O
method -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
slots -X- _ O
accumulates -X- _ O
incrementally -X- _ O
as -X- _ O
the -X- _ O
conversation -X- _ O
progresses -X- _ O
. -X- _ O

In -X- _ O
addition -X- _ O
, -X- _ O
regarding -X- _ O
slot -X- _ B-MetricName
accuracy -X- _ I-MetricName
in -X- _ O
turns -X- _ O
4 -X- _ O
, -X- _ O
5 -X- _ O
, -X- _ O
and -X- _ O
6 -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
score -X- _ O
improvement -X- _ O
for -X- _ O
the -X- _ O
additional -X- _ O
wellpredicted -X- _ O
state -X- _ O
by -X- _ O
the -X- _ O
model -X- _ O
, -X- _ O
whereas -X- _ O
the -X- _ O
score -X- _ O
increases -X- _ O
when -X- _ O
the -X- _ O
newly -X- _ O
added -X- _ O
state -X- _ O
is -X- _ O
matched -X- _ O
in -X- _ O
the -X- _ O
case -X- _ O
of -X- _ O
relative -X- _ B-MetricName
slot -X- _ I-MetricName
accuracy -X- _ I-MetricName
. -X- _ O

culates -X- _ O
the -X- _ O
score -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
unique -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
current -X- _ O
turn -X- _ O
according -X- _ O
to -X- _ O
Equation -X- _ O
3 -X- _ O
. -X- _ O

States -X- _ O
with -X- _ O
blue -X- _ O
denote -X- _ O
correct -X- _ O
prediction -X- _ O
, -X- _ O
and -X- _ O
as -X- _ O
defined -X- _ O
in -X- _ O
Section -X- _ O
2.2 -X- _ O
, -X- _ O
states -X- _ O
with -X- _ O
orange -X- _ O
and -X- _ O
pink -X- _ O
denote -X- _ O
respective -X- _ O
MandW -X- _ O
. -X- _ O

The -X- _ O
relative -X- _ B-MetricName
slot -X- _ I-MetricName
accuracy -X- _ I-MetricName
from -X- _ O
turns -X- _ O
0 -X- _ B-MetricValue
3 -X- _ O
is -X- _ O
measured -X- _ O
as -X- _ O
0 -X- _ O
because -X- _ O
it -X- _ O
cal-300 -X- _ O
. -X- _ O

Table -X- _ O
A6 -X- _ O
compares -X- _ O
the -X- _ O
slot -X- _ B-MetricName
and -X- _ I-MetricName
relative -X- _ I-MetricName
slot -X- _ I-MetricName
accuracies -X- _ I-MetricName
. -X- _ O

Reward -X- _ O
on -X- _ O
Relative -X- _ O
Dialogue -X- _ O
Turn -X- _ O
Relative -X- _ B-MetricName
slot -X- _ I-MetricName
accuracy -X- _ I-MetricName
is -X- _ O
able -X- _ O
to -X- _ O
reward -X- _ O
the -X- _ O
models -X- _ O
correct -X- _ O
prediction -X- _ O
by -X- _ O
measuring -X- _ O
the -X- _ O
accuracy -X- _ B-MetricName
on -X- _ O
a -X- _ O
relative -X- _ O
basis -X- _ O
for -X- _ O
each -X- _ O
turn -X- _ O
. -X- _ O

As -X- _ O
can -X- _ O
be -X- _ O
observed -X- _ O
from -X- _ O
the -X- _ O
results -X- _ O
, -X- _ O
the -X- _ O
relative -X- _ B-MetricName
slot -X- _ I-MetricName
accuracy -X- _ I-MetricName
has -X- _ O
a -X- _ O
higher -X- _ O
deviation -X- _ O
than -X- _ O
the -X- _ O
slot -X- _ B-MetricName
accuracy -X- _ I-MetricName
, -X- _ O
enabling -X- _ O
a -X- _ O
detailed -X- _ O
comparison -X- _ O
among -X- _ O
the -X- _ O
methodologies -X- _ O
. -X- _ O

Figure -X- _ O
4 -X- _ O
illustrates -X- _ O
the -X- _ O
mean -X- _ B-MetricName
and -X- _ O
standard -X- _ B-MetricName
deviations -X- _ I-MetricName
of -X- _ O
the -X- _ O
model -X- _ O
performance -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
relative -X- _ B-MetricName
slot -X- _ I-MetricName
accuracy -X- _ I-MetricName
can -X- _ O
evaluate -X- _ O
the -X- _ O
models -X- _ O
predictive -X- _ O
score -X- _ O
without -X- _ O
being -X- _ O
affected -X- _ O
by -X- _ O
slots -X- _ O
never -X- _ O
seen -X- _ O
in -X- _ O
the -X- _ O
current -X- _ O
dialogue -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
more -X- _ O
realistic -X- _ O
way -X- _ O
, -X- _ O
considering -X- _ O
that -X- _ O
each -X- _ O
dialogue -X- _ O
contains -X- _ O
its -X- _ O
own -X- _ O
turn -X- _ O
and -X- _ O
slot -X- _ O
composition -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
when -X- _ O
evaluating -X- _ O
a -X- _ O
dialogue -X- _ O
sample -X- _ O
that -X- _ O
solely -X- _ O
deals -X- _ O
with -X- _ O
the -X- _ O
restaurant -X- _ O
domain -X- _ O
, -X- _ O
even -X- _ O
domains -X- _ O
that -X- _ O
never -X- _ O
appear -X- _ O
at -X- _ O
all -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
hotel -X- _ O
, -X- _ O
train -X- _ O
, -X- _ O
attraction -X- _ O
, -X- _ O
andtaxi -X- _ O
) -X- _ O
are -X- _ O
involved -X- _ O
in -X- _ O
measuring -X- _ O
performance -X- _ O
, -X- _ O
making -X- _ O
deviations -X- _ O
among -X- _ O
different -X- _ O
models -X- _ O
trivial -X- _ O
. -X- _ O

Dependency -X- _ O
on -X- _ O
Predefined -X- _ O
Slots -X- _ O
As -X- _ O
discussed -X- _ O
in -X- _ O
Section -X- _ O
2.2 -X- _ O
, -X- _ O
slot -X- _ B-MetricName
accuracy -X- _ I-MetricName
requiring -X- _ O
total -X- _ O
predefined -X- _ O
slots -X- _ O
is -X- _ O
not -X- _ O
a -X- _ O
scalable -X- _ O
method -X- _ O
for -X- _ O
evaluating -X- _ O
the -X- _ O
current -X- _ O
dialogue -X- _ O
dataset -X- _ O
that -X- _ O
contains -X- _ O
a -X- _ O
few -X- _ O
domains -X- _ O
in -X- _ O
each -X- _ O
dialogue -X- _ O
. -X- _ O

Slot -X- _ B-MetricName
Acc -X- _ I-MetricName
. -X- _ O

Acc -X- _ B-MetricName
. -X- _ O

In -X- _ O
summary -X- _ O
, -X- _ O
relative -X- _ B-MetricName
slot -X- _ I-MetricName
accuracy -X- _ I-MetricName
enables -X- _ O
relative -X- _ O
comparison -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
the -X- _ O
domain -X- _ O
in -X- _ O
a -X- _ O
dialogue -X- _ O
. -X- _ O
DomainJoint -X- _ O
Slot -X- _ O
Relative -X- _ O
Goal -X- _ O
Acc -X- _ O
. -X- _ O

Because -X- _ O
slot -X- _ B-MetricName
accuracy -X- _ I-MetricName
can -X- _ O
not -X- _ O
distinguish -X- _ O
the -X- _ O
above -X- _ O
trend -X- _ O
, -X- _ O
the -X- _ O
score -X- _ O
of -X- _ O
the -X- _ O
hotel -X- _ O
domain -X- _ O
is -X- _ O
lower -X- _ O
than -X- _ O
that -X- _ O
of -X- _ O
the -X- _ O
taxidomain -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
taxidomain -X- _ O
shows -X- _ O
a -X- _ O
low -X- _ O
score -X- _ O
, -X- _ O
meaning -X- _ O
that -X- _ O
it -X- _ O
has -X- _ O
relatively -X- _ O
several -X- _ O
cases -X- _ O
of -X- _ O
incorrect -X- _ O
predictions -X- _ O
, -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
times -X- _ O
slots -X- _ O
belonging -X- _ O
to -X- _ O
the -X- _ O
taxi -X- _ O
domain -X- _ O
appear -X- _ O
. -X- _ O

Relative -X- _ B-MetricName
slot -X- _ I-MetricName
accuracy -X- _ I-MetricName
derives -X- _ O
a -X- _ O
specific -X- _ O
score -X- _ O
in -X- _ O
the -X- _ O
turn -X- _ O
configuration -X- _ O
and -X- _ O
prediction -X- _ O
ratio -X- _ O
of -X- _ O
each -X- _ O
domain -X- _ O
by -X- _ O
excluding -X- _ O
slots -X- _ O
that -X- _ O
do -X- _ O
not -X- _ O
appear -X- _ O
in -X- _ O
the -X- _ O
conversation -X- _ O
. -X- _ O

Domain -X- _ O
- -X- _ O
specific -X- _ O
Evaluation -X- _ O
We -X- _ O
reported -X- _ O
the -X- _ O
joint -X- _ O
goal -X- _ O
, -X- _ O
slot -X- _ O
, -X- _ O
and -X- _ O
relative -X- _ O
slot -X- _ O
accuracies -X- _ O
per -X- _ O
domain -X- _ O
utilizing -X- _ O
the -X- _ O
SOM -X- _ B-MethodName
- -X- _ I-MethodName
DST -X- _ I-MethodName
model -X- _ I-MethodName
in -X- _ O
Table -X- _ O
2 -X- _ O
. -X- _ O

Specifically -X- _ O
, -X- _ O
it -X- _ O
can -X- _ O
be -X- _ O
compared -X- _ O
with -X- _ O
a -X- _ O
different -X- _ O
perspective -X- _ O
when -X- _ O
using -X- _ O
the -X- _ O
proposed -X- _ O
reward -X- _ O
- -X- _ O
considering -X- _ O
evaluation -X- _ O
metric -X- _ O
. -X- _ O

Furthermore -X- _ O
, -X- _ O
the -X- _ O
correlation -X- _ O
with -X- _ O
joint -X- _ B-MetricName
goal -X- _ I-MetricName
accuracy -X- _ I-MetricName
, -X- _ O
a -X- _ O
mainly -X- _ O
adopted -X- _ O
metric -X- _ O
, -X- _ O
and -X- _ O
relative -X- _ B-MetricName
slot -X- _ I-MetricName
accuracy -X- _ I-MetricName
with -X- _ O
respect -X- _ O
to -X- _ O
each -X- _ O
turn -X- _ O
is -X- _ O
lower -X- _ O
than -X- _ O
the -X- _ O
correlation -X- _ O
with -X- _ O
joint -X- _ B-MetricName
goal -X- _ I-MetricName
accuracy -X- _ I-MetricName
and -X- _ O
slot -X- _ B-MetricName
accuracy -X- _ I-MetricName
, -X- _ O
as -X- _ O
illustrated -X- _ O
in -X- _ O
Figure -X- _ O
3 -X- _ O
. -X- _ O

Meanwhile -X- _ O
, -X- _ O
relative -X- _ B-MetricName
slot -X- _ I-MetricName
accuracy -X- _ I-MetricName
can -X- _ O
explicitly -X- _ O
highlight -X- _ O
the -X- _ O
deviation -X- _ O
among -X- _ O
models -X- _ O
by -X- _ O
showing -X- _ O
a -X- _ O
5.47% -X- _ B-MetricValue
difference -X- _ O
between -X- _ O
the -X- _ O
largest -X- _ O
and -X- _ O
smallest -X- _ O
values -X- _ O
. -X- _ O

It -X- _ O
can -X- _ O
be -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
reasons -X- _ O
that -X- _ O
several -X- _ O
researchers -X- _ O
do -X- _ O
not -X- _ O
report -X- _ O
it -X- _ O
. -X- _ O

Regarding -X- _ O
slot -X- _ B-MetricName
accuracy -X- _ I-MetricName
, -X- _ O
the -X- _ O
difference -X- _ O
between -X- _ O
the -X- _ O
largest -X- _ O
and -X- _ O
smallest -X- _ O
values -X- _ O
is -X- _ O
solely -X- _ O
1.09% -X- _ B-MetricValue
. -X- _ O

4.1 -X- _ O
Results -X- _ O
and -X- _ O
Discussion -X- _ O
Table -X- _ O
1 -X- _ O
presents -X- _ O
the -X- _ O
overall -X- _ O
results -X- _ O
. -X- _ O

Results -X- _ O
for -X- _ O
other -X- _ O
models -X- _ O
are -X- _ O
included -X- _ O
in -X- _ O
Figure -X- _ O
A1 -X- _ O
. -X- _ O

JGA -X- _ O
SA -X- _ O
F1 -X- _ O
RSA -X- _ O
SOM -X- _ O
- -X- _ O
DSTJGA -X- _ O
SA -X- _ O
F1 -X- _ O
RSA1 -X- _ O
0.76 -X- _ O
0.67 -X- _ O
0.58 -X- _ O
0.76 -X- _ O
1 -X- _ O
0.69 -X- _ O
0.6 -X- _ O
0.67 -X- _ O
0.69 -X- _ O
1 -X- _ O
0.78 -X- _ O
0.58 -X- _ O
0.6 -X- _ O
0.78 -X- _ O
1 -X- _ O
0.40.50.60.70.80.91.0Figure -X- _ O
3 -X- _ O
: -X- _ O
Correlation -X- _ O
matrix -X- _ O
of -X- _ O
evaluation -X- _ O
performance -X- _ O
of -X- _ O
total -X- _ O
7,368 -X- _ O
turns -X- _ O
in -X- _ O
999 -X- _ O
MultiWOZ -X- _ B-DatasetName
2.1 -X- _ O
test -X- _ O
set -X- _ O
using -X- _ O
SOM -X- _ B-MethodName
- -X- _ I-MethodName
DST -X- _ I-MethodName
. -X- _ O

2Implementation -X- _ O
codes -X- _ O
for -X- _ O
Simple -X- _ B-MethodName
- -X- _ I-MethodName
TOD -X- _ I-MethodName
and -X- _ O
TripPy -X- _ B-MethodName
are -X- _ O
from -X- _ O
https://github.com/salesforce/coco-dst.299 -X- _ O
. -X- _ O

Additionally -X- _ O
, -X- _ O
we -X- _ O
reported -X- _ O
the -X- _ O
F1 -X- _ B-MetricName
score -X- _ I-MetricName
, -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
calculated -X- _ O
using -X- _ O
the -X- _ O
current -X- _ O
predicted -X- _ O
and -X- _ O
gold -X- _ O
states -X- _ O
. -X- _ O

We -X- _ O
selected -X- _ O
the -X- _ O
DST -X- _ B-MethodName
models -X- _ I-MethodName
in -X- _ O
Table -X- _ O
A5 -X- _ O
that -X- _ O
perform -X- _ O
the -X- _ O
MultiWOZ -X- _ B-DatasetName
experiment -X- _ O
with -X- _ O
the -X- _ O
original -X- _ O
authors -X- _ O
reproducible -X- _ O
code2 -X- _ O
. -X- _ O

Further -X- _ O
discussions -X- _ O
on -X- _ O
the -X- _ O
relative -X- _ O
score -X- _ O
will -X- _ O
be -X- _ O
discussed -X- _ O
in -X- _ O
Section -X- _ O
4.1 -X- _ O
. -X- _ O

It -X- _ O
is -X- _ O
not -X- _ O
presumed -X- _ O
to -X- _ O
be -X- _ O
an -X- _ O
appropriate -X- _ O
metric -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
scalability -X- _ O
. -X- _ O

We -X- _ O
will -X- _ O
discuss -X- _ O
it -X- _ O
in -X- _ O
more -X- _ O
detail -X- _ O
in -X- _ O
Section -X- _ O
4.1 -X- _ O
. -X- _ O

In -X- _ O
addition -X- _ O
, -X- _ O
as -X- _ O
the -X- _ O
turn -X- _ O
progresses -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
no -X- _ O
rewards -X- _ O
for -X- _ O
a -X- _ O
situation -X- _ O
in -X- _ O
which -X- _ O
the -X- _ O
model -X- _ O
tracks -X- _ O
the -X- _ O
belief -X- _ O
state -X- _ O
without -X- _ O
any -X- _ O
challenges -X- _ O
. -X- _ O

It -X- _ O
becomes -X- _ O
difficult -X- _ O
to -X- _ O
compare -X- _ O
various -X- _ O
models -X- _ O
in -X- _ O
detail -X- _ O
, -X- _ O
if -X- _ O
each -X- _ O
model -X- _ O
shows -X- _ O
a -X- _ O
high -X- _ O
performance -X- _ O
, -X- _ O
even -X- _ O
though -X- _ O
nothing -X- _ O
is -X- _ O
adequately -X- _ O
predicted -X- _ O
. -X- _ O

rectly -X- _ O
predicting -X- _ O
states -X- _ O
at -X- _ O
all -X- _ O
. -X- _ O

All -X- _ O
reported -X- _ O
performances -X- _ O
are -X- _ O
our -X- _ O
re -X- _ O
- -X- _ O
implementation -X- _ O
. -X- _ O

Type -X- _ O
ModelJoint -X- _ O
Slot -X- _ O
F1 -X- _ O
Relative -X- _ B-MetricName
Goal -X- _ I-MetricName
Acc -X- _ I-MetricName
. -X- _ O

Each -X- _ O
value -X- _ O
of -X- _ O
x -X- _ O
- -X- _ O
axis -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
indicates -X- _ O
the -X- _ O
maximum -X- _ O
number -X- _ O
of -X- _ O
slots -X- _ O
that -X- _ O
appear -X- _ O
in -X- _ O
a -X- _ O
single -X- _ O
dialogue -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
confirmed -X- _ O
that -X- _ O
approximately -X- _ O
85% -X- _ O
of -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
utilized -X- _ O
solely -X- _ O
less -X- _ O
than -X- _ O
12 -X- _ O
of -X- _ O
the -X- _ O
30 -X- _ O
predefined -X- _ O
slots -X- _ O
in -X- _ O
the -X- _ O
experiment -X- _ O
. -X- _ O

Mdenotes -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
missed -X- _ O
slots -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
does -X- _ O
not -X- _ O
accurately -X- _ O
predict -X- _ O
among -X- _ O
the -X- _ O
slots -X- _ O
included -X- _ O
in -X- _ O
the -X- _ O
gold -X- _ O
state -X- _ O
, -X- _ O
and -X- _ O
Wdenotes -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
wrongly -X- _ O
predicted -X- _ O
slots -X- _ O
among -X- _ O
the -X- _ O
slots -X- _ O
that -X- _ O
do -X- _ O
not -X- _ O
exist -X- _ O
in -X- _ O
the -X- _ O
gold -X- _ O
state -X- _ O
. -X- _ O

Tindicates -X- _ O
the -X- _ O
total -X- _ O
number -X- _ O
of -X- _ O
predefined -X- _ O
slots -X- _ O
for -X- _ O
all -X- _ O
the -X- _ O
domains -X- _ O
. -X- _ O

Refer -X- _ O
to -X- _ O
Appendix -X- _ O
A -X- _ O
. -X- _ O

Table -X- _ O
A1 -X- _ O
and -X- _ O
Table -X- _ O
A2 -X- _ O
show -X- _ O
the -X- _ O
dialogue -X- _ O
situation -X- _ O
in -X- _ O
detail -X- _ O
, -X- _ O
and -X- _ O
Table -X- _ O
A3 -X- _ O
and -X- _ O
Table -X- _ O
A4 -X- _ O
show -X- _ O
the -X- _ O
belief -X- _ O
states -X- _ O
accordingly -X- _ O
. -X- _ O

As -X- _ O
illustrated -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
, -X- _ O
we -X- _ O
measured -X- _ O
the -X- _ O
relative -X- _ O
position -X- _ O
of -X- _ O
the -X- _ O
turn -X- _ O
causing -X- _ O
this -X- _ O
phenomenon -X- _ O
for -X- _ O
the -X- _ O
dialogue -X- _ O
. -X- _ O

( -X- _ O
642 -X- _ O
of -X- _ O
999 -X- _ O
MultiWOZ -X- _ O
2.1 -X- _ O
test -X- _ O
set -X- _ O
with -X- _ O
SOM -X- _ O
- -X- _ O
DST -X- _ O
) -X- _ O
. -X- _ O

It -X- _ O
is -X- _ O
expected -X- _ O
that -X- _ O
the -X- _ O
proposed -X- _ O
metric -X- _ O
can -X- _ O
be -X- _ O
adopted -X- _ O
to -X- _ O
evaluate -X- _ O
model -X- _ O
performance -X- _ O
more -X- _ O
intuitively -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
we -X- _ O
determined -X- _ O
that -X- _ O
these -X- _ O
two -X- _ O
metrics -X- _ O
solely -X- _ O
focus -X- _ O
on -X- _ O
penalizing -X- _ O
states -X- _ O
that -X- _ O
fail -X- _ O
to -X- _ O
predict -X- _ O
, -X- _ O
not -X- _ O
considering -X- _ O
reward -X- _ O
for -X- _ O
well -X- _ O
- -X- _ O
predicted -X- _ O
states -X- _ O
. -X- _ O

That -X- _ O
is -X- _ O
, -X- _ O
the -X- _ O
belief -X- _ O
states -X- _ O
of -X- _ O
the -X- _ O
previous -X- _ O
turns -X- _ O
are -X- _ O
included -X- _ O
in -X- _ O
the -X- _ O
current -X- _ O
turn -X- _ O
. -X- _ O

The -X- _ O
characteristic -X- _ O
of -X- _ O
these -X- _ O
datasets -X- _ O
is -X- _ O
that -X- _ O
belief -X- _ O
states -X- _ O
are -X- _ O
accumulated -X- _ O
and -X- _ O
recorded -X- _ O
every -X- _ O
turn -X- _ O
. -X- _ O

A -X- _ O
belief -X- _ O
state -X- _ O
, -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
core -X- _ O
pieces -X- _ O
of -X- _ O
information -X- _ O
, -X- _ O
refers -X- _ O
to -X- _ O
the -X- _ O
subject -X- _ O
and -X- _ O
its -X- _ O
specific -X- _ O
content -X- _ O
, -X- _ O
and -X- _ O
appears -X- _ O
in -X- _ O
the -X- _ O
form -X- _ O
of -X- _ O
domain -X- _ O
- -X- _ O
slot -X- _ O
- -X- _ O
value -X- _ O
. -X- _ O

Proceedings -X- _ O
of -X- _ O
the -X- _ O
60th -X- _ O
Annual -X- _ O
Meeting -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
Volume -X- _ O
2 -X- _ O
: -X- _ O
Short -X- _ O
Papers -X- _ O
, -X- _ O
pages -X- _ O
297 -X- _ O
- -X- _ O
309 -X- _ O
May -X- _ O
22 -X- _ O
- -X- _ O
27 -X- _ O
, -X- _ O
2022 -X- _ O
c -X- _ O
2022 -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
Mismatch -X- _ O
between -X- _ O
Multi -X- _ O
- -X- _ O
turn -X- _ O
Dialogue -X- _ O
and -X- _ O
its -X- _ O
Evaluation -X- _ O
Metric -X- _ O
in -X- _ O
Dialogue -X- _ O
State -X- _ O
Tracking -X- _ O
Takyoung -X- _ O
Kim1 -X- _ O
, -X- _ O
Hoonsang -X- _ O
Yoon1 -X- _ O
, -X- _ O
Yukyung -X- _ O
Lee1 -X- _ O
, -X- _ O
Pilsung -X- _ O
Kang1 -X- _ O
, -X- _ O
Misuk -X- _ O
Kim2 -X- _ O
1Korea -X- _ O
University -X- _ O
, -X- _ O
Seoul -X- _ O
, -X- _ O
Republic -X- _ O
of -X- _ O
Korea -X- _ O
2Sejong -X- _ O
University -X- _ O
, -X- _ O
Seoul -X- _ O
, -X- _ O
Republic -X- _ O
of -X- _ O
Korea -X- _ O
1{takyoung_kim -X- _ O
, -X- _ O
hoonsang_yoon -X- _ O
, -X- _ O
yukyung_lee -X- _ O
, -X- _ O
pilsung_kang}@korea.ac.kr -X- _ O
2misuk.kim@sejong.ac.kr -X- _ O
Abstract -X- _ O
Dialogue -X- _ O
state -X- _ O
tracking -X- _ O
( -X- _ O
DST -X- _ O
) -X- _ O
aims -X- _ O
to -X- _ O
extract -X- _ O
essential -X- _ O
information -X- _ O
from -X- _ O
multi -X- _ O
- -X- _ O
turn -X- _ O
dialogue -X- _ O
situations -X- _ O
and -X- _ O
take -X- _ O
appropriate -X- _ O
actions -X- _ O
. -X- _ O

Five -X- _ O
domains -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
hotel -X- _ O
, -X- _ O
train -X- _ O
, -X- _ O
restaurant -X- _ O
, -X- _ O
attraction -X- _ O
, -X- _ O
andtaxi -X- _ O
) -X- _ O
are -X- _ O
adopted -X- _ O
in -X- _ O
the -X- _ O
experiment -X- _ O
, -X- _ O
following -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
there -X- _ O
are -X- _ O
a -X- _ O
total -X- _ O
of -X- _ O
30 -X- _ O
domain -X- _ O
- -X- _ O
slot -X- _ O
pairs -X- _ O
. -X- _ O

4 -X- _ O
Experiments -X- _ O
We -X- _ O
measured -X- _ O
MultiWOZ -X- _ B-DatasetName
2.1 -X- _ I-DatasetName
, -X- _ O
an -X- _ O
improved -X- _ O
version -X- _ O
of -X- _ O
MultiWOZ -X- _ B-DatasetName
2.0 -X- _ I-DatasetName
( -X- _ O
Budzianowski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
has -X- _ O
been -X- _ O
adopted -X- _ O
in -X- _ O
several -X- _ O
studies -X- _ O
, -X- _ O
according -X- _ O
to -X- _ O
Table -X- _ O
A5 -X- _ O
. -X- _ O

RSA -X- _ O
= -X- _ O
TMW -X- _ O
T -X- _ O
, -X- _ O
where -X- _ O
0ifT= -X- _ O
0 -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
Relative -X- _ B-MetricName
slot -X- _ I-MetricName
accuracy -X- _ I-MetricName
rewards -X- _ O
well -X- _ O
- -X- _ O
predicted -X- _ O
belief -X- _ O
states -X- _ O
by -X- _ O
measuring -X- _ O
the -X- _ O
scores -X- _ O
in -X- _ O
accumulating -X- _ O
turns -X- _ O
. -X- _ O

Equation -X- _ O
3 -X- _ O
expresses -X- _ O
how -X- _ O
to -X- _ O
calculate -X- _ O
the -X- _ B-MetricName
relative -X- _ I-MetricName
slot -X- _ I-MetricName
accuracy -X- _ I-MetricName
, -X- _ O
and -X- _ O
Tdenotes -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
unique -X- _ O
slots -X- _ O
appearing -X- _ O
in -X- _ O
the -X- _ O
predicted -X- _ O
and -X- _ O
gold -X- _ O
states -X- _ O
in -X- _ O
a -X- _ O
particular -X- _ O
turn -X- _ O
. -X- _ O

Therefore -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
relative -X- _ B-MetricName
slot -X- _ I-MetricName
accuracy -X- _ I-MetricName
, -X- _ O
that -X- _ O
is -X- _ O
not -X- _ O
affected -X- _ O
by -X- _ O
predefined -X- _ O
slots -X- _ O
, -X- _ O
and -X- _ O
is -X- _ O
evaluated -X- _ O
with -X- _ O
adequate -X- _ O
rewards -X- _ O
and -X- _ O
penalties -X- _ O
that -X- _ O
fit -X- _ O
human -X- _ O
intuition -X- _ O
in -X- _ O
every -X- _ O
turn -X- _ O
. -X- _ O

The -X- _ O
deviation -X- _ O
among -X- _ O
DST -X- _ B-MethodName
models -X- _ I-MethodName
will -X- _ O
be -X- _ O
even -X- _ O
more -X- _ O
minor -X- _ O
when -X- _ O
constructing -X- _ O
datasets -X- _ O
with -X- _ O
various -X- _ O
dialogue -X- _ O
situations -X- _ O
, -X- _ O
because -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
predefined -X- _ O
slots -X- _ O
will -X- _ O
continually -X- _ O
in -X- _ O
- -X- _ O
crease -X- _ O
. -X- _ O

3 -X- _ O
Relative -X- _ B-MetricName
Slot -X- _ I-MetricName
Accuracy -X- _ I-MetricName
As -X- _ O
can -X- _ O
be -X- _ O
observed -X- _ O
in -X- _ O
Equation -X- _ O
2 -X- _ O
, -X- _ O
slot -X- _ B-MetricName
accuracy -X- _ I-MetricName
has -X- _ O
the -X- _ O
characteristic -X- _ O
that -X- _ O
the -X- _ O
larger -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
predefined -X- _ O
slots -X- _ O
( -X- _ O
T -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
smaller -X- _ O
the -X- _ O
deviation -X- _ O
between -X- _ O
the -X- _ O
prediction -X- _ O
results -X- _ O
. -X- _ O

Since -X- _ O
average -X- _ B-MetricName
goal -X- _ I-MetricName
accuracy -X- _ I-MetricName
ignores -X- _ O
the -X- _ O
predicted -X- _ O
states -X- _ O
, -X- _ O
it -X- _ O
can -X- _ O
not -X- _ O
properly -X- _ O
distinguish -X- _ O
a -X- _ O
better -X- _ O
model -X- _ O
from -X- _ O
a -X- _ O
worse -X- _ O
model -X- _ O
in -X- _ O
some -X- _ O
specific -X- _ O
situations -X- _ O
. -X- _ O

The -X- _ O
main -X- _ O
difference -X- _ O
between -X- _ O
the -X- _ O
average -X- _ B-MetricName
goal -X- _ I-MetricName
accuracy -X- _ I-MetricName
and -X- _ O
the -X- _ O
proposed -X- _ O
relative -X- _ B-MetricName
slot -X- _ I-MetricName
accuracy -X- _ I-MetricName
is -X- _ O
that -X- _ O
the -X- _ O
average -X- _ B-MetricName
goal -X- _ I-MetricName
accuracy -X- _ I-MetricName
only -X- _ O
considers -X- _ O
the -X- _ O
slots -X- _ O
with -X- _ O
non -X- _ O
- -X- _ O
empty -X- _ O
values -X- _ O
in -X- _ O
the -X- _ O
gold -X- _ O
states -X- _ O
of -X- _ O
each -X- _ O
turn -X- _ O
, -X- _ O
whereas -X- _ O
the -X- _ O
proposed -X- _ O
relative -X- _ O
slot -X- _ O
accuracy -X- _ O
considers -X- _ O
those -X- _ O
in -X- _ O
both -X- _ O
gold -X- _ O
and -X- _ O
predicted -X- _ O
states -X- _ O
. -X- _ O

2.3 -X- _ O
Other -X- _ O
Metric -X- _ O
Recently -X- _ O
, -X- _ O
Rastogi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020b -X- _ O
) -X- _ O
proposed -X- _ O
a -X- _ O
metric -X- _ O
called -X- _ O
average -X- _ B-MetricName
goal -X- _ I-MetricName
accuracy -X- _ I-MetricName
. -X- _ O

Therefore -X- _ O
, -X- _ O
the -X- _ O
slot -X- _ B-MetricName
accuracy -X- _ I-MetricName
measured -X- _ O
according -X- _ O
to -X- _ O
Equation -X- _ O
2 -X- _ O
differs -X- _ O
from -X- _ O
our -X- _ O
intuition -X- _ O
. -X- _ O

The -X- _ O
case -X- _ O
correctly -X- _ O
predicting -X- _ O
two -X- _ O
out -X- _ O
of -X- _ O
three -X- _ O
in -X- _ O
turn -X- _ O
4 -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
case -X- _ O
correctly -X- _ O
predicting -X- _ O
three -X- _ B-MetricValue
out -X- _ I-MetricValue
of -X- _ I-MetricValue
four -X- _ I-MetricValue
in -X- _ O
turn -X- _ O
5 -X- _ O
exhibit -X- _ O
the -X- _ O
same -X- _ O
slot -X- _ B-MetricName
accuracy -X- _ I-MetricName
. -X- _ O

Open -X- _ B-MethodName
vocabularyTransformer -X- _ I-MethodName
- -X- _ I-MethodName
DST -X- _ I-MethodName
( -X- _ O
2021 -X- _ O
) -X- _ O
0.5446 -X- _ O
0.9748 -X- _ O
0.9229 -X- _ O
0.8759 -X- _ O
TripPy -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
0.6131 -X- _ O
0.9707 -X- _ O
0.8573 -X- _ O
0.8432 -X- _ O
SOM -X- _ O
- -X- _ O
DST -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
0.5242 -X- _ O
0.9735 -X- _ O
0.9179 -X- _ O
0.8695 -X- _ O
Simple -X- _ O
- -X- _ O
TOD -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
0.5605 -X- _ O
0.9761 -X- _ O
0.9276 -X- _ O
0.8797 -X- _ O
SA -X- _ O
VN -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
0.5357 -X- _ O
0.9749 -X- _ O
0.9246 -X- _ O
0.8769 -X- _ O
TRADE -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
0.4939 -X- _ O
0.9700 -X- _ O
0.9033 -X- _ O
0.8520 -X- _ O
COMER -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
0.4879 -X- _ O
0.9652 -X- _ O
0.8800 -X- _ O
0.8250 -X- _ O
Ontology -X- _ O
basedDST -X- _ O
- -X- _ O
STAR -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
0.5483 -X- _ O
0.9754 -X- _ O
0.9253 -X- _ O
0.8780 -X- _ O
L4P4K2 -X- _ O
- -X- _ O
DSGraph -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
0.5178 -X- _ O
0.9690 -X- _ O
0.9189 -X- _ O
0.8570 -X- _ O
SUMBT -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
0.4699 -X- _ O
0.9666 -X- _ O
0.8934 -X- _ O
0.8380 -X- _ O
Table -X- _ O
1 -X- _ O
: -X- _ O
Model -X- _ O
performance -X- _ O
of -X- _ O
MultiWOZ -X- _ O
2.1 -X- _ O
with -X- _ O
various -X- _ O
evaluation -X- _ O
metrics -X- _ O
. -X- _ O

Score -X- _ B-MetricName
Slot -X- _ I-MetricName
Acc -X- _ I-MetricName
. -X- _ O

The -X- _ O
slot -X- _ B-MetricName
accuracies -X- _ I-MetricName
of -X- _ O
turns -X- _ B-MetricValue
0 -X- _ I-MetricValue
and -X- _ O
1 -X- _ O
show -X- _ O
approximately -X- _ O
96% -X- _ B-MetricValue
accuracy -X- _ B-MetricName
, -X- _ O
despite -X- _ O
the -X- _ O
model -X- _ O
not -X- _ O
cor-298 -X- _ O
. -X- _ O

Furthermore -X- _ O
, -X- _ O
according -X- _ O
to -X- _ O
Table -X- _ O
A6 -X- _ O
, -X- _ O
we -X- _ O
determined -X- _ O
that -X- _ O
slot -X- _ B-MetricName
accuracy -X- _ I-MetricName
tends -X- _ O
to -X- _ O
be -X- _ O
too -X- _ O
high -X- _ O
. -X- _ O

Accordingly -X- _ O
, -X- _ O
several -X- _ O
previous -X- _ O
studies -X- _ O
still -X- _ O
report -X- _ O
the -X- _ O
model -X- _ O
performance -X- _ O
using -X- _ O
solely -X- _ O
joint -X- _ B-MetricName
goal -X- _ I-MetricName
accuracy -X- _ I-MetricName
because -X- _ O
slot -X- _ B-MetricName
accuracy -X- _ I-MetricName
excessively -X- _ O
depends -X- _ O
on -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
predefined -X- _ O
slots -X- _ O
, -X- _ O
making -X- _ O
the -X- _ O
performance -X- _ O
deviation -X- _ O
among -X- _ O
models -X- _ O
trivial -X- _ O
( -X- _ O
refer -X- _ O
to -X- _ O
Table -X- _ O
A5 -X- _ O
) -X- _ O
. -X- _ O

Because -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
belief -X- _ O
states -X- _ O
appearing -X- _ O
in -X- _ O
the -X- _ O
early -X- _ O
and -X- _ O
middle -X- _ O
turns -X- _ O
of -X- _ O
the -X- _ O
dialogue -X- _ O
are -X- _ O
smaller -X- _ O
, -X- _ O
and -X- _ O
even -X- _ O
fewer -X- _ O
states -X- _ O
make -X- _ O
false -X- _ O
predictions -X- _ O
, -X- _ O
calculating -X- _ O
slot -X- _ B-MetricName
accuracy -X- _ I-MetricName
using -X- _ O
Equation -X- _ O
2 -X- _ O
reduces -X- _ O
the -X- _ O
influence -X- _ O
of -X- _ O
MandW -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
final -X- _ O
score -X- _ O
is -X- _ O
dominated -X- _ O
by -X- _ O
the -X- _ O
total -X- _ O
slot -X- _ O
number -X- _ O
T -X- _ O
. -X- _ O

SA -X- _ O
= -X- _ O
TMW -X- _ O
T(2 -X- _ O
) -X- _ O
Figure -X- _ O
2 -X- _ O
illustrates -X- _ O
the -X- _ O
total -X- _ O
number -X- _ O
of -X- _ O
annotated -X- _ O
slots -X- _ O
in -X- _ O
MultiWOZ -X- _ B-DatasetName
2.1 -X- _ O
to -X- _ O
figure -X- _ O
out -X- _ O
the -X- _ O
limitation -X- _ O
of -X- _ O
slot -X- _ B-MetricName
accuracy -X- _ I-MetricName
. -X- _ O

Equation -X- _ O
2 -X- _ O
expresses -X- _ O
how -X- _ O
to -X- _ O
calculate -X- _ O
the -X- _ O
slot -X- _ B-MetricName
accuracy -X- _ I-MetricName
. -X- _ O

2.2 -X- _ O
Slot -X- _ B-MetricName
Accuracy -X- _ I-MetricName
Slot -X- _ B-MetricName
accuracy -X- _ I-MetricName
can -X- _ O
compensate -X- _ O
for -X- _ O
situations -X- _ O
where -X- _ O
joint -X- _ B-MetricName
goal -X- _ I-MetricName
accuracy -X- _ I-MetricName
does -X- _ O
not -X- _ O
fully -X- _ O
evaluate -X- _ O
the -X- _ O
dialogue -X- _ O
situation -X- _ O
. -X- _ O

012345678910111213141516171819 -X- _ O
# -X- _ O
of -X- _ O
used -X- _ O
slots -X- _ O
( -X- _ O
total -X- _ O
30 -X- _ O
slots)020406080100120140 -X- _ O
# -X- _ O
of -X- _ O
dialogue -X- _ O
091561 -X- _ O
5377121131127 -X- _ O
89 -X- _ O
7496 -X- _ O
66 -X- _ O
34 -X- _ O
24 -X- _ O
87520Figure -X- _ O
2 -X- _ O
: -X- _ O
The -X- _ O
number -X- _ O
of -X- _ O
predefined -X- _ O
gold -X- _ O
slots -X- _ O
used -X- _ O
in -X- _ O
each -X- _ O
dialogue -X- _ O
( -X- _ O
999 -X- _ O
MultiWOZ -X- _ B-DatasetName
2.1 -X- _ O
test -X- _ O
set -X- _ O
) -X- _ O
. -X- _ O

159 -X- _ O
samples -X- _ O
of -X- _ O
the -X- _ O
642 -X- _ O
samples -X- _ O
have -X- _ O
a -X- _ O
joint -X- _ B-MetricName
goal -X- _ I-MetricName
accuracy -X- _ I-MetricName
of -X- _ O
1 -X- _ B-MetricValue
in -X- _ O
the -X- _ O
middle -X- _ O
, -X- _ O
owing -X- _ O
to -X- _ O
a -X- _ O
coincidental -X- _ O
situation -X- _ O
or -X- _ O
differences -X- _ O
in -X- _ O
the -X- _ O
analysis -X- _ O
of -X- _ O
annotation -X- _ O
. -X- _ O

Failure -X- _ O
to -X- _ O
measure -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
latter -X- _ O
part -X- _ O
means -X- _ O
that -X- _ O
it -X- _ O
can -X- _ O
not -X- _ O
consider -X- _ O
various -X- _ O
dialogue -X- _ O
situations -X- _ O
provided -X- _ O
in -X- _ O
the -X- _ O
dataset -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
critical -X- _ O
issue -X- _ O
in -X- _ O
building -X- _ O
a -X- _ O
realistic -X- _ O
DST -X- _ B-MethodName
model -X- _ I-MethodName
. -X- _ O

This -X- _ O
means -X- _ O
that -X- _ O
the -X- _ O
joint -X- _ B-MetricName
goal -X- _ I-MetricName
accuracy -X- _ I-MetricName
after -X- _ O
the -X- _ O
beginning -X- _ O
of -X- _ O
the -X- _ O
dialogue -X- _ O
is -X- _ O
unconditionally -X- _ O
measured -X- _ O
as -X- _ O
zero -X- _ B-MetricValue
because -X- _ O
of -X- _ O
the -X- _ O
initial -X- _ O
misprediction -X- _ O
, -X- _ O
although -X- _ O
the -X- _ O
model -X- _ O
may -X- _ O
correctly -X- _ O
predict -X- _ O
new -X- _ O
belief -X- _ O
states -X- _ O
at -X- _ O
later -X- _ O
turns -X- _ O
. -X- _ O

Accordingly -X- _ O
, -X- _ O
the -X- _ O
relative -X- _ O
position -X- _ O
where -X- _ O
joint -X- _ B-MetricName
goal -X- _ I-MetricName
accuracy -X- _ I-MetricName
first -X- _ O
became -X- _ O
zero -X- _ B-MetricValue
was -X- _ O
mainly -X- _ O
at -X- _ O
the -X- _ O
beginning -X- _ O
of -X- _ O
the -X- _ O
dialogue1 -X- _ O
. -X- _ O

The -X- _ O
DST -X- _ B-MethodName
model -X- _ I-MethodName
selected -X- _ O
for -X- _ O
primary -X- _ O
verification -X- _ O
is -X- _ O
the -X- _ O
SOM -X- _ B-MethodName
- -X- _ I-MethodName
DST -X- _ I-MethodName
( -X- _ O
Kim -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
latest -X- _ O
DST -X- _ B-MethodName
models -X- _ I-MethodName
. -X- _ O

We -X- _ O
used -X- _ B-DatasetName
MultiWOZ -X- _ I-DatasetName
2.1 -X- _ O
( -X- _ O
Eric -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
analyzed -X- _ O
642 -X- _ O
samples -X- _ O
from -X- _ O
a -X- _ O
total -X- _ O
of -X- _ O
999 -X- _ O
test -X- _ O
sets -X- _ O
in -X- _ O
which -X- _ O
the -X- _ O
joint -X- _ B-MetricName
goal -X- _ I-MetricName
accuracy -X- _ I-MetricName
of -X- _ O
the -X- _ O
last -X- _ O
turn -X- _ O
is -X- _ O
zero -X- _ B-MetricValue
. -X- _ O

JGA -X- _ O
=( -X- _ O
1if -X- _ O
predicted -X- _ O
state -X- _ O
= -X- _ O
gold -X- _ O
state -X- _ O
0otherwise -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
joint -X- _ B-MetricName
goal -X- _ I-MetricName
accuracy -X- _ I-MetricName
underestimates -X- _ O
the -X- _ O
accumulated -X- _ O
states -X- _ O
because -X- _ O
it -X- _ O
scores -X- _ O
the -X- _ O
performances -X- _ O
of -X- _ O
later -X- _ O
turn -X- _ O
to -X- _ O
zero -X- _ B-MetricValue
if -X- _ O
the -X- _ O
model -X- _ O
mispredicts -X- _ O
even -X- _ O
once -X- _ O
in -X- _ O
a -X- _ O
particular -X- _ O
turn -X- _ O
, -X- _ O
regardless -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
prediction -X- _ O
quality -X- _ O
at -X- _ O
later -X- _ O
turns -X- _ O
. -X- _ O

010 -X- _ O
20 -X- _ O
30 -X- _ O
40 -X- _ O
50 -X- _ O
60 -X- _ O
70 -X- _ O
80 -X- _ O
90100 -X- _ O
Relative -X- _ O
position -X- _ O
(% -X- _ O
) -X- _ O
020406080100120 -X- _ O
# -X- _ O
of -X- _ O
dialogue94 -X- _ O
69111 -X- _ O
97 -X- _ O
61 -X- _ O
55 -X- _ O
344046 -X- _ O
22 -X- _ O
13Figure -X- _ O
1 -X- _ O
: -X- _ O
The -X- _ O
relative -X- _ O
position -X- _ O
where -X- _ B-MetricName
joint -X- _ I-MetricName
goal -X- _ I-MetricName
accuracy -X- _ I-MetricName
of -X- _ O
the -X- _ O
turn -X- _ O
is -X- _ O
measured -X- _ O
to -X- _ O
be -X- _ O
zero -X- _ O
for -X- _ O
the -X- _ O
first -X- _ O
time -X- _ O
among -X- _ O
the -X- _ O
dialogues -X- _ O
where -X- _ O
joint -X- _ B-MetricName
goal -X- _ I-MetricName
accuracy -X- _ I-MetricName
of -X- _ O
the -X- _ O
last -X- _ O
turn -X- _ O
is -X- _ O
zero -X- _ O
. -X- _ O

Equation -X- _ O
1 -X- _ O
expresses -X- _ O
how -X- _ O
to -X- _ O
calculate -X- _ O
the -X- _ B-MetricName
joint -X- _ I-MetricName
goal -X- _ I-MetricName
accuracy -X- _ I-MetricName
, -X- _ O
depending -X- _ O
on -X- _ O
whether -X- _ O
the -X- _ O
slot -X- _ O
values -X- _ O
match -X- _ O
each -X- _ O
turn.297 -X- _ O
. -X- _ O

2 -X- _ O
Current -X- _ O
Evaluation -X- _ O
Metrics -X- _ O
2.1 -X- _ O
Joint -X- _ B-MetricName
Goal -X- _ I-MetricName
Accuracy -X- _ I-MetricName
Joint -X- _ B-MetricName
goal -X- _ I-MetricName
accuracy -X- _ I-MetricName
, -X- _ O
developed -X- _ O
from -X- _ O
Henderson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2014b -X- _ O
) -X- _ O
and -X- _ O
Zhong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
can -X- _ O
be -X- _ O
said -X- _ O
to -X- _ O
be -X- _ O
an -X- _ O
ideal -X- _ O
metric -X- _ O
, -X- _ O
in -X- _ O
that -X- _ O
it -X- _ O
verifies -X- _ O
that -X- _ O
the -X- _ O
predicted -X- _ O
belief -X- _ O
states -X- _ O
perfectly -X- _ O
match -X- _ O
the -X- _ O
gold -X- _ O
label -X- _ O
. -X- _ O

Therefore -X- _ O
, -X- _ O
relative -X- _ B-MetricName
slot -X- _ I-MetricName
accuracy -X- _ I-MetricName
enables -X- _ O
a -X- _ O
realistic -X- _ O
evaluation -X- _ O
by -X- _ O
rewarding -X- _ O
the -X- _ O
models -X- _ O
correct -X- _ O
predictions -X- _ O
, -X- _ O
a -X- _ O
complementary -X- _ O
approach -X- _ O
that -X- _ O
joint -X- _ O
goal -X- _ O
and -X- _ O
slot -X- _ O
accuracies -X- _ O
can -X- _ O
not -X- _ O
fully -X- _ O
cover -X- _ O
. -X- _ O

To -X- _ O
address -X- _ O
the -X- _ O
above -X- _ O
challenge -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
reporting -X- _ O
the -X- _ O
relative -X- _ B-MetricName
slot -X- _ I-MetricName
accuracy -X- _ I-MetricName
along -X- _ O
with -X- _ O
the -X- _ O
existing -X- _ O
metrics -X- _ O
in -X- _ O
MultiWOZ -X- _ B-DatasetName
dataset -X- _ I-DatasetName
. -X- _ O

While -X- _ O
slot -X- _ B-MetricName
accuracy -X- _ I-MetricName
has -X- _ O
the -X- _ O
challenge -X- _ O
of -X- _ O
overestimation -X- _ O
by -X- _ O
always -X- _ O
considering -X- _ O
all -X- _ O
predefined -X- _ O
slots -X- _ O
in -X- _ O
every -X- _ O
turn -X- _ O
, -X- _ O
relative -X- _ B-MetricName
slot -X- _ I-MetricName
accuracy -X- _ I-MetricName
does -X- _ O
not -X- _ O
depend -X- _ O
on -X- _ O
predefined -X- _ O
slots -X- _ O
, -X- _ O
and -X- _ O
calculates -X- _ O
a -X- _ O
score -X- _ O
that -X- _ O
is -X- _ O
affected -X- _ O
solely -X- _ O
by -X- _ O
slots -X- _ O
that -X- _ O
appear -X- _ O
in -X- _ O
the -X- _ O
current -X- _ O
dialogue -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
lack -X- _ O
of -X- _ O
discussion -X- _ O
on -X- _ O
the -X- _ O
metric -X- _ O
for -X- _ O
evaluating -X- _ O
the -X- _ O
most -X- _ O
used -X- _ O
MultiWOZ -X- _ B-DatasetName
dataset -X- _ I-DatasetName
, -X- _ O
despite -X- _ O
a -X- _ O
recently -X- _ O
published -X- _ O
dataset -X- _ O
( -X- _ O
Rastogi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
proposing -X- _ O
some -X- _ O
metrics -X- _ O
. -X- _ O

Accordingly -X- _ O
, -X- _ O
as -X- _ O
also -X- _ O
pointed -X- _ O
out -X- _ O
in -X- _ O
Rastogi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020a -X- _ O
) -X- _ O
, -X- _ O
joint -X- _ B-MetricName
goal -X- _ I-MetricName
accuracy -X- _ I-MetricName
underestimates -X- _ O
the -X- _ O
model -X- _ O
prediction -X- _ O
because -X- _ O
of -X- _ O
its -X- _ O
error -X- _ O
accumulation -X- _ O
attribute -X- _ O
, -X- _ O
while -X- _ O
slot -X- _ B-MetricName
accuracy -X- _ I-MetricName
overestimates -X- _ O
it -X- _ O
because -X- _ O
of -X- _ O
its -X- _ O
dependency -X- _ O
on -X- _ O
predefined -X- _ O
slots -X- _ O
. -X- _ O

Joint -X- _ B-MetricName
goal -X- _ I-MetricName
accuracy -X- _ I-MetricName
strictly -X- _ O
determines -X- _ O
whether -X- _ O
every -X- _ O
predicted -X- _ O
state -X- _ O
is -X- _ O
identical -X- _ O
to -X- _ O
the -X- _ O
gold -X- _ O
state -X- _ O
, -X- _ O
whereas -X- _ O
slot -X- _ B-MetricName
accuracy -X- _ I-MetricName
measures -X- _ O
the -X- _ O
ratio -X- _ O
of -X- _ O
correct -X- _ O
predictions -X- _ O
. -X- _ O

Joint -X- _ B-MetricName
goal -X- _ I-MetricName
accuracy -X- _ I-MetricName
and -X- _ O
slot -X- _ B-MetricName
accuracy -X- _ I-MetricName
are -X- _ O
utilized -X- _ O
in -X- _ O
most -X- _ O
cases -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
prediction -X- _ O
of -X- _ O
accumu -X- _ O
- -X- _ O
lated -X- _ O
belief -X- _ O
states -X- _ O
. -X- _ O

It -X- _ O
confirms -X- _ O
whether -X- _ O
the -X- _ O
DST -X- _ B-MethodName
model -X- _ I-MethodName
tracks -X- _ O
essential -X- _ O
information -X- _ O
that -X- _ O
has -X- _ O
appeared -X- _ O
up -X- _ O
to -X- _ O
the -X- _ O
present -X- _ O
point -X- _ O
. -X- _ O

Recently -X- _ O
, -X- _ O
multi -X- _ B-DatasetName
- -X- _ I-DatasetName
turn -X- _ I-DatasetName
DST -X- _ I-DatasetName
datasets -X- _ I-DatasetName
have -X- _ O
been -X- _ O
constructed -X- _ O
using -X- _ O
the -X- _ B-MethodName
Wizard -X- _ I-MethodName
- -X- _ I-MethodName
of -X- _ I-MethodName
- -X- _ I-MethodName
Oz -X- _ I-MethodName
method -X- _ I-MethodName
to -X- _ O
reflect -X- _ O
more -X- _ O
realistic -X- _ O
dialogue -X- _ O
situations -X- _ O
( -X- _ O
Wen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Mrki -X- _ O
c -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Budzianowski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

1 -X- _ O
Introduction -X- _ O
The -X- _ B-MethodName
dialogue -X- _ I-MethodName
state -X- _ I-MethodName
tracking -X- _ I-MethodName
( -X- _ I-MethodName
DST -X- _ I-MethodName
) -X- _ I-MethodName
module -X- _ I-MethodName
structures -X- _ O
the -X- _ O
belief -X- _ O
state -X- _ O
that -X- _ O
appears -X- _ O
during -X- _ O
the -X- _ O
conversation -X- _ O
in -X- _ O
the -X- _ O
form -X- _ O
of -X- _ O
domain -X- _ O
- -X- _ O
slot -X- _ O
- -X- _ O
value -X- _ O
, -X- _ O
to -X- _ O
provide -X- _ O
an -X- _ O
appropriate -X- _ O
response -X- _ O
to -X- _ O
the -X- _ O
user -X- _ O
. -X- _ O

This -X- _ O
study -X- _ O
also -X- _ O
encourages -X- _ O
not -X- _ O
solely -X- _ O
the -X- _ O
reporting -X- _ O
of -X- _ O
joint -X- _ B-MetricName
goal -X- _ I-MetricName
accuracy -X- _ I-MetricName
, -X- _ O
but -X- _ O
also -X- _ O
various -X- _ O
complementary -X- _ O
metrics -X- _ O
in -X- _ O
DST -X- _ B-TaskName
tasks -X- _ I-TaskName
for -X- _ O
the -X- _ O
sake -X- _ O
of -X- _ O
a -X- _ O
realistic -X- _ O
evaluation -X- _ O
. -X- _ O

Relative -X- _ B-MetricName
slot -X- _ I-MetricName
accuracy -X- _ I-MetricName
does -X- _ O
not -X- _ O
depend -X- _ O
on -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
predefined -X- _ O
slots -X- _ O
, -X- _ O
and -X- _ O
allows -X- _ O
intuitive -X- _ O
evaluation -X- _ O
by -X- _ O
assigning -X- _ O
relative -X- _ O
scores -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
turn -X- _ O
of -X- _ O
each -X- _ O
dialogue -X- _ O
. -X- _ O

Additionally -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
relative -X- _ B-MetricName
slot -X- _ I-MetricName
accuracy -X- _ I-MetricName
to -X- _ O
complement -X- _ O
existing -X- _ O
metrics -X- _ O
. -X- _ O

The -X- _ O
trained -X- _ O
model -X- _ O
predicts -X- _ O
accumulated -X- _ O
belief -X- _ O
states -X- _ O
in -X- _ O
every -X- _ O
turn -X- _ O
, -X- _ O
and -X- _ B-MetricName
joint -X- _ I-MetricName
goal -X- _ I-MetricName
accuracy -X- _ I-MetricName
and -X- _ O
slot -X- _ B-MetricName
accuracy -X- _ I-MetricName
are -X- _ O
mainly -X- _ O
used -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
prediction -X- _ O
; -X- _ O
however -X- _ O
, -X- _ O
we -X- _ O
specify -X- _ O
that -X- _ O
the -X- _ O
current -X- _ O
evaluation -X- _ O
metrics -X- _ O
have -X- _ O
a -X- _ O
critical -X- _ O
limitation -X- _ O
when -X- _ O
evaluating -X- _ O
belief -X- _ O
states -X- _ O
accumulated -X- _ O
as -X- _ O
the -X- _ O
dialogue -X- _ O
proceeds -X- _ O
, -X- _ O
especially -X- _ O
in -X- _ O
the -X- _ O
most -X- _ O
used -X- _ O
MultiWOZ -X- _ B-DatasetName
dataset -X- _ I-DatasetName
. -X- _ O

