To O
overcome O
this O
confound O
, O
we O
probe O
grammatical O
role O
representation O
in O
English O
BERT B-MethodName
and O
GPT-2 B-MethodName
, O
on O
instances O
where O
lexical O
expectations O
are O
not O
sufficient O
, O
and O
word O
order O
knowledge O
is O
necessary O
for O
correct O
classification O
. O

Recent O
work O
has O
shown O
large O
language O
models O
to O
be O
surprisingly O
word O
order O
invariant O
, O
but O
crucially O
has O
largely O
considered O
natural O
prototypical O
inputs O
, O
where O
compositional O
meaning O
mostly O
matches O
lexical O
expectations O
. O

For O
example O
, O
the O
words O
chopped O
, O
chef O
, O
and O
onion O
are O
more O
likely O
used O
to O
convey O
The O
chef O
chopped O
the O
onion O
, O
not O
The O
onion O
chopped O
the O
chef O
. O

except O
when O
it O
matters O
Isabel O
Papadimitriou O
Stanford O
University O
isabelvp@stanford.eduRichard O
Futrell O
University O
of O
California O
, O
Irvine O
rfutrell@uci.edu O
Kyle O
Mahowald O
The O
University O
of O
Texas O
at O
Austin O
mahowald@utexas.edu O
Abstract O
Because O
meaning O
can O
often O
be O
inferred O
from O
lexical O
semantics O
alone O
, O
word O
order O
is O
often O
a O
redundant O
cue O
in O
natural O
language O
. O

. O

. O

Proceedings O
of O
the O
60th O
Annual O
Meeting O
of O
the O
Association O
for O
Computational O
Linguistics O
Volume O
2 O
: O
Short O
Papers O
, O
pages O
636 O
- O
643 O
May O
22 O
- O
27 O
, O
2022 O
c O
2022 O
Association O
for O
Computational O
Linguistics O
When O
classifying O
grammatical O
role O
, O
BERT O
does O
nt O
care O
about O
word O
order O
. O

ArXiv O
, O
abs/2002.06541.635 O
. O

Learning O
not O
to O
learn O
in O
the O
presence O
of O
noisy O
labels O
. O

2020 O
. O

Liu O
Ziyin O
, O
Blair O
Chen O
, O
Ru O
Wang O
, O
Paul O
Pu O
Liang O
, O
Ruslan O
Salakhutdinov O
, O
Louis O
- O
Philippe O
Morency O
, O
and O
Masahito O
Ueda O
. O

Association O
for O
Computational O
Linguistics O
. O

InProceedings O
of O
the O
Sixth O
Workshop O
on O
Computational O
Linguistics O
and O
Clinical O
Psychology O
, O
pages O
2433 O
, O
Minneapolis O
, O
Minnesota O
. O

CLPsych O
2019 O
shared O
task O
: O
Predicting O
the O
degree O
of O
suicide O
risk O
in O
Reddit O
posts O
. O

2019 O
. O

Ayah O
Zirikly O
, O
Philip O
Resnik O
, O
zlem O
Uzuner O
, O
and O
Kristy O
Hollingshead O
. O

Suicide O
data O
. O

2019 O
. O

WHO O
. O

Nature O
human O
behaviour O
, O
5(2):229238 O
. O

Increase O
in O
suicide O
following O
an O
initial O
decline O
during O
the O
covid-19 O
pandemic O
in O
japan O
. O

2021 O
. O

Takanao O
Tanaka O
and O
Shohei O
Okamoto O
. O

Springer O
. O

In O
Cognitive O
informatics O
for O
biomedicine O
, O
pages O
5980 O
. O

A O
new O
socio O
- O
technical O
model O
for O
studying O
health O
information O
technology O
in O
complex O
adaptive O
healthcare O
systems O
. O

2015 O
. O

Dean O
F O
Sittig O
and O
Hardeep O
Singh O
. O

ACM O
. O

In O
Proceedings O
of O
the O
28th O
ACM O
International O
Conference O
on O
Information O
and O
Knowledge O
Management O
, O
CIKM O
2019 O
, O
Beijing O
, O
China O
, O
November O
3 O
- O
7 O
, O
2019 O
, O
pages O
941950 O
. O

# O
suicidal O
- O
A O
multipronged O
approach O
to O
identify O
and O
explore O
suicidal O
ideation O
in O
twitter O
. O

2019 O
. O

Pradyumna O
Prakhar O
Sinha O
, O
Rohan O
Mishra O
, O
Ramit O
Sawhney O
, O
Debanjan O
Mahata O
, O
Rajiv O
Ratn O
Shah O
, O
and O
Huan O
Liu O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
58th O
Annual O
Meeting O
of O
the O
Association O
for O
Computational O
Linguistics O
, O
pages O
81248137 O
, O
Online O
. O

A O
prioritization O
model O
for O
suicidality O
risk O
assessment O
. O

2020 O
. O

Han O
- O
Chin O
Shing O
, O
Philip O
Resnik O
, O
and O
Douglas O
Oard O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
2021 O
Conference O
of O
the O
North O
American O
Chapter O
of O
the O
Association O
for O
Computational O
Linguistics O
: O
Human O
Language O
Technologies O
, O
pages O
21762190 O
, O
Online O
. O

Suicide O
ideation O
detection O
via O
social O
and O
temporal O
user O
representations O
using O
hyperbolic O
learning O
. O

2021b O
. O

Ramit O
Sawhney O
, O
Harshit O
Joshi O
, O
Rajiv O
Ratn O
Shah O
, O
and O
Lucie O
Flek O
. O

Association O
for O
Computing O
Machinery O
. O

WSDM O
21 O
, O
page O
2230 O
, O
New O
York O
, O
NY O
, O
USA O
. O

Towards O
ordinal O
suicide O
ideation O
detection O
on O
social O
media O
. O

2021a O
. O

Ramit O
Sawhney O
, O
Harshit O
Joshi O
, O
Saumya O
Gandhi O
, O
and O
Rajiv O
Ratn O
Shah O
. O

it O
told O
a O
mock O
patient O
to O
kill O
themselves O
. O

Researchers O
made O
an O
openai O
gpt3 O
medical O
chatbot O
as O
an O
experiment O
. O

2020 O
. O

The O
Register O
. O

Bad O
judgment O
, O
bad O
ethics O
? O
Internet O
Research O
Ethics O
for O
the O
Social O
Age O
, O
page O
95 O
. O

2017 O
. O

Cornelius O
Puschman O
. O

American O
journal O
of O
psychiatry O
, O
168(12):12661277 O
. O

The O
columbia O
suicide O
severity O
rating O
scale O
: O
initial O
validity O
and O
internal O
consistency O
findings O
from O
three O
multisite O
studies O
with O
adolescents O
and O
adults O
. O

Kelly O
Posner O
, O
Gregory O
K O
Brown O
, O
Barbara O
Stanley O
, O
David O
A O
Brent O
, O
Kseniya O
V O
Yershova O
, O
Maria O
A O
Oquendo O
, O
Glenn O
W O
Currier O
, O
Glenn O
A O
Melvin O
, O
Laurence O
Greenhill O
, O
Sa O
Shen O
, O
et O
al O
. O
2011 O
. O

Social O
science O
& O
medicine O
, O
74(4):506514 O
. O

you O
feel O
like O
you O
ca O
nt O
live O
anymore O
: O
Suicide O
from O
the O
perspectives O
of O
canadian O
men O
who O
experience O
depression O
. O

2012 O
. O

John O
L O
Oliffe O
, O
John O
S O
Ogrodniczuk O
, O
Joan O
L O
Bottorff O
, O
Joy O
L O
Johnson O
, O
and O
Kristy O
Hoyak O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
2019 O
Conference O
of O
the O
North O
American O
Chapter O
of O
the O
Association O
for O
Computational O
Linguistics O
: O
Student O
Research O
Workshop O
, O
pages O
147156 O
, O
Minneapolis O
, O
Minnesota O
. O

SNAP O
- O
BATNET O
: O
Cascading O
author O
profiling O
and O
social O
network O
graphs O
for O
suicide O
ideation O
detection O
on O
social O
media O
. O

2019 O
. O

Rohan O
Mishra O
, O
Pradyumn O
Prakhar O
Sinha O
, O
Ramit O
Sawhney O
, O
Debanjan O
Mahata O
, O
Puneet O
Mathur O
, O
and O
Rajiv O
Ratn O
Shah O
. O

BJPsych O
open O
, O
5(2 O
) O
. O

Association O
between O
suicidal O
ideation O
and O
suicide O
: O
metaanalyses O
of O
odds O
ratios O
, O
sensitivity O
, O
specificity O
and O
positive O
predictive O
value O
. O

2019 O
. O

Catherine O
M O
McHugh O
, O
Amy O
Corderoy O
, O
Christopher O
James O
Ryan O
, O
Ian O
B O
Hickie O
, O
and O
Matthew O
Michael O
Large O
. O

Suicide O
and O
Life O
- O
Threatening O
Behavior O
, O
51(6):10861094 O
. O

Examining O
suicide O
assessment O
measures O
for O
research O
use O
: O
Using O
item O
response O
theory O
to O
optimize O
psychometric O
assessment O
for O
research O
on O
suicidal O
ideation O
in O
major O
depressive O
disorder O
. O

2021 O
. O

Michael O
R O
Nadorff O
. O

William O
V O
McCall O
, O
Ben O
Porter O
, O
Ashley O
R O
Pate O
, O
Courtney O
J O
Bolstad O
, O
Christopher O
W O
Drapeau O
, O
Andrew O
D O
Krystal O
, O
Ruth O
M O
Benca O
, O
Meredith O
E O
Rumble O
, O
and634 O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
Sixth O
Workshop O
on O
Computational O
Linguistics O
and O
Clinical O
Psychology O
, O
pages O
3944 O
, O
Minneapolis O
, O
Minnesota O
. O

Suicide O
risk O
assessment O
with O
multi O
- O
level O
dual O
- O
context O
language O
and O
BERT O
. O

2019 O
. O

Andrew O
Schwartz O
. O

Matthew O
Matero O
, O
Akash O
Idnani O
, O
Youngseo O
Son O
, O
Salvatore O
Giorgi O
, O
Huy O
Vu O
, O
Mohammad O
Zamani O
, O
Parth O
Limbachiya O
, O
Sharath O
Chandra O
Guntuku O
, O
and O
H O
. O

In O
Advances O
in O
Neural O
Information O
Processing O
Systems O
32 O
: O
Annual O
Conference O
on O
Neural O
Information O
Processing O
Systems O
2019 O
, O
NeurIPS O
2019 O
, O
December O
8 O
- O
14 O
, O
2019 O
, O
Vancouver O
, O
BC O
, O
Canada O
, O
pages O
1062210632 O
. O

Deep O
gamblers O
: O
Learning O
to O
abstain O
with O
portfolio O
theory O
. O

2019 O
. O

Ziyin O
Liu O
, O
Zhikang O
Wang O
, O
Paul O
Pu O
Liang O
, O
Ruslan O
Salakhutdinov O
, O
Louis O
- O
Philippe O
Morency O
, O
and O
Masahito O
Ueda O
. O

Behavioral O
sciences O
& O
the O
law O
, O
37(3):214222 O
. O

Machine O
learning O
in O
suicide O
science O
: O
Applications O
and O
ethics O
. O

2019 O
. O

Kathryn O
P O
Linthicum O
, O
Katherine O
Musacchio O
Schafer O
, O
and O
Jessica O
D O
Ribeiro O
. O

Association O
for O
Computing O
Machinery O
. O

In O
Proceedings O
of O
the O
26th O
ACM O
Conference O
on O
Hypertext O
& O
Social O
Media O
, O
HT O
15 O
, O
page O
8594 O
, O
New O
York O
, O
NY O
, O
USA O
. O

Detecting O
changes O
in O
suicide O
content O
manifested O
in O
social O
media O
following O
celebrity O
suicides O
. O

2015 O
. O

Mrinal O
Kumar O
, O
Mark O
Dredze O
, O
Glen O
Coppersmith O
, O
and O
Munmun O
De O
Choudhury O
. O

Journal O
of O
affective O
disorders O
, O
140(1):75 O
81 O
. O

Suicidal O
ideation O
and O
the O
subjective O
aspects O
of O
depression O
. O

2012 O
. O

John O
G O
Keilp O
, O
Michael O
F O
Grunebaum O
, O
Marianne O
Gorlyn O
, O
Simone O
LeBlanc O
, O
Ainsley O
K O
Burke O
, O
Hanga O
Galfalvy O
, O
Maria O
A O
Oquendo O
, O
and O
J O
John O
Mann O
. O

IEEE O
Transactions O
on O
Computational O
Social O
Systems O
, O
8(1):214226 O
. O

Suicidal O
ideation O
detection O
: O
A O
review O
of O
machine O
learning O
methods O
and O
applications O
. O

2021b O
. O

Shaoxiong O
Ji O
, O
Shirui O
Pan O
, O
Xue O
Li O
, O
Erik O
Cambria O
, O
Guodong O
Long O
, O
and O
Zi O
Huang O
. O

Neural O
Computing O
and O
Applications O
. O

Suicidal O
ideation O
and O
mental O
disorder O
detection O
with O
attentive O
relation O
networks O
. O

2021a O
. O

Shaoxiong O
Ji O
, O
Xue O
Li O
, O
Zi O
Huang O
, O
and O
Erik O
Cambria O
. O

Archives O
of O
suicide O
research O
, O
22(2):278294 O
. O

Use O
of O
the O
columbia O
- O
suicide O
severity O
rating O
scale O
( O
c O
- O
ssrs O
) O
to O
classify O
suicidal O
behaviors O
. O

2018 O
. O

Hill O
, O
Miriam O
Latorre O
, O
Anton O
Shcherbakov O
, O
Arlene O
King O
, O
and O
Barbara O
Stanley O
. O

Alejandro O
Interian O
, O
Megan O
Chesin O
, O
Anna O
Kline O
, O
Rachael O
Miller O
, O
Lauren O
St O
. O

JAMA O
Psychiatry O
, O
73(2):103104 O
. O

An O
Adjuvant O
Role O
for O
Mobile O
Health O
in O
Psychiatry O
. O

2016 O
. O

Association O
for O
Computational O
Linguistics O
. O
Honor O
Hsin O
, O
John O
Torous O
, O
and O
Laura O
Roberts O
. O

In O
Proceedings O
of O
the O
54th O
Annual O
Meeting O
of O
the O
Association O
for O
Computational O
Linguistics O
( O
Volume O
2 O
: O
Short O
Papers O
) O
, O
pages O
591598 O
, O
Berlin O
, O
Germany O
. O

The O
social O
impact O
of O
natural O
language O
processing O
. O

2016 O
. O

Spruit O
. O

Dirk O
Hovy O
and O
Shannon O
L O
. O

NCHS O
data O
brief O
, O
( O
398):18 O
. O

Suicide O
mortality O
in O
the O
united O
states O
, O
19992019 O
. O

2021 O
. O

Holly O
Hedegaard O
, O
Sally O
C O
Curtin O
, O
and O
Margaret O
Warner O
. O

Infobase O
Publishing O
. O

The O
truth O
about O
illness O
and O
disease O
. O

2009 O
. O

Robert O
N O
Golden O
, O
Carla O
Weiland O
, O
and O
Fred O
Peterson O
. O

PloS O
one O
, O
16(5):e0250448 O
. O

Characterization O
of O
time O
- O
variant O
and O
time O
- O
invariant O
assessment O
of O
suicidality O
on O
reddit O
using O
c O
- O
ssrs O
. O

2021 O
. O

Manas O
Gaur O
, O
Vamsi O
Aribandi O
, O
Amanuel O
Alambo O
, O
Ugur O
Kursuncu O
, O
Krishnaprasad O
Thirunarayan O
, O
Jonathan O
Beich O
, O
Jyotishman O
Pathak O
, O
and O
Amit O
Sheth O
. O

ACM O
. O

In O
The O
World O
Wide O
Web O
Conference O
, O
WWW O
2019 O
, O
San O
Francisco O
, O
CA O
, O
USA O
, O
May O
13 O
- O
17 O
, O
2019 O
, O
pages O
514525 O
. O

Knowledge O
- O
aware O
assessment O
of O
severity O
of O
suicide O
risk O
for O
early O
intervention O
. O

2019 O
. O

Welton O
, O
and O
Jyotishman O
Pathak O
. O

Sheth O
, O
Randy O
S O
. O

Manas O
Gaur O
, O
Amanuel O
Alambo O
, O
Joy O
Prakash O
Sain O
, O
Ugur O
Kursuncu O
, O
Krishnaprasad O
Thirunarayan O
, O
Ramakanth O
Kavuluru O
, O
Amit O
P O
. O

Social O
Media O
+ O
Society O
, O
4(1):2056305118763366 O
. O

participant O
perceptions O
of O
twitter O
research O
ethics O
. O

2018 O
. O

Casey O
Fiesler O
and O
Nicholas O
Proferes O
. O

PloS O
one O
, O
9(10):e110274 O
. O

Insights O
into O
the O
problem O
of O
alarm O
fatigue O
with O
physiologic O
monitor O
devices O
: O
a O
comprehensive O
observational O
study O
of O
consecutive O
intensive O
care O
unit O
patients O
. O

2014 O
. O

Barbara O
J O
Drew O
, O
Patricia O
Harris O
, O
Jessica O
K O
ZgreHemsey O
, O
Tina O
Mammone O
, O
Daniel O
Schindler O
, O
Rebeca O
Salas O
- O
Boni O
, O
Yong O
Bai O
, O
Adelita O
Tinoco O
, O
Quan O
Ding O
, O
and O
Xiao O
Hu O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
2019 O
Conference O
of O
the O
North O
American O
Chapter O
of O
the O
Association O
for O
Computational O
Linguistics O
: O
Human O
Language O
Technologies O
, O
Volume O
1 O
( O
Long O
and O
Short O
Papers O
) O
, O
pages O
41714186 O
, O
Minneapolis O
, O
Minnesota O
. O

BERT B-MethodName
: O
Pre O
- O
training O
of O
deep O
bidirectional O
transformers O
for O
language O
understanding O
. O

2019 O
. O

Jacob O
Devlin O
, O
Ming O
- O
Wei O
Chang O
, O
Kenton O
Lee O
, O
and O
Kristina O
Toutanova O
. O

Philosophy O
& O
Technology O
, O
31(4):669684 O
. O

Ethics O
and O
artificial O
intelligence O
: O
suicide O
prevention O
on O
facebook O
. O

2018 O
. O

Norberto O
Nuno O
Gomes O
de O
Andrade O
, O
Dave O
Pawson O
, O
Dan O
Muriello O
, O
Lizzy O
Donahue O
, O
and O
Jennifer O
Guadagno O
. O

Biomedical O
informatics O
insights O
, O
10:1178222618792860 O
. O

Natural O
language O
processing O
of O
social O
media O
as O
screening O
for O
suicide O
risk O
. O

2018 O
. O

Glen O
Coppersmith O
, O
Ryan O
Leary O
, O
Patrick O
Crutchley O
, O
and O
Alex O
Fine O
. O

ACM.633 O
. O

In O
Proceedings O
of O
the O
2016 O
CHI O
Conference O
on O
Human O
Factors O
in O
Computing O
Systems O
, O
San O
Jose O
, O
CA O
, O
USA O
, O
May O
7 O
- O
12 O
, O
2016 O
, O
pages O
20982110 O
. O

Discovering O
shifts O
to O
suicidal O
ideation O
from O
mental O
health O
content O
in O
social O
media O
. O

2016 O
. O

Munmun O
De O
Choudhury O
, O
Emre O
Kiciman O
, O
Mark O
Dredze O
, O
Glen O
Coppersmith O
, O
and O
Mrinal O
Kumar O
. O

Schizophrenia O
bulletin O
, O
46(1):1114 O
. O

Using O
machine O
learning O
in O
psychiatry O
: O
the O
need O
to O
establish O
a O
framework O
that O
nurtures O
trustworthiness O
. O

2020 O
. O

Chelsea O
Chandler O
, O
Peter O
W O
Foltz O
, O
and O
Brita O
Elvevg O
. O

Association O
for O
Computing O
Machinery O
. O

In O
Proceedings O
of O
the O
19th O
ACM O
Conference O
on O
Computer O
- O
Supported O
Cooperative O
Work O
& O
Social O
Computing O
, O
CSCW O
16 O
, O
page O
11711184 O
, O
New O
York O
, O
NY O
, O
USA O
. O

Quantifying O
and O
predicting O
mental O
illness O
severity O
in O
online O
pro O
- O
eating O
disorder O
communities O
. O

2016 O
. O

Goodman O
, O
Stephanie O
Zerwas O
, O
and O
Munmun O
De O
Choudhury O
. O

Stevie O
Chancellor O
, O
Zhiyuan O
Lin O
, O
Erica O
L O
. O

Association O
for O
Computing O
Machinery O
. O

In O
Proceedings O
of O
the O
Conference O
on O
Fairness O
, O
Accountability O
, O
and O
Transparency O
, O
FAT O
* O
19 O
, O
page O
7988 O
, O
New O
York O
, O
NY O
, O
USA O
. O

A O
taxonomy O
of O
ethical O
tensions O
in O
inferring O
mental O
health O
states O
from O
social O
media O
. O

2019 O
. O

Silenzio O
, O
and O
Munmun O
De O
Choudhury O
. O

B O
. O

Caine O
, O
Vincent O
M O
. O

Birnbaum O
, O
Eric O
D O
. O

Stevie O
Chancellor O
, O
Michael O
L O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
2019 O
Conference O
on O
Empirical O
Methods O
in O
Natural O
Language O
Processing O
and O
the O
9th O
International O
Joint O
Conference O
on O
Natural O
Language O
Processing O
( O
EMNLP O
- O
IJCNLP O
) O
, O
pages O
1718 O
1728 O
, O
Hong O
Kong O
, O
China O
. O

Latent O
suicide O
risk O
detection O
on O
microblog O
via O
suicideoriented O
word O
embeddings O
and O
layered O
attention O
. O

2019 O
. O

Lei O
Cao O
, O
Huijun O
Zhang O
, O
Ling O
Feng O
, O
Zihan O
Wei O
, O
Xin O
Wang O
, O
Ningyun O
Li O
, O
and O
Xiaohao O
He O
. O

IEEE O
Transactions O
on O
Multimedia O
, O
24:87102 O
. O

Building O
and O
using O
personal O
knowledge O
graph O
to O
improve O
suicidal O
ideation O
detection O
on O
social O
media O
. O

2022 O
. O

Lei O
Cao O
, O
Huijun O
Zhang O
, O
and O
Ling O
Feng O
. O

, O
4(3):217231 O
. O

Technol O
. O

Ethics O
and O
Inf O
. O

Studying O
the O
amateur O
artist O
: O
A O
perspective O
on O
disguising O
data O
collected O
inhuman O
subjects O
research O
on O
the O
internet O
. O

2002 O
. O

Amy O
Bruckman O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
First O
ACL O
Workshop O
on O
Ethics O
in O
Natural O
Language O
Processing O
, O
pages O
94102 O
, O
Valencia O
, O
Spain O
. O

Ethical O
research O
protocols O
for O
social O
media O
health O
research O
. O

2017 O
. O

Adrian O
Benton O
, O
Glen O
Coppersmith O
, O
and O
Mark O
Dredze O
. O

ArXiv O
preprint O
, O
abs/1606.06565 O
. O

Concrete O
problems O
in O
ai O
safety O
. O

2016 O
. O

We O
do O
not O
make O
any O
diagnostic O
claims O
, O
rather O
help O
prioritize O
the O
users O
that O
should O
be O
evaluated O
by O
the O
medical O
professionals O
first O
, O
as O
part O
of O
a O
distributed O
human O
- O
in O
- O
the O
- O
loop O
framework O
( O
de O
Andrade O
et O
al O
. O
, O
2018).References O
Dario O
Amodei O
, O
Chris O
Olah O
, O
Jacob O
Steinhardt O
, O
Paul O
Christiano O
, O
John O
Schulman O
, O
and O
Dan O
Man O
. O

We O
also O
agree O
that O
suicidality O
is O
subjective O
( O
Keilp O
et O
al O
. O
, O
2012 O
) O
, O
wherein O
the O
interpretation O
may O
vary O
across O
individuals O
on O
social O
media O
( O
Puschman O
, O
2017 O
) O
. O

For O
instance O
, O
Alarm O
fatigue O
is O
when O
alarms O
are O
so O
excessive O
, O
many O
of O
which O
are O
false O
positives O
, O
that O
healthcare O
providers O
become O
desensitized O
from O
alarms O
( O
Drew O
et O
al O
. O
, O
2014 O
) O
. O

It O
is O
also O
essential O
that O
clinicians O
and O
human O
moderators O
are O
not O
overburdened O
( O
Chancellor O
et O
al O
. O
, O
2019 O
) O
. O

Care O
should O
be O
taken O
to O
not O
to O
create O
stigma O
, O
and O
interventions O
must O
hence O
be O
carefully O
planned O
by O
consulting O
relevant O
stakeholders O
, O
such O
as O
clinicians O
, O
designers O
, O
and O
researchers O
( O
Chancellor O
et O
al O
. O
, O
2016 O
) O
, O
to O
maintain O
social O
media O
as O
a O
safe O
space O
for O
individuals O
looking O
to O
express O
themselves O
( O
Chancellor O
et O
al O
. O
, O
2019 O
) O
. O

While O
the O
essence O
of O
our O
work O
is O
to O
aid O
in O
the O
early O
detection O
of O
at O
- O
risk O
users O
and O
early O
intervention O
, O
any O
interventions O
must O
be O
well O
- O
thought O
, O
failing O
which O
may O
lead O
to O
counter O
- O
helpful O
outcomes O
, O
such O
as O
users O
moving O
to O
fringe O
platforms O
, O
making O
it O
harder O
to O
provide O
assistance O
( O
Kumar O
et O
al O
. O
, O
2015 O
) O
. O

We O
further O
acknowledge O
that O
the O
studied O
data O
may O
be O
susceptible O
to O
demographic O
, O
expert O
annotator O
, O
and O
medium O
- O
specific O
biases O
( O
Hovy O
and O
Spruit O
, O
2016 O
) O
. O

Hence O
, O
we O
ensure O
that O
this O
analysis O
is O
shared O
only O
selectively O
to O
avoid O
misuse O
such O
as O
Samaritans O
Radar O
( O
Hsin O
et O
al O
. O
, O
2016 O
) O
. O

We O
acknowledge O
that O
it O
is O
almost O
impossible O
to O
prevent O
abuse O
of O
released O
technology O
even O
when O
developed O
with O
good O
intentions O
( O
Hovy O
and O
Spruit O
, O
2016 O
) O
. O

Our O
work O
focuses O
on O
building O
an O
assistive O
tool O
for O
screening O
suicidal O
users O
and O
providing O
judgments O
purely O
based O
on O
observational O
capacity O
. O

Taking O
inspiration O
from O
Benton O
et O
al O
. O
( O
2017 O
) O
, O
we O
also O
keep O
the O
annotation O
of O
user O
data O
separate O
from O
raw O
user O
data O
on O
protected O
servers O
linked O
only O
through O
anonymous O
IDs O
. O

All O
examples O
used O
in O
this O
paper O
are O
further O
been O
anonymized O
, O
obfuscated O
, O
and O
paraphrased O
for O
user O
privacy O
( O
Benton O
et O
al O
. O
, O
2017 O
) O
and O
to O
prevent O
misuse O
as O
per O
the O
moderate O
disguise O
scheme O
suggested O
by O
Bruckman O
( O
2002 O
) O
. O

Although O
Reddit O
is O
intended O
for O
anonymous O
posting O
, O
we O
take O
further O
precautions O
by O
performing O
automatic O
de O
- O
identification O
of O
the O
dataset O
using O
named O
entity O
recognition O
( O
Zirikly O
et O
al O
. O
, O
2019 O
) O
. O

The O
primary O
source O
of O
the O
dataset O
used O
in O
this O
study O
is O
Reddit O
. O

ment O
. O

Ethical O
Considerations O
We O
work O
within O
the O
scope O
of O
acceptable O
privacy O
practices O
suggested O
by O
Chancellor O
et O
al O
. O
( O
2019 O
) O
and O
considerations O
presented O
by O
Fiesler O
and O
Proferes O
( O
2018 O
) O
to O
avoid O
coercion O
and O
intrusive O
treat-632 O
. O

We O
would O
also O
like O
to O
thank O
the O
anonymous O
reviewers O
for O
their O
insightful O
suggestions O
on O
various O
aspects O
of O
this O
work O
. O

Amit O
Sheth O
for O
reviewing O
the O
paper O
and O
providing O
valuable O
feedback O
and O
support O
. O

Acknowledgements O
We O
thank O
Prof O
. O

Through O
a O
qualitative O
analysis O
, O
we O
described O
how O
SASI B-MethodName
can O
be O
used O
as O
a O
part O
of O
a O
human O
- O
in O
- O
the O
- O
loop O
framework O
, O
facilitating O
efficient O
responses O
from O
mental O
health O
experts O
. O

We O
demonstrated O
the O
effectiveness O
of O
SASI B-MethodName
through O
quantitative O
evaluations O
on O
real O
- O
world O
data O
, O
wherein O
SASI B-MethodName
avoided O
high O
- O
risk O
situations O
by O
refraining O
from O
making O
83% O
of O
incorrect O
predictions O
. O

SASI B-MethodName
is O
self O
- O
aware O
, O
wherein O
it O
refrains O
from O
making O
a O
prediction O
when O
uncertain O
, O
and O
instead O
assigns O
high O
priority O
to O
such O
data O
samples O
for O
immediate O
review O
by O
mental O
health O
experts O
. O

5 O
Conclusion O
With O
a O
motivation O
to O
provide O
a O
robust O
solution O
to O
fine O
- O
grained O
suicide O
risk O
assessment O
on O
social O
media O
, O
we O
present O
SASI B-MethodName
, O
a O
framework O
that O
integrates O
the O
concept O
of O
selective O
prioritization O
to O
existing O
deep O
learning O
based O
risk O
- O
assessment O
techniques O
. O

While O
this O
example O
is O
not O
a O
cause O
for O
concern O
, O
certain O
situations O
may O
arise O
where O
SASI B-MethodName
also O
confidently O
assigns O
a O
low O
- O
risk O
score O
to O
a O
high O
- O
risk O
user O
, O
opening O
avenues O
for O
future O
work O
that O
involves O
integrating O
and O
reformulating O
ordinal O
regressionover O
the O
principles O
of O
Gamblers O
loss O
. O

However O
, O
the O
user O
is O
not O
high O
risk O
and O
gets O
assigned O
to O
the O
same O
priority O
level O
as O
the O
true O
risk O
label O
. O

User O
C O
is O
an O
erroneous O
case O
wherein O
SASI B-MethodName
is O
confident O
, O
yet O
makes O
a O
wrong O
prediction O
. O

User O
E O
shows O
a O
very O
low O
sign O
of O
risk O
, O
which O
is O
confidently O
captured O
by O
SASI B-MethodName
without O
needing O
to O
refrain O
. O

This O
user O
, O
who O
is O
already O
of O
relatively O
high O
risk O
, O
is O
hence O
assigned O
a O
high O
priority O
. O

SASI B-MethodName
chooses O
to O
refrain O
despite O
predicting O
the O
risk O
level O
of O
user O
B O
correctly O
, O
possibly O
because O
it O
employs O
a O
cautious O
approach O
due O
to O
phrases O
such O
as O
take O
my O
life O
scattered O
in O
the O
users O
timeline O
. O

However O
, O
SASI B-MethodName
refrains O
from O
committing O
to O
these O
predictions O
, O
assigning O
these O
users O
a O
high O
priority O
for O
immediate O
review O
and O
response O
. O

We O
observe O
the O
model O
makes O
erroneous O
predictions O
on O
high O
- O
risk O
users O
A O
and O
D O
. O

We O
study O
five O
users O
with O
snippets O
of O
their O
posts O
, O
as O
shown O
in O
Figure O
4 O
. O

4.3 O
Qualitative O
Analysis O
The O
essence O
of O
SASI B-MethodName
lies O
behind O
its O
ability O
to O
refrain O
from O
making O
misleading O
predictions O
over O
high O
- O
risk O
samples O
. O

On O
the O
other O
hand O
, O
we O
note O
that O
SASI B-MethodName
( O
85% O
) O
provides O
more O
utility O
, O
as O
it O
statistically O
outperforms O
SOTA O
models O
like O
SISMO B-MethodName
, O
while O
maintaining O
a O
fail O
- O
safe O
rejection O
score O
of O
83% O
and O
a O
competitive O
robustness O
score O
of O
61% O
. O

tors O
may O
be O
overburdened O
by O
having O
to O
review O
a O
lot O
of O
redundant O
samples O
. O

All O
examples O
in O
this O
paper O
have O
been O
paraphrased O
as O
per O
the O
moderate O
disguise O
scheme O
( O
Bruckman O
, O
2002 O
) O
to O
protect O
user O
privacy O
. O

We O
further O
demonstrate O
how O
SASI B-MethodName
sorts O
the O
users O
into O
priority O
levels O
. O

For O
each O
user O
, O
we O
show O
the O
real O
labels O
next O
to O
predicted O
labels O
, O
while O
also O
indicating O
whether O
SASI O
refrained O
from O
making O
that O
prediction O
. O

Real O
Pred O
AT O
IDRefrain O
... O
life O
f**s O
meaningless O
and O
h**d O
...... O
t***d O
to O
take O
my O
life O
once O
, O
but O
af***d O
... O
Figure O
4 O
: O
We O
show O
SASI O
can O
be O
used O
for O
efficient O
prioritization O
of O
users O
during O
suicide O
risk O
assessment O
. O

... O
t O
* O
* O
nerve O
I O
've O
never O
h*d O
to O
do O
.. O
. O

.... O
f**li*g O
y**'re O
not O
good O
en**gh O
...... O
t**gh O
as O
I O
c*n't O
af O
ford O
p**fe*s****l O
h*lp O
.. O
. O

... O
think O
ab**t O
your O
family O
and O
loved O
o**s O
... O
y O
* O
* O
will O
be O
a O
much O
stronger O
p***on O
Real O
Pred O
Refrain O
SU O
SU O
User O
B O
User O
A O
User O
C O
User O
D O
User O
E O
High O
PriorityModerate O
PriorityLow O
Priority O
... O
i O
've O
h O
* O
* O
a O
f O
* O
* O
unsuccessful O
tries O
. O

Real O
Pred O
Refrain O
AT O
IN O
... O
t**e O
a O
m***nt O
to O
reflect O
and O
think O
.. O
. O

... O
a*d O
I O
ju O
* O
* O
th**gh O
* O
, O
f**k O
it O
I O
'll O
do O
it O
today O
.. O
. O

... O
e**n O
I O
try O
to O
do O
it O
to O
myself O
on O
o**a**ion O
.. O
. O

Real O
Pred O
Refrain O
ID O
IN O
... O
an**n O
* O
can O
struggle O
t O
* O
f**d O
support O
.. O
. O

... O
I O
u**d O
to O
h*ve O
suicidal O
thoughts O
before O
.. O
. O

... O
the O
feeling O
is O
r**ly O
difficult O
to O
c**e O
with O
.. O
. O

Real O
Pred O
Refrain O
BR O
BR O
... O
I O
w*s O
depressed O
and O
suffering O
f O
* O
* O
* O
anxiety O
.. O
. O

For O
lower O
coverage O
values O
( O
say O
50% O
) O
, O
human O
modera-631 O
. O

We O
hence O
observe O
a O
trade O
- O
off O
, O
wherein O
we O
must O
seek O
to O
achieve O
competitive O
performance O
on O
thecovsamples O
, O
while O
at O
the O
same O
time O
not O
overburden O
moderators O
with O
the O
( O
1 cov)samples O
. O

However O
, O
we O
observe O
a O
decrease O
in O
Fail B-MetricName
- I-MetricName
Safe I-MetricName
Rejects I-MetricName
due O
to O
an O
increasingly O
cautious O
approach O
employed O
by O
the O
model O
, O
which O
implies O
an O
increased O
fraction O
of O
originally O
correct O
predictions O
that O
need O
to O
be O
manually O
reviewed O
. O

As O
shown O
in O
Figure O
3 O
, O
lower O
coverage O
leads O
to O
an O
increase O
in O
Graded B-MetricName
Recall I-MetricName
, O
Precision B-MetricName
, O
and O
FScore B-MetricName
( O
Table O
1 O
) O
, O
as O
the O
model O
only O
keeps O
covpredictions O
which O
it O
is O
highly O
certain O
about O
. O

4.2 O
Coverage O
and O
Performance O
Trade O
- O
off O
We O
further O
evaluate O
SASI B-MethodName
for O
various O
values O
of O
target O
coverage O
( O
cov O
) O
by O
calibrating O
the O
threshold O
. O

40 O
45 O
50 O
55 O
60 O
65 O
70 O
75 O
80 O
85 O
90 O
950:50:60:70:8 O
Data O
coverage O
( O
in% O
) O
Performance O
FScore O
Fail O
Safe O
Rejects O
Figure O
3 O
: O
Changes O
in O
performance O
metrics O
with O
increasing O
coverage O
, O
averaged O
over O
10 O
random O
seeds O
. O

SASI B-MethodName
significantly O
outperforms O
( O
p<0:005 O
) O
these O
methods O
for O
various O
values O
of O
coverage O
( O
cov O
) O
, O
demonstrating O
its O
ability O
to O
avoid O
committing O
to O
erroneous O
predictions O
by O
characterizing O
its O
confidence O
( O
Liu O
et O
al O
. O
, O
2019 O
) O
. O

SISMO B-MethodName
( O
Sawhney O
et O
al O
. O
, O
2021a O
) O
shows O
further O
improvements O
by O
modeling O
the O
ordinal O
nature O
of O
risk O
labels O
. O

( O
Cao O
et O
al O
. O
, O
2019 O
) O
and O
ContextBERT B-MethodName
( O
Matero O
et O
al O
. O
, O
2019 O
) O
generally O
outperform O
ContextualCNN B-MethodName
( O
Gaur O
et O
al O
. O
, O
2019 O
) O
, O
which O
uses O
a O
bag O
- O
of O
- O
posts O
approach O
. O

Bold O
denotes O
best O
performance O
while O
Italics O
denotes O
second O
best O
. O

* O
indicates O
the O
result O
is O
statistically O
significant O
with O
respect O
to O
SISMO B-MethodName
( O
p O
< O
0:005 O
) O
under O
Wilcoxons O
signed O
- O
rank O
test O
. O

Recall B-MetricName
FScore B-MetricName
RobustnessFail B-MetricName
- B-MetricName
Safe I-MetricName
Rejects I-MetricName
Contextual B-MethodName
CNN I-MethodName
0.65 B-MetricValue
0.52 B-MetricValue
0.59 B-MetricValue
- O
SDM B-MethodName
0.61 B-MetricValue
0.54 B-MetricValue
0.57 B-MetricValue
- O
ContextBERT B-MethodName
0.63 B-MetricValue
0.57 B-MetricValue
0.60 B-MetricValue
- O
SISMO B-MethodName
0.66 B-MetricValue
0.61 B-MetricValue
0.64 B-MetricValue
- O
SASI B-MethodName
( O
Cov O
100% O
) O
0.67 B-MetricValue
* O
0.62 B-MetricValue
0.66 B-MetricValue
* O
0.48 B-MetricValue
- O
SASI B-MethodName
( O
Cov O
85% O
) O
0.69 B-MetricValue
* O
0.65 B-MetricValue
* O
0.67 B-MetricValue
* O
0.61 B-MetricValue
0.83 B-MetricValue
SASI B-MethodName
( O
Cov O
50% O
) O
0.71 B-MetricValue
* O
0.69 B-MetricValue
* O
0.70 B-MetricValue
* O
0.73 B-MetricValue
0.65 B-MetricValue
Table O
1 O
: O
We O
report O
the O
median O
of O
results O
over O
10 O
random O
seeds O
. O

Gr O
. O

Prec O
. O

Sequential O
models O
like O
Suicide O
Detection O
Model O
( O
SDM)Model O
Gr O
. O

4 O
Results O
4.1 O
Performance O
Comparison O
We O
compare O
the O
performance O
of O
SASI B-MethodName
with O
various O
state O
- O
of O
- O
the O
- O
art O
baselines O
in O
Table O
1 O
. O

A O
higher O
Fail O
- O
Safe O
Rejects O
score O
hence O
implies O
that O
human O
moderators O
will O
be O
subjected O
to O
a O
lesser O
amounts O
of O
redundant O
work O
. O

Fail O
- O
Safe O
Rejects O
captures O
the O
fraction O
of O
refrained O
samples O
which O
were O
indeed O
erroneous O
. O

We O
additionally O
introduce O
two O
metrics O
, O
Robustness O
andFail O
- O
Safe O
Rejects O
, O
as O
: O
Robustness O
= O
Pcorr+refrain O
PT O
Fail O
- O
Safe O
Rejects O
= O
Pin O
Prefrain(5 O
) O
Robustness O
captures O
the O
fraction O
of O
samples O
which O
are O
correctly O
classified O
or O
instead O
sent O
for O
immediate O
review O
. O

FP O
is O
the O
ratio O
of O
the O
number O
of O
times O
the O
predicted O
risk O
( O
kp O
) O
is O
greater O
than O
the O
actual O
risk O
( O
ka O
) O
, O
given O
as O
: O
FN O
= O
PN O
i=1I(ka O
i O
> O
kp O
i O
) O
N O
FP O
= O
PN O
i=1I(kp O
i O
> O
ka O
i O
) O
N(4 O
) O
LetPTdenote O
the O
total O
number O
of O
test O
samples O
, O
Pcorr+refrain O
the O
sum O
of O
samples O
that O
have O
either O
been O
correctly O
predicted O
or O
have O
been O
refrained O
, O
Prefrain O
the O
total O
number O
of O
refrained O
samples O
, O
and O
Pinthe O
number O
of O
incorrect O
predictions O
among O
the O
refrained O
samples O
. O

FN O
is O
modified O
as O
the O
ratio O
of O
the O
number O
of O
times O
predicted O
severity O
of O
suicide O
risk O
level O
( O
kp O
) O
is O
less O
than O
the O
actual O
risk O
level O
( O
ka O
) O
overNnumber O
of O
samples O
. O

Following O
Gaur O
et O
al O
. O
( O
2019 O
) O
, O
we O
use O
graded O
variants O
of O
F1 B-MetricName
score I-MetricName
, O
Precision B-MetricName
, O
and O
Recall B-MetricName
, O
where O
we O
alter O
the O
formulation O
of O
False O
Negatives O
( O
FN O
) O
and O
False O
Positives O
( O
FP O
) O
. O

3.2 O
Evaluation O
Metrics O
We O
first O
describe O
the O
evaluation O
metrics O
that O
measure O
how O
well O
the O
model O
performs O
on O
the O
covsamples O
. O

The O
average O
number O
of O
tokens O
in O
each O
post O
is O
73.4 O
97.7 O
. O

On O
average O
, O
the O
number O
of O
posts O
made O
by O
a O
user O
is O
18.25 O
27.45 O
with O
a O
maximum O
of O
292 O
posts O
. O

The O
class O
distribution O
of O
each O
category O
with O
increasing O
risk O
level O
is O
: O
Supportive O
( O
20% O
) O
, O
Indicator O
( O
20% O
) O
, O
Ideation O
( O
34% O
) O
, O
Behaviour O
( O
15% O
) O
, O
Attempt O
( O
9% O
) O
. O

average O
pairwise O
agreement O
of O
0.79 O
and O
a O
groupwise O
agreement O
of O
0.73 O
. O

The O
posts O
were O
annotated O
by O
practicing O
psychiatrists O
into O
five O
increasing O
risk O
levels O
based O
on O
the O
Columbia O
Suicide O
Severity O
Risk O
Scale O
( O
Posner O
et O
al O
. O
, O
2011 O
) O
, O
leading O
to O
an O
acceptable630 O
. O

3 O
Experimental O
Setup O
3.1 O
Dataset O
We O
use O
the O
dataset O
released O
by O
Gaur O
et O
al O
. O
( O
2019 O
) O
, O
which O
contains O
Reddit O
posts O
of O
500 O
users O
filtered O
from O
an O
initial O
set O
of O
270,000 O
users O
across O
several O
mental O
health O
and O
suiciderelated O
subreddits O
, O
such O
as O
r O
/ O
StopSelfHarm O
( O
SSH O
) O
, O
r O
/ O
selfharm O
( O
SLF O
) O
, O
r O
/ O
bipolar O
( O
BPL O
) O
, O
r O
/ O
BipolarReddit O
( O
BPR O
) O
, O
r O
/ O
BipolarSOs O
, O
r O
/ O
opiates O
( O
OPT O
) O
, O
r O
/ O
Anxiety O
( O
ANX O
) O
, O
r O
/ O
addiction O
( O
ADD O
) O
, O
r O
/ O
BPD O
, O
r O
/ O
SuicideWatch O
( O
SW O
) O
, O
r O
/ O
schizophrenia O
( O
SCZ O
) O
, O
r O
/ O
autism O
( O
AUT O
) O
, O
r O
/ O
depression O
( O
DPR O
) O
, O
r O
/ O
cripplingalcoholism O
( O
CRP O
) O
, O
and O
r O
/ O
aspergers O
( O
ASP O
) O
. O

Since O
the O
loss O
function O
directly O
learns O
g O
, O
it O
does O
not O
depend O
on O
the O
coverage O
( O
Liu O
et O
al O
. O
, O
2019 O
) O
, O
and O
can O
be O
manually O
set O
to O
any O
value O
during O
evaluation O
. O

A O
higher O
value O
of O
rdiscourages O
restraint O
. O

The O
loss O
function O
is O
given O
as O
: O
L= jYjX O
jyjlog(^yjr+g O
) O
( O
3 O
) O
whereyjis O
the O
true O
label O
, O
and O
the B-HyperparameterName
reward I-HyperparameterName
ris O
a O
hyperparameter O
. O

Thus O
, O
the O
model O
learns O
a O
distribution O
of O
noisy O
/ O
uncertain O
data O
points O
characterized O
by O
the O
selection O
function O
g O
. O

Gamblers O
loss O
allows O
the O
gradients O
to O
propagate O
through O
ginstead O
, O
by O
abstaining O
from O
assigning O
weights O
to O
any O
of O
the O
mclasses O
. O

To O
account O
for O
the O
additional O
refrain O
option O
in O
the O
augmented O
label O
space O
, O
we O
train O
SASI B-MethodName
using O
Gamblers O
Loss O
( O
Liu O
et O
al O
. O
, O
2019 O
) O
. O

2.5 O
Network O
Optimization O
In O
anym O
- O
class O
classification O
problem O
, O
if O
the O
model O
assigns O
a O
high O
probability O
score O
to O
the O
wrong O
class O
, O
then O
learning O
becomes O
difficult O
due O
to O
vanishing O
gradients O
( O
Ziyin O
et O
al O
. O
, O
2020 O
) O
. O

The O
idea O
behind O
this O
approach O
is O
to O
trade O
- O
off O
( O
1 cov O
) O
samples O
for O
immediate O
review O
by O
mental O
health O
experts O
in O
exchange O
for O
higher O
model O
performance O
on O
thecovsamples O
about O
which O
it O
is O
confident O
. O

Specifically O
, O
we O
can O
choose O
some O
value O
such O
that O
there O
will O
be O
( O
1 cov)samples O
for O
which O
g O
. O

The O
covfraction O
of O
total O
samples O
is O
what O
SASI B-MethodName
predicts O
on O
, O
leaving O
out O
( O
1 cov O
) O
samples O
for O
which B-MethodName
SASI I-MethodName
is O
most O
uncertain O
. O

It O
is O
essential O
to O
note O
that O
the O
confidence O
threshold O
is O
not O
utilized O
during O
training O
, O
rather O
as O
athreshold O
variable O
to O
calibrate O
data O
coverage O
( O
cov O
) O
during O
evaluation O
. O

With O
the O
addition O
of O
the O
Refrain O
option O
, O
uncertain O
predictions O
will O
have O
highest O
priority O
, O
alleviating O
the O
possibility O
of O
high O
- O
risk O
users O
being O
neglected O
. O

As O
an O
example O
, O
moderators O
may O
choose O
to O
have O
only O
three O
levels O
of O
priority O
, O
where O
the O
user O
is O
high O
priority O
if O
p2{AT O
, O
BR O
, O
Refrain O
} O
, O
moderate O
if O
p2{ID O
, O
IN O
} O
and O
low O
if O
p2{SU O
} O
. O

Human O
moderators O
can O
then O
define O
the O
level O
of O
granularity O
of O
these O
predictions O
, O
and O
sort O
them O
into O
priority O
levels O
as O
desired O
. O

Letp= O
( O
f;g)(x O
) O
, O
wherep2Y[fRefraingdenote O
the O
final O
prediction O
by O
the O
model O
for O
a O
user O
ui O
. O

The O
augmented O
model O
is O
described O
as O
a O
piece O
- O
wise O
function O
, O
given O
by O
: O
( O
f;g)(x):= O
( O
Refrain O
; O
ifg O
argmax O
( O
^y);otherwise(2 O
) O
Where O
the O
threshold O
2(0;1 O
) O
, O
argmax O
( O
^y)2Y O
. O

As O
shown O
in O
Figure O
2 O
, O
the O
modelf O
: O
RTH!Yis O
augmented O
with O
a O
selection O
function O
g O
: O
RTH!(0;1 O
) O
, O
which O
is O
an O
extra O
logit O
. O

The O
final O
layer O
is O
a O
multilayer O
perceptron O
( O
MLP O
) O
to O
obtain O
the O
prediction O
vector O
^y O
, O
given O
as O
: O
^y O
= O
f(x);where O
f(x O
) O
= O
Softmax(MLP(Attention O
( O
x)))(1 O
) O
2.4 O
Self O
- O
Aware O
Mechanism O
To O
make O
the O
model O
self O
- O
aware O
, O
we O
transform O
the O
model O
such O
that O
it O
makes O
a O
prediction O
only O
when O
certain O
( O
Liu O
et O
al O
. O
, O
2019 O
) O
. O

To O
filter O
out O
relevant O
signals O
from O
the O
potentially O
vast O
user O
history O
( O
Shing O
et O
al O
. O
, O
2020 O
) O
, O
we O
pass O
the O
hidden O
state O
sequence O
through O
an O
attention O
layer O
. O

We O
thus O
obtain O
the O
sequence O
of O
hidden O
states O
, O
x= O
[ O
hi O
1;hi O
2;;hi O
T O
] O
, O
wherehi O
k2RH O
, O
andHis O
the O
hidden B-HyperparameterName
dimension I-HyperparameterName
. O

As O
shown O
in O
Figure O
2 O
, O
we O
then O
pass O
each O
post O
embedding O
sequentially O
through O
a O
bi O
- O
directional O
LSTM O
, O
given O
ashi O
k O
= O
Bi O
- O
LSTM(ei O
k O
) O
. O

To O
encode O
each O
postpi O
k O
, O
we O
use O
the O
768 B-HyperparameterValue
- O
dimensional O
representation O
of O
the O
[ O
CLS O
] O
token O
obtained O
from O
BERT B-MethodName
( O
Devlin O
et O
al O
. O
, O
2019 O
) O
as O
ei O
k O
= O
BERT(pi O
k O
) O
. O

To O
capture O
this O
property O
, O
we O
draw O
inspiration O
from O
existing O
state O
- O
of O
- O
the O
- O
art O
( O
SOTA O
) O
models O
( O
Gaur O
et O
al O
. O
, O
2019 O
; O
Matero O
et O
al O
. O
, O
2019 O
; O
Sawhney O
et O
al O
. O
, O
2021a O
; O
Ji O
et O
al O
. O
, O
2021a O
) O
which O
use O
LSTM O
based O
backbones O
. O

2.3 O
Suicide O
Ideation O
Model O
( O
SIM O
) O
Each O
post O
made O
by O
a O
user O
could O
provide O
detailed O
context O
of O
suicidal O
thought O
manifestation O
over O
time O
( O
Oliffe O
et O
al O
. O
, O
2012 O
) O
. O

For O
a O
given O
Suicide O
Ideation O
Model O
, O
our O
goal O
is O
to O
expand O
the O
cardinality O
of O
the O
label O
space O
tojYj+ O
1so O
as O
to O
enable O
an O
option O
to O
refrain O
when O
the O
model O
is O
uncertain.629 O
. O

We O
denote O
the O
label O
set O
Y= O
{ O
Support O
( O
SU O
) O
, O
Indicator O
( O
IN O
) O
, O
Ideation O
( O
ID O
) O
, O
Behaviour O
( O
BR O
) O
, O
Attempt O
( O
AT O
) O
} O
in O
increasing O
order O
of O
severity O
risk O
, O
defined O
based O
on O
the O
C O
- O
SSRS O
. O

2.2 O
Problem O
Formulation O
Following O
existing O
work O
( O
Gaur O
et O
al O
. O
, O
2019 O
; O
Sawhney O
et O
al O
. O
, O
2021a O
) O
, O
we O
formulate O
the O
problem O
as O
a O
classification O
task O
to O
predict O
the O
suicidal O
risk O
of O
the O
userui2fu1;u2;;uNg O
, O
whose O
posts O
Pi O
= O
fpi O
1;pi O
2;;pi O
Tgare O
authored O
over O
time O
in O
a O
chronological O
order O
, O
with O
the O
latest O
post O
being O
pi O
T O
. O

To O
address O
these O
factors O
, O
two O
additional O
classes O
were O
defined O
( O
Gaur O
et O
al O
. O
, O
2019 O
) O
to O
the O
existing O
C O
- O
SSRS O
scale O
with O
three O
classes O
: O
Suicide O
Indicator O
and O
Supportive O
( O
Negative O
class O
) O
. O

For O
instance O
, O
while O
in O
a O
clinical O
setting O
, O
it O
is O
typically O
suicidal O
candidates O
that O
see O
a O
clinician O
; O
on O
social O
media O
, O
non O
- O
suicidal O
users O
may O
participate O
to O
offer O
support O
to O
others O
deemed O
suicidal O
( O
Gaur O
et O
al O
. O
, O
2021 O
) O
. O

in O
clinical O
settings O
, O
adapting O
the O
same O
metric O
to O
a O
social O
media O
platform O
would O
require O
changes O
to O
address O
the O
varying O
nature O
of O
emotions O
expressed O
. O

It O
refrains O
from O
predicting O
when O
uncertain O
. O

Since O
the O
C O
- O
SSRS O
was O
originally O
designed O
for O
use O
SIMSelf O
- O
A O
ware O
Mechanism O
BERTBi O
- O
LSTM O
+ O
AttentionMLP+Softmax O
Gambler O
's O
Loss O
gSelection O
function O
True O
LabelFigure O
2 O
: O
An O
overview O
of O
SASI O
: O
SASI O
incorporates O
a O
risk O
- O
averse O
, O
self O
- O
aware O
mechanism O
to O
any O
given O
suicide O
ideation O
model O
( O
SIM O
) O
by O
training O
using O
Gamblers O
Loss O
. O

One O
of O
the O
challenges O
researchers O
face O
when O
it O
comes O
to O
dealing O
with O
social O
media O
content O
is O
the O
disparity O
in O
the O
level O
of O
emotions O
expressed O
( O
Gaur O
et O
al O
. O
, O
2019 O
) O
. O

Responses O
to O
the O
questions O
across O
the O
C O
- O
SSRS O
classes O
eventually O
determine O
the O
risk O
of O
suicidality O
of O
an O
individual O
( O
Interian O
et O
al O
. O
, O
2018 O
; O
McCall O
et O
al O
. O
, O
2021 O
) O
. O

Each O
C O
- O
SSRS O
severity O
class O
is O
composed O
of O
a O
conceptually O
organized O
set O
of O
questions O
that O
characterize O
the O
respective O
category O
. O

There O
are O
3 O
items O
in O
the O
scale O
: O
Suicide O
Ideation O
, O
Suicide O
Behavior O
, O
and O
Suicide O
Attempt O
. O

2 O
Methodology O
2.1 O
Columbia O
Suicide O
Severity O
Risk O
Scale O
The O
Columbia O
Suicide O
Severity O
Rating O
Scale O
( O
CSSRS B-MetricName
) O
is O
an O
authoritative O
questionnaire O
employed O
by O
psychiatrists O
to O
measure O
suicide O
risk O
severity O
( O
Posner O
et O
al O
. O
, O
2011 O
) O
. O

We O
further O
demonstrate O
its O
effectiveness O
through O
a O
qualitative O
study O
and O
discuss O
the O
ethical O
implications O
. O

Through O
a O
series O
of O
experiments O
, O
we O
show O
SASI B-MethodName
refrains O
from O
making O
83% O
of O
incorrect O
predictions O
. O

We O
demonstrate O
the O
effectiveness O
of O
SASI B-MethodName
using O
a O
real O
- O
world O
gold O
standard O
Reddit O
dataset O
. O

Through O
a O
human O
- O
in O
- O
the O
- O
loop O
framework O
that O
involves O
a O
domain O
expert O
, O
SASI B-MethodName
assigns O
high O
priority O
to O
uncertain O
predictions O
to O
avoid O
critical O
failure O
( O
Figure O
1 O
) O
. O

We O
show O
that O
SASI B-MethodName
can O
act O
as O
a O
tool O
to O
efficiently O
prioritize O
users O
who O
need O
immediate O
attention O
. O

Based O
on O
a O
set O
threshold O
value O
, O
SASI B-MethodName
refrains O
from O
making O
a O
prediction O
when O
it O
is O
uncertain O
. O

SASI B-MethodName
is O
risk O
- O
averse O
in O
the O
sense O
that O
it O
is O
self O
- O
aware O
, O
as O
it O
incorporates O
a O
selection O
function O
to O
measure O
uncertainty O
. O

Contributions O
: O
We O
reformulate O
suicide B-TaskName
risk I-TaskName
assessment I-TaskName
as O
a O
prioritized O
prediction O
task O
which O
factors O
in O
uncertainty O
, O
and O
propose O
SASI B-MethodName
: O
A O
Risk O
- O
Averse O
Mechanism O
for O
Suicidality O
Assessment O
on O
Social O
MedIa O
. O

We O
hence O
need O
systems O
that O
assign O
high O
priority O
to O
uncertain O
predictions O
, O
for O
immediate O
review O
and O
response O
. O

A O
resulting O
delayed O
response O
from O
mental O
health O
experts O
may O
lead O
to O
adverse O
consequences O
. O

Such O
a O
system O
may O
associate O
a O
lower O
risk O
level O
to O
a O
user O
who O
needs O
urgent O
help O
. O

This O
poses O
a O
challenge O
when O
working O
with O
critical O
tasks O
like O
suicide B-TaskName
risk I-TaskName
assessment I-TaskName
, O
for O
which O
it O
may O
be O
hard O
to O
make O
a O
prediction O
due O
to O
various O
reasons O
such O
as O
task O
hardness O
or O
contained O
ambiguity O
. O

Despite O
the O
significant O
power O
of O
traditional O
NLP O
methods O
, O
such O
models O
are O
inherently O
designed O
to O
make O
a O
prediction O
even O
when O
not O
confident O
. O

One O
such O
case O
was O
covered O
by O
Register O
( O
2020 O
) O
, O
wherein O
a O
medical O
bot O
suggested O
a O
mock O
patient O
kill O
themselves O
, O
demonstrating O
that O
unintended O
harmful O
behavior O
can O
emerge O
from O
AI O
systems O
( O
Amodei O
et O
al O
. O
, O
2016 O
; O
Chandler O
et O
al O
. O
, O
2020).628 O
. O

However O
, O
mental O
health O
is O
a O
safety O
- O
critical O
realm O
, O
where O
technological O
failure O
could O
lead O
to O
severe O
harm O
to O
users O
on O
social O
media O
( O
Sittig O
and O
Singh O
, O
2015 O
) O
. O

Numerous O
deep O
learning O
methods O
already O
exist O
, O
which O
include O
leveraging O
suiciderelated O
word O
- O
embeddings O
( O
Cao O
et O
al O
. O
, O
2019 O
) O
, O
social O
graphs O
( O
Mishra O
et O
al O
. O
, O
2019 O
; O
Sinha O
et O
al O
. O
, O
2019 O
; O
Cao O
et O
al O
. O
, O
2022 O
; O
Sawhney O
et O
al O
. O
, O
2021b O
) O
and O
historical O
context O
( O
Matero O
et O
al O
. O
, O
2019 O
; O
Gaur O
et O
al O
. O
, O
2019 O
) O
. O

Choudhury O
et O
al O
. O
, O
2016 O
) O
, O
with O
automatic O
risk O
assessment O
algorithms O
outperforming O
traditional O
clinical O
methods O
( O
Coppersmith O
et O
al O
. O
, O
2018 O
; O
Linthicum O
et O
al O
. O
, O
2019 O
) O
. O

SASI B-MethodName
assigns O
high O
priority O
to O
uncertain O
predictions O
, O
for O
an O
immediate O
review O
by O
mental O
health O
experts O
. O

With O
a O
human O
- O
in O
- O
the O
- O
loop O
framework O
, O
these O
predictions O
can O
be O
sorted O
into O
various O
risk O
levels O
. O

When O
SASI B-MethodName
assesses O
the O
posts O
, O
it O
returns O
the O
predicted O
risk O
level O
along O
with O
a O
certainty O
score O
. O

The O
advent O
of O
Natural O
Language O
Processing O
( O
NLP O
) O
shows O
promise O
for O
suicide O
risk O
assessment O
based O
on O
online O
user O
behavior O
( O
Ji O
et O
al O
. O
, O
2021b O
; O
Authors O
contributed O
equally O
Model O
( O
SIM O
) O
High O
PriorityRisk O
UncertainHigh O
Low O
PriorityLow O
Moderate O
PriorityPredict O
Moderate O
Mental O
Health O
ExpertsPostsUser O
Human O
- O
in O
- O
the O
- O
loopFigure O
1 O
: O
End O
- O
to O
- O
end O
pipeline O
for O
suicide O
risk O
assessment O
. O

However O
, O
studies O
show O
eight O
out O
of O
ten O
people O
shared O
suicidal O
thoughts O
on O
social O
media O
( O
Golden O
et O
al O
. O
, O
2009 O
) O
. O

While O
80% O
of O
patients O
do O
not O
undergo O
clinical O
treatment O
, O
60% O
of O
those O
who O
succumbed O
to O
suicide O
denied O
having O
suicidal O
thoughts O
to O
mental O
health O
experts O
( O
McHugh O
et O
al O
. O
, O
2019 O
) O
. O

It O
hence O
becomes O
critical O
to O
extend O
clinical O
and O
psychiatric O
care O
, O
which O
relies O
heavily O
on O
identifying O
those O
at O
risk O
. O

While O
it O
is O
the O
leading O
cause O
of O
death O
among O
14 O
- O
35 O
year O
olds O
in O
the O
US O
( O
Hedegaard O
et O
al O
. O
, O
2021 O
) O
, O
suicide O
rates O
have O
increased O
by O
13% O
in O
Japan O
between O
July O
to O
September O
2020 O
( O
Tanaka O
and O
Okamoto O
, O
2021 O
) O
. O

1 O
Introduction O
Suicide O
is O
a O
global O
phenomenon O
responsible O
for O
1.3% O
of O
deaths O
worldwide O
( O
WHO O
, O
2019 O
) O
. O

Furthermore O
, O
we O
discuss O
the O
qualitative O
, O
practical O
, O
and O
ethical O
aspects O
of O
SASI B-MethodName
for O
suicide O
risk O
assessment O
as O
a O
human O
- O
in O
- O
the O
- O
loop O
framework O
. O

We O
show O
that O
SASI B-MethodName
is O
able O
to O
refrain O
from O
83% O
of O
incorrect O
predictions O
on O
real O
- O
world O
Reddit O
data O
. O

We O
propose O
SASI B-MethodName
, O
a O
risk O
- O
averse O
and O
self O
- O
aware O
transformer O
- O
based O
hierarchical O
attention O
classifier O
, O
augmented O
to O
refrain O
from O
making O
uncertain O
predictions O
. O

We O
hence O
reformulate O
suicide O
risk O
assessment O
as O
a O
selective O
prioritized O
prediction O
problem O
over O
the O
Columbia O
Suicide O
Severity O
Risk O
Scale O
( O
C O
- O
SSRS O
) O
. O

However O
, O
such O
systems O
may O
generate O
uncertain O
predictions O
, O
leading O
to O
severe O
consequences O
. O

With O
advances O
in O
Natural O
Language O
Processing O
strategies O
, O
it O
is O
now O
possible O
to O
design O
automated O
systems O
to O
assess O
suicide O
risk O
. O

Proceedings O
of O
the O
60th O
Annual O
Meeting O
of O
the O
Association O
for O
Computational O
Linguistics O
Volume O
2 O
: O
Short O
Papers O
, O
pages O
628 O
- O
635 O
May O
22 O
- O
27 O
, O
2022 O
c O
2022 O
Association O
for O
Computational O
Linguistics O
A O
Risk O
- O
Averse O
Mechanism O
for O
Suicidality O
Assessment O
on O
Social O
Media O
Ramit O
Sawhney1 O
, O
Atula O
Tejaswi O
Neerkaje2 O
, O
Manas O
Gaur1 O
1AI O
Institute O
, O
University O
of O
South O
Carolina O
, O
SC O
, O
USA O
mgaur@email.sc.edu O
2Manipal O
Institute O
of O
Technology O
, O
Manipal O
, O
India O
atula.neerkaje@learner.manipal.edu O
Abstract O
Recent O
studies O
have O
shown O
that O
social O
media O
has O
increasingly O
become O
a O
platform O
for O
users O
to O
express O
suicidal O
thoughts O
outside O
traditional O
clinical O
settings O
. O

We O
used O
Riemannian O
Adam O
( O
Bcigneul O
and O
Ganea O
, O
2018 O
) O
as O
our O
optimizer.627 O
. O

We O
grid O
searched O
our O
learning B-HyperparameterName
rates I-HyperparameterName
in2(1e 5;5e 4;1e 3 B-HyperparameterValue
) O
. O

We O
explored O
the O
lookback B-HyperparameterName
window I-HyperparameterName
length I-HyperparameterName
T2[2;20]and O
the O
hidden B-HyperparameterName
state I-HyperparameterName
dimensions I-HyperparameterName
in O
2(64;128;256 B-HyperparameterValue
) O
. O

We O
followed O
the O
same O
preprocessing O
techniques O
as O
suggested O
by O
the O
dataset O
authors O
. O

We O
performed O
a O
grid O
search O
for O
all O
our O
models O
and O
selected O
the O
best O
values O
based O
on O
the O
validation O
MCC B-MetricName
/ O
MSE B-MetricName
. O

A.4 O
Training O
Setup O
We O
have O
performed O
all O
our O
experiments O
on O
Tesla O
GPU O
. O

HT B-MethodName
- I-MethodName
LSTM I-MethodName
: O
Hierarchical O
Time O
- O
aware O
hyperbolic O
LSTM O
network O
leverages O
the O
hyperbolic O
space O
for O
encoding O
scale O
- O
free O
nature O
of O
a O
text O
stream O
( O
Sawhney O
et O
al O
. O
, O
2021a O
) O
. O

FAST B-MethodName
: O
A O
time O
- O
aware O
LSTM O
network O
capable O
of O
modeling O
the O
fine O
grained O
temporal O
irregularities O
in O
textual O
data O
( O
Sawhney O
et O
al O
. O
, O
2021e O
) O
. O

HAN B-MethodName
: O
Transformer O
model O
with O
hyperbolic O
activations O
and O
attention O
which O
utilises O
hyperbolic O
geometry O
for O
both O
computation O
and O
aggregation O
of O
attention O
weights O
( O
Gulcehre O
et O
al O
. O
, O
2019).H O
- O
LSTM O
: O
A O
RNN O
based O
model O
for O
sequential O
data O
with O
an O
attention O
mechanism O
operating O
in O
the O
hyperbolic O
space O
( O
Lpez O
and O
Strube O
, O
2020 O
) O
. O

LSTM B-MethodName
: O
An O
RNN O
architecture O
capable O
of O
learning O
long O
term O
sequential O
dependencies O
( O
Hochreiter O
and O
Schmidhuber O
, O
1997 O
) O
. O

A.3 O
Baseline O
Models O
We O
compare O
HYPHEN B-MethodName
with O
the O
following O
baselines O
: O
MLP B-MethodName
: O
A O
Bag O
of O
Words O
model O
that O
uses O
unigram O
textual O
features O
as O
input O
along O
with O
the O
TF O
- O
IDF O
vectors O
which O
are O
fed O
into O
a O
multi O
- O
layer O
perceptron O
( O
Abercrombie O
and O
Batista O
- O
Navarro O
, O
2020 O
) O
. O

Mean B-MetricName
squared I-MetricName
error I-MetricName
: O
To O
evaluate O
the O
volatility O
regression O
performance O
, O
we O
adopt O
the O
Mean B-MetricName
Squared I-MetricName
Error I-MetricName
( I-MetricName
MSE I-MetricName
) I-MetricName
to O
compute O
the O
error O
between O
actual O
and O
the O
predicted O
volatility O
values O
. O

We O
use O
MCC B-MetricName
to O
evaluate O
on O
suicide B-TaskName
ideation I-TaskName
detection I-TaskName
and O
political B-TaskName
speech I-TaskName
classification I-TaskName
. O

A.2 O
Evaluation O
Metrics O
Matthews O
correlation O
coefficient O
: O
The O
Matthews B-MetricName
correlation I-MetricName
coefficient I-MetricName
( I-MetricName
MCC I-MetricName
) I-MetricName
produces O
a O
high O
score O
only O
if O
the O
prediction O
obtained O
good O
results O
in O
all O
of O
the O
four O
confusion O
matrix O
categories O
( O
true O
positives O
, O
false O
negatives O
, O
true O
negatives O
, O
and O
false O
positives O
) O
, O
proportionally O
both O
to O
the O
size O
of O
positive O
elements O
and O
the O
size O
of O
negative O
elements O
in O
the O
dataset O
. O

( O
Sawhney O
et O
al O
. O
, O
2021d O
) O
: O
The O
Suicide B-TaskName
ideation I-TaskName
dataset O
is O
built O
upon O
the O
existing O
Twitter O
tweets O
database O
of O
( O
Mishra O
et O
al O
. O
, O
2019 O
) O
. O

Suicide B-TaskName
Ideation I-TaskName
. O

We O
split O
the O
dataset O
temporally O
to O
obtain O
70% B-HyperparameterValue
, O
15% B-HyperparameterValue
and O
15% B-HyperparameterValue
of O
the O
data O
for O
training O
, O
validation O
and O
testing O
respectively O
. O

The O
average O
number O
of O
tokens O
in O
a O
ParlV B-DatasetName
ote I-DatasetName
speech O
is O
760.2 O
901.3 O
. O

ParlV B-DatasetName
ote I-DatasetName
consists O
of O
33,461 O
transcripts O
from O
May O
7th1997 O
to O
November O
5th2019 O
. O

This O
record O
consists O
of O
debate O
transcripts O
from O
the O
UK O
House O
of O
Commons O
obtained O
under O
an O
open O
Parliament O
license O
. O

ParlVote B-DatasetName
( O
Abercrombie O
and O
Batista O
- O
Navarro O
, O
2020 O
): O
Following O
( O
Sawhney O
et O
al O
. O
, O
2020 O
) O
we O
evaluate O
political B-TaskName
stance I-TaskName
detection I-TaskName
on O
the O
ParlV B-DatasetName
ote I-DatasetName
dataset O
. O

We O
split O
the O
China B-DatasetName
& I-DatasetName
HK I-DatasetName
dataset O
temporally O
based O
on O
date O
ranges O
from O
01/01/2015 O
to O
31/08/2015 O
for O
training O
, O
01/09/2015 O
to O
30/09/2015 O
for O
validation O
, O
and O
01/10/2015 O
to O
01/01/2016 O
for O
testing O
all O
models O
. O

China O
and O
Hong O
Kong O
( O
CSE O
) O
( O
Huang O
et O
al O
. O
, O
2018 O
): O
China B-DatasetName
and I-DatasetName
Hong I-DatasetName
Kong I-DatasetName
( I-DatasetName
CSE I-DatasetName
) I-DatasetName
dataset O
consists O
of O
news O
headlines O
of O
85 O
top O
- O
traded O
stocks O
listed O
on O
the O
Shanghai O
, O
Shenzhen O
, O
and O
Hong O
Kong O
Stock O
Exchange O
from O
January O
2015 O
to O
December O
2015 O
. O

Following O
( O
Xu O
and O
Cohen O
, O
2018 O
) O
we O
split O
the O
US B-DatasetName
S&P I-DatasetName
temporally O
based O
on O
date O
ranges O
from O
01/01/2014 O
to O
01/08/2015 O
for O
training O
, O
01/08/2015 O
to O
01/10/2015 O
for O
validation O
, O
and O
01/10/2015 O
to O
01/01/2016 O
for O
test O
. O

These O
tweets O
were O
then O
manually O
annotated O
by O
two O
psychologists O
under O
the O
supervision O
of O
a O
head O
psychologist O
and O
3984 O
tweets O
were O
actually O
identified O
as O
having O
suicidal O
tendencies O
. O

Out O
of O
all O
the O
tweets O
, O
34,306 O
tweets O
were O
identified O
as O
having O
potential O
suicide O
ideation O
words O
. O

The O
dataset O
consists O
of O
tweets O
of O
32,558 O
unique O
users O
, O
spanning O
over O
ten O
years O
of O
historical O
tweets O
from O
2009 O
to O
2019 O
. O

of O
53.57% O
Aye O
and O
46.43% O
No O
labels O
. O

The O
dataset O
is O
fairly O
balanced O
, O
consisting626 O
. O

Based O
on O
a O
speakers O
vote O
to O
their O
speech O
, O
transcripts O
are O
labeled O
as O
Aye O
and O
No O
representing O
positive O
and O
negative O
stance O
respectively O
. O

Following O
( O
Abercrombie O
and O
Batista O
- O
Navarro O
, O
2020 O
) O
we O
remove O
non O
- O
speech O
elements O
from O
the O
transcripts O
and O
the O
original O
casing O
is O
preserved O
. O

The O
qualitative O
data O
comprises O
of O
90,361 O
Chinese O
financial O
news O
headlines O
. O

The O
text O
data O
comprises O
tweets O
from O
01/01/2014 O
to O
01/01/2016 O
. O

US O
S&P O
dataset O
contains O
text O
data O
and O
historical O
prices O
of O
88 O
stocks O
which O
includes O
all O
8 O
stocks O
in O
conglomerates O
and O
the O
top O
10 O
stocks O
by O
market O
capitalization O
in O
each O
of O
the O
other O
industries O
. O

A O
Experimental O
Setup O
A.1 O
Datasets O
US O
S&P O
( O
Xu O
and O
Cohen O
, O
2018 O
): O
US O
S&P O
stocks O
are O
categorized O
into O
9 O
industries O
: O
basic O
materials O
, O
consumer O
goods O
, O
healthcare O
, O
services O
, O
utilities O
, O
conglomerates O
, O
financial O
, O
industrial O
goods O
and O
technology O
. O

PMLR O
. O

In O
International O
Conference O
on O
Machine O
Learning O
, O
pages O
1169211702 O
. O

Transformer O
hawkes O
process O
. O

2020 O
. O

Fluctuation O
and O
Noise O
Letters O
.Simiao O
Zuo O
, O
Haoming O
Jiang O
, O
Zichong O
Li O
, O
Tuo O
Zhao O
, O
and O
Hongyuan O
Zha O
. O

Power O
law O
and O
stretched O
exponential O
effects O
of O
extreme O
events O
in O
chinese O
stock O
markets O
. O

2010 O
. O

Xiaojun O
Zhao O
, O
Pengjian O
Shang O
, O
and O
Yulei O
Pang O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
56th O
Annual O
Meeting O
of O
the O
Association O
for O
Computational O
Linguistics O
( O
Volume O
1 O
: O
Long O
Papers O
) O
, O
pages O
19701979 O
, O
Melbourne O
, O
Australia O
. O

Stock O
movement O
prediction O
from O
tweets O
and O
historical O
prices O
. O

2018 O
. O

Cohen O
. O

Yumo O
Xu O
and O
Shay O
B O
. O

Longman O
London O
. O

Text O
and O
context O
: O
Explorations O
in O
the O
semantics O
and O
pragmatics O
of O
discourse O
. O

1977 O
. O

Teun O
Adrianus O
Van O
Dijk O
. O

Politics O
as O
text O
and O
talk O
: O
Analytic O
approaches O
to O
political O
discourse O
, O
203:203237 O
. O

Political O
discourse O
and O
political O
cognition O
. O

2002 O
. O

Teun O
A O
Van O
Dijk O
. O

World O
Scientific O
. O

Analytic O
hyperbolic O
geometry O
: O
Mathematical O
foundations O
and O
applications O
. O

2005 O
. O

Abraham O
A O
Ungar O
. O

In O
International O
Conference O
on O
Learning O
Representations O
. O

Poincare O
glove O
: O
Hyperbolic O
word O
embeddings O
. O

2019 O
. O

Alexandru O
Tifrea O
, O
Gary O
Becigneul O
, O
and O
OctavianEugen O
Ganea O
. O

In O
International O
Conference O
on O
Learning O
Representations O
. O

Hyperbolic O
neural O
networks++ O
. O

2021 O
. O

Ryohei O
Shimizu O
, O
YUSUKE O
Mukuta O
, O
and O
Tatsuya O
Harada O
. O

Journal O
of O
Banking O
and O
Finance O
, O
38:89 O
105 O
. O

Speed O
, O
algorithmic O
trading O
, O
and O
market O
quality O
around O
macroeconomic O
news O
announcements O
. O

2014 O
. O

Martin O
Scholtus O
, O
Dick O
van O
Dijk O
, O
and O
Bart O
Frijns O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
16th O
Conference O
of O
the O
European O
Chapter O
of O
the O
Association O
for O
Computational O
Linguistics O
: O
Main O
Volume O
, O
pages O
21642175 O
, O
Online O
. O

FAST O
: O
Financial O
news O
and O
tweet O
based O
time O
aware O
network O
for O
stock O
trading O
. O

2021e O
. O

Ramit O
Sawhney O
, O
Arnav O
Wadhwa O
, O
Shivam O
Agarwal O
, O
and O
Rajiv O
Ratn O
Shah O
. O

International O
Committee O
on O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
28th O
International O
Conference O
on O
Computational O
Linguistics O
, O
pages O
48474859 O
, O
Barcelona O
, O
Spain O
( O
Online O
) O
. O

GPolS O
: O
A O
contextual O
graph O
- O
based O
language O
model O
for O
analyzing O
parliamentary O
debates O
and O
political O
cohesion O
. O

2020 O
. O

Ramit O
Sawhney O
, O
Arnav O
Wadhwa O
, O
Shivam O
Agarwal O
, O
and O
Rajiv O
Ratn O
Shah O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
2021 O
Conference O
of O
the O
North O
American O
Chapter O
of O
the O
Association O
for O
Computational O
Linguistics O
: O
Human O
Language O
Technologies O
, O
pages O
21762190 O
, O
Online O
. O

Suicide O
ideation O
detection O
via O
social O
and O
temporal O
user O
representations O
using O
hyperbolic O
learning O
. O

2021d O
. O

Ramit O
Sawhney O
, O
Harshit O
Joshi O
, O
Rajiv O
Ratn O
Shah O
, O
and O
Lucie O
Flek O
. O

Main O
Track.625 O
. O

International O
Joint O
Conferences O
on O
Artificial O
Intelligence O
Organization O
. O

In O
Proceedings O
of O
the O
Thirtieth O
International O
Joint O
Conference O
on O
Artificial O
Intelligence O
, O
IJCAI21 O
, O
pages O
35523558 O
. O

Tec O
: O
A O
time O
evolving O
contextual O
graph O
model O
for O
speaker O
state O
analysis O
in O
political O
debates O
. O

2021c O
. O

Ramit O
Sawhney O
, O
Shivam O
Agarwal O
, O
Arnav O
Wadhwa O
, O
and O
Rajiv O
Shah O
. O

Proceedings O
of O
the O
AAAI O
Conference O
on O
Artificial O
Intelligence O
, O
35(1):497504 O
. O

Stock O
selection O
via O
spatiotemporal O
hypergraph O
attention O
network O
: O
A O
learning O
to O
rank O
approach O
. O

2021b O
. O

Ramit O
Sawhney O
, O
Shivam O
Agarwal O
, O
Arnav O
Wadhwa O
, O
Tyler O
Derr O
, O
and O
Rajiv O
Ratn O
Shah O
. O

Association O
for O
Computing O
Machinery O
, O
New O
York O
, O
NY O
, O
USA O
. O

Hyperbolic O
Online O
Time O
Stream O
Modeling O
, O
page O
16821686 O
. O

2021a O
. O

Ramit O
Sawhney O
, O
Shivam O
Agarwal O
, O
Megh O
Thakkar O
, O
Arnav O
Wadhwa O
, O
and O
Rajiv O
Ratn O
Shah O
. O

PMLR O
. O

In O
Proceedings O
of O
the O
35th O
International O
Conference O
on O
Machine O
Learning O
, O
ICML O
2018 O
, O
Stockholmsmssan O
, O
Stockholm O
, O
Sweden O
, O
July O
10 O
- O
15 O
, O
2018 O
, O
volume O
80 O
of O
Proceedings O
of O
Machine O
Learning O
Research O
, O
pages O
44574466 O
. O

Representation O
tradeoffs O
for O
hyperbolic O
embeddings O
. O

2018 O
. O

Frederic O
Sala O
, O
Christopher O
De O
Sa O
, O
Albert O
Gu O
, O
and O
Christopher O
R O
. O

Expert O
Systems O
with O
Applications O
, O
73:125144 O
. O

The O
impact O
of O
microblogging O
data O
for O
stock O
market O
prediction O
: O
Using O
twitter O
to O
predict O
returns O
, O
volatility O
, O
trading O
volume O
and O
survey O
sentiment O
indices O
. O

2017 O
. O

Nuno O
Oliveira O
, O
Paulo O
Cortez O
, O
and O
Nelson O
Areal O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
2019 O
Conference O
of O
the O
North O
American O
Chapter O
of O
the O
Association O
for O
Computational O
Linguistics O
: O
Student O
Research O
Workshop O
, O
pages O
147156 O
, O
Minneapolis O
, O
Minnesota O
. O

SNAP O
- O
BATNET O
: O
Cascading O
author O
profiling O
and O
social O
network O
graphs O
for O
suicide O
ideation O
detection O
on O
social O
media O
. O

2019 O
. O

Rohan O
Mishra O
, O
Pradyumn O
Prakhar O
Sinha O
, O
Ramit O
Sawhney O
, O
Debanjan O
Mahata O
, O
Puneet O
Mathur O
, O
and O
Rajiv O
Ratn O
Shah O
. O

The O
neural O
hawkes O
process O
: O
A O
neurally O
self O
- O
modulating O
multivariate O
point O
process O
. O

2017 O
. O

Hongyuan O
Mei O
and O
Jason O
Eisner O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
2015 O
Conference O
on O
Empirical O
Methods O
in O
Natural O
Language O
Processing O
, O
pages O
14121421 O
, O
Lisbon O
, O
Portugal O
. O

Effective O
approaches O
to O
attention O
- O
based O
neural O
machine O
translation O
. O

2015 O
. O

Manning O
. O

Thang O
Luong O
, O
Hieu O
Pham O
, O
and O
Christopher O
D O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Findings O
of O
the O
Association O
for O
Computational O
Linguistics O
: O
EMNLP O
2020 O
, O
pages O
460475 O
, O
Online O
. O

A O
fully O
hyperbolic O
neural O
model O
for O
hierarchical O
multi O
- O
class O
classification O
. O

2020 O
. O

Accessed O
: O
2021 O
- O
09 O
- O
15.Federico O
Lpez O
and O
Michael O
Strube O
. O

https://time.com/5607429/ O
most O
- O
important O
- O
debates/ O
. O

The O
most O
important O
presidential O
debates O
in O
american O
history O
, O
according O
to O
historians O
. O

2019 O
. O

Tara O
Law O
. O

In O
Proceedings O
of O
the O
26th O
ACM O
conference O
on O
Hypertext O
& O
Social O
Media O
, O
pages O
8594 O
. O

Detecting O
changes O
in O
suicide O
content O
manifested O
in O
social O
media O
following O
celebrity O
suicides O
. O

2015 O
. O

Mrinal O
Kumar O
, O
Mark O
Dredze O
, O
Glen O
Coppersmith O
, O
and O
Munmun O
De O
Choudhury O
. O

In O
The O
IEEE O
/ O
CVF O
Conference O
on O
Computer O
Vision O
and O
Pattern O
Recognition O
( O
CVPR O
) O
. O

Hyperbolic O
image O
embeddings O
. O

2020 O
. O

Valentin O
Khrulkov O
, O
Leyla O
Mirvakhabova O
, O
Evgeniya O
Ustinova O
, O
Ivan O
Oseledets O
, O
and O
Victor O
Lempitsky O
. O

A O
tensor O
- O
based O
sub O
- O
mode O
coordinate O
algorithm O
for O
stock O
prediction O
. O

2018 O
. O

Jieyun O
Huang O
, O
Yunjia O
Zhang O
, O
Jialai O
Zhang O
, O
and O
Xi O
Zhang O
. O

Association O
for O
Computing O
Machinery O
. O

In O
Proceedings O
of O
the O
Eleventh O
ACM O
International O
Conference O
on O
Web O
Search O
and O
Data O
Mining O
, O
WSDM O
18 O
, O
page O
261269 O
, O
New O
York O
, O
NY O
, O
USA O
. O

Listening O
to O
chaotic O
whispers O
: O
A O
deep O
learning O
framework O
for O
news O
- O
oriented O
stock O
trend O
prediction O
. O

2018 O
. O

Ziniu O
Hu O
, O
Weiqing O
Liu O
, O
Jiang O
Bian O
, O
Xuanzhe O
Liu O
, O
and O
Tie O
- O
Yan O
Liu O
. O

, O
9(8):17351780 O
. O

Neural O
Comput O
. O

Long O
short O
- O
term O
memory O
. O

1997 O
. O

Sepp O
Hochreiter O
and O
Jrgen O
Schmidhuber O
. O

In O
International O
Conference O
on O
Learning O
Representations O
. O

Hyperbolic O
attention O
networks O
. O

2019 O
. O

Caglar O
Gulcehre O
, O
Misha O
Denil O
, O
Mateusz O
Malinowski O
, O
Ali O
Razavi O
, O
Razvan O
Pascanu O
, O
Karl O
Moritz O
Hermann O
, O
Peter O
Battaglia O
, O
Victor O
Bapst O
, O
David O
Raposo O
, O
Adam O
Santoro O
, O
and O
Nando O
de O
Freitas O
. O

In O
International O
Conference O
on O
Learning O
Representations O
. O

Learning O
mixed O
- O
curvature O
representations O
in O
product O
spaces O
. O

2019 O
. O

Albert O
Gu O
, O
Frederic O
Sala O
, O
Beliz O
Gunel O
, O
and O
Christopher O
R O
. O

In O
NeurIPS O
, O
pages O
53505360 O
. O

Hyperbolic O
neural O
networks O
. O

2018 O
. O

Octavian O
- O
Eugen O
Ganea O
, O
Gary O
Bcigneul O
, O
and O
Thomas O
Hofmann O
. O

Journal O
of O
Economic O
Perspectives O
, O
30(1):185206 O
. O

Power O
laws O
in O
economics O
: O
An O
introduction O
. O

2016 O
. O

Xavier O
Gabaix O
. O

The O
Journal O
of O
Finance O
, O
71(1):335382 O
. O

News O
trading O
and O
speed O
. O

2016 O
. O

Thierry O
Foucault O
, O
Johan O
Hombert O
, O
and O
Ioanid O
Ro O
su O
. O

Social O
Media+ O
Society O
, O
4(1):2056305118763366 O
. O

participant O
perceptions O
of O
twitter O
research O
ethics O
. O

2018 O
. O

Casey O
Fiesler O
and O
Nicholas O
Proferes O
. O

Transaction O
publishers O
. O

The O
psychology O
of O
politics O
, O
volume O
2 O
. O

1968 O
. O

Hans O
J O
Eysenck O
. O

Association O
for O
Computational O
Linguistics.624 O
. O

In O
Proceedings O
of O
the O
2019 O
Conference O
of O
the O
North O
American O
Chapter O
of O
the O
Association O
for O
Computational O
Linguistics O
: O
Human O
Language O
Technologies O
, O
Volume O
1 O
( O
Long O
and O
Short O
Papers O
) O
, O
pages O
41714186 O
, O
Minneapolis O
, O
Minnesota O
. O

BERT O
: O
Pre O
- O
training O
of O
deep O
bidirectional O
transformers O
for O
language O
understanding O
. O

2019 O
. O

Jacob O
Devlin O
, O
Ming O
- O
Wei O
Chang O
, O
Kenton O
Lee O
, O
and O
Kristina O
Toutanova O
. O

In O
Proceedings O
of O
the O
2016 O
CHI O
conference O
on O
human O
factors O
in O
computing O
systems O
. O

Discovering O
shifts O
to O
suicidal O
ideation O
from O
mental O
health O
content O
in O
social O
media O
. O

2016 O
. O

Munmun O
De O
Choudhury O
, O
Emre O
Kiciman O
, O
Mark O
Dredze O
, O
Glen O
Coppersmith O
, O
and O
Mrinal O
Kumar O
. O

Computer O
Speech O
& O
Language O
, O
52:23 O
40 O
. O

Perception O
and O
prediction O
of O
speaker O
appeal O
a O
single O
speaker O
study O
. O

2018 O
. O

Ailbhe O
Cullen O
, O
Andrew O
Hines O
, O
and O
Naomi O
Harte O
. O

InProceedings O
of O
the O
19th O
ACM O
Conference O
on O
Computer O
- O
Supported O
Cooperative O
Work O
& O
Social O
Computing O
. O

Quantifying O
and O
predicting O
mental O
illness O
severity O
in O
online O
pro O
- O
eating O
disorder O
communities O
. O

2016 O
. O

Stevie O
Chancellor O
, O
Zhiyuan O
Lin O
, O
Erica O
L O
Goodman O
, O
Stephanie O
Zerwas O
, O
and O
Munmun O
De O
Choudhury O
. O

In O
Proceedings O
of O
the O
conference O
on O
fairness O
, O
accountability O
, O
and O
transparency O
. O

A O
taxonomy O
of O
ethical O
tensions O
in O
inferring O
mental O
health O
states O
from O
social O
media O
. O

2019 O
. O

Stevie O
Chancellor O
, O
Michael O
L O
Birnbaum O
, O
Eric O
D O
Caine O
, O
Vincent O
MB O
Silenzio O
, O
and O
Munmun O
De O
Choudhury O
. O

Ethics O
and O
Information O
Technology O
, O
4(3 O
) O
. O

Studying O
the O
amateur O
artist O
: O
A O
perspective O
on O
disguising O
data O
collected O
in O
human O
subjects O
research O
on O
the O
internet O
. O

2002 O
. O

Amy O
Bruckman O
. O

CoRR O
, O
abs/1810.00760 O
. O

Riemannian O
adaptive O
optimization O
methods O
. O

2018 O
. O

Gary O
Bcigneul O
and O
Octavian O
- O
Eugen O
Ganea O
. O

Association O
for O
Computing O
Machinery O
. O

In O
Proceedings O
of O
the O
23rd O
ACM O
SIGKDD O
International O
Conference O
on O
Knowledge O
Discovery O
and O
Data O
Mining O
, O
KDD O
17 O
, O
page O
6574 O
, O
New O
York O
, O
NY O
, O
USA O
. O

Patient O
subtyping O
via O
time O
- O
aware O
lstm O
networks O
. O

2017 O
. O

Jain O
, O
and O
Jiayu O
Zhou O
. O

Baytas O
, O
Cao O
Xiao O
, O
Xi O
Zhang O
, O
Fei O
Wang O
, O
Anil O
K O
. O

Inci O
M O
. O

European O
Language O
Resources O
Association O
. O

In O
Proceedings O
of O
the O
12th O
Language O
Resources O
and O
Evaluation O
Conference O
, O
pages O
5073 O
5078 O
, O
Marseille O
, O
France O
. O

ParlV O
ote O
: O
A O
corpus O
for O
sentiment O
analysis O
of O
political O
debates O
. O

2020 O
. O

Gavin O
Abercrombie O
and O
Riza O
Batista O
- O
Navarro O
. O

aye O
or O
no O
? O
speech O
- O
level O
sentiment O
analysis O
of O
hansard O
uk O
parliamentary O
debate O
transcripts O
. O

2018 O
. O

Care O
should O
be O
taken O
so O
as O
not O
to O
create O
stigma O
, O
and O
interventions O
must O
be O
carefully O
planned O
by O
consulting O
relevant O
stakeholders O
such O
as O
clinicians O
, O
designers O
, O
and O
researchers O
( O
Chancellor O
et O
al O
. O
, O
2016 O
) O
, O
to O
maintain O
social O
media O
as O
a O
safe O
space O
for O
individuals O
looking O
to O
express O
themselves O
( O
Chancellor O
et O
al O
. O
, O
2019).References O
Gavin O
Abercrombie O
and O
Riza O
Batista O
- O
Navarro O
. O

While O
one O
of O
our O
works O
application O
is O
to O
aid O
in O
the O
early O
detection O
of O
suicidal O
users O
and O
early O
intervention O
, O
it O
is O
imperative O
that O
any O
interventions O
be O
well O
- O
thought O
, O
failing O
which O
may O
lead O
to O
counterhelpful O
outcomes O
, O
such O
as O
users O
moving O
to O
fringe O
platforms O
, O
which O
would O
make O
it O
harder O
to O
provide O
assistance O
( O
Kumar O
et O
al O
. O
, O
2015 O
) O
. O

We O
also O
perform O
automatic O
de O
- O
identification O
using O
named O
entity O
recognition O
to O
identify O
and O
mask O
personally O
identifiable O
information O
. O

We O
paraphrase O
and O
anonymize O
all O
samples O
in O
the O
suicide O
ideation O
detection O
detection O
dataset O
using O
the O
moderate O
disguise O
scheme O
( O
Bruckman O
, O
2002 O
; O
Fiesler O
and O
Proferes O
, O
2018 O
) O
. O

Specifically O
, O
we O
operate O
within O
the O
acceptable O
privacy O
bounds O
( O
Chancellor O
et O
al O
. O
, O
2019 O
) O
and O
considerations O
( O
Fiesler O
and O
Proferes O
, O
2018 O
) O
in O
order O
to O
avoid O
coercion O
and O
harmful O
interventions O
( O
Chancellor O
et O
al O
. O
, O
2019 O
) O
. O

We O
carefully O
adopt O
the O
measures O
followed O
by O
Chancellor O
et O
al O
. O
( O
2016 O
) O
. O

We O
acknowledge O
that O
the O
predictive O
power O
of O
HYPHEN B-MethodName
depends O
on O
the O
data O
, O
which O
is O
in O
tension O
with O
user O
privacy O
concerns O
. O

While O
we O
only O
use O
publicly O
available O
user O
data O
, O
we O
emphasize O
the O
importance O
of O
preserving O
the O
privacy O
of O
the O
users O
involved O
( O
De O
Choudhury O
et O
al O
. O
, O
2016 O
) O
. O

6 O
Ethical O
Considerations O
The O
sensitive O
nature O
of O
this O
work O
calls O
for O
careful O
deliberation O
of O
the O
risks O
and O
ethical O
challenges O
involved O
. O

Acknowledgements O
We O
would O
like O
to O
thank O
the O
Financial O
Services O
Innovation O
Lab O
at O
Georgia O
Institute O
of O
Technology O
for O
their O
generous O
support O
. O

Through O
experiments O
on O
political O
, O
financial O
NLP O
, O
and O
healthcare O
tasks O
, O
we O
show O
the O
applicability O
of O
HYPHEN B-MethodName
on O
4 O
datasets O
. O

We O
propose O
HYPHEN B-MethodName
which O
uses O
hyperbolic O
Hawkes O
attention O
and O
learns O
data O
- O
driven O
geometries O
to O
represent O
varying O
hyperbolic O
properties O
of O
streams O
. O

5 O
Conclusion O
We O
explore O
the O
scale O
- O
free O
dynamics O
and O
timing O
irregularities O
of O
text O
streams O
. O

provides O
the O
best O
results O
with O
debates O
around O
ten O
months O
in O
the O
past O
( O
mid O
- O
sized O
lookbacks O
) O
. O

In O
general O
, O
HYPHEN623 B-MethodName
. O

However O
, O
through O
hyperbolic O
Hawkes O
attention O
HYPHEN B-MethodName
is O
able O
to O
filter O
out O
more O
crucial O
debates O
to O
an O
extent O
. O

Further O
, O
with O
very O
large O
lookback O
periods O
, O
we O
observe O
a O
performance O
drop O
, O
likely O
because O
large O
amounts O
of O
context O
allow O
the O
inclusion O
of O
speeches O
from O
very O
old O
( O
stale O
) O
debates O
, O
which O
may O
not O
contribute O
significantly O
to O
the O
speakers O
present O
state O
( O
Cullen O
et O
al O
. O
, O
2018 O
) O
. O

As O
we O
increase O
the O
lookback O
period O
, O
we O
note O
that O
Hawkes O
attention O
improves O
temporal O
attention O
, O
potentially O
because O
the O
Hawkes O
process O
decays O
the O
impact O
of O
very O
old O
texts O
enabling O
HYPHEN B-MethodName
to O
focus O
on O
more O
recent O
debates O
which O
better O
reects O
a O
speakers O
temporal O
state O
. O

First O
, O
without O
encoding O
the O
historic O
context O
, O
we O
observe O
that O
all O
models O
perform O
poorly O
. O

4.3 O
Impact O
of O
Historical O
Context O
We O
study O
the O
variation O
in O
HYPHENs B-MethodName
performance O
on O
political O
speaker O
state O
modeling O
corresponding O
to O
varying O
amounts O
of O
lookback O
periods O
Tin O
Figure O
2 O
. O

Finally O
, O
learning O
the O
underlying O
hyperbolic O
geometry O
benefits O
HYPHEN B-MethodName
, O
allowing O
it O
to O
generalize O
to O
a O
variety O
of O
text O
streams O
with O
different O
hyperbolic O
properties O
. O

because O
the O
Hawkes O
process O
better O
captures O
the O
excitation O
induced O
by O
inuential O
texts O
. O

Ablation O
ComponentsPVote B-MethodName
MCC"SI B-MetricName
MCC"CSE B-MetricName
MSE#S&P B-MetricName
MSE B-MetricName
# O
LSTM B-MethodName
0.52 B-MetricValue
0.28 B-MetricValue
2.88 B-MetricValue
0.34 B-MetricValue
EUC B-MethodName
- I-MethodName
Time I-MethodName
LSTM+Attn I-MethodName
0.51 B-MetricValue
0.30 B-MetricValue
2.86 B-MetricValue
0.32 B-MetricValue
EUC B-MethodName
- I-MethodName
Time I-MethodName
LSTM+Hwks I-MethodName
0.54 B-MetricValue
0.33 B-MetricValue
2.83 B-MetricValue
0.32 B-MetricValue
HYP B-MethodName
- I-MethodName
time I-MethodName
LSTM I-MethodName
+ I-MethodName
Attn I-MethodName
0.580.312.730.31 B-MetricValue
HYPHEN B-MethodName
- I-MethodName
constant I-MethodName
curvature I-MethodName
0.610.362.720.30 B-MetricValue
HYPHEN B-MethodName
( O
Ours O
) O
0.63 B-MetricValue
* O
0.44 B-MetricValue
* O
2.68 B-MetricValue
* O
0.29 B-MetricValue
* O
0 B-MetricValue
50 I-MetricValue
100 O
1500:20:40:6 O
Time O
( O
in O
Months)MCCHYPHEN B-MethodName
HYP I-MethodName
- I-MethodName
TLSTM I-MethodName
+ I-MethodName
Attn I-MethodName
EUC I-MethodName
- I-MethodName
TLSTM I-MethodName
+ I-MethodName
Hwks I-MethodName
Figure O
2 O
: O
Sensitivity O
of O
HYPHEN B-MethodName
to O
the O
lookback O
period O
Ton O
political O
speaker O
state O
modeling O
. O

* O
, O
indicate O
improvement O
over O
HYPHEN B-MethodName
-constant O
curvature O
and O
Euclidean O
( O
EUC O
) O
counterparts O
are O
significant O
( O
p<0:01 O
) O
under O
Wilcoxons O
signed O
rank O
test O
. O

Further O
, O
enriching O
the O
temporal O
attention O
with O
the O
Hawkes O
process O
leads O
to O
performance O
boosts O
, O
potentiallyTable O
2 O
: O
Ablation O
study O
over O
HYPHEN B-MethodName
( O
mean O
of O
40 O
runs O
) O
. O

Next O
, O
we O
observe O
significant O
( O
p O
< O
0:01 O
) O
improvements O
on O
using O
hyperbolic O
spaces O
to O
represent O
text O
streams O
, O
suggesting O
that O
the O
hyperbolic O
space O
better O
models O
the O
innate O
power O
- O
law O
dynamics O
and O
hierarchies O
in O
online O
text O
streams O
( O
Sala O
et O
al O
. O
, O
2018 O
) O
. O

We O
note O
that O
augmenting O
RNN O
- O
based O
methods O
with O
attention O
leads O
to O
significant O
improvements O
( O
p<0:01 O
) O
, O
as O
HYPHEN B-MethodName
can O
better O
distinguish O
noise O
inducing O
text O
from O
relevant O
information O
( O
Sawhney O
et O
al O
. O
, O
2021e O
) O
. O

4.2 O
Ablation O
Study O
We O
contextualize O
the O
impact O
of O
various O
components O
ofHYPHEN B-MethodName
in O
Table O
2 O
. O

These O
observations O
collectively O
show O
the O
practical O
applicability O
and O
generalizability O
of O
HYPHEN B-MethodName
for O
stream O
modeling O
. O

Second O
, O
through O
hyperbolic O
time O
aware O
learning O
and O
Hawkes O
attention O
, O
HYPHEN B-MethodName
better O
captures O
timing O
irregularities O
between O
the O
subsequent O
release O
of O
texts O
( O
Sawhney O
et O
al O
. O
, O
2021a O
) O
. O

First O
, O
HYPHEN B-MethodName
better O
encodes O
the O
varying O
hyperbolic O
properties O
of O
text O
sequences O
by O
learning O
a O
suitable O
data O
- O
driven O
curvature O
in O
contrast O
to O
other O
hyperbolic O
models O
( O
HT B-MethodName
- I-MethodName
LSTM I-MethodName
) O
, O
which O
constrain O
all O
sequences O
to O
a O
fixed O
hyperbolic O
space O
. O

We O
postulate O
that O
HYPHEN B-MethodName
s O
superior O
performance O
is O
due O
to O
, O
1 O
) O
learnable O
hyperbolic O
geometry O
and O
2 O
) O
time O
- O
aware O
hyperbolic O
Hawkes O
process O
. O

Overall O
, O
we O
note O
that O
methods O
that O
capture O
fine O
- O
grained O
timing O
irregularities O
in O
text O
sequences O
perform O
better O
( O
HYPHEN B-MethodName
, O
FAST B-MethodName
, O
HT B-MethodName
- I-MethodName
LSTM I-MethodName
) O
, O
validating O
our O
premise O
of O
using O
time O
- O
aware O
modeling O
. O

We O
observe O
thatHYPHEN B-MethodName
generally O
outperforms O
most O
baseline O
methods O
by O
10% O
on O
average O
. O

ModelPVote B-MethodName
MCC"SI B-MetricName
MCC"CSE B-MetricName
MSE#S&P B-MetricName
MSE B-MetricName
# O
MLP(2018 B-MethodName
) O
0.36 B-MetricValue
0.24 B-MetricValue
2.91 B-MetricValue
0.38 B-MetricValue
LSTM(1997 B-MethodName
) O
0.52 B-MetricValue
0.28 B-MetricValue
2.88 B-MetricValue
0.34 B-MetricValue
HAN(2019 B-MethodName
) O
0.50 B-MetricValue
0.29 B-MetricValue
2.85 B-MetricValue
0.31 B-MetricValue
H B-MethodName
- I-MethodName
LSTM(2020 I-MethodName
) O
0.53 B-MetricValue
0.29 B-MetricValue
2.87 B-MetricValue
0.33 B-MetricValue
FAST(2021e B-MethodName
) O
0.51 B-MetricValue
0.30 B-MetricValue
2.86 B-MetricValue
0.32 B-MetricValue
HT B-MethodName
- I-MethodName
LSTM(2021a I-MethodName
) O
0.55 B-MetricValue
0.31 B-MetricValue
2.68 B-MetricValue
0.31 B-MetricValue
HYPHEN B-MethodName
( O
Ours O
) O
0.63 B-MetricValue
* O
0.44 B-MetricValue
* O
2.68 B-MetricValue
0.29 B-MetricValue
* O
4 O
Results O
4.1 O
Performance O
Comparison O
We O
compare O
the O
performance O
of O
HYPHEN B-MethodName
over O
financial O
, O
political O
, O
and O
healthcare O
tasks O
spanning O
English O
and O
Chinese O
languages O
in O
Table O
1 O
. O

* O
indicates O
improvement O
over O
SOTA O
is O
significant O
( O
p<0:01 O
) O
under O
Wilcoxons O
signed O
rank O
test O
. O

Table O
1 O
: O
Performance O
comparison O
with O
baselines O
( O
mean O
of O
40 O
runs O
) O
. O

We O
use O
the O
data O
from O
( O
Mishra O
et O
al O
. O
, O
2019 O
) O
containing O
32,558 O
user O
timelines O
and O
2.3 O
M O
texts.622 O
. O

Suicide B-MethodName
Ideation I-MethodName
Following I-MethodName
( O
Sawhney O
et O
al O
. O
, O
2021d O
) O
, O
we O
aim O
to O
detect O
suicidal O
intent O
in O
a O
tweet O
given O
historic O
tweets O
from O
a O
user O
. O

We O
evaluate O
on O
the O
S&P B-DatasetName
( O
Xu O
and O
Cohen O
, O
2018 O
) O
containing O
88 O
stocks O
with O
109,915 O
tweets O
and O
the O
China B-DatasetName
Stock I-DatasetName
Exchange I-DatasetName
( I-DatasetName
CSE I-DatasetName
) I-DatasetName
( O
Huang O
et O
al O
. O
, O
2018 O
) O
containing O
90,361 O
Chinese O
news O
articles O
for O
85 O
stocks O
. O

Following O
( O
Sawhney O
et O
al O
. O
, O
2021a O
) O
we O
regress O
the O
future O
volatility O
of O
a O
stock O
defined O
as O
= O
ln(jpi pi 1 O
pi 1j O
) O
, O
wherepiis O
the O
closing O
price O
. O

Financial O
NLP O
We O
aim O
to O
predict O
future O
stock O
trends O
based O
on O
the O
historic O
texts O
about O
a O
stock O
. O

We O
evaluate O
on O
the O
ParlV O
ote O
dataset O
( O
Abercrombie O
and O
Batista O
- O
Navarro O
, O
2020 O
) O
comprising O
of O
33,461 O
UK O
debate O
transcripts O
of O
1,346 O
politicians O
. O

Following O
( O
Sawhney O
et O
al O
. O
, O
2020 O
) O
, O
we O
aim O
to O
classify O
the O
stance O
of O
a O
speaker O
as O
Aye O
/ O
No O
on O
a O
motion O
based O
on O
their O
historic O
speeches O
. O

3 O
Applications O
and O
Tasks O
Political O
Stance O
Prediction O
Parliamentary O
debates O
consist O
of O
responses O
from O
politicians O
over O
a O
motion O
. O

Formally O
, O
we O
use O
an O
Einstein O
midpoint O
( O
Ungar O
, O
2005 O
) O
to O
aggregate O
hidden O
states O
hvia O
Hawkes O
process O
as O
, O
u O
= O
HYPHEN O
( O
fpi;tigT O
i=1 O
) O
= O
X O
j O
j O
( O
qj)P O
( O
q O
) O
qj O
( O
8) O
qj= O
j O
hj O
expo(ReLU O
( O
logo(hj O
) O
) O
) O
e  O
k O
( O
9 O
) O
where O
, O
( O
qj)=1p O
1 jjqjjj2are O
the O
lorentz O
factors O
. O

The O
hyperbolic B-MethodName
Hawkes I-MethodName
attention I-MethodName
mechanism I-MethodName
learns O
an O
excitation O
parameter O
corresponding O
to O
excitation O
induced O
by O
text O
pjand O
a O
decay O
parameter O
to O
learn O
the O
decay O
rate O
of O
this O
induced O
excitement O
. O

Studies O
( O
Zuo O
et O
al O
. O
, O
2020 O
; O
Sawhney O
et O
al O
. O
, O
2021b O
) O
show O
that O
the O
Hawkes O
process O
can O
be O
used O
to O
model O
text O
sequences O
from O
social O
media O
and O
discourses O
. O

Each O
text O
item O
excites O
the O
process O
in O
the O
sense O
that O
the O
chance O
of O
a O
subsequent O
arrival O
is O
increased O
for O
some O
time O
. O

The O
Hawkes O
process O
is O
a O
temporal O
point O
process O
that O
models O
a O
sequence O
of O
arrival O
of O
texts O
over O
time O
. O

Next O
, O
we O
enhance O
the O
temporal B-MethodName
hyperbolic I-MethodName
attention I-MethodName
using O
the O
Hawkes O
process O
( O
Mei O
and O
Eisner O
, O
2017 O
) O
and O
propose O
a O
hyperbolic B-MethodName
Hawkes I-MethodName
attention I-MethodName
mechanism I-MethodName
. O

This O
mechanism O
learns O
attention O
weights O
i O
for O
each O
hiddden O
state O
hi2h= O
[ O
h1;:::;hT]as O
, O
j O
= O
Softmax  O
exp O
( O
logo(hj)T(Wlogo(h))) O
( O
7)where O
, O
Wdenotes O
learnable O
weights O
. O

We O
use O
a O
temporal B-MethodName
hyperbolic I-MethodName
attention I-MethodName
mechanism I-MethodName
( O
Luong O
et O
al O
. O
, O
2015 O
) O
to O
emphasize O
texts O
likely O
to O
have O
a O
substantial O
inuence O
. O

Hyperbolic O
Hawkes O
Attention O
Studies O
show O
that O
not O
all O
historical O
texts O
are O
equally O
informative O
and O
pose O
a O
diverse O
inuence O
over O
the O
predictions O
( O
Sawhney O
et O
al O
. O
, O
2021c O
) O
. O

Finally O
, O
given O
texts O
[ O
p1;:::p O
T]over O
a O
lookback O
period O
T O
, O
we O
define O
the O
update O
rule O
of O
HTTN O
as O
, O
hj O
= O
HTTN O
( O
mj;j;hj 1);j2[1;T](6 O
) O
where O
, O
hjrepresents O
the O
hidden O
states O
of B-MethodName
HTTN I-MethodName
. O

Using O
the O
adjusted O
previous O
memory O
C O
k 1 O
, O
we O
define O
the O
current O
hidden O
state O
and O
current O
memory O
states O
for B-MethodName
HTTN I-MethodName
, O
with O
hyperbolic O
features O
mas O
: O
eck=logo(Wc O
hk 1Uc O
mkbc O
) O
Ck O
= O
ik O
eckfk O
C O
k 1 O
( O
Current O
memory O
) O
hk O
= O
ok O
expo(tanh O
( O
Ck O
) O
) O
( O
Current O
hidden O
state O
) O
where O
Wc;Uc;bcare O
the O
learnable O
parameters O
, O
ik;fk;okare O
input O
, O
forget O
and O
output O
gates O
. O

Following O
( O
Baytas O
et O
al O
. O
, O
2017 O
) O
we O
setg(k O
) O
= O
1=k O
. O

Thus O
, O
for O
a O
given O
dayk O
, O
HTTN B-MethodName
applies O
a O
decaying O
function O
over O
k O
, O
the O
elapsed O
time O
between O
two O
texts O
[ O
pk;pk 1 O
] O
, O
transforming O
the O
time O
differences O
into O
weights O
: O
Cs O
k 1 O
= O
expo(tanh O
( O
logo(Wd O
Ck 1bd O
) O
) O
) O
^Cs O
k 1 O
= O
Cs O
k 1 O
g(k)Discounted O
short O
- O
term O
memory O
CT O
k 1= Cs O
k 1Ck 1 O
Long O
term O
memory O
C O
k 1 O
= O
CT O
k 1^Cs O
k 1Adjusted O
previous O
memory O
where O
Cs O
k 1is O
the O
previous O
cell O
memory O
, O
Wd;bd O
are O
the O
network O
parameters O
, O
and O
g()is O
a O
heuristic O
decaying O
function O
. O

Intuitively O
, O
the O
greater O
the O
time O
elapsed O
between O
text O
releases O
, O
the O
lesser O
the O
impact O
they O
should O
have O
on O
each O
other O
. O

To O
capture O
these O
time O
dependent O
intricacies O
in O
a O
learnable O
hyperbolic O
space O
, O
we O
modify O
the O
hyperbolic O
LSTM O
( O
Shimizu O
et O
al O
. O
, O
2021 O
) O
as O
shown O
in O
Figure O
1 O
into O
a O
hyperbolic B-MethodName
time I-MethodName
- I-MethodName
aware I-MethodName
temporal I-MethodName
network I-MethodName
( O
HTTN B-MethodName
( O
 O
) O
) O
. O

Consequently O
, O
the O
ideologies O
and O
thought O
process O
of O
the O
speaker O
may O
change O
over O
time O
, O
reecting O
a O
decay O
or O
increase O
in O
dependence O
on O
the O
speakers O
previous O
speeches O
( O
Van O
Dijk O
, O
2002 O
) O
. O

few O
days O
to O
many O
months O
in O
parliamentary O
debates O
. O

For O
instance O
, O
the O
time O
interval O
between O
two O
debates O
can O
vary O
widely O
, O
from O
a621 O
. O

Further O
, O
capturing O
fine O
- O
grained O
timing O
irregularities O
in O
text O
streams O
plays O
a O
crucial O
role O
for O
stream O
state O
modeling O
. O

To O
apply O
hyperbolic O
operations O
over O
text O
features O
^mi O
, O
we O
project O
it O
to O
the O
hyperbolic O
space O
via O
the O
exponential O
mapping O
expo()given O
by O
, O
mi O
= O
expo(^mi O
) O
Hyperbolic B-MethodName
Time I-MethodName
Aware I-MethodName
Temporal I-MethodName
Network I-MethodName
To O
encode O
the O
varying O
scale O
- O
free O
characteristics O
of O
text O
sequences O
, O
we O
introduce O
LSTMs O
over O
learnable O
hyperbolic O
spaces O
by O
leveraging O
Mbius O
operations O
( O
2.1 O
) O
. O

Mbius O
Multiplication O
multiplies O
features O
x2BCwith O
matrix O
W2RC0C O
, O
given O
by O
W O
x O
= O
expo(Wlogo(x O
) O
) O
( O
4 O
) O
Mbius O
Pointwise O
Product O
multiplies O
matrix O
x2BCwith O
matrix O
y2BCpointwise O
, O
x O
y=1pctanhjjxyjj O
yarctan 1(pcjjyjj)jjxyjj O
jjyjj(5 O
) O
2.2 B-MethodName
HYPHEN I-MethodName
: B-MethodName
Hyperbolic I-MethodName
Hawkes I-MethodName
Network I-MethodName
Text I-MethodName
Embedding I-MethodName
Layer I-MethodName
We O
use B-MethodName
Bidirectional I-MethodName
Encoder I-MethodName
Representations I-MethodName
from I-MethodName
Transformers I-MethodName
( B-MethodName
BERT I-MethodName
) O
( O
Devlin O
et O
al O
. O
, O
2019 O
) O
to O
encode O
each O
text O
pi O
to O
features O
^mi O
= O
BERT O
( O
pi)2Rdwhered= O
768 O
, O
obtained O
by O
averaging O
the O
token O
level O
outputs O
from O
the O
final O
layer O
of B-MethodName
BERT I-MethodName
. O

Xk O
concat O
X.Mobius O
Addition O
Mobius O
Matrix O
Multiplication O
Mobius O
Pointwise O
Multiplication O
Euclidean O
Matrix O
Multiplication O
Euclidean O
Pointwise O
Multiplicationlogo O
( O
) O
RNN O
Block O
Hyperbolic O
Hawkes O
AttentionHTTNFigure O
1 O
: O
HYPHEN O
cell O
diagram O
and O
update O
rule O
. O

Ckhku O
uOkhk-1 O
h O
mbWm O
Mobius O
GRU O
. O

.Wd O
bd O
logo()expo O
( O
) O
expo O
( O
) O
expo()tanh O
tanhreluexp O
fc O
fcsoftmaxweighted O
midpointX O
+ O
+ O
+ O
.. O
Ck-1 O
logo O
( O
) O
expo()tanh O
g(k)-1 O
- O
1 O
RNN O
Block O
RNN O
Block O
RNN O
Block O
RNN O
Block O
. O

. O

. O

Exponential O
Map O
maps O
a O
tangent O
vector O
v2 O
TxBto O
a O
point O
expx(v)in O
the O
hyperbolic O
space O
, O
expx(v O
) O
= O
x O
tanhpcxjjvjj O
2vpcjjvjj O
( O
2 O
) O
Logarithmic O
Map O
maps O
a O
point O
y2Bto O
a O
point O
logx(y)on O
the O
tangent O
space O
at O
x O
, O
logx(y)=2pcxtanh 1 pcjj xyjj xy O
jj xyjj(3 O
) O
X O
X+ O
+ O
X+ O
.+ O
+ O
. O

Mbius O
Addition O
for O
two O
points O
x;y2B O
, O
is O
, O
xy=(1 O
+ O
2chx;yi+cjjyjj2)x+ O
( O
1 cjjxjj2)y O
1 O
+ O
2chx;yi+c2jjxjj2jjyjj2(1 O
) O
h:;:i O
, O
jjjj O
denotes O
the O
inner O
product O
and O
norm O
. O

We O
generalize O
Euclidean O
operations O
to O
the O
hyperbolic O
space O
via O
Mbius O
operations O
. O

We O
denote O
the O
tangent O
space O
centered O
at O
point O
xas O
TxB O
. O

Following O
( O
Ganea O
et O
al O
. O
, O
2018 O
) O
we O
define O
the O
hyperbolic O
geometry O
with O
varying O
curvature O
cas(B;gB O
x O
) O
, O
where O
the O
manifold O
B O
= O
fx2Rn O
: O
cjjxjj<1 O
g O
, O
is O
endowed O
with O
the O
Riemannian O
metric O
gB O
x=2 O
xgE O
, O
where O
the O
conformal O
factor O
x=2 O
1 cjjxjj2and O
gE O
= O
diag[1;::;1]is O
the O
Euclidean O
metric O
tensor O
. O

To O
learn O
the O
optimal O
geometry O
, O
we O
aim O
to O
learn O
the O
curvature O
c O
, O
which O
controls O
the O
degree O
of O
hyperbolic O
properties O
represented O
by O
the O
space O
( O
Gu O
et O
al O
. O
, O
2019 O
) O
. O

The O
hyperbolic O
space O
is O
a O
non O
- O
Euclidean O
space O
with O
a O
constant O
negative O
curvature O
c O
. O

Thus O
, O
we O
seek O
to O
learn O
the O
optimal O
underlying O
geometry O
. O

However O
, O
text O
sequences O
exhibit O
a O
varying O
degree O
of O
scale O
- O
free O
dynamics O
, O
which O
a O
single O
geometry O
can O
not O
capture O
( O
Gu O
et O
al O
. O
, O
2019 O
) O
. O

Indeed O
, O
the O
volume O
of O
hyperbolic O
geometry O
grows O
exponentially O
, O
in O
contrast O
to O
Euclidean O
spaces O
where O
the O
growth O
is O
polynomial O
( O
Khrulkov O
et O
al O
. O
, O
2020 O
) O
, O
enabling O
hyperbolic O
spaces O
to O
capture O
the O
underlying O
scale O
- O
free O
properties O
of O
streams O
( O
Sala O
et O
al O
. O
, O
2018 O
) O
. O

2.1 O
Learnable O
Hyperbolic O
Geometry O
Text O
sequences O
from O
social O
media O
and O
political O
discourses O
pose O
hierarchies O
( O
Sawhney O
et O
al O
. O
, O
2021a O
) O
i.e. O
, O
the O
datasets O
represent O
a O
tree O
like O
structure O
which O
call O
for O
the O
use O
of O
hyperbolic O
spaces O
. O

2 O
Methodology O
Problem O
Formulation O
: O
For O
a O
sequence O
of O
texts O
[ O
p1:::;p O
N]released O
at O
times O
[ O
t1;:::;t O
N]sequentially O
, O
with O
[ O
t1<<tN O
] O
, O
our O
target O
is O
to O
model O
this O
sequence O
in O
a O
time O
- O
sensitive O
fashion O
for O
a O
variety O
of O
downstream O
applications O
( O
3 O
) O
. O

com O
/ O
gtfintechlab O
/ O
HYPHEN O
- O
ACL620 O
. O

Through O
quantitative O
( O
4.1 O
) O
and O
exploratory O
( O
4.3 O
) O
experiments O
on O
four O
tasks O
spanning O
suicide B-TaskName
ideation I-TaskName
, O
political B-TaskName
debate I-TaskName
analysis I-TaskName
, O
and O
financial B-TaskName
forecasting I-TaskName
over O
English O
and O
Chinese O
languages O
, O
we O
demonstrate O
the O
practical O
applicability O
of O
HYPHEN B-MethodName
for O
stream O
modeling.1 O
1We O
release O
HYPHENs B-MethodName
code O
at O
: O
https://github O
. O

We O
introduce O
HYPHEN B-MethodName
as O
a O
geometry O
agnostic O
model O
which O
can O
be O
applied O
on O
any O
downstream O
application O
. O

Building O
on O
social O
theories O
, O
HYPHEN B-MethodName
learns O
the O
hyperbolic O
space O
based O
on O
the O
nature O
of O
the O
stream O
( O
2.1 O
) O
. O

Building O
on O
social O
theories O
, O
our O
contributions O
can O
be O
summarized O
as O
: O
We O
explore O
the O
hyperbolic O
properties O
of O
online O
streams O
and O
propose O
a O
Hyperbolic B-MethodName
Hawkes I-MethodName
Attention I-MethodName
Network I-MethodName
( I-MethodName
HYPHEN I-MethodName
) I-MethodName
which O
jointly O
learns O
from O
the O
fine O
- O
grained O
timing O
irregularities O
and O
powerlaw O
dynamics O
of O
streams O
( O
2.2 O
) O
. O

However O
, O
existing O
works O
face O
two O
major O
limitations O
, O
1 O
) O
they O
ignore O
the O
timing O
irregularities O
in O
scale O
- O
free O
sequences O
and O
2 O
) O
they O
use O
a O
single O
hyperbolic O
space O
to O
encode O
varying O
levels O
of O
hyperbolic O
dynamics O
. O

The O
good O
news O
is O
that O
hyperbolic O
learning O
has O
shown O
to O
better O
model O
such O
powerlaw O
dynamics O
compared O
to O
Euclidean O
learning O
over O
domains O
, O
including O
vision O
( O
Khrulkov O
et O
al O
. O
, O
2020 O
) O
and O
NLP O
( O
Tifrea O
et O
al O
. O
, O
2019 O
) O
. O

The O
presence O
of O
varying O
powerlaw O
dynamics O
from O
highly O
inuential O
texts O
correlates O
with O
natural O
hierarchies O
and O
scale O
- O
free O
dynamics O
in O
text O
streams O
, O
making O
them O
difficult O
to O
model O
( O
Sala O
et O
al O
. O
, O
2018 O
) O
. O

Further O
, O
the O
impact O
of O
such O
powerlaw O
excitations O
varies O
for O
each O
event O
. O

For O
example O
, O
in O
political O
debates O
, O
there O
are O
a O
few O
rare O
highly O
- O
inuential O
debates O
that O
heavily O
impact O
the O
overall O
voting O
decisions O
of O
citizens O
( O
Law O
, O
2019 O
) O
. O

Such O
texts O
are O
rare O
and O
the O
Equal O
contribution.excitation O
induced O
by O
them O
follows O
a O
powerlaw O
distribution O
which O
gives O
rise O
to O
scale O
- O
free O
properties O
( O
Zhao O
et O
al O
. O
, O
2010 O
) O
. O

Social O
theories O
show O
that O
from O
a O
vast O
volume O
of O
texts O
in O
a O
stream O
, O
only O
a O
few O
are O
powerful O
enough O
to O
heavily O
inuence O
the O
overall O
trend O
( O
Van O
Dijk O
, O
1977 O
; O
Gabaix O
, O
2016 O
) O
. O

A O
fundamental O
limitation O
in O
existing O
RNN O
methods O
is O
that O
it O
ignores O
the O
natural O
fine O
- O
grained O
timing O
irregularities O
in O
streams O
( O
Foucault O
et O
al O
. O
, O
2016 O
; O
Eysenck O
, O
1968 O
) O
. O

For O
instance O
, O
in O
stock O
markets O
, O
reacting O
a O
second O
slower O
than O
other O
investors O
can O
lead O
to O
massive O
losses O
( O
Scholtus O
et O
al O
. O
, O
2014 O
) O
. O

Second O
, O
timing O
plays O
an O
essential O
role O
in O
online O
stream O
modeling O
as O
users O
quickly O
react O
to O
new O
information O
( O
Sawhney O
et O
al O
. O
, O
2021a O
) O
. O

First O
, O
modeling O
individual O
text O
items O
may O
not O
be O
informative O
enough O
since O
text O
sequences O
display O
a O
sequential O
context O
dependency O
, O
where O
analyzing O
them O
together O
in O
succession O
provides O
better O
contextual O
representation O
( O
Hu O
et O
al O
. O
, O
2018 O
) O
. O

However O
, O
analyzing O
such O
text O
sequences O
poses O
several O
challenges O
. O

1 O
Introduction O
Text O
stream O
modeling O
is O
a O
critical O
problem O
that O
helps O
analyze O
trends O
over O
a O
variety O
of O
applications O
spanning O
finance O
( O
Oliveira O
et O
al O
. O
, O
2017 O
) O
, O
healthcare O
( O
Baytas O
et O
al O
. O
, O
2017 O
) O
, O
and O
political O
discourses O
( O
Sawhney O
et O
al O
. O
, O
2021c O
) O
. O

Through O
quantitative O
and O
exploratory O
experiments O
over O
financial O
NLP O
, O
suicide O
ideation O
detection O
, O
and O
political O
debate O
analysis O
we O
demonstrate O
HYPHEN B-MethodName
s O
practical O
applicability O
for O
modeling O
online O
text O
sequences O
in O
a O
geometry O
agnostic O
manner O
. O

We O
propose O
a O
Hyperbolic B-MethodName
Hawkes I-MethodName
Attention I-MethodName
Network I-MethodName
( I-MethodName
HYPHEN I-MethodName
) I-MethodName
, O
which O
learns O
a O
data O
- O
driven O
hyperbolic O
space O
and O
models O
irregular O
powerlaw O
excitations O
using O
a O
hyperbolic O
Hawkes O
process O
. O

Proceedings O
of O
the O
60th O
Annual O
Meeting O
of O
the O
Association O
for O
Computational O
Linguistics O
Volume O
2 O
: O
Short O
Papers O
, O
pages O
620 O
- O
627 O
May O
22 O
- O
27 O
, O
2022 O
c O
2022 O
Association O
for O
Computational O
Linguistics O
HYPHEN O
: O
Hyperbolic O
Hawkes O
Attention O
For O
Text O
Streams O
Shivam O
Agarwal O
, O
Ramit O
Sawhney O
, O
Sanchit O
Ahuja O
, O
Ritesh O
Soun O
, O
Sudheer O
Chava O
Financial O
Services O
Innovation O
Lab O
, O
Georgia O
Institute O
of O
Technology O
rsawhney31@gatech.edu O
, O
sudheer.chava@scheller.gatech.edu O
Abstract O
Analyzing O
the O
temporal O
sequence O
of O
texts O
from O
sources O
such O
as O
social O
media O
, O
news O
, O
and O
parliamentary O
debates O
is O
a O
challenging O
problem O
as O
it O
exhibits O
time O
- O
varying O
scale O
- O
free O
properties O
and O
fine O
- O
grained O
timing O
irregularities O
. O

Association O
for O
Computational O
Linguistics.619 O
. O

In O
Proceedings O
of O
the O
2016 O
Conference O
on O
Empirical O
Methods O
in O
Natural O
Language O
Processing O
, O
pages O
15681575 O
, O
Austin O
, O
Texas O
. O

Transfer O
learning O
for O
low O
- O
resource O
neural O
machine O
translation O
. O

2016 O
. O

Barret O
Zoph O
, O
Deniz O
Yuret O
, O
Jonathan O
May O
, O
and O
Kevin O
Knight O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
55th O
Annual O
Meeting O
of O
the O
Association O
for O
Computational O
Linguistics O
( O
Volume O
1 O
: O
Long O
Papers O
) O
, O
pages O
19591970 O
, O
Vancouver O
, O
Canada O
. O

Adversarial O
training O
for O
unsupervised O
bilingual O
lexicon O
induction O
. O

2017 O
. O

Meng O
Zhang O
, O
Yang O
Liu O
, O
Huanbo O
Luan O
, O
and O
Maosong O
Sun O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
2020 O
Conference O
on O
Empirical O
Methods O
in O
Natural O
Language O
Processing O
: O
System O
Demonstrations O
, O
pages O
3845 O
, O
Online O
. O

Transformers O
: O
State O
- O
of O
- O
the O
- O
art O
natural O
language O
processing O
. O

2020 O
. O

Thomas O
Wolf O
, O
Lysandre O
Debut O
, O
Victor O
Sanh O
, O
Julien O
Chaumond O
, O
Clement O
Delangue O
, O
Anthony O
Moi O
, O
Pierric O
Cistac O
, O
Tim O
Rault O
, O
Remi O
Louf O
, O
Morgan O
Funtowicz O
, O
Joe O
Davison O
, O
Sam O
Shleifer O
, O
Patrick O
von O
Platen O
, O
Clara O
Ma O
, O
Yacine O
Jernite O
, O
Julien O
Plu O
, O
Canwen O
Xu O
, O
Teven O
Le O
Scao O
, O
Sylvain O
Gugger O
, O
Mariama O
Drame O
, O
Quentin O
Lhoest O
, O
and O
Alexander O
Rush O
. O

In O
Proceedings O
of O
the O
25th O
International O
Conference O
on O
Machine O
Learning O
. O

Extracting O
and O
composing O
robust O
features O
with O
denoising O
autoencoders O
. O

2008 O
. O

Pascal O
Vincent O
, O
Hugo O
Larochelle O
, O
Yoshua O
Bengio O
, O
and O
Pierre O
- O
Antoine O
Manzagol O
. O

In O
Advances O
in O
neural O
information O
processing O
systems O
, O
pages O
59986008 O
. O

Attention O
is O
all O
you O
need O
. O

2017 O
. O

Ashish O
Vaswani O
, O
Noam O
Shazeer O
, O
Niki O
Parmar O
, O
Jakob O
Uszkoreit O
, O
Llion O
Jones O
, O
Aidan O
N O
Gomez O
, O
ukasz O
Kaiser O
, O
and O
Illia O
Polosukhin O
. O

European O
Language O
Resources O
Association O
( O
ELRA O
) O
. O

Turkey O
. O

In O
Proceedings O
of O
the O
Eighth O
International O
Conference O
on O
Language O
Resources O
and O
Evaluation O
( O
LREC12 O
) O
, O
pages O
22142218 O
, O
Istanbul,618 O
. O

Parallel O
data O
, O
tools O
and O
interfaces O
in O
OPUS O
. O

2012 O
. O

Jrg O
Tiedemann O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
56th O
Annual O
Meeting O
of O
the O
Association O
for O
Computational O
Linguistics O
( O
Volume O
1 O
: O
Long O
Papers O
) O
, O
pages O
778 O
788 O
, O
Melbourne O
, O
Australia O
. O

On O
the O
limitations O
of O
unsupervised O
bilingual O
dictionary O
induction O
. O

2018 O
. O

Anders O
Sgaard O
, O
Sebastian O
Ruder O
, O
and O
Ivan O
Vuli O
c O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
54th O
Annual O
Meeting O
of O
the O
Association O
for O
Computational O
Linguistics O
( O
Volume O
1 O
: O
Long O
Papers O
) O
, O
pages O
1715 O
1725 O
, O
Berlin O
, O
Germany O
. O

Neural O
machine O
translation O
of O
rare O
words O
with O
subword O
units O
. O

2016b O
. O

Rico O
Sennrich O
, O
Barry O
Haddow O
, O
and O
Alexandra O
Birch O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
54th O
Annual O
Meeting O
of O
the O
Association O
for O
Computational O
Linguistics O
( O
Volume O
1 O
: O
Long O
Papers O
) O
, O
pages O
8696 O
, O
Berlin O
, O
Germany O
. O

Improving O
neural O
machine O
translation O
models O
with O
monolingual O
data O
. O

2016a O
. O

Rico O
Sennrich O
, O
Barry O
Haddow O
, O
and O
Alexandra O
Birch O
. O

In O
Proceedings O
of O
the O
Third O
Conference O
on O
Machine O
Translation O
: O
Research O
Papers O
, O
pages O
186 O
191 O
. O

A O
call O
for O
clarity O
in O
reporting O
bleu O
scores O
. O

2018 O
. O

Matt O
Post O
. O

The O
Prague O
Bulletin O
of O
Mathematical O
Linguistics O
. O

Efficient O
word O
alignment O
with O
markov O
chain O
monte O
carlo O
. O

Robert O
stling O
, O
Jrg O
Tiedemann O
, O
et O
al O
. O
2016 O
. O

Asian O
Federation O
of O
Natural O
Language O
Processing O
. O

In O
Proceedings O
of O
the O
Eighth O
International O
Joint O
Conference O
on O
Natural O
Language O
Processing O
( O
Volume O
2 O
: O
Short O
Papers O
) O
, O
pages O
296301 O
, O
Taipei O
, O
Taiwan O
. O

Transfer O
learning O
across O
low O
- O
resource O
, O
related O
languages O
for O
neural O
machine O
translation O
. O

2017 O
. O

Nguyen O
and O
David O
Chiang O
. O

Toan O
Q O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
1st O
Workshop O
on O
Representation O
Learning O
for O
NLP O
, O
pages O
121126 O
, O
Berlin O
, O
Germany O
. O

Towards O
crosslingual O
distributed O
representations O
without O
parallel O
text O
trained O
with O
adversarial O
autoencoders O
. O

2016 O
. O

Antonio O
Valerio O
Miceli O
Barone O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
57th O
Annual O
Meeting O
of O
the O
Association O
for O
Computational O
Linguistics O
, O
pages O
31253135 O
, O
Florence O
, O
Italy O
. O

Choosing O
transfer O
languages O
for O
cross O
- O
lingual O
learning O
. O

2019 O
. O

Yu O
- O
Hsiang O
Lin O
, O
Chian O
- O
Yu O
Chen O
, O
Jean O
Lee O
, O
Zirui O
Li O
, O
Yuyan O
Zhang O
, O
Mengzhou O
Xia O
, O
Shruti O
Rijhwani O
, O
Junxian O
He O
, O
Zhisong O
Zhang O
, O
Xuezhe O
Ma O
, O
Antonios O
Anastasopoulos O
, O
Patrick O
Littell O
, O
and O
Graham O
Neubig O
. O

Transactionsof O
the O
Association O
for O
Computational O
Linguistics O
, O
5:365378 O
. O

Fully O
character O
- O
level O
neural O
machine O
translation O
without O
explicit O
segmentation O
. O

2017 O
. O

Jason O
Lee O
, O
Kyunghyun O
Cho O
, O
and O
Thomas O
Hofmann O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
2018 O
Conference O
on O
Empirical O
Methods O
in O
Natural O
Language O
Processing O
, O
pages O
50395049 O
, O
Brussels O
, O
Belgium O
. O

Phrase O
- O
based O
& O
neural O
unsupervised O
machine O
translation O
. O

2018b O
. O

Guillaume O
Lample O
, O
Myle O
Ott O
, O
Alexis O
Conneau O
, O
Ludovic O
Denoyer O
, O
and O
MarcAurelio O
Ranzato O
. O

InProceedings O
of O
the O
6th O
International O
Conference O
on O
Learning O
Representations O
. O

Unsupervised O
machine O
translation O
using O
monolingual O
corpora O
only O
. O

2018a O
. O

Guillaume O
Lample O
, O
Alexis O
Conneau O
, O
Ludovic O
Denoyer O
, O
and O
MarcAurelio O
Ranzato O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
2018 O
Conference O
on O
Empirical O
Methods O
in O
Natural O
Language O
Processing O
: O
System O
Demonstrations O
, O
pages O
6671 O
, O
Brussels O
, O
Belgium O
. O

SentencePiece B-MethodName
: O
A O
simple O
and O
language O
independent O
subword O
tokenizer O
and O
detokenizer O
for O
neural O
text O
processing O
. O

2018 O
. O

Taku O
Kudo O
and O
John O
Richardson O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
First O
Workshop O
on O
Neural O
Machine O
Translation O
, O
pages O
2839 O
, O
Vancouver O
. O

Six O
challenges O
for O
neural O
machine O
translation O
. O

2017 O
. O

Philipp O
Koehn O
and O
Rebecca O
Knowles O
. O

Association O
for O
Computational O
Linguistics O
. O

InProceedings O
of O
the O
Third O
Conference O
on O
Machine O
Translation O
: O
Research O
Papers O
, O
pages O
244252 O
, O
Brussels O
, O
Belgium O
. O

Trivial O
transfer O
learning O
for O
low O
- O
resource O
neural O
machine O
translation O
. O

2018 O
. O

Tom O
Kocmi O
and O
Ond O
rej O
Bojar O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
2018 O
Conference O
on O
Empirical O
Methods O
in O
Natural O
Language O
Processing O
, O
pages O
862868 O
, O
Brussels O
, O
Belgium O
. O

Improving O
unsupervised B-TaskName
word I-TaskName
- I-TaskName
by I-TaskName
- I-TaskName
word I-TaskName
translation I-TaskName
with O
language O
model O
and O
denoising O
autoencoder O
. O

2018 O
. O

Yunsu O
Kim O
, O
Jiahui O
Geng O
, O
and O
Hermann O
Ney O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
57th O
Annual O
Meeting O
of O
the O
Association O
for O
Computational O
Linguistics O
, O
pages O
1246 O
1257 O
, O
Florence O
, O
Italy O
. O

Effective O
cross B-TaskName
- I-TaskName
lingual I-TaskName
transfer I-TaskName
of I-TaskName
neural I-TaskName
machine I-TaskName
translation I-TaskName
models O
without O
shared O
vocabularies O
. O

2019 O
. O

Yunsu O
Kim O
, O
Yingbo O
Gao O
, O
and O
Hermann O
Ney O
. O

Transactions O
of O
the O
Association O
for O
Computational O
Linguistics O
, O
5:339351 O
. O

Googles O
multilingual B-TaskName
neural I-TaskName
machine I-TaskName
translation I-TaskName
system O
: O
Enabling O
zero O
- O
shot O
translation O
. O

2017 O
. O

Le O
, O
Maxim O
Krikun O
, O
Yonghui O
Wu O
, O
Zhifeng O
Chen O
, O
Nikhil O
Thorat O
, O
Fernanda O
Vigas O
, O
Martin O
Wattenberg O
, O
Greg O
Corrado O
, O
Macduff O
Hughes O
, O
and O
Jeffrey O
Dean O
. O

Melvin O
Johnson O
, O
Mike O
Schuster O
, O
Quoc O
V O
. O

Association O
for O
Computational O
Linguistics O
. O

in O
Natural O
Language O
Processing O
, O
pages O
36223631 O
, O
Brussels O
, O
Belgium O
. O

In O
Proceedings O
of O
the O
2018 O
Conference O
on O
Empirical O
Methods617 O
. O

Meta B-TaskName
- I-TaskName
learning I-TaskName
for I-TaskName
lowresource I-TaskName
neural I-TaskName
machine I-TaskName
translation I-TaskName
. O

2018b O
. O

Li O
, O
and O
Kyunghyun O
Cho O
. O

K O
. O

Jiatao O
Gu O
, O
Yong O
Wang O
, O
Yun O
Chen O
, O
Victor O
O O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
2018 O
Conference O
of O
the O
North O
American O
Chapter O
of O
the O
Association O
for O
Computational O
Linguistics O
: O
Human O
Language O
Technologies O
, O
Volume O
1 O
( O
Long O
Papers O
) O
, O
pages O
344354 O
, O
New O
Orleans O
, O
Louisiana O
. O

Universal B-TaskName
neural I-TaskName
machine I-TaskName
translation I-TaskName
for I-TaskName
extremely I-TaskName
low I-TaskName
resource I-TaskName
languages I-TaskName
. I-TaskName

2018a O
. O

Li O
. O

Jiatao O
Gu O
, O
Hany O
Hassan O
, O
Jacob O
Devlin O
, O
and O
Victor O
O.K O
. O

arXiv O
preprint O
arXiv:1909.06516 O
. O

A O
universal O
parent O
model O
for O
low B-TaskName
- I-TaskName
resource I-TaskName
neural I-TaskName
machine I-TaskName
translation I-TaskName
transfer I-TaskName
. O

2019 O
. O

Mozhdeh O
Gheini O
and O
Jonathan O
May O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
2016 O
Conference O
of O
the O
North O
American O
Chapter O
of O
the O
Association O
for O
Computational O
Linguistics O
: O
Human O
Language O
Technologies O
, O
pages O
866875 O
, O
San O
Diego O
, O
California O
. O

Multi B-TaskName
- I-TaskName
way I-TaskName
, I-TaskName
multilingual I-TaskName
neural I-TaskName
machine I-TaskName
translation I-TaskName
with O
a O
shared O
attention O
mechanism O
. O

2016 O
. O

Orhan O
Firat O
, O
Kyunghyun O
Cho O
, O
and O
Yoshua O
Bengio O
. O

ACM O
Transactions O
on O
Asian O
and O
LowResource O
Language O
Information O
Processing O
( O
TALLIP O
) O
, O
18(2):118 O
. O

Nova O
: O
A O
feasible O
and O
exible O
annotation O
system O
for O
joint O
tokenization O
and O
part B-TaskName
- I-TaskName
of I-TaskName
- I-TaskName
speech I-TaskName
tagging I-TaskName
. O

2018 O
. O

Chenchen O
Ding O
, O
Masao O
Utiyama O
, O
and O
Eiichiro O
Sumita O
. O

The O
National O
University O
( O
Phillippines O
) O
. O

InProceedings O
of O
the O
31st O
Pacific O
Asia O
Conference O
on O
Language O
, O
Information O
and O
Computation O
, O
pages O
282286 O
. O

An O
empirical O
study O
of O
language O
relatedness O
for O
transfer O
learning O
in O
neural O
machine O
translation O
. O

2017 O
. O

Raj O
Dabre O
, O
Tetsuji O
Nakagawa O
, O
and O
Hideto O
Kazawa O
. O

In O
Proceedings O
of O
the O
6th O
International O
Conference O
on O
Learning O
Representations O
. O

Word O
translation O
without O
parallel O
data O
. O

2018 O
. O

Alexis O
Conneau O
, O
Guillaume O
Lample O
, O
MarcAurelio O
Ranzato O
, O
Ludovic O
Denoyer O
, O
and O
Herv O
Jgou O
. O

In O
Proceedings O
of O
the O
TwentySixth O
International O
Joint O
Conference O
on O
Artificial O
Intelligence O
, O
pages O
39743980 O
. O

Joint O
training O
for O
pivot O
- O
based O
neural O
machine O
translation O
. O

2017 O
. O

Yong O
Cheng O
, O
Yang O
Liu O
, O
Qian O
Yang O
, O
Maosong O
Sun O
, O
and O
Wei O
Xu O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
Second O
Conference O
on O
Machine O
Translation O
, O
pages O
169 O
214 O
, O
Copenhagen O
, O
Denmark O
. O

Findings O
of O
the O
2017 O
conference O
on O
machine O
translation O
( O
WMT17 O
) O
. O

2017 O
. O

Ondrej O
Bojar O
, O
Rajen O
Chatterjee O
, O
Christian O
Federmann O
, O
Yvette O
Graham O
, O
Barry O
Haddow O
, O
Shujian O
Huang O
, O
Matthias O
Huck O
, O
Philipp O
Koehn O
, O
Qun O
Liu O
, O
Varvara O
Logacheva O
, O
Christof O
Monz O
, O
Matteo O
Negri O
, O
Matt O
Post O
, O
Raphael O
Rubino O
, O
Lucia O
Specia O
, O
and O
Marco O
Turchi O
. O

arXiv O
preprint O
arXiv:1710.11041 O
. O

Unsupervised B-TaskName
neural I-TaskName
machine I-TaskName
translation I-TaskName
. O

2017 O
. O

Association O
for O
Computational O
Linguistics O
. O
Mikel O
Artetxe O
, O
Gorka O
Labaka O
, O
Eneko O
Agirre O
, O
and O
Kyunghyun O
Cho O
. O

In O
neural O
machine O
translation O
, O
what O
does O
transfer B-TaskName
learning I-TaskName
transfer O
? O
In O
Proceedings O
of O
the O
58th O
Annual O
Meeting O
of O
the O
Association O
for O
Computational O
Linguistics O
, O
pages O
77017710 O
, O
Online O
. O

2020 O
. O

References O
Alham O
Fikri O
Aji O
, O
Nikolay O
Bogoychev O
, O
Kenneth O
Heafield O
, O
and O
Rico O
Sennrich O
. O

Acknowledgements O
The O
research O
is O
supported O
by O
National O
Key O
R&D O
Program O
of O
China O
( O
2020YFB1313601 O
) O
and O
National O
Science O
Foundation O
of O
China O
( O
62076174 O
) O
. O

In O
the O
future O
, O
we O
will O
study O
bilingual O
embedding O
transfer O
of O
phonologically O
- O
similar O
words O
, O
so O
as O
to O
further O
improve O
low B-TaskName
- I-TaskName
resource I-TaskName
NMT I-TaskName
. O

For O
example O
, O
the O
phonologies O
of O
hamburger O
in O
German O
and O
Burmese O
are O
similar O
( O
H O
amburger O
vs O
hambhargar O
) O
. O

Additional O
survey O
in O
the O
experiments O
reveals O
that O
phonetic O
symbols O
can O
be O
used O
for O
transfer O
learning O
between O
the O
languages O
belonging O
to O
different O
families O
. O

The O
efficiency O
can O
be O
improved O
with O
the O
ratio O
of O
about O
50% O
at O
best O
. O

More O
importantly O
, O
we O
successfully O
reduce O
the O
training O
duration O
. O

The O
experimental O
results O
demonstrate O
that O
the O
proposed O
method O
yields O
substantial O
improvements O
for O
all O
the O
considered O
MT B-TaskName
scenarios O
( O
including O
My O
- O
En O
, O
Id O
- O
En O
and O
Tr O
- O
En O
) O
. O

6 O
Conclusion O
We O
enhance O
transferable O
Parent O
- O
Child O
NMT B-TaskName
by O
duplicating O
embeddings O
of O
aligned O
sub O
- O
words O
. O

All O
in O
all O
, O
Mean B-MethodName
- I-MethodName
PC I-MethodName
is O
less O
time O
- O
consuming O
when O
producing O
substantial O
improvements O
. O

This O
contributes O
more O
to O
the O
avoidance O
of O
redundant O
learning O
over O
sub O
- O
word O
embeddings O
. O

In O
other O
word O
, O
Mean B-MethodName
- I-MethodName
PC I-MethodName
actually O
transfers O
not O
only O
morphologically O
- O
identical O
sub O
- O
words O
but O
the O
aligned O
ones O
. O

Most O
probably O
, O
it O
is O
caused O
by O
the O
transferring O
of O
a O
larger O
number O
of O
sub O
- O
word O
embeddings O
during O
training O
. O

In O
the O
scenario O
of O
Tr B-TaskName
- I-TaskName
En I-TaskName
MT I-TaskName
, O
the O
training O
duration O
is O
even O
shortened O
from O
4.49 O
hours O
( O
i.e. O
, O
about O
269 O
minutes O
) O
to O
2.14 O
, O
compared O
to O
the O
baseline O
model O
. O

Obviously O
, O
the O
time O
that O
Mean B-MethodName
- I-MethodName
PC I-MethodName
consumes O
during O
training O
is O
less O
than O
other O
models O
. O

All O
experiments O
are O
conducted O
on O
a O
single O
NVIDIA O
P100 O
16 O
GB O
GPU O
. O

We O
use O
mixed O
precision O
for O
training O
the O
child O
MT B-TaskName
model O
. O

We O
compare O
the O
training O
time O
consumption O
of O
all O
experiments O
, O
the O
result O
is O
shown O
in O
Table O
5 O
. O

It O
can O
be O
found O
that O
the O
latter O
model O
almost O
always O
outperforms O
the O
former O
model.616 O
. O

Figure O
1 O
shows O
the O
NMT B-TaskName
performance O
obtained O
when O
the O
i O
- O
th O
top O
- O
ranked O
aligned O
sub O
- O
word O
is O
exclusively O
used O
for O
transfer O
, O
as O
well O
as O
the O
aggregation O
of O
topisub O
- O
words O
is O
used O
. O

Aggregating O
and O
normalizing O
embeddings O
of O
all O
possible O
aligned O
sub O
- O
words O
help O
to O
overcome O
the O
problem O
. O

Due O
to O
unavoidable O
errors O
in O
the O
sub O
- O
word O
alignment O
, O
the O
utilization O
of O
a O
single O
aligned O
sub O
- O
word O
for O
embedding O
duplication O
easily O
results O
in O
performance O
degradation O
. O

As O
shown O
in O
Table O
4 O
, O
both B-MethodName
Top-1 I-MethodName
- I-MethodName
PC I-MethodName
and O
Mean B-MethodName
- I-MethodName
PC I-MethodName
still O
outperform O
MI B-MethodName
- I-MethodName
PC I-MethodName
, O
yielding O
an O
improvement O
of O
2.9 B-MetricValue
BLEU B-MetricName
at O
best O
( O
for O
Id!En O
MT O
) O
. O

It O
can O
be O
illustrated O
in O
a O
separate O
experiment O
where O
the O
BPE B-MethodName
( O
Sennrich O
et O
al O
. O
, O
2016b O
) O
tokenizer O
is O
used O
( O
instead O
of O
SentencePiece B-MethodName
( O
Kudo O
and O
Richardson O
, O
2018 O
) O
) O
, O
and O
all O
the O
transfer O
models O
are O
run O
over O
the O
newly O
- O
aligned O
sub O
- O
words O
. O

Both O
the O
models O
generalize O
well O
across O
changes O
in O
the O
input O
sub O
- O
words O
. O

The O
most O
significant O
improvement O
occurs O
for O
My B-MetricName
! I-MetricName
En I-MetricName
MT B-TaskName
, O
reaching O
up O
to O
1.5 B-MetricValue
BLEU B-MetricName
. O

It O
can O
be O
observed O
that O
, O
compared O
to O
MI B-MethodName
- I-MethodName
PC I-MethodName
, O
both O
Top-1 B-MethodName
- I-MethodName
PC I-MethodName
and O
Mean B-MethodName
- I-MethodName
PC I-MethodName
yield O
improvements O
for O
all O
the O
three O
low B-TaskName
- I-TaskName
resource I-TaskName
MT I-TaskName
scenarios O
. O

models O
( O
i.e. O
, O
Top-1 O
and O
Mean O
in O
Section O
3.3 O
) O
are O
additionally O
adopted O
, O
separately O
. O

Model O
My B-MetricName
- I-MetricName
En I-MetricName
Id B-MetricName
- I-MetricName
En I-MetricName
Tr B-MetricName
- I-MetricName
En I-MetricName
Baseline B-MethodName
1.30 B-MetricValue
1.27 B-MetricValue
4.49 B-MetricValue
MI B-MethodName
- I-MethodName
PC I-MethodName
1.30 B-MetricValue
1.35 B-MetricValue
3.53 B-MetricValue
Top-1 B-MethodName
- I-MethodName
PC I-MethodName
1.11 B-MetricValue
1.00 B-MetricValue
3.07 B-MetricValue
Mean B-MethodName
- I-MethodName
PC I-MethodName
0.96 B-MetricValue
0.94 B-MetricValue
2.14 B-MetricValue
Table O
5 O
: O
The O
time O
( O
in O
hour O
) O
that O
different O
MT B-TaskName
models O
consumed O
during O
training O
in O
all O
experiments O
( O
0.9 O
hour O
is O
equivalent O
to O
54 O
minutes O
) O
. O

We O
report O
NMT B-TaskName
performance O
when O
MI B-MethodName
- I-MethodName
PC I-MethodName
is O
used O
to O
enhance O
the O
baseline O
, O
as O
well O
as O
that O
when O
our O
auxiliary O
transfer O
1 O
2 O
3 O
4 O
5 O
6 O
7 O
8 O
9 O
10182022242628BLEU B-MetricName
T O
op O
( O
Single O
): O
My B-MetricName
- I-MetricName
En I-MetricName
T O
op O
( O
Mean O
): O
My B-MetricName
- I-MetricName
EnT I-MetricName
op O
( O
Single O
): O
Id B-MetricName
- I-MetricName
En I-MetricName
T O
op O
( O
Mean O
): O
Id B-MetricName
- I-MetricName
EnT I-MetricName
op O
( O
Single O
): O
Tr B-MetricName
- I-MetricName
En I-MetricName
T O
op O
( O
Mean O
): O
Tr B-MetricName
- I-MetricName
EnFigure I-MetricName
1 O
: O
Comparison O
between O
embedding O
duplication O
of O
a O
single O
aligned O
sub O
- O
word O
( O
denoted O
with O
Single O
) O
and O
that O
of O
multiple O
sub O
- O
words O
( O
Mean O
) O
. O

MI B-MethodName
- I-MethodName
PC I-MethodName
is O
the O
reproduced O
transfer O
model O
in O
terms O
of O
Aji O
et O
al O
. O
( O
2020)s O
study O
, O
in O
which O
only O
the O
embedding O
transference O
of O
morphologicallyidentical O
sub O
- O
words O
is O
used O
. O

5 O
Results O
and O
Analysis O
Table O
3 O
shows O
the O
test O
results O
, O
where O
all O
the O
considered O
ParentChild O
transfer O
models O
are O
marked O
with O
PC O
, O
and O
the O
baseline O
is O
the O
transformer O
- O
based O
NMT B-TaskName
( O
Section O
3.1 O
) O
which O
is O
trained O
merely O
using O
low O
- O
resource O
parallel O
data O
( O
without O
transfer B-TaskName
learning I-TaskName
) O
. O

For O
each O
model O
, O
we O
selected O
the O
checkpoint O
with O
the O
lowest O
perplexity B-MetricName
on O
the O
validation O
set O
for O
testing O
. O

The B-HyperparameterName
learning I-HyperparameterName
rate I-HyperparameterName
was O
set O
to O
5e-5 B-HyperparameterValue
and O
checkpoint B-HyperparameterName
frequency I-HyperparameterName
to O
500 B-HyperparameterValue
updates I-HyperparameterValue
. O

The B-HyperparameterName
maximum I-HyperparameterName
sentence I-HyperparameterName
length I-HyperparameterName
was O
set O
to O
128 B-HyperparameterValue
and O
the B-HyperparameterName
batch I-HyperparameterName
size I-HyperparameterName
to O
64 B-HyperparameterValue
sentences I-HyperparameterValue
. O

Training O
was O
carried O
out O
with O
HuggingFace O
Transformers O
library O
( O
Wolf O
et O
al O
. O
, O
2020 O
) O
using O
the O
Adam O
optimizer O
with O
0.1 B-HyperparameterValue
weight B-HyperparameterName
decay I-HyperparameterName
rate I-HyperparameterName
. O

Each O
source O
language O
was O
tokenized O
using O
SentencePiece B-MethodName
( O
Kudo O
and O
Richardson O
, O
2018 O
) O
with O
50k B-HyperparameterValue
vocabulary B-HyperparameterName
size I-HyperparameterName
. O

When O
training O
and O
developing O
Child O
, O
we O
adopt O
the O
following O
hyperparameters O
. O

On O
the O
contrary O
, O
the O
Child O
NMT B-TaskName
model O
needs O
to O
be O
regulated O
from O
scratch O
. O

4.2 O
Hyperparameters O
We O
use O
an O
off O
- O
the O
- O
shelf O
NMT B-TaskName
model O
as O
Parent O
( O
Section O
3.1 O
) O
, O
whose O
state O
variables O
( O
i.e. O
, O
hyperparameters O
and O
transformer O
parameters O
) O
and O
embedding O
layer O
are O
all O
set O
. O

We O
evaluate O
all O
the O
considered O
NMT B-TaskName
models O
with O
SacreBLEU B-MetricName
( O
Post O
, O
2018 O
) O
. O

The O
statistics O
in O
the O
training O
, O
validation O
and O
test O
sets O
is O
shown O
in O
Table O
2 O
. O

translation O
task O
( O
Bojar O
et O
al O
. O
, O
2017 O
) O
. O

Model O
My B-MetricName
- I-MetricName
En I-MetricName
Id B-MetricName
- I-MetricName
En I-MetricName
Tr B-MetricName
- I-MetricName
En I-MetricName
Baseline B-MethodName
20.5 B-MetricValue
26.0 B-MetricValue
17.0 B-MetricValue
MI B-MethodName
- I-MethodName
PC I-MethodName
21.0 B-MetricValue
27.5 B-MetricValue
17.6 B-MetricValue
Top-1 B-MethodName
- I-MethodName
PC I-MethodName
21.9 B-MetricValue
27.6 B-MetricValue
18.0 B-MetricValue
Mean B-MethodName
- I-MethodName
PC I-MethodName
22.5 B-MetricValue
28.0 B-MetricValue
18.1 B-MetricValue
Table O
3 O
: O
Results O
using O
SentencePiece B-MethodName
tokenizer O
. O

Model O
My B-MetricName
- I-MetricName
En I-MetricName
Id B-MetricName
- I-MetricName
En I-MetricName
Tr B-MetricName
- I-MetricName
En I-MetricName
Baseline B-MethodName
20.2 B-MetricValue
24.5 B-MetricValue
16.5 B-MetricValue
MI B-MethodName
- I-MethodName
PC I-MethodName
20.4 B-MetricValue
24.2 B-MetricValue
16.8 B-MetricValue
Top-1 B-MethodName
- I-MethodName
PC I-MethodName
21.2 B-MetricValue
26.9 B-MetricValue
16.9 B-MetricValue
Mean B-MethodName
- I-MethodName
PC I-MethodName
21.9 B-MetricValue
27.1 B-MetricValue
16.9 B-MetricValue
Table O
4 O
: O
Results O
using O
BPE O
tokenizer O
. O

There O
are O
three O
low O
- O
resource O
parallel O
datasets O
used O
for O
training O
the O
Child O
NMT B-TaskName
model O
, O
including O
Asian B-DatasetName
Language I-DatasetName
Treebank I-DatasetName
( I-DatasetName
ALT I-DatasetName
) I-DatasetName
( O
Ding O
et O
al O
. O
, O
2018 O
) O
, O
PAN O
Localization O
BPPT6and O
the O
corpus O
of O
WMT17 O
news O
6http://www.panl10n.net/english/OutputsIndonesia2.htm615 O
. O

English O
is O
invariably O
specified O
as O
the O
target O
language O
. O

Mean O
We O
adopt O
all O
the O
sub O
- O
words O
in O
vx O
, O
and O
duplicate O
their O
embedding O
information O
by O
the O
normalized O
element O
- O
wise O
aggregation O
( O
where O
, O
ndenotes O
the O
number O
of O
sub O
- O
words O
in O
vx O
): O
8i O
; O
E O
i(x O
) O
= O
X O
x2vxEi(x)=n O
4 O
Experimentation O
4.1 O
Datasets O
and O
Evaluation O
Metric O
We O
evaluate O
the O
transferable B-TaskName
NMT I-TaskName
models O
for O
three O
source O
languages O
( O
My O
, O
I O
d O
and O
Tr O
) O
. O

Top-1 O
We O
take O
the O
top1sub O
- O
word O
xfromvx O
, O
and O
perform O
element O
- O
wise O
embedding O
duplication O
from O
xtox:8i O
; O
E O
i(x O
) O
= O
Ei(x)(iis O
thei O
- O
th O
dimension O
of O
embedding O
E( O
) O
) O
. O

On O
the O
basis O
, O
we O
carry O
out O
two O
duplication O
methods O
as O
below O
. O

Given O
a O
sub O
- O
word O
xinVa O
land O
the O
aligned O
subwords O
vxinD(x O
) O
, O
we O
rank O
vxin O
terms O
of O
the O
frequency O
with O
which O
they O
were O
found O
to O
be O
aligned O
withxin O
the O
parallel O
data O
. O

It O
is O
because O
that O
, O
in O
a O
large O
number O
of O
cases O
, O
there O
is O
more O
than O
one O
high O
- O
resource O
sub O
- O
word O
corresponding O
to O
a O
single O
low O
- O
resource O
sub O
- O
word O
( O
see O
re O
in O
( O
1 O
) O
) O
. O

To O
enable O
the O
transfer O
, O
we O
tackle O
nto-1 O
embedding O
duplication O
. O

Thus O
, O
in O
the O
embedding O
layer O
of O
Child O
, O
we O
extend O
the O
range O
of O
sub O
- O
words O
for O
embedding O
transfer O
, O
including O
both O
the O
identical O
sub O
- O
words O
Voand O
the O
aligned O
Va O
l O
. O

3.3N O
- O
to-1 O
Embedding O
Duplication O
Assume O
that O
Va O
ldenotes O
the O
sub O
- O
words O
in O
lowresource O
vocabulary O
that O
have O
aligned O
sub O
- O
words O
in O
high O
- O
resource O
vocabulary O
, O
the O
mapping O
is O
D(x O
) O
, O
note O
that8x2Va O
l O
, O
D(x)is O
a O
set O
of O
sub O
- O
words O
. O

between O
vocabularies O
( O
Nguyen O
and O
Chiang O
, O
2017 O
) O
, O
and O
thus O
enables O
the O
transfer O
of O
a O
larger O
number O
of O
concrete O
embeddings O
rather O
than O
random O
ones O
. O

Test O
My O
- O
En O
( O
ALT O
) O
18 O
K O
1 O
K O
1 O
K O
Id O
- O
En O
( O
BPPT O
) O
22 O
K O
1 O
K O
1 O
K O
Tr O
- O
En O
( O
WMT17 O
) O
207 O
K O
3 O
K O
3 O
K O
Table O
2 O
: O
Statistics O
for O
low O
- O
resource O
parallel O
datasets O
. O

Val O
. O

It O
motivated O
by O
the O
findings O
that O
the O
use O
of O
sub O
- O
words O
ensures O
a O
sufficient O
overlap O
3https://github.com/robertostling/eomal O
4https://dumps.wikimedia.org O
5https://github.com/attardi/wikiextractorTrain O
. O

Though O
, O
the O
positive O
effect O
on O
transfer B-TaskName
learning I-TaskName
may O
be O
more O
substantial O
than O
negative O
. O

( O
1 O
) O
Word O
Alignment O
: O
| O
produktion$retme O
|Harnstoff$re O
Sub O
- O
word O
Alignment O
: O
| O
produck${re O
, O
tme O
} O
|tion${re O
, O
tme O
} O
|Harn${re O
} O
|stoff${re O
} O
It O
is O
unavoidable O
that O
some O
of O
the O
aligned O
subwords O
are O
non O
- O
canonical O
. O

See O
the O
De!Tr O
example O
in O
( O
1 O
) O
. O

Sub B-TaskName
- I-TaskName
word I-TaskName
Alignment I-TaskName
Given O
a O
pair O
of O
aligned O
bilingual O
words O
, O
we O
construct O
the O
same O
correspondence O
for O
their O
sub O
- O
words O
by O
many O
- O
to O
- O
many O
mappings O
. O

The O
size B-HyperparameterName
of I-HyperparameterName
De I-HyperparameterName
- I-HyperparameterName
En I-HyperparameterName
vocabulary I-HyperparameterName
is O
58 B-HyperparameterValue
K I-HyperparameterValue
. O

The O
obtained O
vocabulary O
of O
each O
low O
- O
resource O
language O
is O
utilized O
for O
sub B-TaskName
- I-TaskName
word I-TaskName
alignment I-TaskName
, O
towards O
the O
mixed O
De O
- O
En O
sub O
- O
word O
vocabulary O
in O
the O
Parent O
NMT B-TaskName
model O
. O

We O
uniformly O
set O
the O
size B-HyperparameterName
of I-HyperparameterName
sub I-HyperparameterName
- I-HyperparameterName
word I-HyperparameterName
vocabulary I-HyperparameterName
to O
50 B-HyperparameterValue
K I-HyperparameterValue
when O
training O
the O
tokenizers O
. O

The O
statistics O
of O
training O
data O
is O
shown O
in O
Table O
1 O
. O

The O
toolkit O
wikiextractor5is O
utilized O
to O
extract O
plain O
texts O
from O
the O
semi O
- O
structured O
data O
. O

The O
tokenizers O
are O
trained O
on O
monolingual O
plain O
texts O
which O
are O
collected O
from O
Wikipedias O
dumps4 O
. O

Sub O
- O
word O
Tokenizer O
We O
train O
a O
sub O
- O
word O
tokenizer O
using O
the O
unigram O
model O
of O
SentencePiece B-MethodName
for O
each O
low O
- O
resource O
language O
, O
including O
My O
, O
I O
d O
and O
Tr O
. O

We O
separately O
train O
Eomal O
on O
the O
low O
- O
resource O
My O
! O
En O
, O
I O
d O
( O
Indonesian)!En O
and O
Tr O
( O
Turkish O
) O
! O
En O
parallel O
data O
( O
Section O
4 O
) O
. O

Eomal O
is O
not O
only O
computationally O
efficient O
but O
able O
to O
perform O
n O
- O
to-1 O
alignment O
. O

It O
is O
developed O
based O
on O
EFMARAL B-MethodName
( O
stling O
et O
al O
. O
, O
2016 O
) O
, O
where O
Gibbs O
sampling O
is O
run O
for O
inference O
on O
Bayesian O
HMM O
models O
. O

Word O
Alignment O
We O
use O
Eomal3to O
achieve O
the O
word O
alignment O
. O

The O
precondition O
is O
to O
produce O
the O
word O
- O
level O
alignment O
and O
equivalently O
assign O
it O
to O
sub O
- O
words O
. O

Token O
My O
113 O
K O
1.1 O
M O
17.4 O
M O
I O
d O
1.1 O
M O
8.3 O
M O
156.2 O
M O
Tr O
705 O
K O
5.8 O
M O
128.2 O
M O
Table O
1 O
: O
Statistics O
of O
monolingual O
Wikipedia O
data O
. O

Sent O
. O

Doc O
. O

1https://github.com/Helsinki-NLP/OPUS-MTtrain O
/ O
blob O
/ O
master O
/ O
models O
/ O
de O
- O
en O
/ O
README.md O
2https://opus.nlpl.eu/614 O
. O

3.2 O
Tokenizer O
and O
Alignment O
We O
strengthen O
Parent O
- O
Child O
transfer O
learning O
by O
additionally O
duplicating O
embeddings O
for O
aligned O
subwords O
( O
between O
low O
and O
high O
- O
resource O
languages O
) O
. O

On O
the O
basis O
, O
we O
fine O
- O
tune O
Child O
on O
the O
low O
- O
resource O
language O
pairs O
, O
such O
as O
the O
considered O
18 O
K O
My O
! O
En O
( O
Burmese!English O
) O
parallel O
data O
in O
our O
experiments O
. O

Both O
the O
transferred O
inner O
parameters O
and O
the O
duplicated O
embeddings O
constitutes O
the O
initial O
state O
of O
the O
Child O
NMT B-TaskName
model O
. O

Further O
, O
we O
randomly O
initialize O
the O
embeddings O
of O
the O
rest O
sub O
- O
words O
Vrin O
the O
Childs O
embedding O
layer O
( O
Vr O
= O
Vl Vo O
) O
, O
where O
random O
sampling O
from O
a O
Gaussian O
distribution O
is O
used O
. O

Thus O
, O
we O
duplicate O
the O
embeddings O
of O
morphologically O
- O
identical O
sub O
- O
words O
Vo O
from O
the O
embedding O
layer O
of O
Parent O
to O
that O
of O
Child O
. O

Assume O
Vh O
denotes O
the O
high O
- O
resource O
( O
e.g. O
, O
the O
aforementioned O
De O
- O
En O
) O
vocabulary O
while O
Vlthe O
low O
- O
resource O
, O
the O
morphologically O
- O
identical O
sub O
- O
words O
Voare O
then O
specified O
as O
the O
ones O
occurring O
in O
both O
VhandVl O
( O
i.e. O
,Vo O
= O
Vh\Vl O
) O
. O

By O
contrast O
, O
the O
embedding O
layer O
of O
Parent O
is O
partially O
transferred O
to O
Child O
, O
which O
has O
been O
proven O
effective O
in O
Aji O
et O
al O
. O
( O
2020)s O
study O
. O

Further O
, O
we O
transfer O
all O
inner O
parameters O
of O
the O
12 O
- O
layer O
transformers O
from O
Parent O
to O
Child O
. O

We O
regard O
this O
NMT B-TaskName
model O
as O
the O
Parent O
. O

The O
publicly O
- O
available O
data O
of O
OPUS B-DatasetName
( O
Tiedemann O
, O
2012 O
) O
is O
used O
for O
training O
, O
which O
comprises O
about O
351.7 O
M O
De!En O
parallel O
sentence O
pairs2 O
. O

Specifically O
, O
we O
adopt O
an O
off O
- O
the O
- O
shelf O
transformerbased O
NMT1which B-TaskName
was O
adequately O
trained O
on O
highresource O
De!En O
( O
German!English O
) O
language O
pairs O
. O

Parent O
- O
Child O
Transfer O
We O
follow O
Zoph O
et O
al O
. O
( O
2016 O
) O
to O
conduct O
Parent O
- O
Child O
transfer O
learning O
. O

Each O
embedding O
is O
specified O
as O
a O
512 B-HyperparameterValue
- O
dimensional O
real O
- O
valued O
vector O
. O

Embedding O
Layer O
As O
usual O
, O
the O
encoder O
is O
coupled O
with O
a O
trainable O
embedding O
layer O
, O
which O
maintains O
a O
fixed O
bilingual O
vocabulary O
and O
trainable O
subword O
embeddings O
. O

In O
this O
paper O
, O
we O
extend O
Aji O
et O
al O
. O
( O
2020)s O
work O
, O
transferring O
embedding O
information O
not O
only O
among O
the O
morphologically O
- O
identical O
sub O
- O
words O
but O
the O
elaborately O
- O
aligned O
sub O
- O
words.3 O
Approach O
3.1 O
Preliminary O
: O
Basic O
Transferable B-TaskName
NMT I-TaskName
We O
follow O
Kim O
et O
al O
. O
( O
2019 O
) O
and O
Aji O
et O
al O
. O
( O
2020 O
) O
to O
build O
neural B-TaskName
MT I-TaskName
( I-TaskName
NMT I-TaskName
) I-TaskName
models O
with O
12 O
- O
layer O
transformers O
( O
Vaswani O
et O
al O
. O
, O
2017 O
) O
, O
in O
which O
the O
first O
6 O
layers O
are O
used O
as O
the O
encoder O
while O
the O
subsequent O
6 O
layers O
the O
decoder O
. O

In O
addition O
, O
Aji O
et O
al O
. O
( O
2020 O
) O
verify O
the O
different O
effects O
of O
various O
transferring O
strategies O
of O
sub O
- O
word O
embeddings O
, O
such O
as O
that O
among O
morphologically O
- O
identical O
sub O
- O
words O
. O

A O
variety O
of O
optimization O
methods O
have O
been O
proposed O
, O
including O
the O
transfer O
learning O
over O
the O
embeddings O
of O
WordPieces B-MethodName
tokens O
( O
Johnson O
et O
al O
. O
, O
2017 O
) O
, O
BPE B-MethodName
sub I-MethodName
- I-MethodName
words I-MethodName
( O
Nguyen O
and O
Chiang O
, O
2017 O
) O
and O
the O
shared O
multilingual O
vocabularies O
( O
Kocmi O
and O
Bojar O
, O
2018 O
; O
Gheini O
and O
May O
, O
2019 O
) O
, O
as O
well O
as O
the O
transference O
that O
is O
based O
on O
the O
artificial O
or O
automatic O
selection O
of O
congeneric O
parent O
language O
pairs O
( O
Dabre O
et O
al O
. O
, O
2017 O
; O
Lin O
et O
al O
. O
, O
2019 O
) O
. O

Transferable B-TaskName
MT I-TaskName
is O
fundamentally O
similar O
to O
multilingual B-TaskName
MT I-TaskName
, O
whereas O
it O
tends O
to O
play O
the O
aforementioned O
Parent O
- O
Child O
game O
( O
Zoph O
et O
al O
. O
, O
2016 O
) O
. O

The O
benefits O
result O
from O
the O
assimilation O
of O
relatively O
extensive O
translation O
experience O
and O
sophisticated O
modes O
from O
high O
- O
resource O
language O
pairs O
. O

Training O
on O
a O
mix O
of O
high O
- O
resource O
and O
low O
- O
resource O
( O
even O
zeroresource O
) O
language O
pairs O
enables O
the O
shareable O
model O
to O
generalize O
across O
language O
boundaries O
( O
Johnson O
et O
al O
. O
, O
2017 O
) O
. O

Multilingual B-TaskName
MT I-TaskName
conducts O
translation O
merely O
using O
a O
single O
neural O
model O
whose O
parameters O
are O
thoroughly O
shared O
by O
multiple O
language O
pairs O
( O
Firat O
et O
al O
. O
, O
2016 O
; O
Lee O
et O
al O
. O
, O
2017 O
; O
Johnson O
et O
al O
. O
, O
2017 O
; O
Gu O
et O
al O
. O
, O
2018a O
, O
b O
) O
, O
including O
a O
variety O
of O
high O
- O
resource O
language O
pairs O
as O
well O
as O
a O
kind O
of O
low O
- O
resource O
( O
the O
target O
language O
is O
fixed O
and O
definite O
) O
. O

To O
systematize O
unsupervised B-TaskName
MT I-TaskName
, O
most O
( O
although O
not O
all O
) O
of O
the O
arts O
leverage O
bilingual O
dictionary O
induction O
( O
Conneau O
et O
al O
. O
, O
2018 O
; O
Sgaard O
et O
al O
. O
, O
2018 O
) O
, O
iterative O
back O
- O
translation O
( O
Sennrich O
et O
al O
. O
, O
2016a O
; O
Lample O
et O
al O
. O
, O
2018b O
) O
and O
denoised O
auto O
- O
encoding O
( O
Vincent O
et O
al O
. O
, O
2008 O
; O
Kim O
et O
al O
. O
, O
2018 O
) O
. O

representation O
space O
( O
Lample O
et O
al O
. O
, O
2018b O
) O
, O
which O
is O
also O
known O
as O
interlingual O
( O
Cheng O
et O
al O
. O
, O
2017 O
) O
or O
cross O
- O
language O
embedding O
space O
( O
Kim O
et O
al O
. O
, O
2018 O
) O
. O

The O
ingenious O
method O
that O
has O
been O
explored O
successfully O
is O
to O
bridge O
the O
source O
and O
target O
languages O
using O
a O
shareable613 O
. O

Unsupervised B-TaskName
MT I-TaskName
conducts O
translation O
merely O
conditioned O
on O
monolingual O
language O
models O
( O
Lample O
et O
al O
. O
, O
2018a O
; O
Artetxe O
et O
al O
. O
, O
2017 O
) O
. O

2 O
Related O
Work O
The O
majority O
of O
previous O
studies O
can O
be O
sorted O
into O
3 O
aspects O
in O
terms O
of O
the O
exploited O
learning O
strategies O
, O
including O
unsupervised B-TaskName
, I-TaskName
multilingual I-TaskName
and I-TaskName
transfer I-TaskName
learning I-TaskName
. O

The O
experiments O
show O
that O
our O
method O
achieves O
substantial O
improvements O
without O
using O
data O
augmentation O
. O

On O
the O
basis O
, O
we O
develop O
a O
normalized O
element O
- O
wise O
embedding O
aggregation O
method O
to O
tackle O
the O
many O
- O
to O
- O
one O
embedding O
duplication O
for O
aligned O
sub O
- O
words O
( O
Section O
3.3 O
) O
. O

We O
use O
the O
unigram O
model O
from O
SentencePiece B-MethodName
( O
Kudo O
and O
Richardson O
, O
2018 O
) O
for O
tokenizing O
, O
and O
carry O
out O
sub O
- O
word O
alignment O
using O
eomal O
( O
Section O
3.2 O
) O
. O

In O
our O
experiments O
, O
both O
the O
parent O
and O
child O
MT B-TaskName
models O
are O
built O
with O
the O
transformer O
- O
based O
( O
Vaswani O
et O
al O
. O
, O
2017 O
) O
encoder O
- O
decoder O
architecture O
( O
Section O
3.1 O
) O
. O

It O
is O
motivated O
by O
the O
assumption O
that O
if O
the O
duplication O
between O
morphologically O
- O
identical O
subwords O
contributes O
to O
cross O
- O
language O
transference O
, O
the O
duplication O
among O
any O
other O
type O
of O
equivalents O
is O
beneficial O
in O
the O
same O
way O
, O
such O
as O
that O
of O
the O
aligned O
sub O
- O
words O
, O
most O
of O
which O
are O
likely O
to O
be O
morphologically O
- O
dissimilar O
but O
semanticallysimilar O
( O
or O
even O
exactly O
the O
same O
) O
. O

We O
attempt O
to O
extend O
Aji O
et O
al O
. O
( O
2020)s O
work O
by O
additionally O
duplicating O
embedding O
information O
among O
the O
aligned O
multilingual O
sub O
- O
words O
. O

One O
of O
the O
distinctive O
contributions O
in O
Aji O
et O
al O
. O
( O
2020)s O
Corresponding O
author.study O
is O
to O
demonstrate O
the O
significant O
effect O
of O
embedding O
duplication O
for O
transference O
, O
when O
it O
is O
conducted O
between O
the O
morphologically O
- O
identical O
sub O
- O
words O
in O
different O
languages O
. O

Further O
, O
the O
child O
inherits O
the O
parents O
properties O
( O
e.g. O
, O
inner O
parameters O
and O
embedding O
layers O
) O
, O
and O
it O
is O
boosted O
by O
the O
fine B-TaskName
- I-TaskName
tuning I-TaskName
over O
low O
- O
resource O
language O
pairs O
. O

In O
order O
to O
achieve O
the O
sufficient O
warm O
- O
up O
effect O
from O
scratch O
, O
the O
parent O
is O
trained O
onhigh O
-resource O
language O
pairs O
. O

In O
the O
parent O
- O
child O
scenario O
, O
a O
parent O
MT B-TaskName
model O
and O
a O
child O
MT B-TaskName
model O
are O
formed O
successively O
, O
using O
the O
same O
neural O
network O
structure O
. O

In O
this O
paper O
, O
we O
follow O
Aji O
et O
al O
. O
( O
2020)s O
work O
to O
utilize O
cross O
- O
language O
transfer O
learning O
, O
of O
which O
the O
parent O
- O
child O
transfer O
framework O
is O
first O
proposed O
by O
Zoph O
et O
al O
. O
( O
2016 O
) O
. O

Unsupervised B-TaskName
, I-TaskName
multilingual I-TaskName
and I-TaskName
transfer I-TaskName
learning I-TaskName
have O
been O
proven O
effective O
in O
the O
low B-TaskName
- I-TaskName
resource I-TaskName
MT I-TaskName
tasks O
, O
grounded O
on O
different O
advantages O
( O
section O
2 O
) O
. O

1 O
Introduction O
Low B-TaskName
- I-TaskName
resource I-TaskName
machine I-TaskName
translation I-TaskName
( I-TaskName
MT I-TaskName
) I-TaskName
is O
challenging O
due O
to O
the O
scarcity O
of O
parallel O
data O
and O
, O
in O
some O
cases O
, O
the O
absence O
of O
bilingual O
dictionaries O
( O
Zoph O
et O
al O
. O
, O
2016 O
; O
Miceli O
Barone O
, O
2016 O
; O
Koehn O
and O
Knowles O
, O
2017 O
; O
Zhang O
et O
al O
. O
, O
2017 O
) O
. O

All O
the O
models O
and O
source O
codes O
in O
the O
experiments O
will O
be O
made O
publicly O
available O
to O
support O
reproducible O
research O
. O

In O
addition O
, O
the O
method O
is O
computationally O
efficient O
which O
reduces O
the O
consumption O
of O
training O
time O
by O
63.8% O
, O
reaching O
the O
duration O
of O
1.6 O
hours O
when O
training O
on O
a O
Tesla O
16 O
GB O
P100 O
GPU O
. O

The O
test O
results O
show O
that O
our O
method O
produces O
substantial O
improvements O
, O
achieving O
the O
BLEU B-MetricName
scores I-MetricName
of B-MetricValue
22.5 I-MetricValue
, O
28.0 B-MetricValue
and O
18.1 B-MetricValue
respectively O
. O

We O
conduct O
experiments O
on O
benchmark O
datasets O
of O
My O
! O
En O
, O
Id!En O
and O
Tr!En O
translation O
scenarios O
. O

Proceedings O
of O
the O
60th O
Annual O
Meeting O
of O
the O
Association O
for O
Computational O
Linguistics O
Volume O
2 O
: O
Short O
Papers O
, O
pages O
613 O
- O
619 O
May O
22 O
- O
27 O
, O
2022 O
c O
2022 O
Association O
for O
Computational O
Linguistics O
Sub O
- O
Word O
Alignment O
is O
Still O
Useful O
: O
A O
Vest O
- O
Pocket O
Method O
for O
Enhancing O
Low O
- O
Resource O
Machine O
Translation O
Minhan O
Xu O
, O
Yu O
Hong O
School O
of O
Computer O
Science O
and O
Technology O
, O
Soochow O
University O
, O
China O
cosmosbreak5712@gmail.com O
, O
tianxianer@gmail.com O
Abstract O
We O
leverage O
embedding O
duplication O
between O
aligned O
sub O
- O
words O
to O
extend O
the O
Parent O
- O
Child O
transfer O
learning O
method O
, O
so O
as O
to O
improve O
lowresource O
machine O
translation O
. O

We O
present O
these O
results O
in O
Table O
7.612 O
. O

We O
analyze O
token O
- O
level O
attention O
assigned O
to O
the O
individual O
terms O
by O
BERT B-MethodName
, O
where O
color O
intensity O
corresponds O
to O
the O
attention O
score O
. O

E O
Qualitative O
Analysis O
To O
further O
analyze O
DM B-MethodName
IX I-MethodName
, O
we O
perform O
a O
qualitative O
study O
by O
choosing O
examples O
from O
the O
dataset O
and O
compare O
the O
predictions O
made O
by O
TMix B-MethodName
and O
DM B-MethodName
IXNT I-MethodName
with O
DM B-MethodName
IX I-MethodName
. O

The O
training O
ofDM B-MethodName
IXis I-MethodName
still O
supervised O
in O
nature O
and O
involves O
learning O
over O
the O
mixed O
label O
of O
the O
individual O
samples O
being O
used O
for O
interpolation O
. O

DM B-MethodName
IXhowever I-MethodName
chooses O
samples O
based O
on O
their O
spatial O
distribution O
in O
the O
embedding O
space O
, O
but O
does O
not O
have O
a O
training O
objective O
optimizing O
on O
their O
position O
in O
the O
embedding O
space O
. O

Hence O
, O
their O
training O
objective O
directly O
involves O
training O
using O
this O
embedding O
vector O
of O
the O
input O
samples O
in O
the O
dataset O
. O

D O
Comparison O
with O
Contrastive O
Learning O
Contrastive O
learning O
involves O
training O
the O
underlying O
model O
to O
learn O
an O
embedding O
space O
in O
which O
similar O
sample O
pairs O
stay O
close O
to O
each O
other O
while O
dissimilar O
ones O
are O
far O
apart O
. O

Parameter O
Value O
Optimizer O
BERTAdam O
Learning B-HyperparameterName
Rate I-HyperparameterName
2e-5 B-HyperparameterValue
Batch B-HyperparameterName
Size I-HyperparameterName
8 B-HyperparameterValue
1 O
; O
2; O
0.9 B-HyperparameterValue
, O
0.999 B-HyperparameterValue
, O
1e-6 B-HyperparameterValue
# O
Epochs O
5 O
Evaluation O
Metric O
F1 B-MetricName
Score I-MetricName
Base O
ModelBERT B-MethodName
- I-MethodName
base I-MethodName
- I-MethodName
uncased I-MethodName
, O
BERT B-MethodName
- I-MethodName
base I-MethodName
- I-MethodName
multilingual I-MethodName
- I-MethodName
uncased I-MethodName
Classifier O
( O
over O
architecture)Linear O
layer O
Hardware O
Nvidia O
P100 O
Table O
8 O
: O
Model O
and O
training O
setup O
for O
DMix B-MethodName
. O

( O
NAG O
: O
Non O
Aggressive O
, O
OAG O
: O
Overtly O
Aggressive O
, O
CAG O
: O
Covertly O
Aggressive O
) O
. O

Green O
denotes O
correct O
prediction O
and O
red O
denotes O
incorrect O
prediction O
. O

The O
color O
intensity O
of O
each O
word O
corresponds O
to O
the O
token O
- O
level O
attention O
score O
. O

CAG O
NAG O
NAG O
Table O
7 O
: O
Qualitative O
analysis O
of O
the O
performance O
obtained O
by O
TMix B-MethodName
, O
DM B-MethodName
IX I-MethodName
- I-MethodName
NT I-MethodName
, O
and O
DM B-MethodName
IX I-MethodName
. O

Sentence O
TMix B-MethodName
DMix I-MethodName
- I-MethodName
NT I-MethodName
DMix I-MethodName
Intellectuals O
and O
the O
so O
- O
called O
Secular O
are O
more O
illiterate O
Uneducated O
and O
illiterate O
OAG O
NAG O
NAG O
She O
must O
be O
sent O
to O
jail O
for O
anti O
national O
activities O
under O
NSA O
and O
PSA O
NAG O
CAG O
CAG O
Lion O
king O
fan O
hit O
like O
OAG O
CAG O
NAG O
kapil O
why O
are O
u O
listening O
to O
these O
chtsss O
.... O
give O
them O
shut O
up O
call O
... O
insane O
idiots O
CAG O
CAG O
OAG O
Great O
Job O
Mr O
Jahangir O
Sir O
I O
support O
you O
NAG O
CAG O
NAG O
Absolute O
fantastic O
movie O
please O
go O
and O
watch O
the O
movie O
first O
. O

C O
Experimental O
Setup O
We O
mention O
the O
optimal O
hyperparameter O
settings O
in O
Table O
8.611 O
. O

We O
perform O
the O
binary B-TaskName
Hate I-TaskName
/ I-TaskName
Offensive I-TaskName
content I-TaskName
classification I-TaskName
task I-TaskName
on O
the O
Hindi O
dataset O
for O
the O
purpose O
of O
our O
experiments O
. O

( O
Mandl O
et O
al O
. O
, O
2019 O
) O
consists O
of O
content O
sampled O
from O
social O
media O
platforms O
. O

8.HASOC B-DatasetName
. O

The O
data O
is O
obtained O
between O
the O
period O
from O
May O
2015 O
to O
July O
2015 O
. O

( O
Kilin O
et O
al O
. O
, O
2017 O
) O
, O
Turkish O
Text B-TaskName
Categorization I-TaskName
dataset O
consists O
of O
3600 O
Turkish O
documents O
( O
news O
/ O
texts O
) O
classified O
into O
6 O
classes O
. O

7.TTC B-DatasetName
. O

The O
data O
has O
been O
collected O
over O
a O
span O
of O
6 O
months O
from O
March O
2018 O
to O
August O
2018 O
and O
has O
3950 O
samples O
classified O
into O
2 O
classes O
. O

( O
Albadi O
et O
al O
. O
, O
2018 O
) O
is O
an O
Arabic O
hate O
speech O
classification O
dataset O
focusing O
mainly O
on O
Saudi O
Twittersphere O
. O

6.AHS B-DatasetName
. O

Samples O
in O
the O
dataset O
are O
annotated O
for O
sentiment B-TaskName
classification I-TaskName
task I-TaskName
. O

( O
Socher O
et O
al O
. O
, O
2013 O
) O
is O
a O
GLUE B-DatasetName
( O
Wang O
et O
al O
. O
, O
2018 O
) O
benchmark O
dataset O
consisting O
of O
English O
sentences O
from O
movie O
reviews O
. O

5.SST-2 B-DatasetName
. O

It O
is O
a O
collection O
of O
English O
sentences O
from O
23 O
linguistic O
publications O
that O
are O
annotated O
for O
their O
grammatical O
acceptability O
. O

( O
Warstadt O
et O
al O
. O
, O
2018 O
) O
, O
abbreviation O
for O
the O
Corpus B-DatasetName
of I-DatasetName
Linguistic I-DatasetName
Acceptability I-DatasetName
is O
a O
part O
of O
GLUE B-DatasetName
( O
Wang O
et O
al O
. O
, O
2018 O
) O
benchmark O
. O

4.CoLA B-DatasetName
. O

( O
Li O
and O
Roth O
, O
2002 O
) O
contains O
the O
same O
set O
of O
questions O
as O
TREC B-DatasetName
- I-DatasetName
Coarse I-DatasetName
grouped O
into O
47 O
fine O
- O
grained O
classes O
instead O
of O
6 O
. O

3.TREC B-DatasetName
- I-DatasetName
Fine I-DatasetName
. O

The O
data O
is O
sourced O
from O
English O
questions O
by O
USC B-DatasetName
, O
TREC B-DatasetName
8 I-DatasetName
, O
TREC B-DatasetName
9 I-DatasetName
, O
TREC B-DatasetName
10 I-DatasetName
and O
manually O
constructed O
questions O
. O

( O
Li O
and O
Roth O
, O
2002 O
) O
, O
The O
Text B-DatasetName
REtrieval I-DatasetName
Conference I-DatasetName
- I-DatasetName
Coarse I-DatasetName
is O
a O
question O
classification O
dataset O
consisting O
of O
6 O
classes O
. O

2.TREC B-DatasetName
- I-DatasetName
Coarse I-DatasetName
. O

For O
the O
purpose O
of O
our O
experiments O
, O
we O
perform O
the O
aggression B-TaskName
classification I-TaskName
task I-TaskName
, O
for O
which O
, O
the O
data O
is O
labelled O
into O
3 O
classes O
based O
on O
the O
level O
of O
aggression O
. O

( O
Bhattacharya O
et O
al O
. O
, O
2020 O
) O
is O
a O
collection O
of O
posts O
, O
comments O
, O
and O
other O
content O
from O
popular O
social O
media O
, O
streaming O
andsharing O
platforms O
. O

B O
Dataset O
Details O
1.TRAC B-DatasetName
. O

We O
compare O
the O
performance O
of O
DM B-MethodName
IXon I-MethodName
standard O
English O
and O
GLUE B-DatasetName
datasets O
with O
additional O
baselines O
and B-TaskName
interpolative I-TaskName
augmentation I-TaskName
methods O
like O
EMix B-MethodName
( O
Jindal O
et O
al O
. O
, O
2020 O
) O
and O
SSMix B-MethodName
( O
Yoon O
et O
al O
. O
, O
2021 O
) O
. O

A O
Extended O
Analysis O
Model O
CoLA B-DatasetName
TREC B-DatasetName
- I-DatasetName
Coarse I-DatasetName
TREC B-DatasetName
- I-DatasetName
Fine I-DatasetName
SST-2 B-DatasetName
XLNet B-MethodName
( O
2019 O
) O
70.20 B-MetricValue
94.58 B-MetricValue
87.49 B-MetricValue
97.00 B-MetricValue
T5 B-MethodName
- I-MethodName
small I-MethodName
( O
2020 O
) O
71.60 B-MetricValue
95.55 B-MetricValue
86.21 B-MetricValue
91.80 B-MetricValue
FNet B-MethodName
( O
2021 O
) O
78.00 B-MetricValue
96.89 B-MetricValue
89.97 B-MetricValue
94.00 B-MetricValue
EFL B-MethodName
( O
2021 O
) O
86.40 B-MetricValue
93.36 B-MetricValue
80.90 B-MetricValue
96.90 B-MetricValue
EMix B-MethodName
( O
2020 O
) O
85.21 B-MetricValue
97.44 B-MetricValue
90.04 B-MetricValue
91.13 B-MetricValue
SSMix B-MethodName
( O
2021 O
) O
86.76 B-MetricValue
97.60 B-MetricValue
90.24 B-MetricValue
92.95 B-MetricValue
DMix B-MethodName
( O
Ours O
) O
95.94 B-MetricValue
97.80 B-MetricValue
91.14 B-MetricValue
92.44 B-MetricValue
Table O
6 O
: O
Performance O
comparison O
with O
additional O
baselines O
and O
interpolative O
augmentation O
methods O
. O

In O
International O
Conference O
on O
Learning O
Representations O
. O

mixup B-MethodName
: O
Beyond O
empirical O
risk O
minimization O
. O

2018 O
. O

Dauphin O
, O
and O
David O
Lopez O
- O
Paz O
. O

Hongyi O
Zhang O
, O
Moustapha O
Cisse O
, O
Yann O
N O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Findings O
of O
the O
Association O
for O
Computational O
Linguistics O
: O
ACL O
- O
IJCNLP O
2021 O
, O
pages O
32253234 O
, O
Online O
. O

SSMix O
: O
Saliency O
- O
based O
span O
mixup O
for O
text O
classification O
. O

2021 O
. O

Soyoung O
Yoon O
, O
Gyuwan O
Kim O
, O
and O
Kyumin O
Park O
. O

In O
NeurIPS O
. O

Xlnet O
: O
Generalized O
autoregressive O
pretraining O
for O
language O
understanding O
. O

2019 O
. O

Le O
. O

Carbonell O
, O
Ruslan O
Salakhutdinov O
, O
and O
Quoc O
V O
. O

Zhilin O
Yang O
, O
Zihang O
Dai O
, O
Yiming O
Yang O
, O
Jaime O
G O
. O

ArXiv O
, O
abs/2109.03481 O
. O

Sequence O
level O
contrastive O
learning O
for O
text O
summarization O
. O

2021 O
. O

Shusheng O
Xu O
, O
Xingxing O
Zhang O
, O
Yi O
Wu O
, O
and O
Furu O
Wei O
. O

arXiv O
preprint O
arXiv:1805.12471 O
. O

Neural O
network O
acceptability O
judgments O
. O

2018 O
. O

Alex O
Warstadt O
, O
Amanpreet O
Singh O
, O
and O
Samuel O
R O
Bowman O
. O

ArXiv O
, O
abs/2104.14690 O
. O

Entailment O
as O
few O
- O
shot O
learner O
. O

2021 O
. O

Sinong O
Wang O
, O
Han O
Fang O
, O
Madian O
Khabsa O
, O
Hanzi O
Mao O
, O
and O
Hao O
Ma O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
2018 O
EMNLP O
Workshop O
BlackboxNLP O
: O
Analyzing O
and O
Interpreting O
Neural O
Networks O
for O
NLP O
, O
pages O
353355 O
, O
Brussels O
, O
Belgium O
. O

GLUE B-MetricName
: O
A O
multi O
- O
task O
benchmark O
and O
analysis O
platform O
for O
natural O
language O
understanding O
. O

2018 O
. O

Alex O
Wang O
, O
Amanpreet O
Singh O
, O
Julian O
Michael O
, O
Felix O
Hill O
, O
Omer O
Levy O
, O
and O
Samuel O
Bowman O
. O

In O
International O
Conference O
on O
Learning O
Representations O
.610 O
. O

Poincare O
glove O
: O
Hyperbolic O
word O
embeddings O
. O

2019 O
. O

Alexandru O
Tifrea O
, O
Gary O
Becigneul O
, O
and O
OctavianEugen O
Ganea O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
2013 O
Conference O
on O
Empirical O
Methods O
in O
Natural O
Language O
Processing O
, O
pages O
16311642 O
, O
Seattle O
, O
Washington O
, O
USA O
. O

Recursive O
deep O
models O
for O
semantic O
compositionality O
over O
a O
sentiment O
treebank O
. O

2013 O
. O

Manning O
, O
Andrew O
Ng O
, O
and O
Christopher O
Potts O
. O

Richard O
Socher O
, O
Alex O
Perelygin O
, O
Jean O
Wu O
, O
Jason O
Chuang O
, O
Christopher O
D O
. O

Springer O
Singapore O
. O

In O
Communications O
, O
Signal O
Processing O
, O
and O
Systems O
, O
pages O
2191 O
2198 O
, O
Singapore O
. O

Aug O
- O
bert O
: O
An O
efficient O
data O
augmentation O
algorithm O
for O
text O
classification O
. O

2020 O
. O

Linqing O
Shi O
, O
Danyang O
Liu O
, O
Gongshen O
Liu O
, O
and O
Kui O
Meng O
. O

ArXiv O
, O
abs/1910.10683 O
. O

Exploring O
the O
limits O
of O
transfer O
learning O
with O
a O
unified O
text O
- O
to O
- O
text O
transformer O
. O

2020 O
. O

Liu O
. O

Shazeer O
, O
Adam O
Roberts O
, O
Katherine O
Lee O
, O
Sharan O
Narang O
, O
Michael O
Matena O
, O
Yanqi O
Zhou O
, O
Wei O
Li O
, O
and O
Peter O
J O
. O

Colin O
Raffel O
, O
Noam O
M O
. O

Association O
for O
Computing O
Machinery O
. O

In O
Proceedings O
of O
the O
11th O
Forum O
for O
Information O
Retrieval O
Evaluation O
, O
FIRE O
19 O
, O
page O
1417 O
, O
New O
York O
, O
NY O
, O
USA O
. O

Overview O
of O
the O
hasoc O
track O
at O
fire O
2019 O
: O
Hate O
speech O
and O
offensive O
content O
identification O
in O
indo O
- O
european O
languages O
. O

2019 O
. O

Thomas O
Mandl O
, O
Sandip O
Modha O
, O
Prasenjit O
Majumder O
, O
Daksh O
Patel O
, O
Mohana O
Dave O
, O
Chintak O
Mandlia O
, O
and O
Aditya O
Patel O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
59th O
Annual O
Meeting O
of O
the O
Association O
for O
Computational O
Linguistics O
and O
the O
11th O
International O
Joint O
Conference O
on O
Natural O
Language O
Processing O
( O
Volume O
1 O
: O
Long O
Papers O
) O
, O
pages O
58345846 O
, O
Online O
. O

MulDA O
: O
A O
multilingual O
data O
augmentation O
framework O
for O
lowresource O
cross O
- O
lingual O
NER O
. O

2021 O
. O

Linlin O
Liu O
, O
Bosheng O
Ding O
, O
Lidong O
Bing O
, O
Shafiq O
Joty O
, O
Luo O
Si O
, O
and O
Chunyan O
Miao O
. O

In O
COLING O
2002 O
: O
The O
19th O
International O
Conference O
on O
Computational O
Linguistics O
. O

Learning O
question O
classifiers O
. O

2002 O
. O

Xin O
Li O
and O
Dan O
Roth O
. O

ArXiv O
, O
abs/2105.03824 O
. O

Fnet O
: O
Mixing O
tokens O
with O
fourier O
transforms O
. O

2021 O
. O

James O
P O
Lee O
- O
Thorp O
, O
Joshua O
Ainslie O
, O
Ilya O
Eckstein O
, O
and O
Santiago O
Ontan O
. O

Journal O
of O
Information O
Science O
, O
43:174185 O
. O

Ttc-3600 O
: O
A O
new O
benchmark O
dataset O
for O
turkish O
text O
categorization O
. O

2017 O
. O

Deniz O
Kilin O
, O
Akin O
Ozcift O
, O
Fatma O
Bozyi O
git O
, O
Pelin O
Yildirim O
, O
Fatih O
Yucalar O
, O
and O
Emin O
Boranda O
g O
. O

International O
Committee O
on O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
28th O
International O
Conference O
on O
Computational O
Linguistics O
, O
pages O
69316936 O
, O
Barcelona O
, O
Spain O
( O
Online O
) O
. O

2020.Augmenting O
NLP O
models O
using O
latent O
feature O
interpolations O
. O

Amit O
Jindal O
, O
Arijit O
Ghosh O
Chowdhury O
, O
Aniket O
Didolkar O
, O
Di O
Jin O
, O
Ramit O
Sawhney O
, O
and O
Rajiv O
Ratn O
Shah O
. O

Association O
for O
Computational O
Linguistics O
. O

What O
does O
BERT B-MethodName
learn O
about O
the O
structure O
of O
language O
? O
In O
Proceedings O
of O
the O
57th O
Annual O
Meeting O
of O
the O
Association O
for O
Computational O
Linguistics O
, O
pages O
36513657 O
, O
Florence O
, O
Italy O
. O

2019 O
. O

Ganesh O
Jawahar O
, O
Benot O
Sagot O
, O
and O
Djam O
Seddah O
. O

arXiv O
preprint O
arXiv:1905.08941 O
. O

Augmenting O
data O
with O
mixup O
for O
sentence O
classification O
: O
An O
empirical O
study O
. O

2019 O
. O

Hongyu O
Guo O
, O
Yongyi O
Mao O
, O
and O
Richong O
Zhang O
. O

arXiv O
preprint O
arXiv:2002.08973 O
. O

Affinity O
and O
diversity O
: O
Quantifying O
mechanisms O
of O
data B-TaskName
augmentation I-TaskName
. O

2020 O
. O

Raphael O
Gontijo O
- O
Lopes O
, O
Sylvia O
J O
Smullin O
, O
Ekin O
D O
Cubuk O
, O
and O
Ethan O
Dyer O
. O

In O
Advances O
in O
Neural O
Information O
Processing O
Systems O
. O

Hyperbolic O
neural O
networks O
. O

2018 O
. O

Octavian O
Ganea O
, O
Gary O
Becigneul O
, O
and O
Thomas O
Hofmann O
. O

arXiv O
preprint O
arXiv:2002.05709 O
. O

A O
simple O
framework O
for O
contrastive O
learning O
of O
visual O
representations O
. O

2020b O
. O

Ting O
Chen O
, O
Simon O
Kornblith O
, O
Mohammad O
Norouzi O
, O
and O
Geoffrey O
Hinton O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
58th O
Annual O
Meeting O
of O
the O
Association O
for O
Computational O
Linguistics O
, O
pages O
2147 O
2157 O
, O
Online O
. O

MixText B-MethodName
: O
Linguistically O
- O
informed O
interpolation O
of O
hidden O
space O
for O
semi B-TaskName
- I-TaskName
supervised I-TaskName
text I-TaskName
classification I-TaskName
. O

2020a O
. O

Jiaao O
Chen O
, O
Zichao O
Yang O
, O
and O
Diyi O
Yang O
. O

European O
Language O
Resources O
Association O
( O
ELRA O
) O
. O

In O
Proceedings O
of O
the O
Second O
Workshop O
on O
Trolling O
, O
Aggression O
and O
Cyberbullying O
, O
pages O
158168 O
, O
Marseille O
, O
France O
. O

Developing O
a O
multilingual O
annotated O
corpus O
of O
misogyny O
and O
aggression O
. O

2020 O
. O

Ojha O
. O

Shiladitya O
Bhattacharya O
, O
Siddharth O
Singh O
, O
Ritesh O
Kumar O
, O
Akanksha O
Bansal O
, O
Akash O
Bhagat O
, O
Yogesh O
Dawer O
, O
Bornini O
Lahiri O
, O
and O
Atul O
Kr O
. O

ACM O
. O

InProceedings O
of O
the O
2018 O
IEEE O
/ O
ACM O
International O
Conference O
on O
Advances O
in O
Social O
Networks O
Analysis O
and O
Mining O
, O
pages O
6976 O
. O

Are O
they O
our O
brothers O
? O
analysis O
and O
detection O
of O
religious O
hate O
speech O
in O
the O
arabic O
twittersphere O
. O

2018 O
. O

References O
Nuha O
Albadi O
, O
Maram O
Kurdi O
, O
and O
Shivakant O
Mishra O
. O

We O
thank O
the O
anonymous O
reviewers O
for O
their O
valuable O
inputs O
. O

6 O
Acknowledgements O
This O
work O
has O
been O
supported O
by O
the O
German O
Federal O
Ministry O
of O
Education O
and O
Research O
( O
BMBF O
) O
as O
a O
part O
of O
the O
Junior O
AI O
Scientists O
program O
under O
the O
reference O
01 O
- O
S20060 O
. O

DM B-MethodName
IXbeing I-MethodName
independent O
of O
the O
underlying O
model O
and O
modality O
, O
holds O
potential O
to O
be O
applied O
on O
text O
, O
speech O
, O
and O
vision O
downstream O
tasks.609 O
. O

DM B-MethodName
IXachieves I-MethodName
state O
- O
of O
- O
the O
- O
art O
results O
over O
existing O
data O
augmentation O
approaches O
on8standard O
and O
multilingual O
datasets O
in O
English O
, O
Arabic O
, O
Turkish O
, O
and O
Hindi O
languages O
, O
requiring O
3 O
times O
less O
number O
of O
iterations O
than O
random B-MethodName
mixup I-MethodName
. O

5 O
Conclusion O
We O
propose O
DM B-MethodName
IX I-MethodName
, O
a O
novel O
data O
augmentation O
technique O
that O
interpolates O
samples O
intelligently O
chosen O
based O
on O
their O
hyperbolic O
distance O
in O
the O
embedding O
space O
. O

This O
shows O
the O
existence O
of O
an O
optimum O
set O
of O
input O
samples O
for O
performing O
Mixup B-MethodName
, O
and O
we O
conjecture O
it O
can O
be O
related O
to O
the O
sparsity O
in O
the O
embedding O
distribution O
of O
different O
languages O
. O

We O
observe O
a O
drop O
in O
performance O
when O
the O
constrain O
becomes O
very O
high O
, O
indicating O
that O
further O
expanding O
the O
sampling O
space O
does O
not O
lead O
to O
more O
diverse O
synthetic O
samples O
. O

We O
observe O
an O
initial O
increase O
in O
the O
performance O
as O
we O
constrain O
the O
embedding O
space O
, O
suggesting O
the O
sampling O
of O
more O
diverse O
samples O
for O
interpolation O
. O

A O
decreasing O
denotes O
a O
larger O
distribution O
space O
for O
sampling O
instances O
for O
Mixup B-MethodName
, O
and O
a O
Tof0%decomposes O
it O
to O
TMix B-MethodName
or O
random B-MethodName
Mixup I-MethodName
. O

We O
perform O
a O
study O
by O
varying O
the O
threshold O
for B-MethodName
DM I-MethodName
IXand I-MethodName
present O
it O
in O
Figure O
3 O
. O

4.5 O
Effect O
of O
Varying O
Thresholds O
020406080708090 O
TREC B-DatasetName
- I-DatasetName
Fine I-DatasetName
AHS I-DatasetName
Threshold O
( O
T%)F1 O
85 O
75 O
70 O
651;0002;0003;000 O
TTCHASOC B-DatasetName
Threshold O
( O
T%)Diversity O
Figure O
3 O
: O
Change O
in O
performance O
in O
terms O
of O
F1 B-MetricName
and O
Diversity B-MetricName
with O
varying O
threshold O
T O
in% O
for O
DM B-MethodName
IX I-MethodName
. O

This O
suggests O
that O
the O
surface O
- O
level O
information O
contained O
in O
layers O
3 O
and O
4 O
( O
Jawahar O
et O
al O
. O
, O
2019 O
) O
is O
effectively O
leveraged O
by O
the O
distance O
- O
aware O
matrix O
M O
, O
leading O
to O
further O
improvements O
over O
purely O
syntactic O
and O
semantic O
information O
in O
layers O
f6;7;9;12 O
g O
. O

Interestingly O
, O
DM B-MethodName
IX I-MethodName
achieves O
the O
best O
performance O
when O
the O
layer O
is O
sampled O
from O
the O
set O
f3;4;6;7;9;12 O
g O
. O

TMix B-MethodName
attains O
the O
best O
performance O
when O
the O
layer O
setf7;9;12gis O
used O
since O
layers O
6 O
, O
7 O
, O
9 O
and O
12 O
contain O
the O
most O
amount O
of O
syntactic O
and O
semantic O
information O
( O
Chen O
et O
al O
. O
, O
2020a O
) O
. O

We O
compare O
the O
performance O
of O
DM B-MethodName
IXand I-MethodName
TMix B-MethodName
for O
different O
sets O
of O
mixup O
layers O
in O
Table O
5 O
. O

4.4 O
Layer O
- O
wise O
Ablation O
Mixup B-MethodName
Layer O
SetCoLA B-DatasetName
HASOC I-DatasetName
AHS I-DatasetName
TMix B-MethodName
DM I-MethodName
IXTMix I-MethodName
DM I-MethodName
IXTMix I-MethodName
DM I-MethodName
IX I-MethodName
{ O
3,4 O
} O
79.45 B-MetricValue
79.70 I-MetricValue
76.86 I-MetricValue
77.46 I-MetricValue
69.37 I-MetricValue
65.66 I-MetricValue
{ O
0 O
, O
1 O
, O
2 O
} O
80.18 B-MetricValue
94.08 I-MetricValue
76.39 I-MetricValue
77.99 I-MetricValue
69.28 I-MetricValue
71.98 I-MetricValue
{ O
6 O
, O
7 O
, O
9 O
} O
82.91 B-MetricValue
94.63 I-MetricValue
77.12 I-MetricValue
79.44 I-MetricValue
70.11 I-MetricValue
73.45 I-MetricValue
{ O
7 O
, O
9 O
, O
12 O
} O
85.30 B-MetricValue
95.63 I-MetricValue
77.44 I-MetricValue
80.19 I-MetricValue
70.19 I-MetricValue
74.32 I-MetricValue
{ O
3 O
, O
4 O
, O
6 O
, O
7 O
, O
9 O
, O
12 O
} O
84.03 B-MetricValue
95.94 I-MetricValue
76.99 I-MetricValue
80.27 I-MetricValue
70.03 I-MetricValue
74.98 I-MetricValue
Table O
5 O
: O
Layer O
- O
wise O
ablation O
( O
F1 B-MetricName
scores I-MetricName
) O
when O
performing O
interpolative B-TaskName
augmentations I-TaskName
. O

This O
suggests O
that O
the O
selection O
of O
inputs O
for O
interpolation O
is O
more O
important O
than O
the O
mixing O
ratio O
when O
performing O
interpolative B-TaskName
regularization I-TaskName
. O

Using O
matrix O
Mfor O
sample O
selection O
obtains O
larger O
improvements O
compared O
to O
using O
it O
as O
the O
ratio O
for O
performing O
mixup O
. O

We O
observe O
that O
both O
the O
applications O
of O
matrix O
Mlead O
to O
improvements O
over O
TMix B-MethodName
. O

We O
probe O
the O
individual O
impact O
of O
using O
matrix O
M O
for O
distance O
- O
based O
sample O
selection O
and O
using O
it O
for O
performing O
mixup O
in O
Table O
4 O
. O

M B-MethodName
- I-MethodName
Threshold I-MethodName
denotes O
thatMis O
used O
to O
select O
samples O
based O
on O
the O
distance O
and O
mixup O
is O
performed O
with O
a O
random O
ratio O
. O

MRatio B-MethodName
denotes O
Mis O
used O
only O
for O
performing O
mixup O
and O
sample O
selection O
is O
random O
. O

4.3 O
Impact O
of O
Sample O
Selection O
and O
Distance O
- O
Aware O
Mixing O
Ratio O
Model O
TTC B-DatasetName
TREC I-DatasetName
- I-DatasetName
Coarse I-DatasetName
AHS I-DatasetName
TMix I-DatasetName
91.30 B-MetricValue
97.52 I-MetricValue
70.19 I-MetricValue
+ B-MethodName
M I-MethodName
- I-MethodName
Ratio I-MethodName
91.66 B-MetricValue
96.90 I-MetricValue
72.43 I-MetricValue
+ B-MethodName
M I-MethodName
- I-MethodName
Threshold I-MethodName
92.02 B-MetricValue
97.10 I-MetricValue
73.31 I-MetricValue
DMix B-MethodName
92.16 B-MetricValue
97.80 I-MetricValue
74.98 I-MetricValue
Table O
4 O
: O
Ablation O
study O
over O
matrix O
M(F1 B-MetricName
scores I-MetricName
) O
. O

random B-MethodName
Mixup I-MethodName
, O
and O
hence O
is O
more O
generalizable O
and O
effective O
across O
languages O
. O

TMix B-MethodName
DMix I-MethodName
- I-MethodName
NT I-MethodName
DMix1;0002;0003;0004;000 I-MethodName
HASOC#Iterations O
TMix B-MethodName
DMix I-MethodName
- I-MethodName
NT I-MethodName
DMix1;0002;0003;0004;000 I-MethodName
TRAC B-DatasetName
Figure O
2 O
: O
Diversity O
comparison O
of O
TMix B-MethodName
with O
DM B-MethodName
IX I-MethodName
and O
DM B-MethodName
IX I-MethodName
- I-MethodName
NT I-MethodName
as O
number O
of O
training O
steps O
required O
to O
achieve O
benchmark O
F1 B-MetricName
scores I-MetricName
( O
TRAC:75 B-DatasetName
, O
HASOC:77 B-DatasetName
) O
. O

DM B-MethodName
IXrequires I-MethodName
3times O
less O
number O
of O
iterations O
on O
an O
average O
compared O
to O
TMix B-MethodName
, O
or608 O
. O

Since O
DM B-MethodName
IXselects I-MethodName
samples O
for O
Mixup B-MethodName
in O
an O
adaptive O
distance O
- O
aware O
manner O
, O
it O
is O
able O
to O
generate O
more O
diverse O
and O
suitable O
interpolations O
leading O
to O
faster O
generalization O
of O
the O
underlying O
base O
model O
. O

We O
observe O
that O
across O
all O
datasets O
, O
DM B-MethodName
IX I-MethodName
achieves O
a O
benchmark O
F1 B-MetricName
score I-MetricName
in O
less O
number O
of O
training O
iterations O
compared O
to O
TMix B-MethodName
( O
Figure O
2 O
) O
. O

4.2 O
Analyzing O
Convergence O
of O
DM B-MethodName
IX I-MethodName
We O
validate O
" O
Does O
DM B-MethodName
IXconverge I-MethodName
faster O
than O
TMix B-MethodName
? O
" O
. O

We O
observe O
that O
for O
all O
variants O
, O
the O
non O
- O
trainable O
counterparts O
perform O
poorer O
than O
the O
trainable O
counterparts O
, O
indicating O
that O
M O
is O
able O
to O
capture O
sample O
- O
specific O
information O
relative O
to O
other O
samples O
, O
generating O
more O
suitable O
sample O
selection O
and O
mixing O
ratio O
for O
performing O
interpolative B-TaskName
data I-TaskName
augmentation I-TaskName
. O

These O
methods O
have O
matrix O
Mfixed O
, O
and O
only O
select O
samples O
based O
on O
their O
relative O
positions O
in O
the O
embedding O
space O
. O

We O
also O
compare O
DM B-MethodName
IXand I-MethodName
its O
variants O
with O
their O
nontrainable O
versions O
( O
denoted O
by O
-NT B-MethodName
in O
Table O
3 O
) O
. O

present O
in O
sentence O
representations O
, O
leading O
to O
better O
comparisons O
and O
sample O
selection O
. O

Improvements O
are O
shown O
with O
blue O
. O
, O
show O
significant O
( O
p<0:01 O
) O
improvement O
over O
TMix B-MethodName
and O
DM B-MethodName
IX I-MethodName
- I-MethodName
NT I-MethodName
, O
respectively O
. O

Dataset O
TMixEuc B-MethodName
- I-MethodName
DM I-MethodName
IX I-MethodName
NTDM I-MethodName
IX I-MethodName
NTEuc I-MethodName
- I-MethodName
DM I-MethodName
IXDM I-MethodName
IX I-MethodName
TRAC B-DatasetName
75.41 B-MetricValue
76.5278.1677.0278.67 I-MetricValue
TREC B-DatasetName
- I-DatasetName
Coarse I-DatasetName
97.52 B-MetricValue
97.55 I-MetricValue
97.66 I-MetricValue
97.53 I-MetricValue
97.80 I-MetricValue
TREC B-DatasetName
- I-DatasetName
Fine I-DatasetName
90.16 B-MetricValue
89.70 I-MetricValue
90.20 I-MetricValue
89.12 I-MetricValue
91.14 I-MetricValue
CoLA B-DatasetName
85.30 B-MetricValue
85.7386.8186.2395.94 I-MetricValue
SST-2 B-DatasetName
91.05 B-MetricValue
91.15 I-MetricValue
92.3191.9292.44 I-MetricValue
AHS B-DatasetName
70.19 B-MetricValue
72.2374.6572.4174.98 I-MetricValue
TTC B-DatasetName
91.30 B-MetricValue
90.66 I-MetricValue
91.40 I-MetricValue
91.50 I-MetricValue
92.16 I-MetricValue
HASOC B-DatasetName
77.44 B-MetricValue
78.9679.9679.3880.27 I-MetricValue
Table O
3 O
: O
Ablation O
study O
of O
DM B-MethodName
IXwith I-MethodName
distance O
constraints O
using O
different O
similarity O
techniques O
( O
average O
of O
10 O
runs O
) O
. O

This O
suggests O
that O
the O
hyperbolic O
space O
is O
more O
capable O
of O
capturing O
the O
complex O
hierarchical O
information O
1We O
provide O
an O
extended O
comparison O
with O
other O
baselines O
in O
the O
Appendix O
. O
Dataset O
f+WMix B-MethodName
+ I-MethodName
SMix I-MethodName
+ I-MethodName
TMix I-MethodName
+ I-MethodName
DMix I-MethodName
TRAC B-DatasetName
72.52 B-MetricValue
73.52 B-MetricValue
74.20 B-MetricValue
75.41 B-MetricValue
78.67 B-MetricValue
TREC B-DatasetName
- I-DatasetName
Coarse I-DatasetName
97.08 B-MetricValue
96.10 B-MetricValue
96.59 B-MetricValue
97.52 B-MetricValue
97.80 B-MetricValue
TREC B-DatasetName
- I-DatasetName
Fine I-DatasetName
86.86 B-MetricValue
87.13 B-MetricValue
87.89 B-MetricValue
90.16 B-MetricValue
91.14 B-MetricValue
CoLA B-DatasetName
84.91 B-MetricValue
84.95 B-MetricValue
85.14 B-MetricValue
85.30 B-MetricValue
95.94 B-MetricValue
SST-2 B-DatasetName
90.32 B-MetricValue
91.34 B-MetricValue
91.21 B-MetricValue
91.66 B-MetricValue
92.44 B-MetricValue
AHS B-DatasetName
66.39 B-MetricValue
67.10 B-MetricValue
68.30 B-MetricValue
70.19 B-MetricValue
74.98 B-MetricValue
TTC B-DatasetName
91.10 B-MetricValue
90.18 B-MetricValue
91.15 B-MetricValue
91.30 B-MetricValue
92.16 B-MetricValue
HASOC B-DatasetName
76.13 B-MetricValue
77.24 B-MetricValue
76.30 B-MetricValue
77.44 B-MetricValue
80.27 B-MetricValue
Table O
2 O
: O
Performance O
comparison O
in O
terms O
of O
F1 B-MetricName
score I-MetricName
of O
baseline O
methods O
with O
DM B-MethodName
IX(average I-MethodName
of O
10 O
runs). O
shows O
significant O
( O
p<0:01 O
) O
improvement O
over O
TMix B-MethodName
. O

Within O
distanceconstrained O
Mixup B-MethodName
, O
we O
observe O
that O
DM B-MethodName
IX I-MethodName
, O
the O
hyperbolic O
distance O
variant O
outperforms O
Euclidean O
distance O
( O
EucDM B-MethodName
IX I-MethodName
) O
measures O
( O
Table O
3 O
) O
. O

4 O
Results O
and O
Analysis O
4.1 O
Performance O
Comparison O
and O
Ablation O
We O
observe O
that O
distance O
- O
constrained O
Mixup B-MethodName
significantly O
( O
p<0:01 O
) O
outperforms O
all O
baselines O
across O
the O
datasets O
( O
Table O
2 O
) O
validating O
that O
similaritybased O
sample O
selection O
improves O
model O
performance O
, O
likely O
owing O
to O
enhanced O
diversity O
or O
minimizing O
sparsification O
across O
tasks O
. O

Diversity O
Following O
Gontijo O
- O
Lopes O
et O
al O
. O
( O
2020 O
) O
, O
we O
use O
diversity O
defined O
as O
the O
number O
of O
training O
steps O
required O
to O
obtain O
a O
benchmark O
F1 B-MetricName
score I-MetricName
. O

F1We B-MetricName
use O
F1 B-MetricName
score I-MetricName
to O
evaluate O
the O
classification B-TaskName
performance O
of O
DM B-MethodName
IXand I-MethodName
its O
variants O
. O

3.2 O
Evaluation O
We O
compare O
DM B-MethodName
IXwith I-MethodName
word I-MethodName
- I-MethodName
mixup I-MethodName
( I-MethodName
WMix I-MethodName
) I-MethodName
and O
sentence B-MethodName
- I-MethodName
mixup I-MethodName
( I-MethodName
SMix I-MethodName
) I-MethodName
( O
Guo O
et O
al O
. O
, O
2019 O
) O
, O
and O
interpolative B-MethodName
Mixup I-MethodName
( I-MethodName
TMix I-MethodName
) I-MethodName
( O
Chen O
et O
al O
. O
, O
2020a)1 O
. O

Due O
to O
resource O
constraints O
, O
we O
only O
use10;000samples O
of O
SST-2 B-DatasetName
for O
training O
, O
but O
do O
not O
change O
the O
validation O
and O
test O
split O
. O

We O
use O
BERT B-MethodName
for O
English O
and O
mBERT B-MethodName
for O
other O
languages O
as O
the O
base O
model O
ffor O
our O
experiments O
, O
and O
their O
[ O
CLS O
] O
token O
representation O
as O
the O
sentence O
embeddings O
to O
calculate O
the O
distances O
( O
Equation O
5 O
) O
. O

All O
hyperparameters O
were O
selected O
based O
on O
validation O
F1 B-MetricName
- I-MetricName
score I-MetricName
. O

For O
the O
baselines O
, O
we O
sample O
rfrom O
a O
beta O
distribution O
following O
previous O
works O
. O

We O
use O
a O
learning B-HyperparameterName
rate I-HyperparameterName
of O
2e-5 B-HyperparameterValue
, O
batch B-HyperparameterName
size I-HyperparameterName
of O
8 B-HyperparameterValue
and O
a O
weight B-HyperparameterName
decay I-HyperparameterName
of O
0.01 B-HyperparameterValue
for O
all O
the O
combinations O
, O
DM B-MethodName
IX I-MethodName
, O
DMix B-MethodName
- I-MethodName
NT I-MethodName
, O
and O
Mixup B-MethodName
. O

3.1 O
Training O
Setup O
DM B-MethodName
IXis I-MethodName
performed O
over O
a O
layer O
randomly O
sampled O
from O
all O
the O
layers O
of O
the O
model O
. O

Dataset O
Language O
Classes O
Samples O
TRAC B-DatasetName
( O
2020 O
) O
English O
3 O
5,329 O
TREC B-DatasetName
- I-DatasetName
Coarse I-DatasetName
( O
2002 O
) O
English O
6 O
5,952 O
TREC B-DatasetName
- I-DatasetName
Fine I-DatasetName
( O
2002 O
) O
English O
47 O
5,952 O
CoLA B-DatasetName
( O
2018 O
) O
English O
2 O
10,657 O
SST-2 B-DatasetName
( O
2013 O
) O
English O
2 O
12,693 O
AHS B-DatasetName
( O
2018 O
) O
Arabic O
2 O
3,950 O
TTC B-DatasetName
( O
2017 O
) O
Turkish O
6 O
3,600 O
HASOC B-DatasetName
( O
2019 O
) O
Hindi O
2 O
5,983 O
Table O
1 O
: O
Datasets O
, O
languages O
, O
# O
classes O
and O
# O
samples O
. O

3 O
Experimental O
Setup O
We O
evaluate O
DM B-MethodName
IXon I-MethodName
standard O
English O
, O
GLUE B-MetricName
, O
and O
multi O
- O
lingual O
datasets O
in O
4languages O
( O
Table O
1).607 O
. O

We O
optimize O
the O
network O
using O
KL B-MetricName
Divergence I-MetricName
loss I-MetricName
between O
the O
final O
outputg O
( O
hK)and O
mixed O
label O
y0 O
= O
DMixup B-MethodName
( O
yi;yj O
) O
, O
which O
also O
trains O
matrix O
Mend O
- O
to O
- O
end O
. O

The O
final O
hidden O
state O
output O
hKis O
passed O
through O
a O
multi O
- O
layer O
perceptron O
( O
MLP O
) O
g O
for O
classification B-TaskName
. O

To O
perform O
DM B-MethodName
IX I-MethodName
, O
we O
operate O
DMixup B-MethodName
over O
samples O
xiand O
a O
random O
sample O
xj2Si O
, O
DM B-MethodName
IX(xi)=DMixup I-MethodName
( O
xi;xj O
) O
; O
xj2Si O
( O
10 O
) O
We O
replace O
the O
Mixup B-MethodName
operation O
in O
Equation O
3 O
with O
the O
DM B-MethodName
IXoperation I-MethodName
in O
Equation O
10 O
to O
evaluateDM B-MethodName
IX I-MethodName
. O

To O
create O
this O
set O
, O
we O
select O
samples O
havingMijabove O
a O
threshold O
, O
Si O
= O
fxkjxk2X;Mik O
g O
( O
9 O
) O
We O
use O
to O
control O
the O
diversity O
of O
the O
selected O
samples O
. O
= O
Tmax(Mi O
) O
at O
each O
step O
of O
the O
training O
, O
where O
Tis B-HyperparameterName
a O
hyperparameter O
2(0;1 O
) O
. O

To O
perform O
DM B-MethodName
IXover I-MethodName
a O
sample O
xi O
, O
we O
create O
a O
set O
Si O
of O
the O
most O
diverse O
samples O
in O
the O
dataset O
based O
on O
a O
threshold O
. O

To O
perform O
interpolative B-MethodName
Mixup I-MethodName
at O
a O
layer O
k[1;K O
] O
, O
we O
calculate O
the O
latent O
representations O
separately O
for O
the O
inputs O
for O
layers O
before O
the O
k O
- O
th O
layer O
. O

We O
initialize O
Musing O
hyperbolic O
distance O
Dh O
and O
normalize O
it O
row O
wise O
to O
scale O
the O
values O
, O
Mij O
= O
Dh(ei;ej);Mi O
= O
Mi O
max(Mi)(7 O
) O
Using O
learnable O
matrix O
M O
, O
we O
change O
the O
Mixup B-MethodName
formulation O
( O
Equation O
1 O
) O
for O
samples O
iandjand O
define O
DMixup B-MethodName
as O
, O
DMixup O
( O
xi;xj O
) O
= O
( O
1 Mij)xi+Mijxj(8 O
) B-MethodName
DM I-MethodName
IXis I-MethodName
defined O
for O
one O
sample O
as O
compared O
to B-MethodName
Mixup I-MethodName
which O
is O
defined O
for O
two O
samples O
. O

The O
hyperbolic O
distance O
Dhbetween O
sentence O
embeddingsei O
= O
f(xi)andej O
= O
f(xj)is O
, O
Dh(ei;ej O
) O
= O
2 O
tan 1(k( ej)eik O
) O
( O
5 O
) O
Here,represents O
the O
Mbius O
addition O
for O
a O
pair O
of O
points O
x;y2B O
, O
defined O
as O
, O
xy:=(1 O
+ O
2hx;yi+jjyjj2)x+ O
( O
1 jjxjj2)y O
1 O
+ O
2hx;yi+jjxjj2jjyjj2(6 O
) O
, O
h:;:i O
, O
jjjj O
are O
Euclidean O
inner O
product O
and O
norm O
. O

We O
use O
the O
hyperbolic O
distance O
as O
our O
similarity O
metric O
to O
initialize O
matrix O
Mas O
it O
effectively O
captures O
the O
hierarchical O
structures O
and O
complex O
geometries O
that O
natural O
language O
text O
possesses O
. O

To O
perform O
DM B-MethodName
IX I-MethodName
, O
we O
first O
create O
a O
learnable O
matrix O
MNxN O
, O
which O
is O
used O
to O
perform O
Mixup B-MethodName
between O
pair O
ofsamples O
. O

Hence O
, O
we O
formulate O
distance O
- O
aware O
Mixup B-MethodName
, O
or O
DM B-MethodName
IX I-MethodName
. O

Augmenting O
the O
sample O
selection O
strategy O
with O
intelligence O
derived O
from O
the O
spatial O
distribution O
of O
the O
samples O
to O
be O
mixed O
can O
lead O
to O
improved O
generalization O
. O

For O
input O
sample O
xi O
, O
we O
lethi O
ndenote O
the O
hidden O
state O
representations O
at O
layer O
n O
, O
hi O
n O
= O
f;n(hi O
n 1 O
) O
; O
n2[1;k O
] O
hj O
n O
= O
f;n(hj O
n 1 O
) O
; O
n2[1;k](2 O
) O
We O
then O
perform B-MethodName
Mixup I-MethodName
over O
individual O
hidden O
state O
representations O
hi O
k;hj O
kfrom O
layerkas O
, O
hk O
= B-MethodName
Mixup I-MethodName
( O
hi O
k;hj O
k)=rhi O
k+ O
( O
1 r)hj O
k(3 O
) O
The O
mixed O
hidden O
representation O
hkis O
used O
as O
the O
input O
for O
the O
continuing O
forward O
pass O
, O
hn O
= O
f;n(hn 1);n2[k+ O
1;K O
] O
( O
4 O
) O
2.2 B-MethodName
DM I-MethodName
IX O
: O
Distance O
- O
aware B-MethodName
Mixup I-MethodName
Though B-MethodName
Mixup I-MethodName
helps O
generalize O
models O
better O
, O
it O
selects O
samples O
completely O
randomly O
for O
interpolation O
. O

Let O
f()be O
a O
model O
with O
parameters O
havingKlayers B-HyperparameterName
, O
f;n()denotes O
the O
n O
- O
th O
layer O
of O
the O
model O
and O
hnis O
the O
hidden O
space O
vector O
at O
layernforn2[1;K]andh0denotes B-HyperparameterName
the O
input O
vector O
. O

We O
propose O
DM B-MethodName
IX I-MethodName
, O
an O
adaptive O
distance O
- O
aware O
interpolative O
data B-TaskName
augmentation I-TaskName
method O
. O

Instead O
of O
choosing O
random O
inputs O
from O
the O
complete O
training O
distribution O
as O
in O
the O
case O
of O
Mixup B-MethodName
, O
DM B-MethodName
IXsamples I-MethodName
instances O
based O
on O
the O
( O
dis)similarity O
between O
latent O
representations O
of O
samples O
in O
the O
hyperbolic O
space O
. O

2.1 O
Interpolative B-MethodName
Mixup I-MethodName
Given O
two O
data O
samples O
xi;xj2Xwith O
labels O
yi;yj2Y O
, O
andi;j2[1;N O
] O
, O
Mixup B-MethodName
( O
Zhang O
et O
al O
. O
, O
2018 O
) O
uses O
linear O
interpolation O
with O
mixing O
ratio O
r O
to O
generate O
the O
synthetic O
sample O
x0and O
corresponding O
mixed O
label O
y0 O
, O
x0 O
= O
Mixup O
( O
xi;xj O
) O
= O
rxi+ O
( O
1 r)xj O
y0 O
= O
Mixup O
( O
yi;yj O
) O
= O
ryi+ O
( O
1 r)yj(1 O
) B-MethodName
Interpolative I-MethodName
Mixup I-MethodName
( O
Chen O
et O
al O
. O
, O
2020a O
) O
performs O
linear O
interpolation O
over O
the O
latent O
representations O
of O
models O
. O

We O
first O
introduce O
interpolative B-MethodName
Mixup I-MethodName
( O
2.1 O
) O
, O
and O
then O
formulate O
DM B-MethodName
IXby I-MethodName
leveraging O
the O
relative O
sample O
distribution O
in O
the O
hyperbolic O
space O
( O
2.2 O
) O
. O

2 O
Methodology O
We O
present O
an O
overview O
of O
DM B-MethodName
IXin I-MethodName
Figure O
1 O
. O

while O
being O
generalizable O
across O
tasks O
, O
datasets O
, O
and O
modalities O
. O

DM B-MethodName
IXachieves I-MethodName
threshold O
F1 B-MetricName
scores I-MetricName
with O
3times O
less O
number O
of O
iterations O
than O
random O
Mixup606 B-MethodName
. O

DM B-MethodName
IXoutperforms I-MethodName
existing O
interpolative O
data B-TaskName
augmentation I-TaskName
baselines O
for O
8benchmark O
sentence B-TaskName
classification I-TaskName
tasks O
across O
four O
languages O
. O

Our O
contributions O
are O
: O
We O
propose O
DM B-MethodName
IX I-MethodName
, O
a O
novel O
adaptive O
distanceaware O
interpolative O
regularization O
method O
developed O
over O
the O
spatial O
distribution O
of O
dataset O
sampled O
in O
the O
hyperbolic O
space O
. O

Furthermore O
, O
DM B-MethodName
IXperforms I-MethodName
interpolations O
with O
trainable O
pair O
- O
wise O
parameters O
derived O
from O
the O
spatial O
distribution O
of O
the O
samples O
rather O
than O
sampling O
mixing O
ratios O
randomly O
from O
standard O
distributions O
, O
making O
it O
adaptive O
for O
pair O
- O
wise O
interpolation O
. O

Hyperbolic O
geometry O
presents O
a O
solution O
in O
defining O
similarity O
between O
latent O
representations O
( O
Tifrea O
et O
al O
. O
, O
2019 O
) O
. O

Further O
, O
natural O
language O
possesses O
hierarchical O
structures O
and O
complex O
geometries O
, O
which O
the O
standard O
Euclidean O
space O
can O
not O
capture O
effectively O
( O
Ganea O
et O
al O
. O
, O
2018 O
) O
. O

The O
relative O
spatial O
position O
of O
samples O
can O
be O
leveraged O
to O
produce O
more O
suitable O
synthetic O
inputs O
for O
training O
underlying O
models O
( O
Xu O
et O
al O
. O
, O
2021 O
) O
. O

2020b O
) O
. O

Figure O
1 O
: O
Overview O
of O
DM B-MethodName
IXshowing I-MethodName
the O
sample O
selection O
based O
on O
the O
hyperbolic O
distance O
and O
using O
distance O
matrix O
Mto O
perform O
interpolation O
. O

While O
randomization O
in O
Mixup O
helps O
, O
augmenting O
Mixups O
sample O
selection O
strategy O
with O
logic O
based O
on O
the O
similarity O
of O
the O
samples O
to O
be O
mixed O
can O
lead O
to O
improved O
generalization O
( O
Chen O
et O
al O
. O
, O
Equal O
contribution O
. O

However O
, O
Mixup O
does O
not O
account O
for O
the O
spatial O
distribution O
of O
dataset O
samples O
, O
but O
choosing O
samples O
randomly O
for O
interpolation O
- O
based O
augmentation O
. O

Mixup O
over O
latent O
representations O
of O
inputs O
leads O
to O
further O
improvements O
( O
Chen O
et O
al O
. O
, O
2020a O
) O
. O

Interpolationbased O
augmentation O
techniques O
such O
as O
Mixup O
( O
Zhang O
et O
al O
. O
, O
2018 O
) O
have O
shown O
improved O
performance O
across O
different O
modalities O
. O

Data O
augmentation O
techniques O
can O
efficiently O
use O
this O
limited O
training O
data O
( O
Liu O
et O
al O
. O
, O
2021 O
; O
Shi O
et O
al O
. O
, O
2020 O
) O
. O

1 O
Introduction O
Deep O
learning O
models O
, O
though O
effective O
for O
many O
applications O
are O
prone O
to O
overfitting O
in O
absence O
of O
sufficient O
training O
data O
. O

DM B-MethodName
IX I-MethodName
being O
generalizable O
, O
can O
be O
applied O
to O
various O
tasks O
, O
models O
and O
modalities O
. O

We O
probe O
the O
effectiveness O
of O
DM B-MethodName
IXin I-MethodName
conjunction O
with O
various O
similarity O
measures O
and O
qualitatively O
analyze O
the O
different O
components O
. O

DM B-MethodName
IX I-MethodName
achieves O
state O
- O
of O
- O
the O
- O
art O
results O
on O
sentence O
classification O
over O
existing O
data O
augmentation O
methods O
on O
8benchmark O
datasets O
across O
English O
, O
Arabic O
, O
Turkish O
, O
and O
Hindi O
languages O
while O
achieving O
benchmark O
F1 B-MetricName
scores O
in O
3 O
times O
less O
number O
of O
iterations O
. O

DM B-MethodName
IXleverages I-MethodName
the O
hyperbolic O
space O
as O
a O
similarity O
measure O
among O
input O
samples O
for O
a O
richer O
encoded O
representation O
. O

We O
extend O
Mixup O
and O
propose O
DM O
IX O
, O
an O
adaptive O
distanceaware O
interpolative O
Mixup O
that O
selects O
samples O
based O
on O
their O
diversity O
in O
the O
embedding O
space O
. O

Proceedings O
of O
the O
60th O
Annual O
Meeting O
of O
the O
Association O
for O
Computational O
Linguistics O
Volume O
2 O
: O
Short O
Papers O
, O
pages O
606 O
- O
612 O
May O
22 O
- O
27 O
, O
2022 O
c O
2022 O
Association O
for O
Computational O
Linguistics O
DM O
IX O
: O
Adaptive O
Distance O
- O
aware O
Interpolative O
Mixup O
Ramit O
Sawhneyy O
, O
Megh O
Thakkarx O
, O
Shrey O
Panditx O
, O
Ritesh O
Soun| O
Di O
JinF O
, O
Diyi O
Yang4 O
, O
Lucie O
Fleky O
yConversational O
AI O
and O
Social O
Analytics O
( O
CAISA O
) O
Lab O
, O
University O
of O
Marburg O
xBITS O
, O
Pilani O
|Sri O
Venkateswara O
College O
, O
DU O
FAmazon O
Alexa O
AI O
4Georgia O
Institute O
of O
Technology O
rsawhney@mathematik.uni-marburg.de O
, O
lucie.flek@uni-marburg.de O
Abstract O
Interpolation O
- O
based O
regularisation O
methods O
such O
as O
Mixup O
, O
which O
generate O
virtual O
training O
samples O
, O
have O
proven O
to O
be O
effective O
for O
various O
tasks O
and O
modalities O
. O

Association O
for O
Computational O
Linguistics.605 O
. O

InProceedings O
of O
the O
1st O
Workshop O
on O
Documentgrounded O
Dialogue O
and O
Conversational B-TaskName
Question I-TaskName
Answering I-TaskName
( O
DialDoc O
2021 O
) O
, O
pages O
4651 O
, O
Online O
. O

CAiRE B-MethodName
in O
DialDoc21 B-DatasetName
: O
Data O
augmentation O
for O
information O
seeking O
dialogue O
system O
. O

2021 O
. O

Yan O
Xu O
, O
Etsuko O
Ishii O
, O
Genta O
Indra O
Winata O
, O
Zhaojiang O
Lin O
, O
Andrea O
Madotto O
, O
Zihan O
Liu O
, O
Peng O
Xu O
, O
and O
Pascale O
Fung O
. O

Association O
for O
Computational O
Linguistics.604 O
. O

In O
Proceedings O
of O
the O
2021 O
Conference O
on O
Empirical O
Methods O
in O
Natural O
Language O
Processing O
, O
pages O
18521863 O
, O
Online O
and O
Punta O
Cana O
, O
Dominican O
Republic O
. O

DIALKI B-MethodName
: O
Knowledge B-TaskName
identification I-TaskName
in O
conversational O
systems O
through O
dialoguedocument O
contextualization O
. O

2021 O
. O

Zeqiu O
Wu O
, O
Bo O
- O
Ru O
Lu O
, O
Hannaneh O
Hajishirzi O
, O
and O
Mari O
Ostendorf O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
57th O
Annual O
Meeting O
of O
the O
Association O
for O
Computational O
Linguistics O
, O
pages O
808819 O
, O
Florence O
, O
Italy O
. O

Transferable O
multi O
- O
domain O
state O
generator O
for O
task O
- O
oriented O
dialogue O
systems O
. O

2019 O
. O

Chien O
- O
Sheng O
Wu O
, O
Andrea O
Madotto O
, O
Ehsan O
HosseiniAsl O
, O
Caiming O
Xiong O
, O
Richard O
Socher O
, O
and O
Pascale O
Fung O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
2020 O
Conference O
on O
Empirical O
Methods O
in O
Natural O
Language O
Processing O
: O
System O
Demonstrations O
, O
pages O
3845 O
, O
Online O
. O

Transformers O
: O
State O
- O
of O
- O
the O
- O
art O
natural O
language O
processing O
. O

2020 O
. O

Thomas O
Wolf O
, O
Lysandre O
Debut O
, O
Victor O
Sanh O
, O
Julien O
Chaumond O
, O
Clement O
Delangue O
, O
Anthony O
Moi O
, O
Pierric O
Cistac O
, O
Tim O
Rault O
, O
Remi O
Louf O
, O
Morgan O
Funtowicz O
, O
Joe O
Davison O
, O
Sam O
Shleifer O
, O
Patrick O
von O
Platen O
, O
Clara O
Ma O
, O
Yacine O
Jernite O
, O
Julien O
Plu O
, O
Canwen O
Xu O
, O
Teven O
Le O
Scao O
, O
Sylvain O
Gugger O
, O
Mariama O
Drame O
, O
Quentin O
Lhoest O
, O
and O
Alexander O
Rush O
. O

PMLR O
. O

In O
Proceedings O
of O
the O
34th O
International O
Conference O
on O
Machine O
Learning O
, O
volume O
70 O
of O
Proceedings O
of O
Machine O
Learning O
Research O
, O
pages O
3732 O
3741 O
. O

Latent O
intention O
dialogue O
models O
. O

2017 O
. O

Tsung O
- O
Hsien O
Wen O
, O
Yishu O
Miao O
, O
Phil O
Blunsom O
, O
and O
Steve O
Young O
. O

Journal O
of O
Machine O
Learning O
Research O
, O
21(140):167 O
. O

Exploring O
the O
limits O
of O
transfer O
learning O
with O
a O
unified O
text O
- O
totext O
transformer O
. O

2020 O
. O

Liu O
. O

Colin O
Raffel O
, O
Noam O
Shazeer O
, O
Adam O
Roberts O
, O
Katherine O
Lee O
, O
Sharan O
Narang O
, O
Michael O
Matena O
, O
Yanqi O
Zhou O
, O
Wei O
Li O
, O
and O
Peter O
J O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
Third O
Conference O
on O
Machine O
Translation O
: O
Research O
Papers O
, O
pages O
186 O
191 O
, O
Brussels O
, O
Belgium O
. O

A O
call O
for O
clarity O
in O
reporting O
BLEU B-MetricName
scores O
. O

2018 O
. O

Matt O
Post O
. O

Transactions O
of O
the O
Association O
for O
Computational O
Linguistics O
, O
9:807824 O
. O

Soloist O
: O
Building O
Task O
Bots O
at O
Scale O
with O
Transfer O
Learning O
and O
Machine O
Teaching O
. O

2021 O
. O

Baolin O
Peng O
, O
Chunyuan O
Li O
, O
Jinchao O
Li O
, O
Shahin O
Shayandeh O
, O
Lars O
Liden O
, O
and O
Jianfeng O
Gao O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
40th O
Annual O
Meeting O
of O
the O
Association O
for O
Computational O
Linguistics O
, O
pages O
311318 O
, O
Philadelphia O
, O
Pennsylvania O
, O
USA O
. O

Bleu O
: O
a O
method O
for O
automatic O
evaluation O
of O
machine O
translation O
. O

2002 O
. O

In O
International O
Conference O
on O
Learning O
Representations O
.Kishore O
Papineni O
, O
Salim O
Roukos O
, O
Todd O
Ward O
, O
and O
WeiJing O
Zhu O
. O

Decoupled O
weight O
decay O
regularization O
. O

2019 O
. O

Ilya O
Loshchilov O
and O
Frank O
Hutter O
. O

In O
International O
Conference O
on O
Learning O
Representations O
. O

Learning O
endto O
- O
end O
goal O
- O
oriented O
dialog O
. O

2017 O
. O

Ilya O
Loshchilov O
and O
Frank O
Hutter O
. O

arXiv O
preprint O
arXiv:2107.13586 O
. O

Pretrain O
, O
prompt O
, O
and O
predict O
: O
A O
systematic O
survey O
of O
prompting O
methods O
in O
natural O
language O
processing O
. O

2021 O
. O

Pengfei O
Liu O
, O
Weizhe O
Yuan O
, O
Jinlan O
Fu O
, O
Zhengbao O
Jiang O
, O
Hiroaki O
Hayashi O
, O
and O
Graham O
Neubig O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
59th O
Annual O
Meeting O
of O
the O
Association O
for O
Computational O
Linguistics O
and O
the O
11th O
International O
Joint O
Conference O
on O
Natural O
Language O
Processing O
( O
Volume O
1 O
: O
Long O
Papers O
) O
, O
pages O
45824597 O
, O
Online O
. O

Prefix O
- O
tuning O
: O
Optimizing O
continuous O
prompts O
for O
generation O
. O

2021 O
. O

Xiang O
Lisa O
Li O
and O
Percy O
Liang O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
1st O
Workshop O
on O
Document O
- O
grounded O
Dialogue O
and O
Conversational O
Question O
Answering O
( O
DialDoc O
2021 O
) O
, O
pages O
5256 O
, O
Online O
. O

Technical O
report O
on O
shared O
task O
in O
DialDoc21 O
. O

2021 O
. O

Jiapeng O
Li O
, O
Mingda O
Li O
, O
Longxuan O
Ma O
, O
Wei O
- O
Nan O
Zhang O
, O
and O
Ting O
Liu O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
58th O
Annual O
Meeting O
of O
the O
Association O
for O
Computational O
Linguistics O
, O
pages O
78717880 O
, O
Online O
. O

BART O
: O
Denoising O
sequence O
- O
to O
- O
sequence O
pretraining O
for O
natural O
language O
generation O
, O
translation O
, O
and O
comprehension O
. O

2020 O
. O

Mike O
Lewis O
, O
Yinhan O
Liu O
, O
Naman O
Goyal O
, O
Marjan O
Ghazvininejad O
, O
Abdelrahman O
Mohamed O
, O
Omer O
Levy O
, O
Veselin O
Stoyanov O
, O
and O
Luke O
Zettlemoyer O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
2021 O
Conference O
on O
Empirical O
Methods O
in O
Natural O
Language O
Processing O
, O
pages O
30453059 O
, O
Online O
and O
Punta O
Cana O
, O
Dominican O
Republic O
. O

The O
power O
of O
scale O
for O
parameter O
- O
efficient O
prompt O
tuning O
. O

2021 O
. O

Brian O
Lester O
, O
Rami O
Al O
- O
Rfou O
, O
and O
Noah O
Constant O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
21th O
Annual O
Meeting O
of O
the O
Special O
Interest O
Group O
on O
Discourse O
and O
Dialogue O
, O
pages O
278289 O
, O
1st O
virtual O
meeting O
. O

Beyond O
domain O
APIs O
: O
Task O
- O
oriented O
conversational O
modeling O
with O
unstructured O
knowledge O
access O
. O

2020 O
. O

Seokhwan O
Kim O
, O
Mihail O
Eric O
, O
Karthik O
Gopalakrishnan O
, O
Behnam O
Hedayatnia O
, O
Yang O
Liu O
, O
and O
Dilek O
HakkaniTur O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
1st O
Workshop O
on O
Document O
- O
grounded O
Dialogue O
and O
Conversational O
Question O
Answering O
( O
DialDoc O
2021 O
) O
, O
pages O
98102 O
, O
Online O
. O

systems O
on O
pre O
- O
trained O
language O
model O
with O
diverse O
input O
representation O
. O

Document O
- O
grounded O
goal O
- O
oriented O
dialogue603 O
. O

2021 O
. O

Boeun O
Kim O
, O
Dohaeng O
Lee O
, O
Sihyung O
Kim O
, O
Yejin O
Lee O
, O
Jin O
- O
Xia O
Huang O
, O
Oh O
- O
Woog O
Kwon O
, O
and O
Harksoo O
Kim O
. O

Curran O
Associates O
, O
Inc O
. O

In O
Advances O
in O
Neural O
Information O
Processing O
Systems O
, O
volume O
33 O
, O
pages O
2017920191 O
. O

A O
simple O
language O
model O
for O
task O
- O
oriented O
dialogue O
. O

2020 O
. O

Ehsan O
Hosseini O
- O
Asl O
, O
Bryan O
McCann O
, O
Chien O
- O
Sheng O
Wu O
, O
Semih O
Yavuz O
, O
and O
Richard O
Socher O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
2020 O
Conference O
on O
Empirical O
Methods O
in O
Natural O
Language O
Processing O
( O
EMNLP O
) O
, O
pages O
81188128 O
, O
Online O
. O

doc2dial B-DatasetName
: O
A O
goal O
- O
oriented O
document O
- O
grounded O
dialogue O
dataset O
. O

2020 O
. O

Song O
Feng O
, O
Hui O
Wan O
, O
Chulaka O
Gunasekara O
, O
Siva O
Patel O
, O
Sachindra O
Joshi O
, O
and O
Luis O
Lastras O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
1st O
Workshop O
on O
Documentgrounded O
Dialogue O
and O
Conversational O
Question O
Answering O
( O
DialDoc O
2021 O
) O
, O
pages O
17 O
, O
Online O
. O

DialDoc O
2021 O
shared O
task O
: O
Goaloriented O
document O
- O
grounded O
dialogue O
modeling O
. O

2021 O
. O

Song O
Feng O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
2019 O
Conference O
of O
the O
North O
American O
Chapter O
of O
the O
Association O
for O
Computational O
Linguistics O
: O
Human O
Language O
Technologies O
, O
Volume O
1 O
( O
Long O
and O
Short O
Papers O
) O
, O
pages O
41714186 O
, O
Minneapolis O
, O
Minnesota O
. O

BERT B-MethodName
: O
Pre O
- O
training O
of O
deep O
bidirectional O
transformers O
for O
language B-TaskName
understanding I-TaskName
. O

2019 O
. O

Jacob O
Devlin O
, O
Ming O
- O
Wei O
Chang O
, O
Kenton O
Lee O
, O
and O
Kristina O
Toutanova O
. O

Association O
for O
Computational O
Linguistics O
. O

InProceedings O
of O
the O
1st O
Workshop O
on O
Documentgrounded O
Dialogue O
and O
Conversational O
Question O
Answering O
( O
DialDoc O
2021 O
) O
, O
pages O
5762 O
, O
Online O
. O

Cascaded O
span O
extraction O
and O
response O
generation O
for O
document O
- O
grounded O
dialog O
. O

2021 O
. O

Nico O
Daheim O
, O
David O
Thulke O
, O
Christian O
Dugast O
, O
and O
Hermann O
Ney O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
1st O
Workshop O
on O
Document O
- O
grounded O
Dialogue O
and O
Conversational O
Question O
Answering O
( O
DialDoc O
2021 O
) O
, O
pages O
109112 O
, O
Online O
. O

Building O
goal O
- O
oriented O
document O
- O
grounded O
dialogue O
systems O
. O

2021 O
. O

References O
Xi O
Chen O
, O
Faner O
Lin O
, O
Yeju O
Zhou O
, O
Kaixin O
Ma O
, O
Jonathan O
Francis O
, O
Eric O
Nyberg O
, O
and O
Alessandro O
Oltramari O
. O

Both O
automatic O
evaluation O
and O
human O
evaluation O
demonstrate O
the O
effectiveness O
of O
our O
framework O
. O

The O
numbers O
indicate O
how O
many O
instances O
there O
are O
in O
each O
case.4 O
Conclusion O
Our O
UniGDD B-MethodName
framework O
unifies O
knowledge B-TaskName
identification I-TaskName
and O
response B-TaskName
generation I-TaskName
and O
models O
their O
characteristics O
via O
a O
multi O
- O
task O
generative O
modeling O
strategy O
. O

Win O
Tie O
Lose O
Relevance O
26 O
64 O
10 O
Informativeness O
23 O
69 O
8 O
Table O
3 O
: O
UniGDD B-MethodName
- I-MethodName
base I-MethodName
vs O
RoBERTa B-MethodName
- I-MethodName
large+T5 I-MethodName
- I-MethodName
base I-MethodName
. O

Moreover O
, O
our O
framework O
has O
a O
clear O
advantage O
over O
the O
baseline O
in O
terms O
of O
Informativeness O
since O
it O
can O
utilize O
rich O
document O
context O
during O
the O
generation O
. O

Compared O
with O
the O
pipeline O
method O
, O
our O
framework O
can O
reduce O
error O
propagation O
, O
resulting O
in O
more O
relevant O
and O
appropriate O
responses O
. O

For O
each O
instance O
, O
given O
the O
dialogue O
context O
and O
grounding O
document O
, O
three O
human O
annotators O
are O
asked O
to O
conduct O
a O
pairwise O
comparison O
between O
the O
response O
generated O
by O
UniGDD B-MethodName
- I-MethodName
base I-MethodName
and O
the O
one O
generated O
by O
the O
pipeline O
baseline O
RoBERTalarge+T5 B-MethodName
- I-MethodName
base I-MethodName
in O
terms O
of O
two O
aspects O
: O
( O
1 O
) O
Relevance O
: O
which O
response O
is O
more O
relevant O
and O
appropriate O
to O
the O
user O
query O
? O
( O
2 O
) O
Informativeness O
: O
which O
response O
is O
more O
informative O
? O
Results O
are O
shown O
in O
Table O
3 O
. O

3.3 O
Human O
Evaluation O
We O
randomly O
sample O
100 O
evaluation O
instances O
. O

In O
contrast O
, O
the O
pipeline O
method O
only O
gives O
a O
relatively O
general O
response O
that O
is O
not O
suitable O
in O
this O
case O
. O

proper O
and O
informative O
response O
about O
the O
reasons O
for O
the O
problem O
the O
user O
encounters O
. O

SupportingDocument O
ResponseFigure O
4 O
: O
A O
case O
from O
the O
development O
set O
. O

If O
you O
do O
not O
, O
your O
time O
will O
run O
out O
and O
your O
work O
on O
that O
page O
will O
be O
lost O
. O

After O
the O
third O
warning O
on O
a O
page O
, O
you O
must O
move O
to O
another O
page O
. O

You O
will O
receive O
a O
warning O
after O
25 O
minutes O
without O
doing O
anything O
, O
and O
you O
will O
be O
able O
to O
extend O
your O
time O
on O
the O
page O
. O

GroundTruth O
How O
Long O
Can O
You O
Stay O
On O
Each O
Page O
? O
For O
security O
reasons O
, O
there O
are O
time O
limits O
for O
viewing O
each O
page O
. O

Were O
you O
gone O
for O
a O
long O
time O
? O
Yes O
I O
guess O
I O
was O
. O
DialogueContext O
RoBERTa B-MethodName
- I-MethodName
large+T5 I-MethodName
- I-MethodName
baseDo I-MethodName
you O
have O
any O
more O
questions O
about O
the O
Retirement O
Estimator?UniGDD B-MethodName
- I-MethodName
baseForsecurityreasons I-MethodName
, O
therearetimelimitsforviewingeachpage O
. O
Youwillreceiveawarningafter25minuteswithoutdoinganythingandyouwillbeabletoextendyourtimeonthepage O
. O
Forreasonsofsecurity O
, O
therearetimelimitsforviewingeachpage O
. O

IfilledoutalloftheinformationintheRetirementEstimatorandittookalongtime O
. O
WhenIcamebackfromansweringthedoor O
, O
alloftheinformationwasgone O
. O
Whathappened O
? O
Oh O
that O
's O
too O
bad O
. O

It O
can O
be O
observed O
that O
our O
framework O
identifies O
accurate O
knowledge O
from O
the O
supporting O
document O
and O
thus O
provides O
a602 O
. O

Case O
Study O
Figure O
4 O
shows O
a O
real O
case O
including O
the O
dialogue O
context O
, O
supporting O
document O
, O
and O
the O
responses O
generated O
by O
the O
pipeline O
method O
and O
our O
proposed O
UniGDD B-MethodName
framework O
. O

Particularly O
, O
when O
there O
is O
only O
1/32 O
training O
data O
, O
UniGDD B-MethodName
- I-MethodName
base I-MethodName
obtains O
more O
than O
20 O
and O
10 O
absolute O
points O
improvement O
over O
the O
pipeline O
approach O
on O
EM B-MetricName
and O
BLEU B-MetricName
, O
respectively O
. O

Generally O
, O
our O
framework O
performs O
substantially O
better O
than O
the O
pipeline O
method O
on O
both O
tasks O
. O

Figure O
3 O
shows O
the O
results O
of O
UniGDD B-MethodName
- I-MethodName
base I-MethodName
and O
the O
best O
- O
performing O
pipeline O
baseline O
RoBERTa B-MethodName
- I-MethodName
large+T5 I-MethodName
- I-MethodName
base I-MethodName
on O
the O
four O
low O
- O
resource O
training O
splits O
. O

Low O
- O
Resource O
Setting O
To O
evaluate O
the O
model O
in O
low O
- O
resource O
scenarios O
, O
we O
randomly O
shufe O
the O
training O
set O
and O
then O
take O
1/32 O
, O
1/16 O
, O
1/8 O
, O
and O
1/4 O
of O
the O
data O
for O
training O
. O

This O
indicates O
that O
CP O
enables O
the O
model O
to O
take O
advantage O
of O
the O
connections O
between O
the O
three O
tasks O
. O

With O
these O
prompts O
, O
UniGDD B-MethodName
- I-MethodName
base I-MethodName
obtains O
64.9 B-MetricValue
EM B-MetricName
, O
76.2 B-MetricValue
F1 B-MetricName
, O
and O
42.3 B-MetricValue
BLEU B-MetricName
, O
which O
performs O
worse O
than O
using O
CP O
. O

As O
in O
the O
case O
of O
CP O
, O
we O
randomly O
initialize O
the O
embeddings O
of O
these O
three O
special O
tokens O
. O

Effect O
of O
Connected B-MethodName
Prompts I-MethodName
( I-MethodName
CP I-MethodName
) I-MethodName
To O
examine O
whether O
CP O
can O
capture O
the O
connections O
of O
different O
tasks O
, O
we O
use O
an O
alternative O
approach O
that O
employs O
task O
- O
independent O
prompts O
" O
< O
Task1 O
> O
: O
" O
, O
" O
< O
Task2 O
> O
: O
" O
, O
and O
" O
< O
Task3 O
> O
: O
" O
to O
specify O
each O
task O
for O
comparison O
. O

This O
indicates O
that O
LTS B-MethodName
can O
guide O
the O
model O
to O
pay O
more O
attention O
to O
relevant O
content O
during O
generation O
and O
bring O
improvements O
on O
two O
sub O
- O
tasks O
. O

Further O
removing O
LTS B-MethodName
, O
the O
performance O
drops O
to O
64.7 B-MetricValue
EM B-MetricName
, O
76.0 B-MetricValue
F1 B-MetricName
, O
and O
41.7 O
BLEU B-MetricName
. O

Effect O
of O
Prompt B-TaskName
- I-TaskName
Connected I-TaskName
Multi I-TaskName
- I-TaskName
task I-TaskName
Learning I-TaskName
( I-TaskName
PCMTL I-TaskName
) I-TaskName
and O
Linear B-TaskName
Temperature I-TaskName
Scheduling I-TaskName
( I-TaskName
LTS I-TaskName
) I-TaskName
To O
verify O
the O
effectiveness O
of O
PCMTL B-TaskName
and O
LTS B-TaskName
, O
we O
first O
remove O
PCMTL B-TaskName
( O
i.e. O
, O
training O
with O
the O
main O
task O
only O
) O
, O
and O
the O
performance O
of O
UniGDD B-MethodName
- I-MethodName
base I-MethodName
on O
two O
tasks O
decreases O
102030405060 O
1/32 O
1/16 O
1/8 O
1/4 O
RoBERTa B-MethodName
- I-MethodName
large+T5 I-MethodName
- I-MethodName
base I-MethodName
UniGDD B-MethodName
- I-MethodName
base(a I-MethodName
) O
EM B-MetricName
152025303540 O
1/32 O
1/16 O
1/8 O
1/4 O
RoBERTa B-MethodName
- I-MethodName
large+T5 I-MethodName
- I-MethodName
base I-MethodName
UniGDD B-MethodName
- I-MethodName
base I-MethodName
( O
b O
) O
BLEU B-MetricName
Figure O
3 O
: O
Experimental O
results O
on O
knowledge O
identification O
and O
response O
generation O
in O
low O
- O
resource O
scenarios O
to O
65.2 B-MetricValue
EM B-MetricName
, O
76.3 B-MetricValue
F1 B-MetricName
, O
and O
42.3 B-MetricValue
BLEU B-MetricName
, O
showing O
that O
PCMTL B-TaskName
endows O
the O
model O
with O
the O
ability O
of O
modeling O
the O
characteristics O
and O
connections O
of O
different O
tasks O
and O
achieving O
better O
generation O
. O

This O
verifies O
our O
assumption O
that O
our O
unified O
generative O
framework O
can O
alleviate O
the O
error O
propagation O
problem O
of O
pipeline O
approaches O
. O

On O
the O
response O
generation O
task O
, O
UniGDD B-MethodName
obtains O
a O
marked O
improvement O
over O
all O
pipeline O
methods O
. O

With O
a O
larger O
model O
size O
, O
UniGDDlarge B-MethodName
achieves O
new O
state O
- O
of O
- O
the O
- O
art O
performance O
. O

On O
the O
knowledge B-TaskName
identification I-TaskName
task O
, O
UniGDD B-MethodName
- I-MethodName
base I-MethodName
can O
obtain O
comparable O
results O
to O
previous O
state O
- O
of O
- O
theart O
methods O
. O

Our O
UniGDD B-MethodName
framework O
outperforms O
all O
the O
baselines O
on O
two O
sub O
- O
tasks O
. O

3.2 O
Results O
The O
results O
on O
knowledge B-TaskName
identification I-TaskName
and O
response O
generation O
are O
shown O
in O
Table O
1 O
and O
Table O
2 O
, O
respectively O
. O

For O
our O
constructed O
baseline O
RoBERTa+T5 B-MethodName
for O
response O
generation O
, O
we O
use O
RoBERTa B-MethodName
- I-MethodName
large I-MethodName
and O
T5 B-MethodName
- I-MethodName
base I-MethodName
and O
adopt O
the O
implementation O
from O
the O
DialDoc21 B-DatasetName
shared O
task O
. O

For O
linear O
temperature O
scheduling O
, O
we O
set O
the O
starting O
temperature O
s= O
1 O
and O
choose O
the O
best O
ending O
temperature O
from O
{ O
0.5 O
, O
0.6 O
, O
0.7 O
, O
0.8 O
, O
0.9 O
} O
. O

For O
decoding O
, O
we O
use O
beam B-MethodName
search I-MethodName
, O
and O
the O
beam O
size O
is O
2 O
. O

We O
train O
10 O
epochs O
for O
single B-TaskName
- I-TaskName
task I-TaskName
learning I-TaskName
and O
5 O
epochs O
for O
multi B-TaskName
- I-TaskName
task I-TaskName
learning I-TaskName
. O

For O
training O
, O
we O
use O
the O
AdamW O
( O
Loshchilov O
and O
Hutter O
, O
2019 O
) O
optimizer O
with O
an O
initial O
learning O
rate O
of10 4and O
a O
linear O
learning O
rate O
decay O
scheduler O
. O

Any O
sequence O
over O
2560 O
tokens O
will O
be O
truncated O
. O

We O
set O
the O
max O
input O
length O
to O
2560 O
. O

We O
adopt O
the O
implementation O
from O
Hugging O
Face O
Transformers O
( O
Wolf O
et O
al O
. O
, O
2020 O
) O
. O

Implementation O
Details O
We O
report O
results O
of O
UniGDD B-MethodName
with O
two O
model O
sizes O
: O
UniGDD B-MethodName
- I-MethodName
base I-MethodName
and O
UniGDD B-MethodName
- I-MethodName
large I-MethodName
, O
which O
are O
initialized O
with O
pretrained O
T5 B-MethodName
- I-MethodName
base I-MethodName
and O
T5 B-MethodName
- I-MethodName
large I-MethodName
models O
( O
Raffel O
et O
al O
. O
, O
2020 O
) O
, O
respectively O
. O

We O
also O
build O
a O
strong O
baseline O
model O
RoBERTa+T5 B-MethodName
which O
uses O
the O
same O
pretrained O
generative O
model O
as O
ours O
. O

For O
response O
generation O
, O
we O
compare O
UniGDD B-MethodName
with O
several O
pipeline O
methods O
, O
including O
DIALKI+BART B-MethodName
( O
Wu O
et O
al O
. O
, O
2021 O
) O
that O
uses O
DIALKI B-MethodName
to O
conduct O
knowledge B-TaskName
identification I-TaskName
, O
followed O
by O
BART B-MethodName
( O
Lewis O
et O
al O
. O
, O
2020 O
) O
to O
conduct O
response O
generation O
and O
RoBERTa B-MethodName
- I-MethodName
PR+BART I-MethodName
( O
Daheim O
et O
al O
. O
, O
2021 O
) O
. O

from O
the O
document O
. O

These O
models O
formulate O
knowledge B-TaskName
identification I-TaskName
as O
the O
machine B-TaskName
reading I-TaskName
comprehension I-TaskName
task I-TaskName
and O
extract O
the O
grounding O
span O
1https://github.com/doc2dial/sharedtask-dialdoc2021 O
2Since O
we O
can O
not O
access O
the O
test O
set O
, O
we O
report O
results O
on O
the O
development O
set O
for O
comparison.601 B-DatasetName
. O

Baselines O
For O
knowledge B-TaskName
identification I-TaskName
, O
we O
compare O
UniGDD B-MethodName
with O
several O
strong O
baselines O
, O
including O
BERTQA B-MethodName
( O
Devlin O
et O
al O
. O
, O
2019 O
) O
, O
BERT B-MethodName
- I-MethodName
PR I-MethodName
( O
Daheim O
et O
al O
. O
, O
2021 O
) O
, O
RoBERTa B-MethodName
- I-MethodName
PR I-MethodName
( O
Daheim O
et O
al O
. O
, O
2021 O
) O
, O
Multi B-MethodName
- I-MethodName
Sentence I-MethodName
( O
Wu O
et O
al O
. O
, O
2021 O
) O
, O
and O
DIALKI B-MethodName
( O
Wu O
et O
al O
. O
, O
2021 O
) O
. O

Evaluation O
Metrics O
Following O
Feng O
( O
2021 O
) O
, O
we O
use O
Exact B-MetricName
Match I-MetricName
( I-MetricName
EM I-MetricName
) I-MetricName
and O
token B-MetricName
- I-MetricName
level I-MetricName
F1 I-MetricName
for O
knowledge B-TaskName
identification I-TaskName
and O
BLEU B-MetricName
( O
Papineni O
et O
al O
. O
, O
2002 O
; O
Post O
, O
2018 O
) O
for O
response O
generation O
. O

It O
contains O
3,474 O
dialogues O
with O
44,149 O
turns O
for O
training O
and O
661 O
dialogues O
with O
8539 O
turns O
for O
evaluation2 O
. O

3 O
Experiments O
3.1 O
Experimental O
Setup O
Dataset O
We O
conduct O
experiments O
on O
the O
goaloriented O
document O
- O
grounded O
dialogue O
dataset O
Doc2Dial B-DatasetName
( O
Feng O
, O
2021 O
) O
, O
which O
is O
adopted O
by O
the O
DialDoc21 B-DatasetName
shared O
task1 O
. O

Inference O
After O
training O
, O
for O
each O
pair O
of O
dialogue O
context O
and O
document O
( O
C;D O
) O
, O
we O
generate O
the O
target O
sequence O
of O
the O
main O
task O
for O
obtaining O
the O
grounding O
knowledge O
ktand O
the O
response O
at O
. O

We O
mix O
the O
data O
of O
the O
main O
task O
and O
two O
auxiliary O
tasks O
for O
training O
. O

length O
ofY O
. O

Models O
BLEU B-MethodName
DIALKI+BART B-MethodName
- I-MethodName
base I-MethodName
25.8 B-MetricValue
RoBERTa B-MethodName
- I-MethodName
PR I-MethodName
- I-MethodName
large+BART I-MethodName
- I-MethodName
base I-MethodName
39.6 B-MetricValue
RoBERTa B-MethodName
- I-MethodName
large+T5 I-MethodName
- I-MethodName
base I-MethodName
40.7 B-MetricValue
UniGDD B-MethodName
- I-MethodName
base I-MethodName
42.8 B-MetricValue
UniGDD B-MethodName
- I-MethodName
large I-MethodName
42.9 B-MetricValue
Table O
2 O
: O
Results O
on O
response O
generation O
. O

Given O
the O
training O
example O
e= O
( O
C;D;TP;Y O
) O
, O
the O
objective O
Lis O
defined O
as O
L= nX O
i=1logP(YijY O
< O
i;C;D;TP O
) O
( O
3 O
) O
whereis O
the O
model O
parameters O
, O
TPis O
the O
task O
prompt O
, O
Yis O
the O
target O
sequence O
, O
and O
nis O
theModels B-MethodName
EM I-MethodName
F1 B-MetricName
BERTQA B-MetricName
42.2 B-MetricValue
58.1 B-MetricValue
BERT B-MethodName
- I-MethodName
PR I-MethodName
- I-MethodName
large I-MethodName
56.3 B-MetricValue
70.8 B-MetricValue
RoBERTa B-MethodName
- I-MethodName
PR I-MethodName
- I-MethodName
large I-MethodName
65.6 B-MetricValue
77.3 B-MetricValue
Multi B-MethodName
- I-MethodName
Sentence I-MethodName
59.5 B-MetricValue
68.8 B-MetricValue
DIALKI B-MethodName
( I-MethodName
Lnextonly I-MethodName
) B-MetricValue
60.4 I-MetricValue
71.2 B-MetricValue
DIALKI B-MethodName
65.9 B-MetricValue
74.8 B-MetricValue
UniGDD B-MethodName
- I-MethodName
base I-MethodName
65.6 B-MetricValue
76.8 B-MetricValue
UniGDD B-MethodName
- I-MethodName
large I-MethodName
66.9 B-MetricValue
77.5 B-MetricValue
Table O
1 O
: O
Results O
on B-TaskName
knowledge I-TaskName
identification I-TaskName
. O

Training O
The O
model O
is O
trained O
with O
a O
maximum O
likelihood O
objective O
. O

Compared O
with O
the O
original O
cross O
- O
attention O
module O
, O
the O
ending O
temperature O
0 O
< O
e<1leads O
to O
a O
sharper O
attention O
distribution O
, O
giving O
more O
attention O
weight O
to O
the O
relevant O
content O
. O

Specifically O
, O
we O
design O
the O
softmax O
function O
in O
the O
cross O
- O
attention O
module O
of O
each O
decoder O
layer O
as O
follows O
: O
ai O
= O
exp O
( O
zi= O
) O
P O
jexp O
( O
zj= O
) O
( O
1 O
) O
= O
( O
e  O
s)Sc O
Stotal+ O
s O
( O
2 O
) O
whereaiis O
the O
attention O
weight O
for O
the O
i O
- O
th O
input O
token O
, O
ziis O
the O
logit O
for O
the O
i O
- O
th O
input O
token O
, O
Scis O
the O
current O
training O
step O
, O
Stotal O
is O
the O
total O
training O
steps O
, O
sand O
eare O
the O
starting O
and O
ending O
temperature O
respectively O
, O
e O
< O
s O
, O
and O
0 O
< O
e<1 O
. O

To O
force O
the O
model O
to O
pay O
less O
attention O
to O
the O
irrelevant O
parts O
, O
we O
propose O
a O
linear O
temperature O
scheduling O
strategy O
to O
make O
the O
attention O
distribution O
of O
cross O
- O
attention O
gradually O
sharper O
during O
the O
training O
process O
. O

Linear O
Temperature O
Scheduling O
For O
a O
specific O
user O
query O
in O
the O
dialogue O
, O
many O
document O
contents O
are O
actually O
irrelevant O
. O

Instead O
of O
using O
discrete O
language O
phrases O
, O
we O
randomly O
initialize O
the O
embeddings O
of O
those O
special O
tokens O
in O
the O
prompts O
and O
train O
them O
end O
- O
to O
- O
end O
to O
better O
encode O
the O
characteristics O
and O
connections O
of O
these O
tasks O
. O

As O
a O
result O
, O
the O
connections O
between O
different O
tasks O
are O
naturally O
modeled O
. O

These O
prompts O
indicate O
the O
model O
that O
the O
goals O
of O
the O
two O
auxiliary O
tasks O
are O
to O
generate O
the O
first O
part O
and O
the O
second O
part O
of O
the O
target O
sequence O
of O
the O
main O
task O
, O
respectively O
. O

As O
depicted O
in O
Figure O
2 O
, O
we O
construct O
prompts O
" O
generate O
< O
grounding O
> O
: O
" O
and O
" O
generate O
< O
agent O
> O
: O
" O
for O
them O
. O

Given O
the O
dialogue O
context O
Cand O
grounding O
documentD O
, O
these O
two O
tasks O
aim O
to O
generate O
the O
grounding O
knowledge O
ktand O
the O
response O
atwith O
the O
same O
modelM O
. O

Prompt B-TaskName
- I-TaskName
Connected I-TaskName
Multi I-TaskName
- I-TaskName
Task I-TaskName
Learning I-TaskName
We O
introduce O
two O
auxiliary O
tasks O
to O
steer O
our O
framework O
to O
model O
the O
respective O
characteristics O
of O
knowledge B-TaskName
identification I-TaskName
and O
response B-TaskName
generation I-TaskName
. O

The O
input O
- O
to O
- O
target O
generation O
can O
be O
modeled O
with O
a O
pre O
- O
trained O
encoder O
- O
decoder O
modelM O
: O
( O
C;D;TP O
) O
! O
( O
kt;at)such O
as O
T5 O
( O
Raffel O
et O
al O
. O
, O
2020 O
) O
, O
where O
TPis O
the O
task O
prompt.600 O
. O

The O
prompt O
" O
generate O
< O
grounding O
> O
then O
< O
agent O
> O
: O
" O
is O
added O
to O
the O
dialogue O
context O
and O
supporting O
document O
to O
form O
the O
input O
and O
guide O
the O
model O
to O
generate O
the O
grounding O
knowledge O
and O
the O
response O
in O
order O
. O

For O
example O
, O
we O
add O
" O
< O
user O
> O
" O
in O
front O
of O
each O
user O
utterance O
, O
" O
< O
agent O
> O
" O
in O
front O
of O
each O
agent O
utterance O
, O
and O
" O
< O
grounding O
> O
" O
in O
front O
of O
the O
grounding O
knowledge O
. O

We O
use O
different O
special O
tokens O
to O
identify O
different O
elements O
in O
the O
input O
and O
output O
. O

Output O
: O
< O
grounding O
> O
Your O
application O
for O
... O
< O
agent O
> O
Renewal O
of O
a O
Driving O
.. O
. O

Your O
application O
for O
renewal O
.. O
. O

? O
< O
title O
> O
Renew O
Driving O
School O
License O
< O
/title O
> O
.. O
. O

< O
user O
> O
How O
often O
do O
.. O
. O

? O
< O
agent O
> O
Each O
time O
you O
.. O
. O

Specifically O
, O
for O
the O
example O
in O
Figure O
1 O
, O
the O
input O
and O
output O
of O
the O
main O
task O
are O
as O
follows O
: O
Input O
: O
generate O
< O
grounding O
> O
then O
< O
agent O
> O
: O
< O
user O
> O
I O
would O
like O
to O
renew O
.. O
. O

Main O
Task O
Given O
the O
dialogue O
context O
C= O
( O
u1;a1;:::;ut 1;at 1;ut)and O
grounding O
documentD O
, O
whereuiis O
thei O
- O
th O
user O
utterance O
and O
aiis O
thei O
- O
th O
agent O
utterance O
, O
our O
main O
task O
aims O
to O
generate O
the O
target O
sequence O
Y= O
( O
kt;at O
) O
, O
where O
ktis O
the O
grounding O
knowledge O
from O
Dandatis O
the O
response O
to O
ut O
. O

2 O
Our O
UniGDD B-TaskName
framework O
UniGDD B-TaskName
is O
a O
multi O
- O
task O
generative O
framework O
for O
the O
goal O
- O
oriented O
document O
- O
grounded O
dialogue O
problem O
. O

( O
3 O
) O
Our O
framework O
advances O
state O
- O
of O
- O
the O
- O
art O
methods O
on O
the O
concerned O
task O
, O
especially O
in O
low O
- O
resource O
scenarios O
. O

We O
develop O
a O
prompt B-TaskName
- I-TaskName
connected I-TaskName
multi I-TaskName
- I-TaskName
task I-TaskName
learning I-TaskName
strategy O
to O
exploit O
the O
characteristics O
and O
connections O
of O
different O
tasks O
and O
introduce O
linear O
temperature O
scheduling O
to O
enable O
the O
model O
to O
pay O
more O
attention O
to O
relevant O
information O
. O

( O
2 O
) O
generate O
< O
grounding O
> O
then O
< O
agent O
> O
: O
dialogue O
context+ O
documentgenerate O
< O
grounding O
> O
: O
dialogue O
context O
+ O
documentgenerate O
< O
agent O
> O
: O
dialogue O
context O
+ O
documentUniGDD B-MethodName
< O
grounding O
> O
grounding O
knowledge O
< O
agent O
> O
agent O
response O
< O
grounding O
> O
grounding O
knowledge O
< O
agent O
> O
agent O
responseFigure O
2 O
: O
Overview O
of O
our O
framework O
. O

Our O
contributions O
are O
summarized O
as O
follows O
: O
( O
1 O
) O
We O
propose O
a O
unified O
generative O
framework O
for O
the O
goal O
- O
oriented O
document O
- O
grounded O
dialogue O
. O

To O
tackle O
this O
problem O
, O
we O
introduce O
linear O
temperature O
scheduling O
to O
make O
the O
attention O
distribution O
to O
the O
input O
document O
gradually O
sharper O
during O
the O
training O
process O
in O
order O
to O
enable O
the O
model O
to O
learn O
to O
pay O
more O
attention O
to O
the O
relevant O
content O
. O

Thus O
, O
much O
information O
in O
the O
input O
document O
is O
irrelevant O
. O

In O
addition O
, O
for O
a O
particular O
user O
query O
in O
the O
goal O
- O
oriented O
dialogue O
, O
the O
selected O
knowledge O
and O
generated O
response O
need O
to O
be O
specific O
, O
while O
the O
generation O
conditions O
on O
a O
relatively O
long O
document O
. O

Through O
this O
prompt B-TaskName
- I-TaskName
connected I-TaskName
multi I-TaskName
- I-TaskName
task I-TaskName
learning I-TaskName
strategy O
, O
the O
model O
can O
capture O
the O
characteristics O
of O
different O
tasks O
as O
well O
as O
exploit O
the O
connections O
between O
them O
. O

These O
prompts O
can O
naturally O
connect O
these O
tasks O
via O
indicating O
the O
model O
that O
each O
auxiliary O
task O
aims O
to O
generate O
a O
part O
of O
the O
target O
sequence O
of O
the O
main O
task O
. O

Moreover O
, O
inspired O
by O
the O
recent O
success O
in O
prompt B-TaskName
learning I-TaskName
for O
pre O
- O
trained O
models O
( O
Li O
and O
Liang O
, O
2021 O
; O
Lester O
et O
al O
. O
, O
2021 O
; O
Liu O
et O
al O
. O
, O
2021 O
) O
, O
we O
design O
prompts O
for O
these O
three O
tasks O
to O
guide O
the O
model O
on O
what O
to O
generate O
for O
each O
task O
. O

Therefore O
, O
in O
addition O
to O
the O
main O
task O
that O
uses O
the O
concatenation O
of O
the O
grounding O
knowledge O
and O
response O
as O
the O
target O
sequence O
, O
we O
introduce O
the O
generation O
of O
the O
grounding O
knowledge O
and O
the O
generation O
of O
the O
response O
as O
two O
auxiliary O
tasks O
in O
the O
same O
framework O
to O
force O
the O
model O
to O
capture O
their O
characteristics O
so O
as O
to O
perform O
well O
on O
them O
as O
well O
. O

Generating O
the O
grounding O
knowledge O
is O
similar O
to O
copying O
appropriate O
sentences O
from O
the O
document O
, O
while O
generating O
the O
response O
needs O
more O
effort O
to O
make O
the O
response O
coherent O
with O
the O
dialogue O
and O
consistent O
with O
the O
grounding O
knowledge O
. O

Although O
KI B-TaskName
and O
RG B-TaskName
can O
be O
unified O
with O
the O
proposed O
generative O
method O
, O
they O
have O
different O
characteristics O
. O

On O
the O
other O
hand O
, O
the O
generation O
of O
the O
grounding O
knowledge O
receives O
the O
supervision O
signal O
from O
the O
agent O
response O
when O
training O
, O
leading O
to O
more O
accurate O
knowledge B-TaskName
identification I-TaskName
. O

On O
one O
hand O
, O
the O
generation O
of O
the O
agent O
response O
depends O
not O
only O
on O
the O
dialogue O
context O
and O
external O
document O
but O
also O
on O
the O
identified O
knowledge O
, O
forcing O
the O
model O
to O
focus O
on O
the O
specific O
knowledge O
. O

Therefore O
, O
the O
inherent O
dependencies O
between O
these O
two O
sub O
- O
tasks O
can O
be O
naturally O
modeled O
. O

tially O
generating O
the O
grounding O
knowledge O
and O
the O
agent O
response O
. O

Given O
the O
dialogue O
context O
and O
associated O
document O
, O
instead O
of O
treating O
KI B-TaskName
and O
RG B-TaskName
as O
two O
separate O
processes O
, O
we O
tackle O
them O
simultaneously O
via O
sequen-599 B-MethodName
. O

To O
address O
the O
aforementioned O
issue O
, O
we O
propose O
aUnified B-MethodName
generative I-MethodName
framework I-MethodName
for I-MethodName
Goal I-MethodName
- I-MethodName
oriented I-MethodName
Document I-MethodName
- I-MethodName
grounded I-MethodName
Dialogue I-MethodName
( I-MethodName
UniGDD I-MethodName
) I-MethodName
. O

The O
problem O
is O
more O
pronounced O
in O
low O
- O
resource O
scenarios O
, O
where O
accurate O
knowledge O
identification O
is O
difficult O
due O
to O
limited O
data O
, O
making O
it O
harder O
to O
generate O
appropriate O
responses O
. O

As O
a O
result O
, O
error O
propagation O
is O
a O
serious O
problem O
. O

However O
, O
such O
pipeline O
methods O
fail O
to O
capture O
the O
interdependence O
between O
KI B-TaskName
and O
RG B-TaskName
. O

Therefore O
, O
one O
straightforward O
solution O
for O
this O
problem O
is O
to O
use O
two O
models O
to O
conduct O
KI B-TaskName
and O
RG B-TaskName
in O
a O
pipeline O
manner O
( O
Daheim O
et O
al O
. O
, O
2021 O
; O
Kim O
et O
al O
. O
, O
2021 O
; O
Xu O
et O
al O
. O
, O
2021 O
; O
Chen O
et O
al O
. O
, O
2021 O
; O
Li O
et O
al O
. O
, O
2021 O
) O
. O

Response O
generation O
then O
aims O
at O
generating O
a O
proper O
agent O
response O
according O
to O
the O
dialogue O
context O
and O
the O
selected O
knowledge O
. O

Given O
the O
dialogue O
context O
and O
supporting O
document O
, O
knowledge B-TaskName
identification I-TaskName
aims O
to O
identify O
a O
text O
span O
in O
the O
document O
as O
the O
grounding O
knowledge O
for O
the O
next O
agent O
response O
, O
which O
is O
often O
formulated O
as O
a O
conversational O
reading O
comprehension O
task O
( O
Feng O
, O
2021 O
; O
Wu O
et O
al O
. O
, O
2021 O
) O
. O

As O
shown O
in O
Figure O
1 O
, O
the O
goal O
- O
oriented O
document O
- O
grounded O
dialogue O
problem O
is O
commonly O
formulated O
as O
a O
sequential O
process O
including O
two O
sub O
- O
tasks O
: O
knowledge B-TaskName
identification I-TaskName
( O
KI O
) O
and O
response B-TaskName
generation I-TaskName
( O
RG O
) O
( O
Feng O
, O
2021 O
) O
. O

RG O
DialogueContextSupportingDocumentFigure O
1 O
: O
An O
example O
of O
the O
goal O
- O
oriented O
documentgrounded O
dialogue O
problem O
. O

I O
would O
like O
to O
renew O
my O
Driving O
School O
License O
, O
when O
is O
the O
right O
time O
to O
do O
so O
? O
RenewalofaDrivingSchoolLicensemustbeperformedbetween30and60daysbeforetheexpirationdateasseenonyourlicense O
. O

YourapplicationforrenewalofaDrivingSchoolLicensemustbesubmittedbetween30and60daysbeforethelicenseexpires(theexpirationdateisprintedonyourlicense O
. O
) O
GroundingKnowledge O
KIHow O
often O
do O
I O
have O
to O
renew O
the O
Driving O
School O
License?Each O
time O
you O
renew O
your O
license O
, O
it O
is O
renewed O
for O
two O
years O
. O

The O
work O
described O
in O
this O
paper O
is O
substantially O
supported O
by O
a O
grant O
from O
the O
Research O
Grant O
Council O
of O
the O
Hong O
Kong O
Special O
Administrative O
Region O
, O
China O
( O
Project O
Code O
: O
14200620 O
) O
. O

To O
address O
this O
challenge O
, O
goal O
- O
oriented O
document O
- O
grounded O
dialogue O
has O
been O
proposed O
to O
leverage O
external O
documents O
as O
the O
knowledge O
source O
to O
assist O
the O
dialogue O
system O
in O
satisfying O
users O
diverse O
information O
needs O
( O
Feng O
et O
al O
. O
, O
2020 O
; O
Wu O
et O
al O
. O
, O
2021 O
) O
. O

However O
, O
due O
to O
the O
lack O
of O
external O
knowledge O
, O
most O
goal O
- O
oriented O
dialogue O
systems O
are O
restricted O
to O
providing O
information O
that O
can O
only O
be O
handled O
by O
given O
databases O
or O
APIs O
( O
Kim O
et O
al O
. O
, O
2020 O
) O
and O
completing O
certain O
tasks O
in O
a O
specific O
domain O
such O
as O
restaurant O
booking O
. O

1 O
Introduction O
Recent O
years O
have O
seen O
significant O
progress O
in O
goaloriented O
dialogues O
( O
Loshchilov O
and O
Hutter O
, O
2017 O
; O
Wen O
et O
al O
. O
, O
2017 O
; O
Wu O
et O
al O
. O
, O
2019 O
; O
Hosseini O
- O
Asl O
et O
al O
. O
, O
2020 O
; O
Peng O
et O
al O
. O
, O
2021 O
) O
, O
which O
aim O
at O
assisting O
end O
users O
in O
accomplishing O
certain O
goals O
via O
natural O
language O
interactions O
. O

Experimental O
results O
demonstrate O
the O
effectiveness O
of O
our O
framework O
. O

We O
further O
develop O
a O
prompt O
- O
connected O
multi B-TaskName
- I-TaskName
task I-TaskName
learning I-TaskName
strategy O
to O
model O
the O
characteristics O
and O
connections O
of O
different O
tasks O
and O
introduce O
linear O
temperature O
scheduling O
to O
reduce O
the O
negative O
effect O
of O
irrelevant O
document O
information O
. O

This O
paper O
proposes O
to O
unify O
these O
two O
sub O
- O
tasks O
via O
sequentially O
generating O
the O
grounding O
knowledge O
and O
the O
response O
. O

However O
, O
such O
pipeline O
methods O
would O
unavoidably O
suffer O
from O
the O
error O
propagation O
issue O
. O

Existing O
studies O
tackle O
this O
problem O
by O
decomposing O
it O
into O
two O
sub O
- O
tasks O
: O
knowledge O
identification O
and O
response O
generation O
. O

Proceedings O
of O
the O
60th O
Annual O
Meeting O
of O
the O
Association O
for O
Computational O
Linguistics O
Volume O
2 O
: O
Short O
Papers O
, O
pages O
599 O
- O
605 O
May O
22 O
- O
27 O
, O
2022 O
c O
2022 O
Association O
for O
Computational O
Linguistics O
UniGDD O
: O
A O
Unified O
Generative O
Framework O
for O
Goal O
- O
Oriented O
Document O
- O
Grounded O
Dialogue O
Chang O
Gao O
, O
Wenxuan O
Zhang O
, O
and O
Wai O
Lam O
The O
Chinese O
University O
of O
Hong O
Kong O
{ O
gaochang,wxzhang,wlam}@se.cuhk.edu.hk O
Abstract O
The O
goal O
- O
oriented O
document O
- O
grounded O
dialogue O
aims O
at O
responding O
to O
the O
user O
query O
based O
on O
the O
dialogue O
context O
and O
supporting O
document O
. O

Table O
A.3 O
: O
Examples O
of O
a O
human O
written O
note O
and O
automatically O
generated O
notes O
with O
the O
four O
baseline O
models.598 O
. O

You O
may O
want O
to O
take O
some O
ibuprofen O
or O
paracetamol O
in O
addition O
to O
any O
prescribed O
medication O
. O

You O
should O
begin O
the O
treatment O
prescribed O
as O
we O
discussed O
. O

You O
should O
start O
the O
treatment O
you O
have O
been O
prescribed O
. O

Osteoarthritis O
of O
the O
elbow O
. O

SH O
: O
Mobile O
and O
active O
, O
exercise O
2 O
- O
3 O
times O
a O
week O
, O
running O
. O

NKDA O
. O

No O
injury O
to O
the O
elbow O
. O

No O
previous O
history O
of O
this O
. O

No O
injury O
. O

No O
pain O
, O
no O
swelling O
, O
no O
uid O
in O
the O
elbow O
. O

Not O
painful O
at O
all O
, O
but O
slightly O
warm O
, O
slightly O
warm O
. O

1 O
week O
ago O
noticed O
a O
weird O
swelling O
on O
the O
left O
elbow O
. O

BART B-MethodName
- I-MethodName
finetYou I-MethodName
have O
a O
problem O
with O
your O
left O
elbow O
. O

, O
take O
care O
then O
. O

All O
right O
then O
, O
OK O
. O

do O
nt O
need O
to O
worry O
. O

I O
run O
regularly O
, O
like O
two O
, O
three O
times O
a O
week O
. O

So O
, O
, O
this O
, O
this O
is O
not O
the O
case O
right O
now O
. O

. O

, O
yeah O
, O
no O
, O
I O
m O
, O
think O
I O
m O
healthy O
. O

- O
. O

OK O
. O

OK O
, O
yeah O
that O
sounds O
good O
. O

OK O
. O

But O
you O
contact O
us O
, O
, O
after O
you O
ve O
had O
the O
blood O
test O
done O
, O
and O
we O
can O
review O
things O
then O
, O
OK O
. O

do O
you O
, O
do O
you O
think O
its O
something O
dangerous O
? O
Fantastic O
. O

Yes O
, O
a O
few O
years O
ago O
. O

OK O
, O
OK O
, O
great O
. O

No O
, O
no O
I O
have O
nt O
noticed O
that O
before O
. O

RandomSure O
. O

We O
can O
do O
that O
as O
well O
, O
that O
s O
, O
that O
s O
your O
call O
. O

Maybe O
within O
a O
, O
actually O
you O
know O
, O
the O
follow O
- O
up O
appointment O
does O
nt O
have O
to O
be O
face O
- O
to O
- O
face O
, O
if O
its O
more O
convenient O
for O
you O
do O
, O
to O
do O
it O
over O
the O
phone O
, O
we O
can O
do O
that O
over O
the O
phone O
, O
, O
over O
video O
. O

that O
s O
four O
hundred O
milligrams O
, O
two O
times O
a O
day O
. O

do O
you O
, O
do O
you O
think O
its O
something O
dangerous O
? O
Like O
something O
, O
like O
could O
I O
die O
from O
that O
, O
or O
is O
it O
, O
is O
it O
No O
. O

That O
would O
require O
more O
immediate O
assessment O
, O
more O
immediate O
treatment O
. O

However O
, O
if O
your O
, O
the O
elbow O
was O
to O
become O
very O
red O
, O
very O
painful O
, O
, O
and O
the O
redness O
was O
to O
spread O
or O
become O
, O
you O
know O
more O
intense O
. O

and O
, O
your O
, O
your O
joint O
does O
nt O
look O
like O
that O
. O

And O
, O
there O
ll O
be O
instructions O
within O
that O
pack O
, O
about O
where O
to O
go O
to O
get O
those O
blood O
tests O
done O
. O

, O
what O
I O
think O
we O
should O
do O
is O
, O
I O
think O
you O
should O
be O
on O
some O
anti O
- O
inammatory O
medication O
, O
in O
the O
, O
in O
the O
first O
instance O
. O

and O
, O
do O
you O
have O
any O
other O
illnesses O
at O
all O
? O
, O
I O
run O
regularly O
, O
like O
two O
, O
three O
times O
a O
week O
. O

, O
and O
, O
, O
in O
terms O
of O
your O
job O
, O
do O
you O
do O
anything O
physical O
? O
so O
you O
know O
you O
said O
you O
think O
you O
ve O
got O
, O
, O
osteoarthritis O
. O

But O
its O
just O
, O
just O
a O
bit O
, O
a O
bit O
weird O
, O
to O
see O
that O
. O

And O
I O
was O
born O
on O
the O
fifth O
of O
April O
, O
, O
nineteen O
seventy O
three O
. O

Do O
you O
have O
any O
other O
illnesses O
at O
all O
? O
BERT B-MethodName
- I-MethodName
extBefore I-MethodName
we O
start O
your O
appointment O
, O
could O
you O
please O
tell O
me O
your O
first O
name O
and O
your O
date O
of O
birth O
. O

Deen O
takes O
a O
look O
at O
Johns O
elbow O
to O
see O
if O
there O
is O
anything O
wrong O
with O
it O
. O

He O
also O
says O
he O
is O
allergic O
to O
peanuts O
. O

John O
says O
he O
has O
a O
weird O
swelling O
on O
his O
left O
elbow O
. O

BART B-MethodName
- I-MethodName
CNNDoctor I-MethodName
Deen O
Mirza O
from O
GP O
at O
Hand O
sees O
John O
Smith O
. O

Mild O
erythema O
and O
minimal O
swelling O
( O
if O
any O
) O
around O
olecranon O
process O
left O
elbow O
Imp O
: O
possible O
bursitis O
Plan O
: O
for O
NSAIDsusual O
advice O
re O
SE O
For O
rheum O
bloods O
: O
esr O
, O
crp O
, O
fbc O
, O
rheum O
factor O
and O
urate O
Review O
thereafter O
in O
person/ O
via O
video O
To O
contact O
us O
back O
in O
interim O
if O
any O
deterioration O
/ O
concernspt O
warned O
re O
symptoms O
of O
septic O
arthritis O
. O

No O
FH O
of O
rheumatological O
diseaseNB O
pt O
says O
he O
has O
been O
old O
he O
has O
OA O
previously O
by O
doctors? O
need O
to O
confirm O
this O
Works O
in O
a O
desk O
job O
Not O
happened O
before O
Otherwise O
wellPMHx O
: O
nil O
of O
note O
FH O
: O
nil O
of O
note O
DH O
: O
not O
on O
any O
medication O
, O
allergic O
to O
peanuts O
SH O
: O
exercises O
regularly O
, O
active O
Ex O
: O
looks O
well O
, O
not O
in O
pain O
. O

No O
trauma O
. O

Not O
painful O
. O

Human O
NoteHx O
: O
1 O
week O
history O
of O
spontaneous O
elbow O
swelling O
left O
. O

Both O
are O
partial.597 O
. O

Table O
A.2 O
: O
An O
example O
of O
a O
human O
transcript O
and O
a O
Google O
Speech B-TaskName
- I-TaskName
to I-TaskName
- I-TaskName
text I-TaskName
transcript O
for O
one O
of O
the O
mock O
consultations O
. O

Patient O
: O
Bye O
- O
bye O
. O

Doctor O
: O
Hope O
you O
have O
a O
good O
day O
. O

Patient O
: O
Thank O
you O
very O
much O
. O

Well O
, O
I O
wish O
you O
all O
the O
best O
. O

Doctor O
: O
Okay O
. O

Doctor O
: O
Okay O
any O
questions O
for O
me O
? O
Patient O
: O
And O
now O
that O
s O
it O
. O

Patient O
: O
That O
sounds O
good O
. O

Its O
definitely O
worth O
trying O
its O
not O
gon O
na O
do O
you O
any O
harm O
but O
I O
say O
anything O
using O
the O
steroids O
and O
the O
emollients O
on O
a O
regular O
basis O
over O
the O
next O
week O
to O
10 O
days O
should O
hopefully O
care O
control O
your O
symptoms O
, O
but O
do O
come O
back O
and O
see O
me O
next O
week O
if O
things O
do O
nt O
get O
better O
. O

Doctor O
: O
something O
like O
fix O
the O
penalty O
in O
which O
I O
can O
give O
to O
you O
today O
. O

So O
something O
for O
you O
to O
think O
about O
a O
you O
can O
get O
different O
types O
of O
and O
system O
means O
I O
can O
give O
you O
something O
Little O
Bit O
Stronger O
today O
as O
well O
Patient O
: O
Okay O
. O

* O
* O
* O
Doctor O
: O
It O
did O
nt O
okay O
. O

Patient O
: O
really O
annoying O
because O
I O
can O
actually O
think O
about O
what O
happened O
say O
, O
I O
m O
always O
like O
disturbed O
by O
this O
disease O
. O

Its O
Doctor O
: O
Yeah O
. O

Like O
I O
really O
need O
something O
quickly O
to O
study O
because O
even O
at O
work O
I O
like O
when O
I O
m O
in O
the O
meeting O
and O
I O
have O
to O
like O
think O
about O
my O
work O
Focus O
like O
actually O
focus O
on O
my O
work O
. O

Its O
super O
annoying O
like O
its O
itching O
a O
lot O
like O
all O
the O
time O
and O
I O
ca O
nt O
even O
sleep O
at O
night O
. O

Patient O
: O
Mostly O
like O
my O
chest O
my O
my O
hands O
my O
arms O
like O
agree O
. O

Happy O
to O
help O
whereabouts O
of O
your O
skin O
is O
affected O
. O

Doctor O
: O
No O
, O
no O
problem O
. O

Patient O
: O
So O
I O
d O
like O
to O
find O
something O
quick O
to O
serve O
it O
. O

Doctor O
: O
Okay O
. O

I O
have O
like O
a O
sore O
and O
the O
Redskin O
its O
kind O
of O
its O
really O
itchy O
and O
its O
like O
super O
annoying O
. O

So O
, O
how O
can O
I O
help O
you O
, O
sir O
? O
Patient O
: O
Yes O
, O
so O
its O
been O
a O
few O
days O
now O
. O

Doctor O
: O
okay O
, O
lets O
talk O
again O
. O

Anyway O
, O
Patient O
: O
Okay O
. O

But O
lets O
continue O
. O

Its O
not O
very O
clear O
. O

Its O
a O
bit O
. O

Its O
a O
bit O
. O

Patient O
: O
Hello O
, O
can O
you O
hear O
me O
wet O
? O
Doctor O
: O
Yes O
, O
I O
think O
its O
a O
bit O
better O
. O

Bye O
. O
Doctor O
: O
Hello O
. O

Thank O
you O
as O
well O
. O

Bye O
. O

Thank O
you O
very O
much O
. O

Doctor O
: O
OK O
? O
Um O
do O
you O
have O
any O
questions O
for O
me O
? O
Patient O
: O
Uh O
, O
no O
that O
s O
it O
. O

Patient O
: O
That O
sounds O
good O
. O

But O
do O
come O
back O
and O
see O
me O
next O
week O
, O
if O
things O
do O
nt O
get O
better O
. O

Doctor O
: O
Um O
but O
I O
think O
using O
the O
steroids O
and O
the O
emollients O
, O
um O
on O
a O
regular O
basis O
Uh O
over O
the O
next O
week O
to O
ten O
days O
, O
should O
hopefully O
control O
your O
symptoms O
. O

Patient O
: O
OK O
. O

Its O
definitely O
worth O
trying O
, O
and O
its O
not O
going O
to O
do O
you O
any O
harm O
. O

Um O
, O
something O
like O
Fexofenadine O
, O
which O
I O
can O
give O
to O
you O
today O
. O

I O
can O
give O
you O
something O
a O
little O
bit O
stronger O
today O
as O
well O
. O

you O
can O
get O
different O
types O
of O
antihistamines O
. O

So O
its O
something O
for O
you O
to O
think O
about O
. O

OK O
. O

* O
* O
* O
Doctor O
: O
OK O
. O

I O
m O
always O
like O
, O
uh O
, O
disturbed O
by O
this O
disease O
. O

Its O
really O
annoying O
because O
I O
ca O
nt O
actually O
think O
about O
, O
uh O
, O
what O
I O
have O
to O
say O
. O

Because O
even O
at O
work O
I O
, O
I O
can O
, O
when O
I O
m O
in O
a O
meeting O
and O
I O
have O
to O
, O
like O
uh O
think O
about O
my O
work O
, O
I O
ca O
nt O
focus O
, O
I O
ca O
nt O
actually O
focus O
on O
my O
work O
. O

I O
really O
need O
something O
quickly O
to O
, O
to O
solve O
it O
. O

And O
I O
ca O
nt O
even O
sleep O
at O
night O
. O

Like O
its O
itching O
a O
lot O
, O
like O
all O
the O
time O
. O

Like O
, O
like O
really O
, O
its O
its O
super O
annoying O
. O

Um O
whereabouts O
in O
your O
skin O
is O
it O
affected O
? O
Patient O
: O
Uh O
, O
mostly O
like O
my O
chest O
, O
my O
, O
my O
hands O
, O
my O
arms O
. O

I O
m O
happy O
to O
help O
. O

No O
, O
no O
problem O
. O

Doctor O
: O
OK O
. O

So O
I O
d O
like O
to O
find O
something O
quick O
to O
solve O
it O
. O

Its O
kind O
of O
, O
its O
really O
itchy O
, O
and O
its O
like O
super O
annoying O
. O

I O
have O
like O
a O
sore O
, O
and O
a O
red O
skin O
. O

So O
, O
its O
been O
a O
few O
days O
now O
. O

So O
how O
can O
I O
help O
you O
sir O
? O
Patient O
: O
Yes O
. O

Lets O
start O
again O
. O

Doctor O
: O
Uh O
, O
OK O
. O

Patient O
: O
OK O
. O

But O
lets O
continue O
anyway O
. O

Its O
a O
bit O
, O
its O
a O
bit O
, O
its O
not O
very O
clear O
. O

Its O
a O
bit O
better O
. O

I O
think O
. O

Can O
you O
hear O
me O
well O
? O
Doctor O
: O
Uh O
uh O
yes O
. O

Human O
Transcription O
Google O
Speech B-TaskName
- I-TaskName
to I-TaskName
- I-TaskName
text I-TaskName
Doctor O
: O
Hello O
? O
Patient O
: O
Hello O
. O

Mock O
patients O
were O
given O
a O
case O
card O
and O
asked O
to O
study O
it O
before O
consulting O
with O
the O
clinician.596 O
. O

Was O
constipated O
until O
1 O
week O
ago O
but O
that O
has O
cleared O
up O
now O
Had O
sexual O
intercourse O
4 O
days O
ago O
No O
new O
sexual O
partner O
since O
last O
STI O
screen O
6 O
months O
ago O
No O
vaginal O
discharge O
Has O
Implanon O
contraceptive O
implant O
for O
1 O
year O
No O
change O
in O
vaginal O
bleeding O
No O
loin O
pain O
Activities O
of O
daily O
living O
: O
No O
problems O
performing O
daily O
activities O
Family O
history O
: O
nil O
Past O
Medical O
History O
: O
nil O
Drug O
History O
: O
Implanon O
Allergies O
: O
Amoxicillin O
Table O
A.1 O
: O
Example O
clinical O
case O
card O
for O
a O
Urinary O
Tract O
Infection O
. O

Symptoms O
and O
risk O
factors O
: O
There O
is O
some O
blood O
in O
the O
urine O
pink O
colour O
Pain O
below O
belly O
button O
Feeling O
nauseated O
but O
no O
vomiting O
Going O
to O
the O
toilet O
a O
little O
more O
often O
but O
drinking O
lots O
of O
uids O
No O
urine O
urgency O
or O
pain O
when O
passing O
urine O
. O

Demographics O
( O
age O
, O
gender O
): O
23 O
year O
old O
female O
Presenting O
Complaint O
: O
Lower O
abdominal O
pain O
Duration O
of O
symptoms O
: O
2 O
days O
History O
, O
on O
open O
questioning O
: O
Have O
a O
terrible O
ache O
in O
my O
lower O
tummy O
and O
feeling O
hot O
and O
sweaty O
. O

Appendix O
Figure O
A.1 O
: O
Accent O
and O
age O
group O
distributions O
for O
patients O
in O
the O
57 O
mock O
consultations O
. O

In O
Proceedings O
of O
the O
58th O
Annual O
Meeting O
of O
the O
Association O
for O
Computational O
Linguistics O
, O
pages O
51085120.595 O
. O

Optimizing O
the O
factual O
correctness O
of O
a O
summary O
: O
A O
study O
of O
summarizing O
radiology O
reports O
. O

2020 O
. O

Yuhao O
Zhang O
, O
Derek O
Merck O
, O
Emily O
Tsai O
, O
Christopher O
D O
Manning O
, O
and O
Curtis O
Langlotz O
. O

In O
International O
Conference O
on O
Learning O
Representations O
. O

Bertscore B-MetricName
: O
Evaluating O
text O
generation O
with O
bert B-MethodName
. O

2019 O
. O

Tianyi O
Zhang O
, O
Varsha O
Kishore O
, O
Felix O
Wu O
, O
Kilian O
Q O
Weinberger O
, O
and O
Yoav O
Artzi O
. O

arXiv O
preprint O
arXiv:2109.12174 O
. O

Leveraging O
pretrained O
models O
for O
automatic O
summarization O
of O
doctor O
- O
patient O
conversations O
. O

2021.594 O
. O

Longxiang O
Zhang O
, O
Renato O
Negrinho O
, O
Arindam O
Ghosh O
, O
Vasudevan O
Jagannathan O
, O
Hamid O
Reza O
Hassanzadeh O
, O
Thomas O
Schaaf O
, O
and O
Matthew O
R O
Gormley O
. O

In O
Proceedings O
of O
the O
Second O
Workshop O
on O
Natural O
Language O
Processing O
for O
Medical O
Conversations O
, O
pages O
1020 O
. O

Towards O
automating O
medical O
scribing O
: O
Clinic O
visit O
dialogue2note O
sentence O
alignment O
and O
snippet O
summarization O
. O

2021 O
. O

Wen O
- O
wai O
Yim O
and O
Meliha O
Yetisgen O
- O
Yildiz O
. O

In O
Advances O
in O
neural O
information O
processing O
systems O
, O
pages O
59986008 O
. O

Attention O
is O
all O
you O
need O
. O

2017 O
. O

Ashish O
Vaswani O
, O
Noam O
Shazeer O
, O
Niki O
Parmar O
, O
Jakob O
Uszkoreit O
, O
Llion O
Jones O
, O
Aidan O
N O
Gomez O
, O
ukasz O
Kaiser O
, O
and O
Illia O
Polosukhin O
. O

ArXiv O
: O
2104.02219 O
. O

arXiv:2104.02219 O
[ O
cs O
] O
. O

Understanding O
Medical O
Conversations O
: O
Rich O
Transcription O
, O
Confidence O
Scores O
& O
Information O
Extraction O
. O

2021 O
. O

Hagen O
Soltau O
, O
Mingqiu O
Wang O
, O
Izhak O
Shafran O
, O
and O
Laurent O
El O
Shafey O
. O

Springer O
International O
Publishing O
, O
Cham O
. O

Buckeridge O
, O
editors O
, O
Explainable O
AI O
in O
Healthcare O
and O
Medicine O
: O
Building O
a O
Culture O
of O
Transparency O
and O
Accountability O
, O
Studies O
in O
Computational O
Intelligence O
, O
pages O
195209 O
. O

In O
Arash O
Shaban O
- O
Nejad O
, O
Martin O
Michalowski O
, O
and O
David O
L O
. O

Medication O
Regimen O
Extraction O
from O
Medical O
Conversations O
. O

2021 O
. O

Selvaraj O
and O
Sandeep O
Konam O
. O

Sai O
P O
. O

Publisher O
: O
SAGE O
Publications O
Ltd O
. O

Health O
Informatics O
Journal O
, O
26(4):29062914 O
. O

Identifying O
relevant O
information O
in O
medical O
conversations O
to O
summarize O
a O
clinician O
- O
patient O
encounter O
. O

2020 O
. O

Juan O
C O
Quiroz O
, O
Liliana O
Laranjo O
, O
Ahmet O
Baki O
Kocaballi O
, O
Agustina O
Briatore O
, O
Shlomo O
Berkovsky O
, O
Dana O
Rezazadegan O
, O
and O
Enrico O
Coiera O
. O

IEEE O
Signal O
Processing O
Society O
. O

In O
IEEE O
2011 O
workshop O
on O
automatic B-TaskName
speech I-TaskName
recognition I-TaskName
and I-TaskName
understanding I-TaskName
, O
CONF O
. O

The O
kaldi O
speech O
recognition O
toolkit O
. O

Daniel O
Povey O
, O
Arnab O
Ghoshal O
, O
Gilles O
Boulianne O
, O
Lukas O
Burget O
, O
Ondrej O
Glembek O
, O
Nagendra O
Goel O
, O
Mirko O
Hannemann O
, O
Petr O
Motlicek O
, O
Yanmin O
Qian O
, O
Petr O
Schwarz O
, O
et O
al O
. O
2011 O
. O

The O
Nurse O
Practitioner O
, O
41(2):2936 O
. O

The O
essential O
soap O
note O
in O
an O
ehr O
age O
. O

2016 O
. O

Patricia O
F O
Pearce O
, O
Laurie O
Anne O
Ferguson O
, O
Gwen O
S O
George O
, O
and O
Cynthia O
A O
Langford O
. O

In O
Proceedings O
of O
The O
20th O
SIGNLL O
Conference O
on O
Computational O
Natural O
Language O
Learning O
, O
pages O
280290 O
. O

Abstractive O
text B-TaskName
summarization I-TaskName
using O
sequence O
- O
to O
- O
sequence O
rnns O
and O
beyond O
. O

2016 O
. O

Ramesh O
Nallapati O
, O
Bowen O
Zhou O
, O
Cicero O
dos O
Santos O
, O
aglar O
Gulehre O
, O
and O
Bing O
Xiang O
. O

In O
Proceedings O
of O
the O
60th O
Annual O
Meeting O
of O
the O
Association O
for O
Computational O
Linguistics O
. O

( O
in O
press):Human O
evaluation O
and O
correlation O
with O
automatic O
metrics O
in O
consultation O
note O
generation O
. O

2022 O
. O

Francesco O
Moramarco O
, O
Alex O
Papadopoulos O
Korfiatis O
, O
Mark O
Perera O
, O
Damir O
Juric O
, O
Jack O
Flann O
, O
Ehud O
Reiter O
, O
Anya O
Belz O
, O
and O
Aleksandar O
Savkov O
. O

In O
Proceedings O
of O
the O
Workshop O
on O
Human O
Evaluation O
of O
NLP O
Systems O
( O
HumEval O
) O
, O
pages O
6268 O
. O

A O
preliminary O
study O
on O
evaluating O
consultation O
notes O
with O
post O
- O
editing O
. O

2021 O
. O

Francesco O
Moramarco O
, O
Alex O
Papadopoulos O
Korfiatis O
, O
Aleksandar O
Savkov O
, O
and O
Ehud O
Reiter O
. O

Advanced O
Information O
Systems O
Engineering O
Workshops O
, O
382:7688 O
. O

Medical B-TaskName
Dialogue I-TaskName
Summarization I-TaskName
for O
Automated O
Reporting O
in O
Healthcare O
. O

2020 O
. O

Sabine O
Molenaar O
, O
Lientje O
Maas O
, O
Vernica O
Burriel O
, O
Fabiano O
Dalpiaz O
, O
and O
Sjaak O
Brinkkemper O
. O

arXiv O
preprint O
arXiv:1906.04165 O
. O

Leveraging O
bert B-MethodName
for O
extractive O
text B-TaskName
summarization I-TaskName
on O
lectures O
. O

2019 O
. O

Derek O
Miller O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
First O
Workshop O
on O
Natural O
Language O
Processing O
for O
Medical O
Conversations O
, O
pages O
711 O
, O
Online O
. O

Towards O
Understanding O
ASR B-TaskName
Error O
Correction O
for O
Medical O
Conversations O
. O

2020 O
. O

Anirudh O
Mani O
, O
Shruti O
Palaskar O
, O
and O
Sandeep O
Konam O
. O

InProceedings O
of O
the O
42nd O
International O
ACM O
SIGIR O
Conference O
on O
Research O
and O
Development O
in O
Information O
Retrieval O
, O
pages O
10131016 O
. O

Ontology B-TaskName
- I-TaskName
aware I-TaskName
clinical I-TaskName
abstractive I-TaskName
summarization I-TaskName
. O

2019 O
. O

Sean O
MacAvaney O
, O
Sajad O
Sotudeh O
, O
Arman O
Cohan O
, O
Nazli O
Goharian O
, O
Ish O
Talati O
, O
and O
Ross O
W O
Filice O
. O

IEEE O
. O

In O
2019 O
IEEE O
Automatic B-TaskName
Speech I-TaskName
Recognition I-TaskName
and I-TaskName
Understanding I-TaskName
Workshop O
( O
ASRU O
) O
, O
pages O
814821 O
. O

Topic O
- O
aware O
pointergenerator O
networks O
for O
summarizing O
spoken O
conversations O
. O

2019 O
. O

Zhengyuan O
Liu O
, O
Angela O
Ng O
, O
Sheldon O
Lee O
, O
Ai O
Ti O
Aw O
, O
and O
Nancy O
F O
Chen O
. O

In O
Text B-TaskName
summarization I-TaskName
branches O
out O
, O
pages O
7481 O
. O

Rouge O
: O
A O
package O
for O
automatic O
evaluation O
of O
summaries O
. O

2004 O
. O

Chin O
- O
Yew O
Lin O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
58th O
Annual O
Meeting O
of O
the O
Association O
for O
Computational O
Linguistics O
, O
pages O
78717880 O
, O
Online O
. O

BART B-MethodName
: O
Denoising O
sequence O
- O
to O
- O
sequence O
pretraining O
for O
natural O
language O
generation O
, O
translation O
, O
and O
comprehension O
. O

2020 O
. O

Mike O
Lewis O
, O
Yinhan O
Liu O
, O
Naman O
Goyal O
, O
Marjan O
Ghazvininejad O
, O
Abdelrahman O
Mohamed O
, O
Omer O
Levy O
, O
Veselin O
Stoyanov O
, O
and O
Luke O
Zettlemoyer O
. O

Publisher O
: O
Georg O
Thieme O
Verlag O
KG O
. O

Applied O
Clinical O
Informatics O
, O
09(3):541552 O
. O

Electronic O
Health O
Record O
Interactions O
through O
V O
oice O
: O
A O
Review O
. O

2018 O
. O

Lehmann O
. O

Anders O
, O
and O
Christoph O
U O
. O

Goode O
, O
Shilo O
H O
. O

Whyte O
, O
Edward O
S O
. O

Pirtle O
, O
Harrison O
M O
. O

Kumah O
- O
Crystal O
, O
Claude O
J O
. O

Yaa O
A O
. O

Association O
for O
Computational O
Linguistics O
. O

Conference O
on O
Natural O
Language O
Processing O
( O
Volume O
1 O
: O
Long O
Papers O
) O
, O
pages O
49584972 O
, O
Online O
. O

In O
Proceedings O
of O
the O
59th O
Annual O
Meeting O
of O
the O
Association O
for O
Computational O
Linguistics O
and O
the O
11th O
International O
Joint593 O
. O

Generating O
SOAP O
notes O
from O
doctor O
- O
patient O
conversations O
using O
modular O
summarization O
techniques O
. O

2021 O
. O

Lipton O
. O

Kundan O
Krishna O
, O
Sopan O
Khosla O
, O
Jeffrey O
Bigham O
, O
and O
Zachary O
C O
. O

IEEE O
. O

In O
ICASSP O
2020 O
- O
2020 O
IEEE O
International O
Conference O
on O
Acoustics O
, O
Speech O
and O
Signal O
Processing O
( O
ICASSP O
) O
, O
pages O
61246128 O
. O

Quartznet B-MethodName
: O
Deep O
automatic B-TaskName
speech I-TaskName
recognition I-TaskName
with O
1d O
time O
- O
channel O
separable O
convolutions O
. O

2020 O
. O

Samuel O
Kriman O
, O
Stanislav O
Beliaev O
, O
Boris O
Ginsburg O
, O
Jocelyn O
Huang O
, O
Oleksii O
Kuchaiev O
, O
Vitaly O
Lavrukhin O
, O
Ryan O
Leary O
, O
Jason O
Li O
, O
and O
Yang O
Zhang O
. O

AMIA O
Annual O
Symposium O
Proceedings O
, O
2018:683689 O
. O

A O
systematic O
comparison O
of O
contemporary O
automatic O
speech O
recognition O
engines O
for O
conversational O
clinical O
speech O
. O

2018 O
. O

Marc O
Overhage O
. O

Jodi O
Kodish O
- O
Wachs O
, O
Emin O
Agassi O
, O
Patrick O
Kenny O
, O
and O
J O
. O

thesis O
, O
Carnegie O
Mellon O
University O
. O

End B-TaskName
- I-TaskName
to I-TaskName
- I-TaskName
End I-TaskName
Speech I-TaskName
Recognition I-TaskName
on I-TaskName
Conversations I-TaskName
. O

2020 O
. O

Suyoun O
Kim O
. O

Dataset O
for O
automated O
medical O
transcription O
. O

2020 O
. O

Nazmul O
Kazi O
, O
Matt O
Kuntz O
, O
Upulee O
Kanewala O
, O
and O
Indika O
Kahanda O
. O

https://github.com/UCSD-AI4H/COVID-Dialogue O
. O

Coviddialog O
: O
Medical O
dialogue O
datasets O
about O
covid-19 O
. O

2020 O
. O

Zeqian O
Ju O
, O
Subrato O
Chakravorty O
, O
Xuehai O
He O
, O
Shu O
Chen O
, O
Xingyi O
Yang O
, O
and O
Pengtao O
Xie O
. O

In O
Proceedings O
of O
the O
2020 O
Conference O
on O
Empirical O
Methods O
in O
Natural O
Language O
Processing O
: O
Findings O
, O
pages O
37553763 O
. O

summarize O
: O
Global O
summarization O
of O
medical O
dialogue O
by O
exploiting O
local O
structures O
. O

Dr O
. O

2020 O
. O

Anirudh O
Joshi O
, O
Namit O
Katariya O
, O
Xavier O
Amatriain O
, O
and O
Anitha O
Kannan O
. O

BMC O
Medical O
Informatics O
and O
Decision O
Making O
, O
14:94 O
. O

A O
systematic O
review O
of O
speech O
recognition O
technology O
in O
health O
care O
. O

2014 O
. O

Maree O
Johnson O
, O
Samuel O
Lapkin O
, O
Vanessa O
Long O
, O
Paula O
Sanchez O
, O
Hanna O
Suominen O
, O
Jim O
Basilakis O
, O
and O
Linda O
Dawson O
. O

Journal O
of O
the O
American O
Medical O
Informatics O
Association O
: O
JAMIA O
, O
23(e1):e169e179 O
. O

Risks O
and O
benefits O
of O
speech B-TaskName
recognition I-TaskName
for I-TaskName
clinical I-TaskName
documentation I-TaskName
: O
a O
systematic O
review O
. O

2016 O
. O

Tobias O
Hodgson O
and O
Enrico O
Coiera O
. O

ArXiv O
: O
2004.03329 O
. O

arXiv:2004.03329 O
[ O
cs O
, O
stat O
] O
. O

MedDialog O
: O
Two O
Large O
- O
scale O
Medical O
Dialogue O
Datasets O
. O

2020 O
. O

Xuehai O
He O
, O
Shu O
Chen O
, O
Zeqian O
Ju O
, O
Xiangyu O
Dong O
, O
Hongchao O
Fang O
, O
Sicheng O
Wang O
, O
Yue O
Yang O
, O
Jiaqi O
Zeng O
, O
Ruisi O
Zhang O
, O
Ruoyu O
Zhang O
, O
Meng O
Zhou O
, O
Penghui O
Zhu O
, O
and O
Pengtao O
Xie O
. O

Conformer O
: O
Convolution O
- O
augmented O
transformer O
for O
speech O
recognition O
. O

2020 O
. O

IEEE O
Computer O
Society O
. O
Anmol O
Gulati O
, O
James O
Qin O
, O
Chung O
- O
Cheng O
Chiu O
, O
Niki O
Parmar O
, O
Yu O
Zhang O
, O
Jiahui O
Yu O
, O
Wei O
Han O
, O
Shibo O
Wang O
, O
Zhengdong O
Zhang O
, O
Yonghui O
Wu O
, O
and O
Ruoming O
Pang O
. O

In O
Proceedings O
of O
the O
1992 O
IEEE O
international O
conference O
on O
Acoustics O
, O
speech O
and O
signal O
processing O
- O
Volume O
1 O
, O
ICASSP92 O
, O
pages O
517520 O
, O
USA O
. O

SWITCHBOARD B-DatasetName
: O
telephone O
speech O
corpus O
for O
research O
and O
development O
. O

1992 O
. O

Holliman O
, O
and O
Jane O
McDaniel O
. O

Godfrey O
, O
Edward O
C O
. O

John O
J O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
2018 O
Conference O
of O
the O
North O
American O
Chapter O
of O
the O
Association O
for O
Computational O
Linguistics O
: O
Demonstrations O
, O
pages O
1115 O
, O
New O
Orleans O
, O
Louisiana O
. O

An O
automated O
medical O
scribe O
for O
documenting O
clinical O
encounters O
. O

2018 O
. O

Gregory O
Finley O
, O
Erik O
Edwards O
, O
Amanda O
Robinson O
, O
Michael O
Brenndoerfer O
, O
Najmeh O
Sadoughi O
, O
James O
Fone O
, O
Nico O
Axtmann O
, O
Mark O
Miller O
, O
and O
David O
Suendermann O
- O
Oeft O
. O

In O
Proceedings O
of O
the O
first O
workshop O
on O
natural O
language O
processing O
for O
medical O
conversations O
, O
pages O
2230 O
. O

Generating O
medical O
reports O
from O
patientdoctor O
conversations O
using O
sequence O
- O
to O
- O
sequence O
models O
. O

Seppo O
Enarvi O
, O
Marilisa O
Amoia O
, O
Miguel O
Del O
- O
Agua O
Teba O
, O
Brian O
Delaney O
, O
Frank O
Diehl O
, O
Stefan O
Hahn O
, O
Kristina O
Harris O
, O
Liam O
McGrath O
, O
Yue O
Pan O
, O
Joel O
Pinto O
, O
et O
al O
. O
2020b O
. O

Association O
for O
Computational O
Linguistics O
. O

In O
Proceedings O
of O
the O
First O
Workshop O
on O
Natural O
Language O
Processing O
for O
Medical O
Conversations O
, O
pages O
2230 O
, O
Online O
. O

Generating O
Medical O
Reports O
from O
Patient O
- O
Doctor O
Conversations O
Using O
Sequence O
- O
to O
- O
Sequence O
Models O
. O

2020a O
. O

Seppo O
Enarvi O
, O
Marilisa O
Amoia O
, O
Miguel O
Del O
- O
Agua O
Teba O
, O
Brian O
Delaney O
, O
Frank O
Diehl O
, O
Stefan O
Hahn O
, O
Kristina O
Harris O
, O
Liam O
McGrath O
, O
Yue O
Pan O
, O
Joel O
Pinto O
, O
Luca O
Rubini O
, O
Miguel O
Ruiz O
, O
Gagandeep O
Singh O
, O
Fabian O
Stemmer O
, O
Weiyi O
Sun O
, O
Paul O
V O
ozila O
, O
Thomas O
Lin O
, O
and O
Ranjani O
Ramamurthy O
. O

Studies O
in O
health O
technology O
and O
informatics O
, O
121:279 O
. O

Snomed O
- O
ct O
: O
The O
advanced O
terminology O
and O
coding O
system O
for O
ehealth O
. O

Kevin O
Donnelly O
et O
al O
. O
2006 O
. O

In O
NAACL O
- O
HLT O
( O
1 O
) O
. O

Bert O
: O
Pre O
- O
training O
of O
deep O
bidirectional O
transformers O
for O
language B-TaskName
understanding I-TaskName
. O

2019 O
. O

Jacob O
Devlin O
, O
Ming O
- O
Wei O
Chang O
, O
Kenton O
Lee O
, O
and O
Kristina O
Toutanova O
. O

The O
Fisher B-DatasetName
corpus O
: O
A O
resource O
for O
the O
next O
generations O
of O
speech B-TaskName
- I-TaskName
to I-TaskName
- I-TaskName
text I-TaskName
. O

2004 O
. O

Christopher O
Cieri O
, O
David O
Miller O
, O
and O
Kevin O
Walker O
. O

Speech B-TaskName
recognition I-TaskName
for I-TaskName
medical I-TaskName
conversations I-TaskName
. O

2018 O
. O

Chung O
- O
Cheng O
Chiu O
, O
Anshuman O
Tripathi O
, O
Kat O
Chou O
, O
Chris O
Co O
, O
Navdeep O
Jaitly O
, O
Diana O
Jaunzeikare O
, O
Anjuli O
Kannan O
, O
Patrick O
Nguyen O
, O
Hasim O
Sak O
, O
Ananth O
Sankar O
, O
Justin O
Jesada O
Tansuwan O
, O
Nathan O
Wan O
, O
Yonghui O
Wu O
, O
and O
Frank O
Zhang O
. O

In O
Proceedings O
of O
the O
Second O
Workshop O
on O
Natural O
Language O
Processing O
for O
Medical O
Conversations O
, O
pages O
6676 O
. O

3 O
as O
a O
data O
generator O
for O
medical B-TaskName
dialogue I-TaskName
summarization I-TaskName
. O

Medically O
aware O
gpt-592 O
. O

2021 O
. O

References O
Bharath O
Chintagunta O
, O
Namit O
Katariya O
, O
Xavier O
Amatriain O
, O
and O
Anitha O
Kannan O
. O

By O
publishing O
this O
dataset O
, O
we O
hope O
to O
offer O
a O
benchmark O
for O
future O
studies O
in O
both O
ASR B-TaskName
for I-TaskName
clinical I-TaskName
conversations I-TaskName
and O
Consultation B-TaskName
Note I-TaskName
Generation I-TaskName
for O
the O
primary O
care O
domain O
. O

6 O
Conclusion O
We O
present O
a O
dataset O
of O
57 O
high O
quality O
mocked O
consultation O
audio O
recordings O
, O
their O
manually O
aligned O
and O
diarised O
transcripts O
, O
and O
consultation O
notes O
. O

A O
more O
detailed O
evaluation O
of O
this O
task O
can O
be O
found O
in O
Moramarco O
et O
al O
. O
( O
2022 O
) O
; O
example O
notes O
can O
be O
found O
in O
Appendix O
Table O
A.3 O
. O

This O
highlights O
the O
differences O
between O
consultation B-TaskName
note I-TaskName
generation I-TaskName
and O
general O
- O
purpose O
summarisation O
. O

The O
results O
can O
be O
seen O
in O
Table O
5 O
: O
the O
finetuned O
BART B-MethodName
model O
scores O
highest O
with O
all O
metrics O
, O
while O
BART B-MethodName
- I-MethodName
CNN I-MethodName
andBERT B-MethodName
- I-MethodName
ext I-MethodName
fail O
to O
outperform O
theRandom B-MethodName
baseline O
model O
. O

We O
evaluate O
the O
models O
on O
our O
dataset O
and O
report O
common O
summarisation O
metrics O
scores O
: O
Rouge-1,-2 B-MetricName
& I-MetricName
-L I-MetricName
( O
Lin O
, O
2004 O
) O
which O
compute O
the O
F B-MetricName
- I-MetricName
score I-MetricName
across O
ngrams O
between O
generated O
and O
human O
notes O
; O
and O
BERTScore B-MetricName
( O
Zhang O
et O
al O
. O
, O
2019 O
) O
, O
which O
computes O
the O
similarity O
between O
BERT B-MetricName
embeddings O
of O
the O
notes O
. O

BART B-MethodName
- I-MethodName
CNN I-MethodName
: O
a O
neural O
sequence O
- O
to O
- O
sequence O
summariser O
based O
on O
the O
BART B-MethodName
model O
( O
Lewis O
et O
al O
. O
, O
2020 O
) O
and O
fine B-TaskName
- I-TaskName
tuned I-TaskName
on O
the O
Dailymail B-DatasetName
/ I-DatasetName
CNN I-DatasetName
dataset O
( O
Nallapati O
et O
al O
. O
, O
2016 O
) O
; O
BERT B-MethodName
- I-MethodName
ext I-MethodName
: O
a O
general O
- O
purpose O
extractive O
summariser O
based O
on O
Bert B-MethodName
embeddings O
( O
Miller O
, O
2019 O
) O
; O
Random B-MethodName
: O
a O
baseline O
that O
extracts O
15 O
random O
sentences O
from O
the O
transcript O
and O
collates O
them O
to O
form O
a O
note O
; O
BART B-MethodName
- I-MethodName
finet I-MethodName
: O
a O
BART B-MethodName
- I-MethodName
CNN I-MethodName
model O
further O
finetuned B-TaskName
on O
a O
proprietary O
dataset O
of O
8,000 O
real O
transcripts O
and O
consultation O
notes O
. O

B O
represents O
nonrescaled O
BERTScore B-MetricName
; O
score O
range O
is O
between O
0.7 B-MetricValue
to O
0.9 B-MetricValue
, O
so O
differences O
are O
less O
pronounced O
. O

R1 B-MetricName
through O
L O
represent O
Rouge O
F1 B-MetricName
scores I-MetricName
for O
unigrams O
, O
bigrams O
, O
and O
longest O
- O
common O
- O
subsequence O
. O

Model O
R1 B-MetricName
R2 B-MetricName
RL B-MetricName
B B-MetricName
BART B-MethodName
- I-MethodName
CNN I-MethodName
0.17 B-MetricValue
0.02 B-MetricValue
0.10 B-MetricValue
0.80 B-MetricValue
BERT B-MethodName
- I-MethodName
ext I-MethodName
0.21 B-MetricValue
0.03 B-MetricValue
0.10 B-MetricValue
0.78 B-MetricValue
Random B-MethodName
0.19 B-MetricValue
0.02 B-MetricValue
0.09 B-MetricValue
0.78 B-MetricValue
BART B-MethodName
- I-MethodName
finet I-MethodName
0.31 B-MetricValue
0.08 B-MetricValue
0.17 B-MetricValue
0.81 B-MetricValue
Table O
5 O
: O
Average O
common O
metrics O
scores O
of O
different O
models O
on O
the O
57 O
consultations O
. O

Table O
4 O
: O
Snippet O
of O
a O
mock O
consultation O
transcript O
and O
the O
corresponding O
note O
, O
written O
by O
the O
consulting O
clinician O
. O

And O
, O
um O
, O
in O
this O
six O
week O
period O
, O
have O
you O
had O
anything O
else O
happen O
? O
Have O
you O
had O
any O
other O
ear O
symptoms O
at O
all O
? O
Patient O
Um O
, O
I O
occasionally O
get O
like O
a O
ringing O
in O
my O
left O
ear O
, O
uh O
just O
on O
the O
one O
side O
and O
um O
there O
s O
actually O
been O
a O
few O
times O
when O
I O
felt O
kind O
of O
a O
bit O
sick O
or O
a O
bit O
dizzy O
as O
well O
. O

Clinician O
Right O
, O
OK O
, O
OK O
. O

Um O
, O
and O
before O
that O
have O
you O
had O
any O
hearing O
problem O
at O
all O
? O
Patient O
Um O
I O
had O
something O
maybe O
, O
about O
a O
year O
ago O
, O
but O
it O
only O
lasted O
a O
couple O
of O
days O
, O
it O
was O
nt O
anything O
as O
long O
as O
this O
. O

Clinician O
Six O
weeks O
, O
OK O
. O

How O
long O
has O
this O
been O
going O
on O
for O
? O
Patient O
Uh O
about O
six O
weeks O
. O

Clinician O
Right O
, O
OK O
. O

Imp O
: O
need O
to O
exclude O
impacted O
wax O
in O
ear O
canal O
first O
Pln O
: O
for O
face O
to O
face O
GP O
appointment O
in O
5 O
days O
to O
examine O
ear O
If O
any O
problems O
in O
interim O
to O
ring O
us O
back O
Pt O
happy O
with O
and O
understands O
planPatient O
Yeah O
, O
so O
I O
just O
feel O
I O
ca O
nt O
really O
hear O
as O
well O
as O
I O
used O
to O
, O
like O
my O
hearing O
is O
kind O
of O
deteriorating O
in O
some O
way O
. O

No O
discharge O
/ O
fever O
/ O
itchiness O
/ O
pain O
Does O
nt O
use O
cotton O
wool O
buds O
No O
Pmhx O
of O
note O
Ex O
: O
Looks O
well O
, O
not O
in O
pain O
. O

One O
previous O
similar O
episode O
in O
the O
pastresolved O
spontaneously O
. O

Is O
that O
right?History O
: O
Hx O
of O
difficulty O
hearing O
left O
ear O
for O
6 O
weeks O
with O
tinnitus O
and O
slight O
nausea/ O
dizziness O
. O

You O
ve O
been O
saying O
there O
s O
a O
problem O
with O
your O
hearing O
. O

Transcript O
Note O
Clinician O
So O
, O
um O
, O
tell O
me O
what O
s O
been O
going O
on O
. O

The O
approaches O
considered O
include O
: O
8https://github.com/usnistgov/SCTK591 O
. O

We O
propose O
a O
benchmark O
for O
this O
task O
by O
evaluating O
a O
number O
of O
baseline O
approaches O
and O
reporting O
common O
automatic O
metric O
scores O
on O
our O
dataset O
. O

5 O
Consultation O
Note O
Generation O
Benchmark O
The O
consultation O
transcripts O
and O
corresponding O
notes O
( O
see O
example O
in O
Table O
4 O
) O
are O
intended O
as O
a O
parallel O
dataset O
to O
evaluate O
methods O
for O
automatically O
generating O
primary O
care O
consultation O
notes O
. O

The O
results O
mostly O
match O
the O
WER B-MetricName
comparisons O
; O
the O
medical O
- O
domain O
Amazon O
model O
does O
not O
seem O
to O
perform O
better O
. O

We O
extract O
medical O
concepts O
from O
each O
utterance O
in O
both O
reference O
and O
hypothesis O
transcripts O
, O
then O
compare O
the O
concepts O
extracted O
to O
estimate O
accuracy B-MetricName
based O
on O
clinical O
terminology O
( O
ECCA B-MetricName
in O
Table O
3 O
) O
. O

To O
test O
this O
, O
we O
use O
a O
proprietary O
clinical O
information O
extraction O
engine O
based O
on O
fuzzy O
string O
matching O
, O
linking O
to O
SNOMED B-MethodName
- I-MethodName
CT I-MethodName
( O
Donnelly O
et O
al O
. O
, O
2006 O
) O
. O

The O
base O
WER B-MetricName
metric O
treats O
all O
words O
in O
a O
transcript O
as O
equally O
important O
; O
this O
may O
be O
less O
desirable O
in O
the O
clinical O
domain O
, O
where O
the O
correct O
transcription O
of O
specific O
clinical O
terms O
is O
expected O
to O
be O
more O
important O
. O

Conformer B-MethodName
performs O
surprisingly O
well O
, O
given O
that O
it O
is O
a O
character O
- O
level O
model O
evaluated O
on O
a O
word O
- O
level O
metric O
. O

Even O
though O
both O
are O
general O
domain O
, O
Google O
and O
Azure O
together O
are O
the O
best O
performing O
models O
on O
our O
dataset O
( O
p= B-MetricName
0:097 B-MetricValue
) O
. O

The O
mean B-MetricName
WER I-MetricName
, O
including O
a O
breakdown O
by O
gender O
, O
role O
, O
and O
accent O
can O
be O
seen O
in O
Table O
3 O
. O

5https://cloud.google.com/speech-to-text O
6https://aws.amazon.com/transcribe/medical/ O
7https://azure.microsoft.com/en-us/services/ O
cognitive O
- O
services O
/ O
speech B-TaskName
- I-TaskName
to I-TaskName
- I-TaskName
text I-TaskName
/ O
Finally O
, O
we O
compute O
the O
Word B-MetricName
Error I-MetricName
Rate I-MetricName
( O
WER B-MetricName
) O
for O
each O
utterance O
using O
SCTKs O
sclite8tool O
. O

These O
are O
included O
in O
the O
reference O
transcripts O
, O
but O
often O
omitted O
in O
each O
STT B-TaskName
service O
; O
2.Replace O
numerals O
( O
" O
5 O
" O
, O
" O
9th O
" O
, O
" O
1984 O
" O
) O
with O
written O
equivalents O
( O
" O
five O
" O
, O
" O
ninth O
" O
, O
" O
nineteen O
eighty O
- O
four O
" O
) O
to O
ensure O
uniformity O
; O
3.Remove O
all O
punctuation O
, O
collapse O
multiple O
spaces O
and O
convert O
to O
lowercase O
. O

We O
ensure O
consistency O
by O
performing O
the O
following O
post O
- O
processing O
steps O
on O
both O
human O
and O
automatic O
transcripts O
: O
1.Remove O
disuencies O
( O
" O
umm O
" O
, O
" O
uhh O
" O
, O
etc O
. O
) O
. O

We O
then O
generate O
a O
transcript O
for O
the O
utterance O
using O
each O
of O
the O
ASR B-TaskName
engines O
. O

To O
test O
the O
accuracy O
of O
the O
above O
services O
, O
we O
first O
extract O
the O
audio O
for O
each O
individual O
utterance O
identified O
by O
our O
human O
transcribers O
. O

We O
use O
the O
Standard O
model O
. O

5.Azure O
Speech B-TaskName
- I-TaskName
to I-TaskName
- I-TaskName
text I-TaskName
( O
ASTT O
) O
: O
7a O
commercially O
available O
, O
general O
domain O
service O
. O

There O
are O
models O
available O
for O
clinical O
dictation O
and O
clinical O
conversation O
; O
we O
use O
the O
conversation O
model O
with O
speciality O
= O
Primary O
Care O
. O

3.Google O
Cloud O
Speech B-TaskName
- I-TaskName
to I-TaskName
- I-TaskName
text I-TaskName
( O
GCSTT O
) O
: O
5a O
commercially O
available O
, O
general O
domain O
service O
. O

4.Amazon O
Transcribe O
Medical O
( O
ATM O
) O
: O
6a O
commercially O
available O
service O
, O
tailored O
specifically O
for O
medical O
use O
cases O
. O

We O
use O
the O
video O
enhanced O
model O
which O
is O
only O
available O
for O
the O
en O
- O
us O
language O
. O

Both O
models O
are O
end O
- O
to O
- O
end O
and O
do O
not O
use O
a O
language O
model O
. O

yindicates O
lack O
of O
statistical O
significance O
between O
mean B-MetricName
WER I-MetricName
scores I-MetricName
( O
p= O
0:097);z O
is O
weak O
significance O
( O
p= O
0:026 O
) O
; O
all O
other O
scores O
are O
p O
< O
0:001 O
. O

The O
gender O
, O
role O
and O
accent O
breakdowns O
show O
how O
each O
factor O
affects O
the O
mean O
WER B-MetricName
. O

WER B-MetricName
ECCA B-MetricName
Gender O
Role O
Accent B-TaskName
ASR I-TaskName
mean O
stdev O
M O
F O
Clinician O
Patient O
en O
- O
gb O
other O
Pr B-MetricName
Re B-MetricName
F1 B-MetricName
GC B-MetricName
STT B-MetricName
30.9y12.7 O
32.7 O
28.9 O
28.5 O
33.4 O
30.0 O
32.2 O
0.83 O
0.82 O
0.81 O
Azure O
STT O
31.3y12.8 O
32.7 O
29.6 O
26.7 O
35.8 O
30.2 O
32.7 O
0.87 O
0.79 O
0.82 O
ATM O
34.0z13.9 O
33.8 O
34.2 O
32.8 O
35.2 O
31.6 O
37.2 O
0.79 O
0.75 O
0.78 O
Kaldi O
48.9 O
14.9 O
52.7 O
44.6 O
47.0 O
50.8 O
49.5 O
48.2 O
0.64 O
0.69 O
0.68 O
QuartzNet O
46.4 O
15.5 O
48.4 O
44.1 O
48.1 O
44.7 O
46.6 O
46.1 O
0.67 O
0.49 O
0.56 O
Conformer B-MethodName
34.4z14.5 O
36.8 O
31.7 O
35.6 O
33.2 O
35.0 O
33.7 O
0.79 O
0.71 O
0.75 O
Table O
3 O
: O
Word B-MetricName
Error I-MetricName
Rate I-MetricName
( O
WER B-MetricName
) O
scores O
for O
a O
number O
of O
Speech B-TaskName
- I-TaskName
to I-TaskName
- I-TaskName
text I-TaskName
engines O
, O
and O
Extracted B-MetricName
Clinical I-MetricName
Concepts I-MetricName
Accuracy I-MetricName
( O
ECCA B-MetricName
) O
based O
on O
recognised O
clinical O
terms O
. O

2.NeMo B-MethodName
QuartzNet I-MethodName
& I-MethodName
Conformer I-MethodName
: O
These O
systems O
use O
QuartzNet B-MethodName
( O
Kriman O
et O
al O
. O
, O
2020 O
) O
and O
Conformer B-MethodName
( O
Gulati O
et O
al O
. O
, O
2020 O
) O
ASR B-TaskName
models O
, O
which O
we O
load O
using O
Nvidias O
NeMo B-MethodName
toolkit.4 O
3http://zamia-speech.org/asr/ O
4https://github.com/NVIDIA/NeMo590 O
. O

It O
uses O
a O
pretrained O
acoustic O
model O
from O
Zamia O
Speech3 O
and O
a O
3 O
- O
gram O
language O
model O
trained O
on O
a O
proprietary O
medical O
question O
answering O
dataset O
. O

4 O
ASR B-TaskName
Benchmark O
We O
perform O
a O
baseline O
study O
of O
ASR B-TaskName
for O
clinical O
conversations O
by O
passing O
the O
audio O
recordings O
of O
the O
mock O
consultations O
through O
commonly O
used O
open O
- O
source O
and O
commercial O
speech B-TaskName
- I-TaskName
to I-TaskName
- I-TaskName
text I-TaskName
engines O
: O
1.Kaldi B-MethodName
: O
This O
is O
our O
baseline O
system O
, O
built O
using O
the O
Kaldi O
( O
Povey O
et O
al O
. O
, O
2011 O
) O
speech O
recognition O
toolkit O
, O
running O
locally O
. O

Interestingly O
, O
patients O
tend O
to O
take O
longer O
turns O
than O
clinicians O
in O
the O
beginning O
of O
the O
consultation O
, O
where O
they O
presumably O
state O
their O
presenting O
complaint O
; O
turns O
are O
more O
balanced O
in O
the O
middle O
, O
and O
clinicians O
seem O
to O
take O
over O
during O
the O
diagnosis O
and O
management O
at O
the O
end O
( O
see O
Figure O
2 O
) O
. O

592 O
words O
per O
consultation O
) O
and O
take O
longer O
turns O
( O
19.3 O
vs O
12.8 O
words O
per O
turn O
) O
. O

Consultations O
have O
92 O
conversation O
turns O
and O
1,489 O
words O
on O
average O
; O
clinicians O
tend O
to O
speak O
more O
than O
patients O
( O
897 O
vs O
. O

Thus O
we O
obtained O
a O
collection O
of O
start O
times O
, O
end O
times O
, O
and O
utterance O
- O
level O
transcriptions O
, O
important O
for O
the O
ASR B-TaskName
evaluation O
described O
below O
. O

3.Provide O
an O
accurate O
transcription O
of O
each O
of O
the O
utterances O
identified O
. O

The O
patient O
initially O
speaks O
more O
than O
the O
clinician O
but O
later O
in O
the O
consultation O
this O
trend O
is O
reversed O
. O

Figure O
2 O
: O
Average O
utterance O
length O
for O
clinician O
and O
patient O
as O
a O
function O
of O
conversation O
turns O
. O

3.2 O
Manual O
transcription O
To O
transcribe O
the O
consultation O
recordings O
, O
we O
employed O
transcribers O
with O
experience O
in O
the O
clinical O
conversation O
domain O
, O
who O
were O
asked O
to O
: O
1.Listen O
to O
the O
consultation O
audio O
recordings O
, O
in O
separate O
channels O
for O
clinicians O
and O
patients O
; O
2.Identify O
the O
start O
and O
end O
points O
of O
individual O
utterances O
( O
continuous O
speech O
segments O
ending O
in O
a O
pause O
) O
; O
2Due O
to O
limitations O
of O
the O
software O
, O
audio O
was O
exported O
in O
compressed O
form O
( O
WebM O
encoder O
, O
Opus O
codec O
at O
a O
variable O
bitrate O
) O
. O

The O
resulting O
mock O
consultations O
ranged O
between O
3m48s O
and O
14m18s O
, O
with O
an O
average O
consultation O
length O
of O
9m5s O
. O

Clinicians O
were O
asked O
to O
act O
as O
close O
as O
possible O
to O
their O
actual O
consultation O
sessions O
, O
including O
conforming O
to O
a O
consultation O
length O
of O
10 O
minutes O
and O
writing O
a O
consultation O
note O
in O
the O
SOAP O
format O
( O
Pearce O
et O
al O
. O
, O
2016 O
) O
. O

We O
recorded O
57 O
mock O
consultations O
( O
8h38m6s O
in O
total O
) O
over O
5 O
days O
, O
using O
proprietary O
telemedicine O
software O
that O
allowed O
us O
to O
export O
the O
individual O
clinician O
and O
patient O
audio O
channels.2In O
order O
to O
emulate O
real O
clinical O
practice O
, O
clinicians O
were O
using O
laptops O
while O
patients O
were O
using O
mobile O
phones O
in O
an O
office O
environment O
with O
background O
noise O
. O

An O
example O
case O
card O
is O
given O
in O
Table O
2 O
. O

For O
a O
breakdown O
of O
presenting O
complaints O
, O
see O
Table O
1 O
. O

The O
case O
cards O
were O
drawn O
from O
a O
pool O
of O
primary O
care O
conditions O
, O
representative O
of O
presenting O
complaints O
in O
UK O
primary O
care O
. O

tions O
, O
and O
medications O
. O

Full O
version O
available O
in O
the O
Appendix O
. O

Mock O
patients O
were O
given O
a O
case O
card O
and O
asked O
to O
study O
it O
before O
consulting O
with O
the O
clinician O
. O

Symptoms O
and O
risk O
factors O
: O
There O
is O
some O
blood O
in O
the O
urine O
pink O
colour O
Pain O
below O
belly O
button O
Feeling O
nauseated O
but O
no O
vomiting O
* O
* O
* O
Table O
2 O
: O
An O
abridged O
example O
of O
a O
clinical O
case O
card O
for O
a O
Urinary O
Tract O
Infection O
. O

Demographics O
( O
age O
, O
gender O
): O
23 O
year O
old O
female O
Presenting O
Complaint O
: O
Lower O
abdominal O
pain O
Duration O
of O
symptoms O
: O
2 O
days O
History O
, O
on O
open O
questioning O
: O
Have O
a O
terrible O
ache O
in O
my O
lower O
tummy O
and O
feeling O
hot O
and O
sweaty O
. O

Each O
mock O
patient O
was O
given O
a O
case O
card O
that O
included O
background O
information O
( O
age O
, O
social O
history O
, O
family O
history O
of O
illnesses O
) O
as O
well O
as O
information O
about O
their O
presenting O
complaint O
, O
symptoms O
, O
condi-589 O
. O

The O
gender O
distribution O
was O
relatively O
even O
( O
52.6% O
women O
, O
47.4% O
men O
) O
; O
most O
participants O
were O
from O
25 O
to O
45 O
years O
old O
( O
see O
Figure O
A.1 O
) O
. O

The O
patient O
accent O
distribution O
is O
as O
follows O
: O
British O
English O
( O
47.4% O
) O
, O
various O
European O
( O
31.6% O
) O
, O
other O
English O
( O
10.5% O
) O
, O
and O
other O
non O
- O
English O
( O
10.5% O
) O
. O

Four O
of O
the O
clinicians O
were O
men O
and O
three O
were O
women O
; O
five O
of O
them O
had O
British O
English O
accent O
, O
and O
two O
of O
them O
Indian O
. O

Participation O
was O
optional O
and O
anyone O
could O
choose O
to O
withdraw O
at O
any O
time O
. O

The O
clinicians O
had O
experience O
with O
virtual O
consultations O
. O

3.1 O
Mock O
consultation O
recordings O
We O
employed O
7 O
clinicians O
and O
57 O
actors O
posing O
as O
patients O
from O
a O
range O
of O
ethnicities O
. O

Figure O
1 O
shows O
an O
overview O
of O
the O
data O
collection O
process O
. O

The O
case O
card O
diagnoses O
were O
selected O
to O
be O
representative O
of O
common O
telemedecine O
presenting O
complaints O
. O

The O
diagram O
inConsultation O
type O
Count O
Otitis O
2 O
Anaphylactic O
reaction O
3 O
Cardiovascular O
11 O
Dermatitis O
4 O
Fever O
4 O
Urinary O
tract O
infection O
6 O
Upper O
respiratory O
infection O
6 O
Asthma O
2 O
Gastroenteritis O
8 O
Mental O
health O
3 O
Physical O
injury O
2 O
Migraine O
6 O
Table O
1 O
: O
A O
breakdown O
by O
consultation O
case O
card O
. O

We O
built O
a O
mock O
consultation O
dataset O
as O
close O
as O
possible O
to O
the O
real O
conditions O
as O
a O
pragmatic O
alternative O
. O

3 O
Dataset O
The O
requirements O
for O
releasing O
a O
dataset O
containing O
Personal O
Health O
Information O
( O
PHI O
) O
are O
typically O
costly O
and O
involve O
collecting O
patient O
consent O
and/or O
de O
- O
identification O
, O
which O
is O
especially O
challenging O
with O
audio O
recordings O
. O

Kazi O
et O
al O
. O
( O
2020 O
) O
provide O
the O
only O
open O
access O
clinical O
dataset O
that O
could O
be O
used O
as O
a O
benchmark O
but O
it O
only O
contains O
psychiatric O
consultations O
, O
which O
is O
less O
applicable O
to O
primary O
care O
. O

However O
, O
in O
a O
similar O
fashion O
to O
the O
ASR B-TaskName
studies O
discussed O
above O
, O
most O
studies O
do O
nt O
publish O
these O
resources O
; O
hence O
, O
it O
is O
again O
prohibitively O
difficult O
to O
compare O
their O
proposed O
methods O
. O

Several O
studies O
( O
Liu O
et O
al O
. O
, O
2019 O
; O
MacAvaney O
et O
al O
. O
, O
2019 O
; O
Zhang O
et O
al O
. O
, O
2020 O
; O
Enarvi O
et O
al O
. O
, O
2020b O
; O
Joshi O
et O
al O
. O
, O
2020 O
; O
Krishna O
et O
al O
. O
, O
2021 O
; O
Chintagunta O
et O
al O
. O
, O
2021 O
; O
Yim O
and O
Yetisgen O
- O
Yildiz O
, O
2021 O
; O
Moramarco O
et O
al O
. O
, O
2021 O
; O
Zhang O
et O
al O
. O
, O
2021 O
) O
use O
proprietary O
datasets O
of O
transcripts O
and O
notes O
to O
train O
NLG B-TaskName
models O
endto O
- O
end O
, O
and O
a O
number O
of O
them O
carry O
out O
automatic O
or O
human O
evaluations O
on O
their O
proprietary O
test O
sets O
. O

Automatic B-TaskName
consultation I-TaskName
note I-TaskName
generation I-TaskName
and O
other O
long O
- O
form O
text B-TaskName
summarisation I-TaskName
tasks O
have O
rapidly O
developed O
due O
to O
recent O
advances O
in O
Natural B-TaskName
Language I-TaskName
Generation I-TaskName
( O
NLG B-TaskName
) O
architectures O
( O
Vaswani O
et O
al O
. O
, O
2017 O
; O
Devlin O
et O
al O
. O
, O
2019 O
) O
. O

Kazi O
et O
al O
. O
( O
2020 O
) O
provide O
a O
dataset O
of O
audio O
recordings O
, O
automated O
transcripts O
and O
consultation O
notes O
for O
70 O
mock O
psychiatric O
consultations O
but O
no O
human O
transcripts O
. O

datasets O
are O
gathered O
from O
online O
clinical O
question O
answering O
sources O
; O
while O
they O
are O
relevant O
for O
clinical O
chatbot O
research O
, O
they O
are O
not O
representative O
of O
clinical O
interactions O
and O
do O
not O
include O
audio O
. O

The O
resulting O
dataset O
includes O
the O
consultation O
audio O
recordings O
, O
notes O
and O
manual O
transcripts O
. O

A O
mock O
patient O
, O
reading O
from O
a O
medical O
case O
card O
, O
has O
a O
consultation O
with O
a O
clinician O
which O
is O
recorded O
and O
transcribed O
. O

Figure O
1 O
: O
Overview O
of O
the O
data O
collection O
process O
. O

These O
1https://github.com/babylonhealth/primock57588 O
. O

Ju O
et O
al O
. O
( O
2020 O
) O
do O
the O
same O
for O
COVID-19 O
related O
clinical O
dialogue O
. O

As O
for O
open O
- O
access O
datasets O
, O
He O
et O
al O
. O
( O
2020 O
) O
compile O
and O
release O
two O
clinical O
dialogue O
datasets O
in O
Chinese O
and O
English O
, O
covering O
a O
wide O
range O
of O
clinical O
specialties O
. O

Johnson O
et O
al O
. O
( O
2014 O
) O
and O
Kodish O
- O
Wachs O
et O
al O
. O
( O
2018 O
) O
perform O
systematic O
reviews O
of O
the O
accuracy O
of O
a O
number O
of O
open O
- O
source O
and O
commercial O
ASR B-TaskName
models O
for O
clinical O
conversation O
transcription O
; O
again O
, O
on O
proprietary O
datasets O
. O

Similarly O
, O
Kim O
( O
2020 O
) O
, O
Soltau O
et O
al O
. O
( O
2021 O
) O
develop B-TaskName
end I-TaskName
- I-TaskName
toend I-TaskName
ASR I-TaskName
models O
for O
clinical O
conversations O
and O
Mani O
et O
al O
. O
( O
2020 O
) O
train O
a O
sequence B-TaskName
- I-TaskName
to I-TaskName
- I-TaskName
sequence I-TaskName
machine I-TaskName
translation I-TaskName
model O
to O
correct O
the O
errors O
of O
general O
- O
domain O
ASR B-TaskName
engines O
; O
but O
they O
all O
use O
different O
, O
proprietary O
datasets O
. O

For O
example O
, O
Chiu O
et O
al O
. O
( O
2018 O
) O
detail O
a O
dataset O
of14,000 O
hours O
of O
recorded O
and O
manually O
transcribed O
consultations O
that O
they O
use O
to O
train O
an O
endto O
- O
end O
clinical O
conversation O
ASR B-TaskName
model O
. O

Because O
of O
this O
, O
comparing O
different O
approaches O
for O
clinical O
conversation O
ASR B-TaskName
is O
challenging O
. O

2 O
Related O
Work O
Automated O
transcription O
of O
clinical O
consultations O
has O
attracted O
quite O
significant O
research O
interest O
; O
however O
, O
as O
mentioned O
above O
, O
there O
is O
no O
easily O
accessible O
common O
benchmark O
dataset O
in O
the O
style O
of O
Switchboard B-DatasetName
( O
Godfrey O
et O
al O
. O
, O
1992 O
) O
or O
Fisher O
( O
Cieri O
et O
al O
. O
, O
2004 O
) O
, O
which O
are O
both O
nonmedical O
conversational O
audio O
datasets O
. O

These O
limitations O
slow O
down O
progress O
in O
the O
field O
. O
We O
release1a O
high O
quality O
public O
dataset O
of O
primary O
care O
consultation O
audio O
recordings O
, O
including O
manual O
transcriptions O
and O
associated O
consultation O
notes O
, O
which O
is O
the O
basis O
of O
our O
contributions O
: O
1.a O
benchmark O
for O
ASR B-TaskName
for O
primary O
care O
conversations O
; O
2.a O
benchmark O
for O
automatic O
generation O
of O
consultation O
notes O
for O
primary O
care O
. O

Furthermore O
, O
as O
the O
datasets O
are O
not O
shared O
, O
research O
teams O
always O
need O
to O
invest O
time O
and O
resources O
into O
making O
their O
own O
private O
dataset O
. O

Despite O
this O
being O
an O
active O
area O
of O
research O
it O
still O
lacks O
a O
commonly O
recognised O
ASR B-TaskName
benchmark O
due O
to O
the O
sensitive O
nature O
of O
clinical O
conversations O
. O

In O
turn O
, O
this O
is O
beneficial O
for O
downstream O
Natural B-TaskName
Language I-TaskName
Processing I-TaskName
( O
NLP B-TaskName
) O
tasks O
, O
such O
as O
information O
extraction O
from O
clinical O
conversations O
( O
Selvaraj O
and O
Konam O
, O
2021 O
; O
Soltau O
et O
al O
. O
, O
2021 O
) O
and O
automatic O
generation O
of O
consultation O
notes O
( O
Finley O
et O
al O
. O
, O
2018 O
; O
Enarvi O
et O
al O
. O
, O
2020a O
; O
Quiroz O
et O
al O
. O
, O
2020 O
; O
Molenaar O
et O
al O
. O
, O
2020 O
) O
. O

Additionally O
, O
ASR B-TaskName
models O
have O
become O
much O
more O
robust O
to O
applications O
in O
the O
clinical O
domain O
. O

However O
, O
the O
adoption O
of O
telemedicine O
, O
especially O
in O
primary O
care O
, O
generates O
vast O
quantities O
of O
clinical O
interaction O
recordings O
. O

1 O
Introduction O
The O
use O
of O
Automatic B-TaskName
Speech I-TaskName
Recognition I-TaskName
( O
ASR B-TaskName
) O
is O
widespread O
in O
the O
clinical O
domain O
but O
it O
is O
generally O
used O
to O
alleviate O
the O
administrative O
burden O
of O
clinical O
notes O
through O
dictation O
( O
Hodgson O
and O
Coiera O
, O
2016 O
; O
Kumah O
- O
Crystal O
et O
al O
. O
, O
2018 O
) O
. O

Our O
work O
illustrates O
how O
the O
dataset O
can O
be O
used O
as O
a O
benchmark O
for O
conversational B-TaskName
medical I-TaskName
ASR I-TaskName
as O
well O
as O
consultation O
note O
generation O
from O
transcripts O
. O

We O
detail O
the O
development O
of O
a O
public O
access O
, O
high O
quality O
dataset O
comprising O
of O
57 O
mocked O
primary O
care O
consultations O
, O
including O
audio O
recordings O
, O
their O
manual O
utterancelevel O
transcriptions O
, O
and O
the O
associated O
consultation O
notes O
. O

However O
, O
access O
to O
clinical O
datasets O
is O
heavily O
restricted O
due O
to O
patient O
privacy O
, O
thus O
slowing O
down O
normal O
research O
practices O
. O

Proceedings O
of O
the O
60th O
Annual O
Meeting O
of O
the O
Association O
for O
Computational O
Linguistics O
Volume O
2 O
: O
Short O
Papers O
, O
pages O
588 O
- O
598 O
May O
22 O
- O
27 O
, O
2022 O
c O
2022 O
Association O
for O
Computational O
Linguistics O
PriMock57 B-MethodName
: O
A O
Dataset O
Of O
Primary O
Care O
Mock O
Consultations O
Alex O
Papadopoulos O
Korfiatis O
Babylon O
alex.papadopoulos1Francesco O
Moramarco O
Babylon O
, O
University O
of O
Aberdeen O
francesco.moramarco1 O
Radmila O
Sarac O
radmila.sarac@gmail.comAleksandar O
Savkov O
Babylon O
sasho.savkov1 O
1@babylonhealth.co.uk O
Abstract O
Recent O
advances O
in O
Automatic B-TaskName
Speech I-TaskName
Recognition I-TaskName
( O
ASR B-TaskName
) O
have O
made O
it O
possible O
to O
reliably O
produce O
automatic O
transcripts O
of O
clinicianpatient O
conversations O
. O

