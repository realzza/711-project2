-DOCSTART- -X- O
Our -X- _ O
single -X- _ B-MethodName
box -X- _ I-MethodName
model -X- _ I-MethodName
represents -X- _ O
each -X- _ O
even -X- _ O
in -X- _ O
an -X- _ O
input -X- _ O
paragraph -X- _ O
using -X- _ O
a -X- _ O
box -X- _ O
and -X- _ O
the -X- _ O
pairwise -X- _ B-MethodName
box -X- _ I-MethodName
model -X- _ I-MethodName
adds -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
these -X- _ O
, -X- _ O
one -X- _ O
box -X- _ O
each -X- _ O
for -X- _ O
every -X- _ O
pair -X- _ O
of -X- _ O
events -X- _ O
( -X- _ O
see -X- _ O
section -X- _ O
3.2).244 -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
take -X- _ O
this -X- _ O
a -X- _ O
step -X- _ O
forward -X- _ O
by -X- _ O
representing -X- _ O
the -X- _ O
input -X- _ O
event -X- _ O
complex -X- _ O
using -X- _ O
multiple -X- _ B-MethodName
boxes -X- _ I-MethodName
. -X- _ O

Motivated -X- _ O
by -X- _ O
these -X- _ O
works -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
box -X- _ O
model -X- _ O
to -X- _ O
automatically -X- _ O
handle -X- _ O
inherent -X- _ O
constraints -X- _ O
without -X- _ O
heavily -X- _ O
relying -X- _ O
on -X- _ O
constrained -X- _ O
learning -X- _ O
across -X- _ O
two -X- _ O
different -X- _ O
tasks -X- _ O
. -X- _ O

Later -X- _ O
works -X- _ O
utilized -X- _ O
a -X- _ O
structured -X- _ B-MethodName
learning -X- _ I-MethodName
( -X- _ O
Ning -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
and -X- _ O
neural -X- _ B-MethodName
methods -X- _ I-MethodName
to -X- _ O
characterize -X- _ O
relations -X- _ O
. -X- _ O

The -X- _ O
results -X- _ O
of -X- _ O
symmetry -X- _ O
and -X- _ O
conjunctive -X- _ O
constraint -X- _ O
violations -X- _ O
confirm -X- _ O
our -X- _ O
expectation -X- _ O
and -X- _ O
exhibit -X- _ O
a -X- _ O
similar -X- _ O
observation -X- _ O
from -X- _ O
Table -X- _ O
4.F -X- _ O
Related -X- _ O
Work -X- _ O
F.1 -X- _ O
Event -X- _ B-TaskName
- -X- _ I-TaskName
Event -X- _ I-TaskName
Relation -X- _ I-TaskName
Extraction -X- _ I-TaskName
This -X- _ O
task -X- _ O
has -X- _ O
been -X- _ O
traditionally -X- _ O
modeled -X- _ O
as -X- _ O
a -X- _ O
pairwise -X- _ B-TaskName
classification -X- _ I-TaskName
task -X- _ I-TaskName
with -X- _ O
hand -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
engineered -X- _ I-HyperparameterName
features -X- _ I-HyperparameterName
and -X- _ O
early -X- _ O
attempts -X- _ O
applied -X- _ O
conventional -X- _ B-MethodName
machine -X- _ I-MethodName
learning -X- _ I-MethodName
methods -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
logistic -X- _ B-MethodName
regressions -X- _ I-MethodName
and -X- _ O
SVM -X- _ B-MethodName
( -X- _ O
Mani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2006b -X- _ O
; -X- _ O
Verhagen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2007 -X- _ O
; -X- _ O
Verhagen -X- _ O
and -X- _ O
Pustejovsky -X- _ O
, -X- _ O
2008 -X- _ O
) -X- _ O
. -X- _ O

Interestingly -X- _ O
, -X- _ O
our -X- _ O
approach -X- _ O
without -X- _ O
any -X- _ O
injected -X- _ O
constraints -X- _ O
shows -X- _ O
a -X- _ O
smaller -X- _ O
or -X- _ O
similar -X- _ O
ratio -X- _ O
to -X- _ O
Vector -X- _ B-MethodName
- -X- _ I-MethodName
c -X- _ I-MethodName
in -X- _ O
the -X- _ O
cross -X- _ O
- -X- _ O
category -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
- -X- _ O
category -X- _ O
. -X- _ O

Our -X- _ O
approach -X- _ O
shows -X- _ O
a -X- _ O
smaller -X- _ O
ratio -X- _ O
of -X- _ O
constraint -X- _ O
violations -X- _ O
in -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
categories -X- _ O
, -X- _ O
with -X- _ O
only -X- _ O
a -X- _ O
few -X- _ O
exceptions -X- _ O
. -X- _ O

" -X- _ O
n -X- _ O
/ -X- _ O
a -X- _ O
" -X- _ O
refers -X- _ O
to -X- _ O
no -X- _ O
predictions -X- _ O
and -X- _ O
this -X- _ O
frequently -X- _ O
appears -X- _ O
on -X- _ O
COREF -X- _ B-DatasetName
andEQUAL -X- _ B-DatasetName
due -X- _ O
to -X- _ O
their -X- _ O
sparsity -X- _ B-HyperparameterName
in -X- _ O
the -X- _ O
corpus -X- _ O
. -X- _ O

The -X- _ O
comparison -X- _ O
of -X- _ O
constraint -X- _ O
violations -X- _ O
between -X- _ O
the -X- _ O
vector -X- _ O
model -X- _ O
with -X- _ O
constrained -X- _ O
learning -X- _ O
( -X- _ O
Vector -X- _ B-MethodName
- -X- _ I-MethodName
c -X- _ I-MethodName
) -X- _ O
and -X- _ O
the -X- _ O
box -X- _ O
model -X- _ O
without -X- _ O
constrained -X- _ O
learning -X- _ O
( -X- _ O
BERE -X- _ B-TaskName
- -X- _ I-TaskName
p -X- _ I-TaskName
) -X- _ O
is -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
8 -X- _ O
. -X- _ O

D -X- _ O
Detailed -X- _ O
analysis -X- _ O
on -X- _ O
conjunctive -X- _ O
constraint -X- _ O
violation -X- _ O
Constraint -X- _ B-TaskName
Violation -X- _ I-TaskName
Analysis -X- _ I-TaskName
, -X- _ O
Table -X- _ O
8 -X- _ O
We -X- _ O
further -X- _ O
break -X- _ O
down -X- _ O
constraint -X- _ B-MetricName
violations -X- _ I-MetricName
for -X- _ O
each -X- _ O
label -X- _ O
on -X- _ O
HiEve -X- _ B-DatasetName
and -X- _ O
MATRES -X- _ B-DatasetName
. -X- _ O

C -X- _ O
Vector -X- _ B-MethodName
model -X- _ O
architecture -X- _ O
Refer -X- _ O
to -X- _ O
Figure -X- _ O
2 -X- _ O
for -X- _ O
architecture -X- _ O
of -X- _ O
previous -X- _ O
vector -X- _ O
models -X- _ O
. -X- _ O

Compared -X- _ O
to -X- _ O
the -X- _ O
results -X- _ O
from -X- _ O
BERE -X- _ B-TaskName
- -X- _ I-TaskName
p -X- _ I-TaskName
, -X- _ O
BERE -X- _ B-TaskName
- -X- _ I-TaskName
c -X- _ I-TaskName
shows -X- _ O
a -X- _ O
significantly -X- _ O
smaller -X- _ O
ratio -X- _ O
of -X- _ O
constraint -X- _ B-MetricName
violations -X- _ I-MetricName
than -X- _ O
BERE -X- _ B-TaskName
- -X- _ I-TaskName
p -X- _ I-TaskName
, -X- _ O
while -X- _ O
sacrificing -X- _ O
F1by2 -X- _ B-MetricName
point -X- _ B-MetricValue
from -X- _ O
the -X- _ O
performance -X- _ O
with -X- _ O
BERE -X- _ B-TaskName
- -X- _ I-TaskName
p -X- _ I-TaskName
. -X- _ O

B -X- _ O
Conjunctive -X- _ O
Consistency -X- _ O
Loss -X- _ O
With -X- _ O
consistency -X- _ O
requirements -X- _ O
on -X- _ O
conjunctive -X- _ O
relations -X- _ O
over -X- _ O
temporal -X- _ O
and -X- _ O
subevent -X- _ O
datasets -X- _ O
( -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
6 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
incorporate -X- _ O
the -X- _ O
loss -X- _ O
function -X- _ O
introduced -X- _ O
by -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
into -X- _ O
our -X- _ O
box -X- _ O
model -X- _ O
to -X- _ O
handle -X- _ O
conjunctive -X- _ O
constraints -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
wandb -X- _ O
( -X- _ O
Biewald -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
tool -X- _ O
for -X- _ O
efficient -X- _ O
hyperparameter -X- _ O
tuning -X- _ O
. -X- _ O

A -X- _ O
threshold -X- _ B-HyperparameterName
for -X- _ O
HiEve -X- _ B-DatasetName
is -X- _ O
selected -X- _ O
between -X- _ O
-0.4 -X- _ B-HyperparameterValue
and -X- _ O
-0.3 -X- _ B-HyperparameterValue
and -X- _ O
a -X- _ O
threshold -X- _ B-HyperparameterName
for -X- _ O
MATRES -X- _ B-DatasetName
is -X- _ O
chosen -X- _ O
between -X- _ O
-0.7 -X- _ B-HyperparameterValue
and -X- _ O
-0.6 -X- _ B-HyperparameterValue
. -X- _ O

We -X- _ O
use -X- _ O
three -X- _ O
weights -X- _ O
, -X- _ O
1;2 -X- _ O
; -X- _ O
and3 -X- _ O
, -X- _ O
to -X- _ O
balance -X- _ O
our -X- _ O
three -X- _ O
learning -X- _ O
objectives -X- _ O
L1 -X- _ O
, -X- _ O
L2 -X- _ O
, -X- _ O
andL3(see -X- _ O
Section -X- _ O
3.2 -X- _ O
and -X- _ O
Appendix -X- _ O
B -X- _ O
) -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
the -X- _ O
weights -X- _ B-HyperparameterName
are -X- _ O
selected -X- _ O
between -X- _ O
0.1 -X- _ B-HyperparameterValue
and -X- _ O
1 -X- _ B-HyperparameterValue
. -X- _ O

This -X- _ O
is -X- _ O
to -X- _ O
encourage -X- _ O
the -X- _ O
models -X- _ O
to -X- _ O
learn -X- _ O
and -X- _ O
evaluate -X- _ O
all -X- _ O
types -X- _ O
of -X- _ O
relations -X- _ O
that -X- _ O
exist -X- _ O
in -X- _ O
the -X- _ O
datasets -X- _ O
when -X- _ O
NOREL -X- _ B-HyperparameterValue
overwhelmingly -X- _ O
represents -X- _ O
the -X- _ O
dataset -X- _ O
. -X- _ O

On -X- _ O
HiEve -X- _ B-DatasetName
and -X- _ O
ESL -X- _ B-DatasetName
, -X- _ O
we -X- _ O
sample -X- _ O
N -X- _ B-HyperparameterValue
OREL -X- _ B-HyperparameterName
in -X- _ O
trainset -X- _ O
using -X- _ O
downsample -X- _ O
ratio -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
fixed -X- _ O
to -X- _ O
0.015 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
the -X- _ O
downsample -X- _ B-HyperparameterName
ratio -X- _ I-HyperparameterName
for -X- _ O
valid -X- _ O
and -X- _ O
test -X- _ O
sets -X- _ O
is -X- _ O
fixed -X- _ O
to -X- _ O
0.4 -X- _ B-HyperparameterValue
. -X- _ O

models -X- _ O
are -X- _ O
trained -X- _ O
for -X- _ O
100 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
with -X- _ O
AMSGrad -X- _ B-MethodName
optimizer -X- _ O
and -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
is -X- _ O
set -X- _ O
to -X- _ O
be -X- _ O
0.001 -X- _ B-HyperparameterValue
. -X- _ O

A -X- _ O
Hyperparameters -X- _ O
We -X- _ O
utilize -X- _ O
768 -X- _ B-HyperparameterValue
dimensional -X- _ B-HyperparameterName
pretrained -X- _ O
RoBERTa -X- _ B-MethodName
model -X- _ O
to -X- _ O
compute -X- _ O
word -X- _ B-HyperparameterName
embeddings -X- _ I-HyperparameterName
for -X- _ O
events -X- _ O
. -X- _ O

Our -X- _ O
model -X- _ O
shows -X- _ O
that -X- _ O
box -X- _ O
representation -X- _ O
can -X- _ O
provide -X- _ O
coherent -X- _ O
classification -X- _ O
across -X- _ O
multiple -X- _ O
event -X- _ O
relations -X- _ O
and -X- _ O
opens -X- _ O
up -X- _ O
future -X- _ O
research -X- _ O
for -X- _ O
box -X- _ O
representations -X- _ O
in -X- _ O
event -X- _ B-TaskName
- -X- _ I-TaskName
to -X- _ I-TaskName
- -X- _ I-TaskName
event -X- _ I-TaskName
relation -X- _ I-TaskName
classification -X- _ I-TaskName
. -X- _ O

Through -X- _ O
experiments -X- _ O
on -X- _ O
three -X- _ O
datasets -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
proposed -X- _ O
method -X- _ O
not -X- _ O
only -X- _ O
free -X- _ O
of -X- _ O
antisymmetric -X- _ O
constraint -X- _ O
violations -X- _ O
but -X- _ O
also -X- _ O
have -X- _ O
drastically -X- _ O
lower -X- _ O
conjunctive -X- _ O
constraint -X- _ O
violations -X- _ O
while -X- _ O
maintaining -X- _ O
similar -X- _ O
or -X- _ O
better -X- _ O
performance -X- _ O
inF1 -X- _ B-MetricName
. -X- _ O

Utilizing -X- _ O
this -X- _ O
box -X- _ B-MethodName
representation -X- _ I-MethodName
, -X- _ O
we -X- _ O
design -X- _ O
our -X- _ O
relation -X- _ O
extraction -X- _ O
model -X- _ O
to -X- _ O
handle -X- _ O
antisymmetry -X- _ O
between -X- _ O
events -X- _ O
of -X- _ O
( -X- _ O
ei;ej)and -X- _ O
( -X- _ O
ej;ei)which -X- _ O
previous -X- _ O
vector -X- _ O
models -X- _ O
were -X- _ O
not -X- _ O
capable -X- _ O
of -X- _ O
. -X- _ O

The -X- _ O
proposed -X- _ O
method -X- _ O
projects -X- _ O
each -X- _ O
event -X- _ O
to -X- _ O
a -X- _ O
box -X- _ O
representation -X- _ O
which -X- _ O
can -X- _ O
model -X- _ B-MethodName
asymmetric -X- _ I-MethodName
relationships -X- _ I-MethodName
between -X- _ I-MethodName
entities -X- _ I-MethodName
. -X- _ O

We -X- _ O
also -X- _ O
note -X- _ O
that -X- _ O
training -X- _ O
Vector -X- _ O
with -X- _ O
the -X- _ O
augmented -X- _ O
symmetrical -X- _ O
dataset -X- _ O
does -X- _ O
not -X- _ O
help -X- _ O
with -X- _ O
conjunctive -X- _ B-MetricName
constraint -X- _ I-MetricName
violations -X- _ I-MetricName
( -X- _ O
6:17!6:70 -X- _ O
) -X- _ O
, -X- _ O
although -X- _ O
it -X- _ O
reduces -X- _ O
symmetrical -X- _ B-MetricName
constraint -X- _ I-MetricName
violations -X- _ I-MetricName
( -X- _ O
24:08!12:01).6 -X- _ O
Conclusion -X- _ O
We -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
event -X- _ B-MethodName
relation -X- _ I-MethodName
extraction -X- _ I-MethodName
method -X- _ I-MethodName
that -X- _ O
utilizes -X- _ O
box -X- _ O
representation -X- _ O
. -X- _ O

The -X- _ O
results -X- _ O
in -X- _ O
Table -X- _ O
5 -X- _ O
reconfirm -X- _ O
the -X- _ O
BERE -X- _ B-MetricValue
- -X- _ O
p -X- _ O
s -X- _ O
superior -X- _ O
ability -X- _ O
in -X- _ O
handling -X- _ O
constraints -X- _ O
with -X- _ O
better -X- _ O
performance -X- _ O
, -X- _ O
while -X- _ O
Vector -X- _ O
requires -X- _ O
significantly -X- _ O
longer -X- _ O
training -X- _ O
time -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
extended -X- _ O
training -X- _ O
dataset -X- _ O
with -X- _ O
worse -X- _ O
performance -X- _ O
. -X- _ O

5 -X- _ O
Ablation -X- _ B-MethodName
Study -X- _ I-MethodName
We -X- _ O
conduct -X- _ O
additional -X- _ O
experiments -X- _ O
to -X- _ O
see -X- _ O
whether -X- _ O
Vector -X- _ B-MethodName
trained -X- _ O
with -X- _ O
the -X- _ O
augmented -X- _ B-DatasetName
symmetrical -X- _ I-DatasetName
dataset -X- _ I-DatasetName
will -X- _ O
affect -X- _ O
the -X- _ O
conclusion -X- _ O
of -X- _ O
BERE -X- _ B-TaskName
- -X- _ O
p -X- _ O
. -X- _ O

This -X- _ O
further -X- _ O
indicates -X- _ O
, -X- _ O
without -X- _ O
explicitly -X- _ O
injecting -X- _ O
constraints -X- _ O
into -X- _ O
objectives -X- _ B-MetricName
, -X- _ O
our -X- _ O
model -X- _ O
can -X- _ O
persist -X- _ O
logical -X- _ B-MetricName
consistency -X- _ I-MetricName
among -X- _ O
different -X- _ O
relations -X- _ O
. -X- _ O

For -X- _ O
label -X- _ O
pairs -X- _ O
across -X- _ O
datasets -X- _ O
, -X- _ O
our -X- _ O
approach -X- _ O
also -X- _ O
shows -X- _ O
fewer -X- _ O
or -X- _ O
similar -X- _ O
levels -X- _ O
of -X- _ O
violation -X- _ O
. -X- _ O

For -X- _ O
label -X- _ O
pairs -X- _ O
from -X- _ O
the -X- _ O
same -X- _ O
dataset -X- _ O
, -X- _ O
our -X- _ O
approach -X- _ O
excels -X- _ O
in -X- _ O
almost -X- _ O
every -X- _ O
cases -X- _ O
. -X- _ O

Constraint -X- _ O
Violation -X- _ O
Analysis -X- _ O
, -X- _ O
Table -X- _ O
8 -X- _ O
( -X- _ O
Appendix -X- _ O
) -X- _ O
We -X- _ O
analyze -X- _ O
constraint -X- _ O
violations -X- _ O
for -X- _ O
each -X- _ O
label -X- _ O
from -X- _ O
both -X- _ O
HiEve -X- _ B-DatasetName
and -X- _ O
MATRES -X- _ B-DatasetName
. -X- _ O

denote -X- _ O
symmetric -X- _ B-MetricName
and -X- _ I-MetricName
conjunctive -X- _ I-MetricName
constraint -X- _ I-MetricName
violations -X- _ I-MetricName
(% -X- _ O
) -X- _ O
, -X- _ O
respectively -X- _ O
; -X- _ O
H -X- _ O
, -X- _ O
M -X- _ O
, -X- _ O
and -X- _ O
ESL -X- _ B-DatasetName
are -X- _ O
HiEve -X- _ B-DatasetName
, -X- _ O
MATRES -X- _ B-DatasetName
, -X- _ O
Event -X- _ B-DatasetName
StoryLine -X- _ I-DatasetName
datasets -X- _ O
, -X- _ O
respectively -X- _ O
; -X- _ O
single -X- _ O
task -X- _ O
( -X- _ O
top -X- _ O
) -X- _ O
and -X- _ O
joint -X- _ O
task -X- _ O
( -X- _ O
bottom -X- _ O
) -X- _ O
ModelF1Score -X- _ B-MetricName
symmetry -X- _ O
const -X- _ O
. -X- _ O

Table -X- _ O
4 -X- _ O
: -X- _ O
F1scores -X- _ B-MetricName
with -X- _ O
symmetric -X- _ O
and -X- _ O
conjunctive -X- _ B-MetricName
constraint -X- _ I-MetricName
violation -X- _ I-MetricName
results -X- _ I-MetricName
over -X- _ O
original -X- _ O
and -X- _ O
symmetrical -X- _ O
datasets -X- _ O
. -X- _ O

In -X- _ O
addition -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
noteworthy -X- _ O
that -X- _ O
our -X- _ O
method -X- _ O
without -X- _ O
constrained -X- _ O
learning -X- _ O
excelsVector -X- _ B-MethodName
- -X- _ O
c -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
trained -X- _ O
with -X- _ O
constrained -X- _ O
learning -X- _ O
. -X- _ O

This -X- _ O
demonstrates -X- _ O
the -X- _ O
BERE -X- _ B-TaskName
- -X- _ O
p -X- _ O
successfully -X- _ O
captures -X- _ O
symmetrical -X- _ O
relations -X- _ O
, -X- _ O
while -X- _ O
previous -X- _ O
vector -X- _ O
models -X- _ O
do -X- _ O
not -X- _ O
. -X- _ O

The -X- _ O
performance -X- _ O
gains -X- _ O
from -X- _ O
asymmetrical -X- _ O
to -X- _ O
symmetrical -X- _ O
datasets -X- _ O
with -X- _ O
BERE -X- _ B-DatasetName
- -X- _ O
p -X- _ O
are -X- _ O
much -X- _ O
larger -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
increase -X- _ O
of -X- _ O
Vector -X- _ B-MethodName
s -X- _ O
. -X- _ O

Our -X- _ O
approach -X- _ O
clearly -X- _ O
outperforms -X- _ O
the -X- _ O
baseline -X- _ O
methods -X- _ O
on -X- _ O
symmetric -X- _ O
evaluation -X- _ O
with -X- _ O
a -X- _ O
gain -X- _ O
of -X- _ O
6.79 -X- _ B-MetricValue
, -X- _ O
4.26 -X- _ B-MetricValue
, -X- _ O
and -X- _ O
9.34 -X- _ B-MetricValue
F1 -X- _ B-MetricName
points -X- _ I-MetricName
on -X- _ O
the -X- _ O
single -X- _ O
task -X- _ O
over -X- _ O
HiEve -X- _ B-DatasetName
, -X- _ O
MATRES -X- _ B-DatasetName
, -X- _ O
and -X- _ O
ESL -X- _ B-DatasetName
datasets -X- _ O
, -X- _ O
respectively -X- _ O
and -X- _ O
with -X- _ O
a -X- _ O
gain -X- _ O
of -X- _ O
0.95 -X- _ B-MetricValue
and -X- _ O
3.29 -X- _ B-MetricValue
F1points -X- _ B-MetricName
on -X- _ O
the -X- _ O
joint -X- _ B-TaskName
task -X- _ I-TaskName
over -X- _ O
HiEve -X- _ B-DatasetName
and -X- _ O
MATRES -X- _ B-DatasetName
. -X- _ O

It -X- _ O
indicates -X- _ O
that -X- _ O
promoting -X- _ O
the -X- _ O
relevant -X- _ O
event -X- _ O
pairs -X- _ O
to -X- _ O
mingle -X- _ O
together -X- _ O
in -X- _ O
the -X- _ O
geometrical -X- _ O
space -X- _ O
is -X- _ O
helpful -X- _ O
and -X- _ O
it -X- _ O
is -X- _ O
particularly -X- _ O
useful -X- _ O
when -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
relation -X- _ O
extraction -X- _ O
model -X- _ O
encodes -X- _ O
individual -X- _ O
sentences -X- _ O
independently -X- _ O
. -X- _ O

The -X- _ O
model -X- _ O
with -X- _ O
pairwise -X- _ B-MetricName
loss -X- _ I-MetricName
shows -X- _ O
about -X- _ O
2.8 -X- _ B-MetricValue
F1point -X- _ B-MethodName
improvement -X- _ O
on -X- _ O
HiEve -X- _ B-DatasetName
and -X- _ O
1 -X- _ B-MetricValue
F1point -X- _ B-MetricName
improvement -X- _ O
on -X- _ O
MATRES -X- _ B-DatasetName
. -X- _ O

4.2 -X- _ O
Results -X- _ O
and -X- _ O
Discussion -X- _ O
Impact -X- _ O
of -X- _ O
pairwise -X- _ O
box -X- _ O
, -X- _ O
Table -X- _ O
3 -X- _ O
We -X- _ O
first -X- _ O
show -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
BERE -X- _ B-TaskName
andBERE -X- _ B-TaskName
- -X- _ O
p -X- _ O
with -X- _ O
and -X- _ O
without -X- _ O
pairwise -X- _ B-MetricName
loss -X- _ I-MetricName
. -X- _ O

On -X- _ O
HiEve -X- _ B-DatasetName
and -X- _ O
ESL -X- _ B-DatasetName
, -X- _ O
the -X- _ O
microF1score -X- _ B-MetricName
of -X- _ O
PARENT -X- _ O
-CHILD -X- _ O
and -X- _ O
CHILD -X- _ O
-PARENT -X- _ O
pairs -X- _ O
is -X- _ O
reported -X- _ O
( -X- _ O
Glava -X- _ O
and -X- _ O
najder -X- _ O
, -X- _ O
2014 -X- _ O
; -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

Metrics -X- _ O
Following -X- _ O
the -X- _ O
same -X- _ O
evaluation -X- _ O
setting -X- _ O
in -X- _ O
previous -X- _ O
works -X- _ O
, -X- _ O
we -X- _ O
report -X- _ O
the -X- _ O
microF1score -X- _ B-MetricName
of -X- _ O
all -X- _ O
pairs -X- _ O
, -X- _ O
except -X- _ O
VAGUE -X- _ B-MethodName
pairs -X- _ O
, -X- _ O
on -X- _ O
MATRES -X- _ B-MethodName
( -X- _ O
Han -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019b -X- _ O
; -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

For -X- _ O
a -X- _ O
fair -X- _ O
comparison -X- _ O
, -X- _ O
we -X- _ O
utilize -X- _ O
the -X- _ O
same -X- _ O
RoBERTa -X- _ B-MethodName
+ -X- _ O
BiLSTM -X- _ B-MethodName
+ -X- _ O
MLP -X- _ B-MethodName
architecture -X- _ O
for -X- _ O
projecting -X- _ O
event -X- _ O
to -X- _ O
box -X- _ O
representation -X- _ O
. -X- _ O

On -X- _ O
top -X- _ O
of -X- _ O
this -X- _ O
, -X- _ O
as -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
showed -X- _ O
that -X- _ O
constraint -X- _ O
injection -X- _ O
improves -X- _ O
performance -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
compare -X- _ O
with -X- _ O
the -X- _ O
constraint -X- _ O
- -X- _ O
injected -X- _ O
model -X- _ O
( -X- _ O
Vector -X- _ O
- -X- _ O
c -X- _ O
) -X- _ O
. -X- _ O

Givenvij -X- _ O
, -X- _ O
vector -X- _ B-MethodName
model -X- _ I-MethodName
( -X- _ I-MethodName
Vector -X- _ I-MethodName
) -X- _ I-MethodName
simply -X- _ O
computes -X- _ O
softmax -X- _ B-MetricName
over -X- _ B-MetricName
projected -X- _ I-MetricName
logits -X- _ I-MetricName
to -X- _ O
produce -X- _ O
probability -X- _ B-MetricName
for -X- _ O
every -X- _ O
possible -X- _ O
relations -X- _ O
. -X- _ O

This -X- _ O
model -X- _ O
utilizes -X- _ O
RoBERTa -X- _ B-MethodName
with -X- _ O
frozen -X- _ O
parameters -X- _ O
and -X- _ O
further -X- _ O
trains -X- _ O
BiLSTM -X- _ B-MethodName
to -X- _ O
represent -X- _ O
text -X- _ O
inputs -X- _ O
into -X- _ O
vector -X- _ O
hi(forei -X- _ O
) -X- _ O
and -X- _ O
then -X- _ O
further -X- _ O
utilizes -X- _ O
MLP -X- _ B-MethodName
to -X- _ O
represent -X- _ O
pairwise -X- _ O
representation -X- _ O
vijfor -X- _ O
( -X- _ O
ei;ej -X- _ O
) -X- _ O
. -X- _ O

Baseline -X- _ O
We -X- _ O
compare -X- _ O
our -X- _ O
BERE -X- _ B-TaskName
, -X- _ O
BERE -X- _ B-TaskName
- -X- _ O
p -X- _ O
against -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
event -X- _ O
- -X- _ O
event -X- _ O
relation -X- _ O
exTable -X- _ O
3 -X- _ O
: -X- _ O
F1scores -X- _ O
of -X- _ O
BERE -X- _ O
andBERE -X- _ O
- -X- _ O
p -X- _ O
ModelF1Score -X- _ O
HiEve -X- _ O
MATRES -X- _ O
BERE -X- _ O
0.4483 -X- _ O
0.7069 -X- _ O
BERE -X- _ O
- -X- _ O
p -X- _ O
0.4771 -X- _ O
0.7105traction -X- _ O
model -X- _ O
proposed -X- _ O
by -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
ESL -X- _ O
dataset -X- _ O
is -X- _ O
defined -X- _ O
differently -X- _ O
compared -X- _ O
to -X- _ O
HiEve -X- _ B-DatasetName
and -X- _ O
MATRES -X- _ B-DatasetName
, -X- _ O
so -X- _ O
we -X- _ O
mapped -X- _ O
the -X- _ O
ESL -X- _ B-DatasetName
labels -X- _ O
into -X- _ O
the -X- _ O
labels -X- _ O
in -X- _ O
HiEve -X- _ B-DatasetName
similar -X- _ O
to -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
. -X- _ O

Event -X- _ B-DatasetName
StoryLine -X- _ I-DatasetName
( -X- _ I-DatasetName
ESL -X- _ I-DatasetName
) -X- _ I-DatasetName
corpus -X- _ O
is -X- _ O
a -X- _ O
dataset -X- _ O
that -X- _ O
contains -X- _ O
258 -X- _ B-HyperparameterValue
news -X- _ B-HyperparameterName
documents -X- _ I-HyperparameterName
and -X- _ O
includes -X- _ O
event -X- _ O
temporal -X- _ O
and -X- _ O
subevent -X- _ O
relations -X- _ O
. -X- _ O

MATRES -X- _ B-DatasetName
is -X- _ O
a -X- _ O
four -X- _ B-HyperparameterValue
- -X- _ O
class -X- _ B-HyperparameterName
temporal -X- _ B-DatasetName
relation -X- _ I-DatasetName
dataset -X- _ I-DatasetName
, -X- _ O
which -X- _ O
contains -X- _ O
275 -X- _ B-HyperparameterValue
news -X- _ B-HyperparameterName
articles -X- _ I-HyperparameterName
drawn -X- _ O
from -X- _ O
a -X- _ O
number -X- _ O
of -X- _ O
different -X- _ O
sources -X- _ O
. -X- _ O

HiEve -X- _ B-DatasetName
consists -X- _ O
of -X- _ O
100 -X- _ B-HyperparameterValue
articles -X- _ B-HyperparameterName
and -X- _ O
the -X- _ O
narratives -X- _ O
in -X- _ O
news -X- _ O
stories -X- _ O
are -X- _ O
represented -X- _ O
as -X- _ O
event -X- _ O
hierarchies -X- _ O
. -X- _ O

Lastly -X- _ O
, -X- _ O
we -X- _ O
provide -X- _ O
experimental -X- _ O
results -X- _ O
and -X- _ O
a -X- _ O
detailed -X- _ O
analysis -X- _ O
of -X- _ O
logical -X- _ O
consistency -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
remainder -X- _ O
of -X- _ O
the -X- _ O
paper -X- _ O
, -X- _ O
BERE -X- _ B-TaskName
refers -X- _ O
to -X- _ O
a -X- _ O
model -X- _ O
trained -X- _ O
with -X- _ O
loss -X- _ B-MetricName
L1andBERE -X- _ I-MetricName
- -X- _ O
p -X- _ O
refers -X- _ O
to -X- _ O
a -X- _ O
model -X- _ O
trained -X- _ O
with -X- _ O
two -X- _ O
losses -X- _ O
L1;L2combined -X- _ O
. -X- _ O

For -X- _ O
irrelevant -X- _ O
event -X- _ O
pairs -X- _ O
such -X- _ O
as -X- _ O
having -X- _ O
NOREL -X- _ B-DatasetName
orVAGUE -X- _ B-DatasetName
, -X- _ O
their -X- _ O
intersection -X- _ O
and -X- _ O
pairwise -X- _ O
boxes -X- _ O
are -X- _ O
forced -X- _ O
to -X- _ O
be -X- _ O
disjoint -X- _ O
. -X- _ O

For -X- _ O
two -X- _ O
related -X- _ O
events -X- _ O
, -X- _ O
we -X- _ O
enforce -X- _ O
the -X- _ O
intersection -X- _ O
of -X- _ O
corresponding -X- _ O
boxes -X- _ O
bi\bjto -X- _ O
be -X- _ O
inside -X- _ O
the -X- _ O
pairwise -X- _ O
box -X- _ O
. -X- _ O

The -X- _ O
pairwise -X- _ B-HyperparameterName
features -X- _ I-HyperparameterName
we -X- _ O
use -X- _ O
here -X- _ O
are -X- _ O
similar -X- _ O
to -X- _ O
( -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
except -X- _ O
that -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
use -X- _ O
subtraction -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
preserve -X- _ O
symmetry -X- _ O
between -X- _ B-HyperparameterName
pairwise -X- _ I-HyperparameterName
features -X- _ I-HyperparameterName
of -X- _ O
( -X- _ O
ei;ej)and -X- _ O
( -X- _ O
ej;ei -X- _ O
) -X- _ O
, -X- _ O
i.e.bij -X- _ O
= -X- _ O
bji -X- _ O
. -X- _ O

Then -X- _ O
, -X- _ O
a -X- _ O
multi -X- _ B-MethodName
- -X- _ I-MethodName
layer -X- _ I-MethodName
perceptron -X- _ I-MethodName
( -X- _ I-MethodName
MLP -X- _ I-MethodName
) -X- _ I-MethodName
is -X- _ O
used -X- _ O
to -X- _ O
transform -X- _ O
pairwise -X- _ O
vectors -X- _ O
to -X- _ O
box -X- _ O
representations -X- _ O
bij -X- _ O
. -X- _ O

3.2 -X- _ O
Loss -X- _ O
functions -X- _ O
for -X- _ O
training -X- _ O
BCE -X- _ B-MetricName
loss -X- _ I-MetricName
As -X- _ O
we -X- _ O
require -X- _ O
two -X- _ O
dimensions -X- _ O
of -X- _ O
scalar -X- _ O
P(bijbj)andP(bjjbi)to -X- _ O
classifyr(ei;ej -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
for -X- _ O
ease -X- _ O
of -X- _ O
notation -X- _ O
, -X- _ O
we -X- _ O
define -X- _ O
our -X- _ O
label -X- _ O
space -X- _ O
with -X- _ O
2 -X- _ B-HyperparameterValue
- -X- _ O
dimensional -X- _ B-HyperparameterName
binary -X- _ B-HyperparameterName
variable -X- _ I-HyperparameterName
y(i;j)as -X- _ O
shown -X- _ O
in -X- _ O
Figure1(b -X- _ O
) -X- _ O
. -X- _ O

Figure -X- _ O
1(B -X- _ O
) -X- _ O
states -X- _ O
our -X- _ O
classification -X- _ O
rule -X- _ O
formulated -X- _ O
based -X- _ O
on -X- _ O
this -X- _ O
observation -X- _ O
. -X- _ O

Moreover -X- _ O
, -X- _ O
other -X- _ O
than -X- _ O
complete -X- _ O
containment -X- _ O
in -X- _ O
either -X- _ O
direction -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
other -X- _ O
two -X- _ O
prominent -X- _ O
configurations -X- _ O
possible -X- _ O
, -X- _ O
i.e -X- _ O
. -X- _ O

( -X- _ O
C -X- _ O
) -X- _ O
An -X- _ O
example -X- _ O
shows -X- _ O
the -X- _ O
fundamental -X- _ O
difference -X- _ O
between -X- _ O
VECTOR -X- _ B-MethodName
andBOXmodel -X- _ B-MethodName
: -X- _ O
BOXmodel -X- _ B-MethodName
will -X- _ O
map -X- _ O
events -X- _ O
into -X- _ O
consistent -X- _ O
box -X- _ O
representations -X- _ O
regardless -X- _ O
of -X- _ O
the -X- _ O
order -X- _ O
; -X- _ O
V -X- _ B-MethodName
ECTOR -X- _ I-MethodName
model -X- _ O
treats -X- _ O
both -X- _ O
cases -X- _ O
separately -X- _ O
and -X- _ O
may -X- _ O
not -X- _ O
persist -X- _ O
logical -X- _ O
consistency -X- _ O
. -X- _ O

Lastly -X- _ O
, -X- _ O
3.2 -X- _ O
describes -X- _ O
loss -X- _ B-MetricName
function -X- _ I-MetricName
used -X- _ O
to -X- _ O
learn -X- _ O
the -X- _ O
parameters -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O

3BERE -X- _ B-TaskName
model -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
the -X- _ O
proposed -X- _ O
box -X- _ O
model -X- _ O
BERE -X- _ B-TaskName
for -X- _ O
event -X- _ B-TaskName
- -X- _ I-TaskName
event -X- _ I-TaskName
relation -X- _ I-TaskName
extraction -X- _ I-TaskName
. -X- _ O

The -X- _ O
full -X- _ O
explanation -X- _ O
on -X- _ O
symmetry -X- _ B-MethodName
and -X- _ I-MethodName
conjunction -X- _ I-MethodName
consistency -X- _ I-MethodName
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

Conjunctive -X- _ B-MethodName
constraints -X- _ I-MethodName
refer -X- _ O
to -X- _ O
the -X- _ O
constraints -X- _ O
that -X- _ O
exist -X- _ O
in -X- _ O
the -X- _ O
relations -X- _ O
among -X- _ O
any -X- _ O
event -X- _ O
triplet -X- _ O
. -X- _ O

Symmetry -X- _ B-MethodName
constraints -X- _ I-MethodName
indicate -X- _ O
the -X- _ O
event -X- _ O
pair -X- _ O
with -X- _ O
ipping -X- _ O
orders -X- _ O
will -X- _ O
have -X- _ O
the -X- _ O
reversed -X- _ O
relation -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
probabilistic -X- _ O
gumbel -X- _ O
box -X- _ O
, -X- _ O
these -X- _ O
min -X- _ O
and -X- _ O
max -X- _ O
points -X- _ O
are -X- _ O
taken -X- _ O
to -X- _ O
be -X- _ O
independent -X- _ O
gumbel -X- _ O
- -X- _ O
max -X- _ O
and -X- _ O
gumbel -X- _ O
- -X- _ O
min -X- _ O
random -X- _ B-HyperparameterName
variables -X- _ I-HyperparameterName
, -X- _ O
respectively -X- _ O
. -X- _ O

Lastly -X- _ O
, -X- _ O
the -X- _ O
last -X- _ O
label -X- _ O
( -X- _ O
NOREL -X- _ O
andVAGUE -X- _ O
) -X- _ O
represents -X- _ O
a -X- _ O
case -X- _ O
when -X- _ O
an -X- _ O
event -X- _ O
pair -X- _ O
is -X- _ O
not -X- _ O
related -X- _ O
at -X- _ O
all -X- _ O
. -X- _ O

Its -X- _ O
values -X- _ O
are -X- _ O
defined -X- _ O
in -X- _ O
the -X- _ O
label -X- _ O
space -X- _ O
{ -X- _ O
PARENT -X- _ O
-CHILD -X- _ O
, -X- _ O
CHILD -X- _ O
- -X- _ O
PARENT -X- _ O
, -X- _ O
COREF -X- _ O
, -X- _ O
NOREL -X- _ O
} -X- _ O
for -X- _ O
subevent -X- _ O
relationship -X- _ O
( -X- _ O
HiEve -X- _ B-DatasetName
) -X- _ O
and -X- _ O
{ -X- _ O
BEFORE -X- _ O
, -X- _ O
AFTER -X- _ O
, -X- _ O
EQUAL -X- _ O
, -X- _ O
VAGUE -X- _ O
} -X- _ O
for -X- _ O
temporal -X- _ O
relationship -X- _ O
( -X- _ O
MATRES).2 -X- _ B-DatasetName
Both -X- _ O
subevent -X- _ O
and -X- _ O
temporal -X- _ O
relationships -X- _ O
have -X- _ O
four -X- _ O
similar -X- _ O
- -X- _ O
category -X- _ O
relationship -X- _ O
labels -X- _ O
where -X- _ O
the -X- _ O
first -X- _ O
two -X- _ O
labels -X- _ O
, -X- _ O
( -X- _ O
PARENT -X- _ O
-CHILD -X- _ O
, -X- _ O
CHILD -X- _ O
-PARENT -X- _ O
) -X- _ O
and -X- _ O
( -X- _ O
BEFORE -X- _ O
, -X- _ O
AFTER -X- _ O
) -X- _ O
hold -X- _ O
reciprocal -X- _ O
relationship -X- _ O
, -X- _ O
the -X- _ O
third -X- _ O
label -X- _ O
( -X- _ O
COREF -X- _ O
andEQUAL -X- _ O
) -X- _ O
occurs -X- _ O
when -X- _ O
it -X- _ O
is -X- _ O
hard -X- _ O
to -X- _ O
tell -X- _ O
which -X- _ O
of -X- _ O
the -X- _ O
first -X- _ O
two -X- _ O
labels -X- _ O
that -X- _ O
event -X- _ O
pair -X- _ O
should -X- _ O
be -X- _ O
classified -X- _ O
to -X- _ O
. -X- _ O

We -X- _ O
show -X- _ O
that -X- _ O
handling -X- _ O
antisymmetric -X- _ B-MethodName
constraints -X- _ I-MethodName
, -X- _ O
that -X- _ O
exist -X- _ O
among -X- _ O
different -X- _ O
relations -X- _ O
, -X- _ O
can -X- _ O
satisfy -X- _ O
the -X- _ O
interwined -X- _ O
conjunctive -X- _ O
constraints -X- _ O
and -X- _ O
encourage -X- _ O
the -X- _ O
model -X- _ O
towards -X- _ O
a -X- _ O
coherent -X- _ O
output -X- _ O
across -X- _ O
temporal -X- _ O
and -X- _ O
subevent -X- _ O
tasks -X- _ O
. -X- _ O

Furthermore -X- _ O
, -X- _ O
our -X- _ O
BERE -X- _ B-TaskName
model -X- _ O
decreases -X- _ O
conjunctive -X- _ B-MetricName
constraint -X- _ I-MetricName
violation -X- _ I-MetricName
rate -X- _ I-MetricName
by -X- _ O
8588% -X- _ B-TaskName
on -X- _ O
a -X- _ O
single -X- _ B-MethodName
- -X- _ I-MethodName
task -X- _ I-MethodName
models -X- _ I-MethodName
compared -X- _ O
to -X- _ O
plain -X- _ O
vector -X- _ O
model -X- _ O
, -X- _ O
and -X- _ O
by -X- _ O
38% -X- _ B-MetricValue
on -X- _ O
joint -X- _ B-MethodName
- -X- _ I-MethodName
task -X- _ I-MethodName
model -X- _ I-MethodName
compared -X- _ O
to -X- _ O
constraint -X- _ B-MethodName
- -X- _ I-MethodName
injected -X- _ I-MethodName
vector -X- _ I-MethodName
model -X- _ I-MethodName
. -X- _ O

2020 -X- _ O
) -X- _ O
by -X- _ O
6.8 -X- _ B-MetricValue
and -X- _ O
4.2 -X- _ B-MetricValue
F1points -X- _ B-MetricName
on -X- _ O
single -X- _ O
task -X- _ O
and -X- _ O
by -X- _ O
0.95 -X- _ B-MetricValue
and -X- _ O
3.29 -X- _ B-MetricValue
F1points -X- _ B-MetricName
on -X- _ O
joint -X- _ O
task -X- _ O
over -X- _ O
symmetrical -X- _ B-DatasetName
dataset -X- _ I-DatasetName
. -X- _ O

Experimental -X- _ O
results -X- _ O
over -X- _ O
three -X- _ O
datasets -X- _ O
, -X- _ O
HiEve -X- _ B-DatasetName
, -X- _ O
MATRES -X- _ B-DatasetName
, -X- _ O
and -X- _ O
Event -X- _ B-DatasetName
StoryLine -X- _ I-DatasetName
( -X- _ I-DatasetName
ESL -X- _ I-DatasetName
) -X- _ I-DatasetName
, -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
method -X- _ O
improves -X- _ O
the -X- _ O
baseline -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
.,235 -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
the -X- _ O
previous -X- _ O
models -X- _ O
based -X- _ O
on -X- _ O
pairwise -X- _ B-MethodName
- -X- _ I-MethodName
event -X- _ I-MethodName
vector -X- _ I-MethodName
representations -X- _ I-MethodName
have -X- _ O
no -X- _ O
real -X- _ O
relation -X- _ O
between -X- _ O
representations -X- _ O
( -X- _ O
e1;e2)and(e2;e1)that -X- _ O
can -X- _ O
guarantee -X- _ O
the -X- _ B-MethodName
logical -X- _ I-MethodName
coherence -X- _ I-MethodName
. -X- _ O

Such -X- _ O
a -X- _ O
model -X- _ O
enforces -X- _ O
logical -X- _ B-MethodName
constraints -X- _ I-MethodName
by -X- _ O
design -X- _ O
( -X- _ O
see -X- _ O
Section -X- _ O
3.2 -X- _ O
) -X- _ O
. -X- _ O

Box -X- _ B-MetricName
embeddings -X- _ I-MetricName
( -X- _ O
Vilnis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
were -X- _ O
first -X- _ O
introduced -X- _ O
to -X- _ O
embed -X- _ B-TaskName
nodes -X- _ I-TaskName
of -X- _ I-TaskName
hierarchical -X- _ I-TaskName
graphs -X- _ I-TaskName
into -X- _ I-TaskName
Euclidean -X- _ I-TaskName
space -X- _ I-TaskName
using -X- _ O
hyperrectangles -X- _ O
, -X- _ O
which -X- _ O
were -X- _ O
later -X- _ O
extended -X- _ O
to -X- _ O
jointly -X- _ O
embed -X- _ O
multi -X- _ B-MethodName
- -X- _ I-MethodName
relational -X- _ I-MethodName
graphs -X- _ I-MethodName
and -X- _ O
perform -X- _ O
logical -X- _ B-MethodName
queries -X- _ I-MethodName
( -X- _ O
Patel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Abboud -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
propose -X- _ O
a -X- _ O
Box -X- _ B-TaskName
Event -X- _ I-TaskName
Relation -X- _ I-TaskName
Extraction -X- _ I-TaskName
( -X- _ I-TaskName
BERE -X- _ I-TaskName
) -X- _ I-TaskName
model -X- _ O
that -X- _ O
represents -X- _ O
each -X- _ O
event -X- _ O
as -X- _ O
a -X- _ O
probabilistic -X- _ O
box -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
it -X- _ O
is -X- _ O
possible -X- _ O
to -X- _ O
induce -X- _ B-MethodName
coherence -X- _ I-MethodName
in -X- _ O
a -X- _ O
much -X- _ O
stronger -X- _ O
manner -X- _ O
by -X- _ O
representing -X- _ O
each -X- _ O
event -X- _ O
using -X- _ O
a -X- _ O
box -X- _ O
( -X- _ O
Dasgupta -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
since -X- _ O
the -X- _ O
coherence -X- _ O
is -X- _ O
enforced -X- _ O
in -X- _ O
a -X- _ O
soft -X- _ O
manner -X- _ O
using -X- _ O
extra -X- _ O
loss -X- _ O
terms -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
still -X- _ O
room -X- _ O
for -X- _ O
incoherent -X- _ B-TaskName
predictions -X- _ I-TaskName
. -X- _ O

To -X- _ O
address -X- _ O
this -X- _ O
problem -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
introduced -X- _ O
a -X- _ O
constrained -X- _ B-TaskName
learning -X- _ I-TaskName
framework -X- _ I-TaskName
, -X- _ O
wherein -X- _ O
they -X- _ O
enforce -X- _ O
logical -X- _ O
coherence -X- _ O
amongst -X- _ O
the -X- _ O
predicted -X- _ O
event -X- _ O
types -X- _ O
through -X- _ O
extra -X- _ O
loss -X- _ O
terms -X- _ O
. -X- _ O

In -X- _ O
general -X- _ O
, -X- _ O
predicting -X- _ O
the -X- _ O
relationships -X- _ O
between -X- _ O
different -X- _ O
events -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
document -X- _ O
, -X- _ O
such -X- _ O
that -X- _ O
these -X- _ O
predictions -X- _ O
are -X- _ O
coherent -X- _ O
, -X- _ O
is -X- _ O
a -X- _ O
challenging -X- _ O
task -X- _ O
( -X- _ O
Xiang -X- _ O
and -X- _ O
Wang -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

All -X- _ O
the -X- _ O
phone -X- _ O
lines -X- _ O
were -X- _ O
dead -X- _ O
the -X- _ O
next -X- _ O
morning -X- _ O
. -X- _ O

For -X- _ O
instance -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
paragraph -X- _ O
, -X- _ O
There -X- _ O
was -X- _ O
a -X- _ O
storm -X- _ O
in -X- _ O
Atlanta -X- _ O
in -X- _ O
the -X- _ O
night -X- _ O
. -X- _ O

Both -X- _ O
temporal -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
subevent -X- _ O
relationships -X- _ O
between -X- _ O
events -X- _ O
satisfy -X- _ O
transitivity -X- _ B-MethodName
constraints -X- _ I-MethodName
. -X- _ O

Our -X- _ O
experiments -X- _ O
show -X- _ O
that -X- _ O
BERE -X- _ B-TaskName
has -X- _ O
stronger -X- _ O
conjunctive -X- _ O
constraint -X- _ O
satisfaction -X- _ O
while -X- _ O
performing -X- _ O
on -X- _ O
par -X- _ O
or -X- _ O
better -X- _ O
in -X- _ O
terms -X- _ O
ofF1compared -X- _ O
to -X- _ O
previous -X- _ O
models -X- _ O
with -X- _ O
constraint -X- _ O
injection.1 -X- _ O
1 -X- _ O
Introduction -X- _ O
A -X- _ O
piece -X- _ O
of -X- _ O
text -X- _ O
can -X- _ O
contain -X- _ O
several -X- _ O
events -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
modify -X- _ O
the -X- _ O
underlying -X- _ O
ERE -X- _ B-TaskName
model -X- _ O
to -X- _ O
guarantee -X- _ O
coherence -X- _ O
by -X- _ O
representing -X- _ O
each -X- _ O
event -X- _ O
as -X- _ O
a -X- _ O
box -X- _ B-MethodName
representation -X- _ I-MethodName
( -X- _ O
BERE -X- _ B-TaskName
) -X- _ O
without -X- _ O
applying -X- _ O
explicit -X- _ O
constraints -X- _ O
. -X- _ O

Current -X- _ O
frameworks -X- _ O
of -X- _ O
event -X- _ O
relation -X- _ O
extraction -X- _ O
do -X- _ O
not -X- _ O
guarantee -X- _ O
this -X- _ O
anti -X- _ B-MethodName
- -X- _ I-MethodName
symmetry -X- _ I-MethodName
and -X- _ O
thus -X- _ O
enforce -X- _ O
it -X- _ O
via -X- _ O
a -X- _ O
constraint -X- _ B-MetricName
loss -X- _ I-MetricName
function -X- _ I-MetricName
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

For -X- _ O
instance -X- _ O
, -X- _ O
if -X- _ O
a -X- _ O
phone -X- _ O
linedied -X- _ O
after -X- _ O
storm -X- _ O
, -X- _ O
then -X- _ O
it -X- _ O
is -X- _ O
evident -X- _ O
that -X- _ O
thestorm -X- _ O
happened -X- _ O
before -X- _ O
the -X- _ O
died -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
existing -X- _ O
event -X- _ B-TaskName
relation -X- _ I-TaskName
extraction -X- _ I-TaskName
( -X- _ I-TaskName
ERE -X- _ I-TaskName
) -X- _ I-TaskName
frameworks -X- _ O
regard -X- _ O
it -X- _ O
as -X- _ O
a -X- _ O
multi -X- _ B-TaskName
- -X- _ I-TaskName
class -X- _ I-TaskName
classification -X- _ I-TaskName
task -X- _ I-TaskName
, -X- _ O
and -X- _ O
do -X- _ O
not -X- _ O
guarantee -X- _ O
any -X- _ O
coherence -X- _ O
between -X- _ O
different -X- _ O
relation -X- _ O
types -X- _ O
. -X- _ O

The -X- _ O
top -X- _ O
level -X- _ O
datasets -X- _ O
contain -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
data -X- _ O
while -X- _ O
the -X- _ O
bottom -X- _ O
contain -X- _ O
SPR -X- _ B-DatasetName
data -X- _ O
. -X- _ O

We -X- _ O
additionally -X- _ O
use -X- _ O
surprisal -X- _ O
estimates -X- _ O
from -X- _ O
a -X- _ O
5 -X- _ O
- -X- _ O
gram -X- _ O
model -X- _ O
trained -X- _ O
on -X- _ O
WikiText-103 -X- _ B-DatasetName
using -X- _ O
the -X- _ O
KenLM -X- _ B-MethodName
( -X- _ O
Heafield -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
library -X- _ O
with -X- _ O
default -X- _ O
hyperparameters -X- _ O
for -X- _ O
KneserEssenNey -X- _ B-MethodName
smoothing -X- _ I-MethodName
. -X- _ O

Both -X- _ O
GPT-2 -X- _ B-MethodName
and -X- _ O
BERT -X- _ B-MethodName
use -X- _ O
sub -X- _ B-MethodName
- -X- _ I-MethodName
word -X- _ I-MethodName
tokenization -X- _ I-MethodName
. -X- _ O

Notably -X- _ O
, -X- _ O
BERT -X- _ B-MethodName
models -X- _ O
the -X- _ O
probability -X- _ O
of -X- _ O
a -X- _ O
word -X- _ O
given -X- _ O
both -X- _ O
prior -X- _ O
andlater -X- _ O
context -X- _ O
, -X- _ O
which -X- _ O
means -X- _ O
it -X- _ O
can -X- _ O
only -X- _ O
give -X- _ O
us -X- _ O
pseudo -X- _ O
estimates -X- _ O
of -X- _ O
surprisal -X- _ O
. -X- _ O

Specifically -X- _ O
, -X- _ O
for -X- _ O
GPT-2 -X- _ B-MethodName
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
default -X- _ O
OpenAI -X- _ O
version -X- _ O
( -X- _ O
gpt2 -X- _ O
) -X- _ O
; -X- _ O
for -X- _ O
TransformerXL -X- _ B-MethodName
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
version -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
( -X- _ O
architecture -X- _ O
described -X- _ O
in -X- _ O
Dai -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
) -X- _ O
that -X- _ O
has -X- _ O
been -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
WikiText103 -X- _ B-DatasetName
( -X- _ O
transfo -X- _ O
- -X- _ O
xl -X- _ O
- -X- _ O
wt103 -X- _ O
) -X- _ O
; -X- _ O
for -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
bert -X- _ B-MethodName
- -X- _ I-MethodName
base -X- _ I-MethodName
- -X- _ I-MethodName
cased -X- _ I-MethodName
version -X- _ O
. -X- _ O

For -X- _ O
reproducibility -X- _ O
, -X- _ O
we -X- _ O
employ -X- _ O
the -X- _ O
model -X- _ O
checkpoints -X- _ O
provided -X- _ O
by -X- _ O
Hugging -X- _ O
Face -X- _ O
( -X- _ O
Wolf -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

A.2 -X- _ O
Surprisal -X- _ O
Estimates -X- _ O
We -X- _ O
use -X- _ O
pre -X- _ B-MethodName
- -X- _ I-MethodName
trained -X- _ I-MethodName
neural -X- _ I-MethodName
language -X- _ I-MethodName
models -X- _ I-MethodName
to -X- _ O
compute -X- _ O
most -X- _ O
surprisal -X- _ B-MetricName
estimates -X- _ I-MetricName
. -X- _ O

We -X- _ O
removed -X- _ O
outlier -X- _ O
wordlevel -X- _ O
reading -X- _ O
times -X- _ O
( -X- _ O
specifically -X- _ O
those -X- _ O
with -X- _ O
a -X- _ O
zscore -X- _ B-MetricName
> -X- _ O
3when -X- _ B-MetricValue
the -X- _ O
distribution -X- _ O
was -X- _ O
modeled -X- _ O
as -X- _ O
log -X- _ O
- -X- _ O
linear -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
estimate -X- _ O
unigram -X- _ B-MetricName
log -X- _ I-MetricName
- -X- _ I-MetricName
probabilities -X- _ I-MetricName
on -X- _ O
WikiText-103 -X- _ B-DatasetName
using -X- _ O
the -X- _ O
KenLM -X- _ B-MethodName
( -X- _ O
Heafield -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
library -X- _ O
with -X- _ O
default -X- _ O
hyperparameters -X- _ O
. -X- _ O

Capitalization -X- _ O
was -X- _ O
kept -X- _ O
intact -X- _ O
albeit -X- _ O
the -X- _ O
lowercase -X- _ O
version -X- _ O
of -X- _ O
words -X- _ O
were -X- _ O
used -X- _ O
in -X- _ O
unigram -X- _ B-TaskName
probability -X- _ I-TaskName
estimates -X- _ I-TaskName
. -X- _ O

We -X- _ O
determine -X- _ O
clause -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
final -X- _ I-HyperparameterName
words -X- _ I-HyperparameterName
as -X- _ O
all -X- _ O
those -X- _ O
ending -X- _ O
in -X- _ O
punctuation -X- _ O
. -X- _ O

In -X- _ O
short -X- _ O
, -X- _ O
our -X- _ O
results -X- _ O
provide -X- _ O
evidence -X- _ O
( -X- _ O
either -X- _ O
in -X- _ O
support -X- _ O
or -X- _ O
against -X- _ O
) -X- _ O
about -X- _ O
several -X- _ O
theories -X- _ O
of -X- _ O
the -X- _ O
nature -X- _ O
of -X- _ O
wrap -X- _ O
- -X- _ O
up -X- _ O
processes -X- _ O
. -X- _ O

Further -X- _ O
, -X- _ O
these -X- _ O
processes -X- _ O
may -X- _ O
indeed -X- _ O
be -X- _ O
different -X- _ O
in -X- _ O
nature -X- _ O
than -X- _ O
those -X- _ O
required -X- _ O
for -X- _ O
sentence -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
medial -X- _ I-HyperparameterName
words -X- _ I-HyperparameterName
. -X- _ O

This -X- _ O
suggests -X- _ O
that -X- _ O
information -X- _ O
- -X- _ O
theoretic -X- _ O
attributes -X- _ O
of -X- _ O
text -X- _ O
can -X- _ O
shed -X- _ O
light -X- _ O
on -X- _ O
the -X- _ O
cognitive -X- _ O
processes -X- _ O
happening -X- _ O
during -X- _ O
the -X- _ O
comprehension -X- _ O
of -X- _ O
clause -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
final -X- _ I-HyperparameterName
words -X- _ I-HyperparameterName
. -X- _ O

We -X- _ O
find -X- _ O
that -X- _ O
operationalizations -X- _ O
of -X- _ O
the -X- _ O
information -X- _ O
contained -X- _ O
in -X- _ O
preceding -X- _ O
context -X- _ O
lead -X- _ O
to -X- _ O
better -X- _ O
predictions -X- _ O
of -X- _ O
these -X- _ O
RTs -X- _ B-MetricName
, -X- _ O
while -X- _ O
not -X- _ O
adding -X- _ O
significant -X- _ O
predictive -X- _ O
power -X- _ O
for -X- _ O
sentence -X- _ B-MetricName
- -X- _ I-MetricName
medial -X- _ I-MetricName
RTs -X- _ I-MetricName
. -X- _ O

On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
these -X- _ O
results -X- _ O
provide -X- _ O
evidence -X- _ O
against -X- _ O
the -X- _ O
hypothesis -X- _ O
that -X- _ O
the -X- _ O
cognitive -X- _ O
processes -X- _ O
occurring -X- _ O
during -X- _ O
the -X- _ O
comprehension -X- _ O
of -X- _ O
sentence -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
medial -X- _ I-HyperparameterName
and -X- _ B-HyperparameterName
clause -X- _ I-HyperparameterName
- -X- _ I-HyperparameterName
final -X- _ I-HyperparameterName
words -X- _ I-HyperparameterName
are -X- _ O
the -X- _ O
same -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
case -X- _ O
, -X- _ O
the -X- _ O
observed -X- _ O
correlation -X- _ O
between -X- _ O
wrap -X- _ O
- -X- _ O
up -X- _ O
times -X- _ O
and -X- _ O
INF(k)(w)may -X- _ O
potentially -X- _ O
be -X- _ O
linked -X- _ O
to -X- _ O
two -X- _ O
factors -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
contextual -X- _ B-MethodName
ambiguities -X- _ I-MethodName
increasing -X- _ O
variation -X- _ O
in -X- _ O
per -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
word -X- _ I-HyperparameterName
information -X- _ I-HyperparameterName
content -X- _ I-HyperparameterName
; -X- _ O
and -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
contextual -X- _ B-MethodName
ambiguities -X- _ I-MethodName
being -X- _ O
resolved -X- _ O
at -X- _ O
clause -X- _ O
ends -X- _ O
. -X- _ O

When -X- _ O
considering -X- _ O
prior -X- _ O
theories -X- _ O
of -X- _ O
wrap -X- _ B-MethodName
- -X- _ I-MethodName
up -X- _ I-MethodName
processes -X- _ I-MethodName
, -X- _ O
these -X- _ O
results -X- _ O
have -X- _ O
several -X- _ O
implications -X- _ O
. -X- _ O

This -X- _ O
artifact -X- _ O
may -X- _ O
manifest -X- _ O
as -X- _ O
the -X- _ O
noisiness -X- _ O
or -X- _ O
a -X- _ O
lack -X- _ O
of -X- _ O
a -X- _ O
significant -X- _ O
increase -X- _ O
in -X- _ O
log -X- _ B-MetricName
- -X- _ I-MetricName
likelihood -X- _ I-MetricName
( -X- _ O
on -X- _ O
a -X- _ O
held -X- _ O
- -X- _ O
out -X- _ O
test -X- _ O
set -X- _ O
) -X- _ O
over -X- _ O
the -X- _ O
baseline -X- _ O
that -X- _ O
we -X- _ O
observe -X- _ O
in -X- _ O
some -X- _ O
cases -X- _ O
. -X- _ O

We -X- _ O
see -X- _ O
that -X- _ O
with -X- _ O
the -X- _ O
smaller -X- _ O
datasets -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
UCL -X- _ B-DatasetName
and -X- _ O
Provo -X- _ B-DatasetName
) -X- _ O
, -X- _ O
there -X- _ O
may -X- _ O
not -X- _ O
be -X- _ O
enough -X- _ O
data -X- _ O
to -X- _ O
learn -X- _ O
accurate -X- _ O
model -X- _ B-HyperparameterName
parameters -X- _ I-HyperparameterName
. -X- _ O

Another -X- _ O
( -X- _ O
perhaps -X- _ O
more -X- _ O
influential -X- _ O
) -X- _ O
factor -X- _ O
in -X- _ O
the -X- _ O
difference -X- _ O
in -X- _ O
trends -X- _ O
comes -X- _ O
from -X- _ O
the -X- _ O
variation -X- _ O
in -X- _ O
dataset -X- _ O
sizes -X- _ O
. -X- _ O

Due -X- _ O
to -X- _ O
the -X- _ O
nature -X- _ O
of -X- _ O
psycholinguistic -X- _ B-TaskName
studies -X- _ I-TaskName
, -X- _ O
it -X- _ O
is -X- _ O
natural -X- _ O
to -X- _ O
expect -X- _ O
some -X- _ O
variation -X- _ O
due -X- _ O
to -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
data -X- _ O
collection -X- _ O
procedures -X- _ O
or -X- _ O
inaccuracies -X- _ O
from -X- _ O
measurement -X- _ O
devices -X- _ O
. -X- _ O

Notably -X- _ O
, -X- _ O
we -X- _ O
see -X- _ O
some -X- _ O
variation -X- _ O
in -X- _ O
trends -X- _ O
across -X- _ O
datasets -X- _ O
. -X- _ O

We -X- _ O
see -X- _ O
that -X- _ O
our -X- _ O
informationtheoretic -X- _ O
predictors -X- _ O
contribute -X- _ O
much -X- _ O
less -X- _ O
modeling -X- _ O
power -X- _ O
to -X- _ O
the -X- _ O
prediction -X- _ O
of -X- _ O
sentence -X- _ B-MetricName
- -X- _ I-MetricName
medial -X- _ I-MetricName
RTs -X- _ I-MetricName
in -X- _ O
comparison -X- _ O
to -X- _ O
sentenceand -X- _ O
clause -X- _ B-MetricName
- -X- _ I-MetricName
final -X- _ I-MetricName
RTs -X- _ I-MetricName
. -X- _ O

The -X- _ O
effect -X- _ O
of -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
surprisal -X- _ O
throughout -X- _ O
the -X- _ O
sentence -X- _ O
is -X- _ O
stronger -X- _ O
for -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
data -X- _ O
than -X- _ O
for -X- _ O
SPR -X- _ B-DatasetName
; -X- _ O
further -X- _ O
, -X- _ O
the -X- _ O
trends -X- _ O
are -X- _ O
even -X- _ O
more -X- _ O
pronounced -X- _ O
when -X- _ O
measuring -X- _ O
regression -X- _ O
times -X- _ O
for -X- _ O
eye -X- _ O
- -X- _ O
tracking -X- _ O
data -X- _ O
( -X- _ O
see -X- _ O
App -X- _ O
. -X- _ O

Note -X- _ O
that -X- _ O
these -X- _ O
effects -X- _ O
hold -X- _ O
above -X- _ O
and -X- _ O
beyond -X- _ O
the -X- _ O
spill -X- _ O
- -X- _ O
over -X- _ O
effects -X- _ O
from -X- _ O
the -X- _ O
window -X- _ O
immediately -X- _ O
preceding -X- _ O
the -X- _ O
sentence -X- _ O
boundary -X- _ O
. -X- _ O

The -X- _ O
same -X- _ O
experiments -X- _ O
for -X- _ O
sentence -X- _ O
- -X- _ O
medial -X- _ O
words -X- _ O
show -X- _ O
these -X- _ O
quantities -X- _ O
are -X- _ O
less -X- _ O
helpful -X- _ O
when -X- _ O
modeling -X- _ O
their -X- _ O
RTs -X- _ B-MetricName
. -X- _ O

This -X- _ O
indicates -X- _ O
that -X- _ O
unevenness -X- _ O
in -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
surprisal -X- _ O
is -X- _ O
stronger -X- _ O
than -X- _ O
the -X- _ O
total -X- _ O
surprisal -X- _ O
content -X- _ O
alone -X- _ O
as -X- _ O
a -X- _ O
predictor -X- _ O
of -X- _ O
clause -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
final -X- _ I-HyperparameterName
RTs -X- _ I-HyperparameterName
. -X- _ O

Here -X- _ O
we -X- _ O
explore -X- _ O
the -X- _ O
additional -X- _ O
predictive -X- _ O
power -X- _ O
that -X- _ O
INF(k)gives -X- _ O
us -X- _ O
when -X- _ O
modeling -X- _ O
clause -X- _ B-MethodName
- -X- _ I-MethodName
final -X- _ I-MethodName
RTs -X- _ I-MethodName
. -X- _ O

Unless -X- _ O
otherwise -X- _ O
stated -X- _ O
, -X- _ O
GPT-2 -X- _ B-MethodName
estimates -X- _ O
are -X- _ O
used -X- _ O
for -X- _ O
baseline -X- _ O
surprisal -X- _ O
estimates -X- _ O
in -X- _ O
all -X- _ O
models -X- _ O
. -X- _ O

Surprisal -X- _ O
from -X- _ O
two -X- _ O
words -X- _ O
back -X- _ O
is -X- _ O
included -X- _ O
for -X- _ O
SPR -X- _ B-DatasetName
datasets -X- _ O
. -X- _ O

These -X- _ O
values -X- _ O
, -X- _ O
albeit -X- _ O
computed -X- _ O
on -X- _ O
the -X- _ O
previous -X- _ O
word -X- _ O
, -X- _ O
are -X- _ O
also -X- _ O
included -X- _ O
to -X- _ O
account -X- _ O
for -X- _ O
spill -X- _ O
- -X- _ O
over -X- _ O
effects -X- _ O
( -X- _ O
Smith -X- _ O
and -X- _ O
Levy -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
. -X- _ O

Our -X- _ O
baseline -X- _ O
model -X- _ O
for -X- _ O
predicting -X- _ O
perword -X- _ O
RTs -X- _ B-HyperparameterName
contains -X- _ O
predictors -X- _ O
for -X- _ O
surprisal -X- _ O
, -X- _ O
unigram -X- _ O
log -X- _ O
- -X- _ O
frequency -X- _ O
, -X- _ O
character -X- _ O
length -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
interaction -X- _ O
of -X- _ O
the -X- _ O
latter -X- _ O
two -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
10 -X- _ B-HyperparameterValue
- -X- _ O
fold -X- _ B-HyperparameterName
cross -X- _ B-MethodName
- -X- _ I-MethodName
validation -X- _ I-MethodName
to -X- _ O
compute -X- _ O
LogLik -X- _ B-MetricName
values -X- _ O
so -X- _ O
as -X- _ O
to -X- _ O
avoid -X- _ O
overfitting -X- _ O
, -X- _ O
taking -X- _ O
the -X- _ O
mean -X- _ B-MetricName
across -X- _ O
the -X- _ O
held -X- _ O
- -X- _ O
out -X- _ O
folds -X- _ O
as -X- _ O
our -X- _ O
final -X- _ O
metric -X- _ O
. -X- _ O

Following -X- _ O
Wilcox -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
Meister -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
quantify -X- _ O
the -X- _ O
predictive -X- _ O
power -X- _ O
of -X- _ O
a -X- _ O
variable -X- _ O
of -X- _ O
interest -X- _ O
( -X- _ O
INF(k)(w)here -X- _ O
) -X- _ O
as -X- _ O
the -X- _ O
mean -X- _ O
difference -X- _ O
in -X- _ O
log -X- _ B-MetricName
- -X- _ I-MetricName
likelihood -X- _ I-MetricName
LogLik -X- _ O
of -X- _ O
a -X- _ O
( -X- _ O
held -X- _ O
- -X- _ O
out -X- _ O
) -X- _ O
data -X- _ O
point -X- _ O
when -X- _ O
using -X- _ O
a -X- _ O
model -X- _ O
with -X- _ O
and -X- _ O
without -X- _ O
that -X- _ O
predictor -X- _ O
. -X- _ O

We -X- _ O
compute -X- _ O
per -X- _ B-MetricName
- -X- _ I-MetricName
word -X- _ I-MetricName
surprisal -X- _ I-MetricName
as -X- _ O
the -X- _ O
sum -X- _ O
of -X- _ O
subword -X- _ O
surprisals -X- _ O
, -X- _ O
when -X- _ O
applicable -X- _ O
. -X- _ O

We -X- _ O
obtain -X- _ O
surprisal -X- _ O
estimates -X- _ O
from -X- _ O
three -X- _ B-MethodName
language -X- _ I-MethodName
models -X- _ I-MethodName
: -X- _ O
GPT-2 -X- _ B-MethodName
( -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
TransformerXL -X- _ O
( -X- _ O
Dai -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
a -X- _ O
5 -X- _ O
- -X- _ O
gram -X- _ O
model -X- _ O
, -X- _ O
estimated -X- _ O
using -X- _ O
Modified -X- _ B-MethodName
KneserEssenNey -X- _ I-MethodName
Smoothing -X- _ I-MethodName
( -X- _ O
Ney -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
1994 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
provide -X- _ O
an -X- _ O
analysis -X- _ O
of -X- _ O
regression -X- _ B-MetricName
( -X- _ O
a.k.a -X- _ O
. -X- _ O

For -X- _ O
eye -X- _ B-DatasetName
- -X- _ I-DatasetName
tracking -X- _ I-DatasetName
data -X- _ I-DatasetName
, -X- _ O
we -X- _ O
take -X- _ O
reading -X- _ O
time -X- _ O
to -X- _ O
be -X- _ O
the -X- _ O
sum -X- _ O
over -X- _ O
all -X- _ O
fixation -X- _ O
times -X- _ O
on -X- _ O
that -X- _ O
word -X- _ O
. -X- _ O

All -X- _ O
corpora -X- _ O
are -X- _ O
in -X- _ O
English -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
reading -X- _ O
time -X- _ O
data -X- _ O
from -X- _ O
5 -X- _ B-HyperparameterValue
corpora -X- _ B-HyperparameterName
over -X- _ O
2 -X- _ B-HyperparameterValue
modalities -X- _ B-HyperparameterName
: -X- _ O
the -X- _ O
Natural -X- _ B-DatasetName
Stories -X- _ I-DatasetName
( -X- _ O
Futrell -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
Brown -X- _ B-DatasetName
( -X- _ O
Smith -X- _ O
and -X- _ O
Levy -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
UCL -X- _ B-DatasetName
( -X- _ I-DatasetName
SP -X- _ I-DatasetName
) -X- _ I-DatasetName
( -X- _ O
Frank -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
Corpora -X- _ O
, -X- _ O
which -X- _ O
contain -X- _ O
SPR -X- _ B-DatasetName
data -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
Provo -X- _ B-DatasetName
( -X- _ O
Luke -X- _ O
and -X- _ O
Christianson -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
Dundee -X- _ B-DatasetName
( -X- _ O
Kennedy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2003 -X- _ O
) -X- _ O
and -X- _ B-DatasetName
UCL -X- _ I-DatasetName
( -X- _ I-DatasetName
ET -X- _ I-DatasetName
) -X- _ I-DatasetName
( -X- _ O
Frank -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
Corpora -X- _ O
, -X- _ O
which -X- _ O
contain -X- _ O
eye -X- _ O
movements -X- _ O
during -X- _ O
reading -X- _ O
. -X- _ O

Thus -X- _ O
, -X- _ O
we -X- _ O
ask -X- _ O
whether -X- _ O
taking -X- _ O
into -X- _ O
account -X- _ O
information -X- _ O
from -X- _ O
the -X- _ O
entire -X- _ O
prior -X- _ O
context -X- _ O
can -X- _ O
give -X- _ O
us -X- _ O
a -X- _ O
better -X- _ O
model -X- _ O
of -X- _ O
these -X- _ O
clause -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
final -X- _ I-HyperparameterName
RTs -X- _ I-HyperparameterName
. -X- _ O

sults -X- _ O
provide -X- _ O
further -X- _ O
confirmation -X- _ O
that -X- _ O
clause -X- _ O
- -X- _ O
final -X- _ O
data -X- _ O
does -X- _ O
not -X- _ O
adhere -X- _ O
to -X- _ O
the -X- _ O
same -X- _ O
relationship -X- _ O
with -X- _ O
RT -X- _ B-HyperparameterName
as -X- _ O
sentence -X- _ O
- -X- _ O
medial -X- _ O
data -X- _ O
, -X- _ O
a -X- _ O
phenomenon -X- _ O
that -X- _ O
may -X- _ O
perhaps -X- _ O
be -X- _ O
accounted -X- _ O
for -X- _ O
by -X- _ O
additional -X- _ O
factors -X- _ O
at -X- _ O
play -X- _ O
in -X- _ O
the -X- _ O
comprehension -X- _ O
of -X- _ O
clause -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
final -X- _ I-HyperparameterName
words -X- _ I-HyperparameterName
. -X- _ O

6The -X- _ O
opposite -X- _ O
is -X- _ O
true -X- _ O
for -X- _ O
regression -X- _ B-MetricName
times -X- _ I-MetricName
in -X- _ O
eye -X- _ B-DatasetName
- -X- _ I-DatasetName
tracking -X- _ I-DatasetName
data -X- _ I-DatasetName
; -X- _ O
see -X- _ O
App -X- _ O
. -X- _ O

Further -X- _ O
, -X- _ O
these -X- _ O
trends -X- _ O
appear -X- _ O
to -X- _ O
be -X- _ O
different -X- _ O
for -X- _ O
eyetracking -X- _ O
and -X- _ O
SPR -X- _ B-DatasetName
data -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
latter -X- _ O
are -X- _ O
skewed -X- _ O
towards -X- _ O
lower -X- _ O
values -X- _ O
for -X- _ O
all -X- _ O
datasets.6These -X- _ O
re5Several -X- _ O
works -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
Stowe -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
have -X- _ O
argued -X- _ O
the -X- _ O
cognitive -X- _ O
processes -X- _ O
involved -X- _ O
in -X- _ O
comprehension -X- _ O
of -X- _ O
clause -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
final -X- _ I-HyperparameterName
words -X- _ I-HyperparameterName
are -X- _ O
exactly -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
those -X- _ O
for -X- _ O
sentence -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
medial -X- _ I-HyperparameterName
words -X- _ I-HyperparameterName
. -X- _ O

1 -X- _ O
, -X- _ O
we -X- _ O
see -X- _ O
that -X- _ O
when -X- _ O
our -X- _ O
baseline -X- _ O
linear -X- _ O
model -X- _ O
( -X- _ O
described -X- _ O
more -X- _ O
precisely -X- _ O
in -X- _ O
4 -X- _ O
) -X- _ O
is -X- _ O
fit -X- _ O
to -X- _ O
sentence -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
medial -X- _ I-HyperparameterName
RTs -X- _ I-HyperparameterName
, -X- _ O
the -X- _ O
residuals -X- _ O
for -X- _ O
predictions -X- _ O
of -X- _ O
clause -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
final -X- _ I-HyperparameterName
RTs -X- _ I-HyperparameterName
appear -X- _ O
to -X- _ O
be -X- _ O
neither -X- _ O
normally -X- _ O
distributed -X- _ O
nor -X- _ O
centered -X- _ O
around -X- _ B-HyperparameterValue
0 -X- _ I-HyperparameterValue
. -X- _ O

While -X- _ O
this -X- _ O
paradigm -X- _ O
is -X- _ O
successful -X- _ O
in -X- _ O
modeling -X- _ O
sentence -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
medial -X- _ I-HyperparameterName
RTs -X- _ I-HyperparameterName
( -X- _ O
Smith -X- _ O
and -X- _ O
Levy -X- _ O
, -X- _ O
2013 -X- _ O
; -X- _ O
Goodkind -X- _ O
and -X- _ O
Bicknell -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Wilcox -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
its -X- _ O
effectiveness -X- _ O
for -X- _ O
modeling -X- _ O
sentenceand -X- _ B-HyperparameterName
clause -X- _ I-HyperparameterName
- -X- _ I-HyperparameterName
final -X- _ I-HyperparameterName
times -X- _ I-HyperparameterName
is -X- _ O
largely -X- _ O
unknown -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
omission -X- _ O
of -X- _ O
this -X- _ O
data -X- _ O
from -X- _ O
the -X- _ O
majority -X- _ O
of -X- _ O
RT -X- _ B-TaskName
analyses -X- _ I-TaskName
. -X- _ O

The -X- _ O
predictive -X- _ O
power -X- _ O
of -X- _ O
these -X- _ O
models -X- _ O
, -X- _ O
together -X- _ O
with -X- _ O
the -X- _ O
structure -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
itself -X- _ O
( -X- _ O
which -X- _ O
defines -X- _ O
a -X- _ O
specific -X- _ O
relationship -X- _ O
between -X- _ O
RTs -X- _ B-MethodName
and -X- _ O
surprisal -X- _ O
) -X- _ O
, -X- _ O
is -X- _ O
then -X- _ O
used -X- _ O
as -X- _ O
evidence -X- _ O
of -X- _ O
the -X- _ O
studied -X- _ O
effect -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
computational -X- _ B-TaskName
psycholinguistics -X- _ I-TaskName
literature -X- _ O
, -X- _ O
the -X- _ O
RTsurprisal -X- _ O
relationship -X- _ O
is -X- _ O
typically -X- _ O
studied -X- _ O
using -X- _ O
predictive -X- _ O
models -X- _ O
: -X- _ O
RTs -X- _ B-HyperparameterName
are -X- _ O
predicted -X- _ O
using -X- _ O
surprisal -X- _ B-MethodName
estimates -X- _ I-MethodName
( -X- _ O
along -X- _ O
with -X- _ O
other -X- _ O
attributes -X- _ O
such -X- _ O
as -X- _ O
number -X- _ O
of -X- _ O
characters -X- _ O
) -X- _ O
for -X- _ O
the -X- _ O
current -X- _ O
word -X- _ O
. -X- _ O

2020 -X- _ O
) -X- _ O
, -X- _ O
exciting -X- _ O
new -X- _ O
results -X- _ O
in -X- _ O
computational -X- _ B-TaskName
psycholinguistics -X- _ I-TaskName
may -X- _ O
follow -X- _ O
, -X- _ O
connecting -X- _ O
reading -X- _ O
behavior -X- _ O
to -X- _ O
the -X- _ O
statistics -X- _ O
of -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
. -X- _ O

B -X- _ O
, -X- _ O
where -X- _ O
we -X- _ O
also -X- _ O
show -X- _ O
models -X- _ O
fit -X- _ O
to -X- _ O
regression -X- _ B-MetricName
times -X- _ I-MetricName
, -X- _ O
rather -X- _ O
than -X- _ O
full -X- _ O
reading -X- _ O
times -X- _ O
. -X- _ O

Full -X- _ O
distributions -X- _ O
of -X- _ O
RTs -X- _ B-HyperparameterName
are -X- _ O
shown -X- _ O
in -X- _ O
App -X- _ O
. -X- _ O

The -X- _ O
top -X- _ O
level -X- _ O
datasets -X- _ O
contain -X- _ O
eye -X- _ B-DatasetName
- -X- _ I-DatasetName
tracking -X- _ I-DatasetName
data -X- _ I-DatasetName
while -X- _ O
the -X- _ O
bottom -X- _ O
contain -X- _ O
SPR -X- _ B-DatasetName
data -X- _ I-DatasetName
. -X- _ O

Models -X- _ O
are -X- _ O
fit -X- _ O
to -X- _ O
( -X- _ O
the -X- _ O
log -X- _ O
- -X- _ O
transform -X- _ O
of -X- _ O
) -X- _ O
non -X- _ O
clause -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
final -X- _ I-HyperparameterName
average -X- _ I-HyperparameterName
RTs -X- _ I-HyperparameterName
. -X- _ O

Figure -X- _ O
1 -X- _ O
: -X- _ O
Distributions -X- _ O
of -X- _ O
residuals -X- _ O
when -X- _ O
predicting -X- _ O
either -X- _ O
clause -X- _ B-MethodName
- -X- _ I-MethodName
final -X- _ I-MethodName
or -X- _ O
non -X- _ B-MethodName
clause -X- _ I-MethodName
- -X- _ I-MethodName
final -X- _ I-MethodName
times -X- _ O
using -X- _ O
our -X- _ O
baseline -X- _ O
linear -X- _ O
models -X- _ O
. -X- _ O

4Perplexity -X- _ B-MetricName
is -X- _ O
a -X- _ O
monotonic -X- _ O
function -X- _ O
of -X- _ O
the -X- _ O
average -X- _ B-MetricName
surprisal -X- _ I-MetricName
of -X- _ O
linguistic -X- _ O
units -X- _ O
in -X- _ O
- -X- _ O
context -X- _ O
under -X- _ O
a -X- _ O
model -X- _ O
. -X- _ O

It -X- _ O
has -X- _ O
even -X- _ O
been -X- _ O
observed -X- _ O
that -X- _ O
a -X- _ O
language -X- _ B-TaskName
models -X- _ I-TaskName
perplexity4correlates -X- _ B-MetricName
negatively -X- _ O
with -X- _ O
the -X- _ O
psychometric -X- _ B-MethodName
predictive -X- _ I-MethodName
power -X- _ I-MethodName
provided -X- _ O
by -X- _ O
its -X- _ O
surprisal -X- _ B-MetricName
estimates -X- _ I-MetricName
( -X- _ O
Frank -X- _ O
and -X- _ O
Bod -X- _ O
, -X- _ O
2011 -X- _ O
; -X- _ O
Goodkind -X- _ O
and -X- _ O
Bicknell -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Wilcox -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

One -X- _ O
widely -X- _ O
embraced -X- _ O
technique -X- _ O
in -X- _ O
informationtheoretic -X- _ B-TaskName
psycholinguistics -X- _ I-TaskName
is -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
these -X- _ O
language -X- _ O
models -X- _ O
to -X- _ O
estimate -X- _ O
the -X- _ O
probabilities -X- _ O
required -X- _ O
for -X- _ O
computing -X- _ B-TaskName
surprisal -X- _ I-TaskName
( -X- _ O
Hale -X- _ O
, -X- _ O
2001 -X- _ O
; -X- _ O
Demberg -X- _ O
and -X- _ O
Keller -X- _ O
, -X- _ O
2008 -X- _ O
; -X- _ O
Mitchell -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2010 -X- _ O
; -X- _ O
Fernandez -X- _ O
Monsalve -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
. -X- _ O

Model -X- _ O
parameters -X- _ O
are -X- _ O
typically -X- _ O
estimated -X- _ O
by -X- _ O
minimizing -X- _ O
the -X- _ O
negative -X- _ O
loglikelihood -X- _ O
of -X- _ O
a -X- _ O
corpus -X- _ O
of -X- _ O
natural -X- _ B-HyperparameterName
language -X- _ I-HyperparameterName
strings -X- _ I-HyperparameterName
C -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
minimizing -X- _ O
L(bp -X- _ O
) -X- _ O
= -X- _ O
P -X- _ O
yClogbp(y -X- _ O
) -X- _ O
. -X- _ O

Consequently -X- _ O
, -X- _ O
in -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
ask -X- _ O
whether -X- _ O
the -X- _ O
reading -X- _ O
behavior -X- _ O
observed -X- _ O
at -X- _ O
the -X- _ O
end -X- _ O
of -X- _ O
a -X- _ O
sentence -X- _ O
or -X- _ O
clause -X- _ O
can -X- _ O
be -X- _ O
described -X- _ O
( -X- _ O
at -X- _ O
least -X- _ O
partially -X- _ O
) -X- _ O
by -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
information -X- _ O
content -X- _ O
in -X- _ O
the -X- _ O
preceding -X- _ O
context,3as -X- _ O
this -X- _ O
may -X- _ O
give -X- _ O
insights -X- _ O
for -X- _ O
several -X- _ O
prior -X- _ O
hypotheses -X- _ O
about -X- _ O
wrap -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
up -X- _ I-HyperparameterName
effects -X- _ I-HyperparameterName
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
high -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
surprisal -X- _ I-HyperparameterName
words -X- _ I-HyperparameterName
in -X- _ O
the -X- _ O
preceding -X- _ O
context -X- _ O
may -X- _ O
correlate -X- _ O
with -X- _ O
the -X- _ O
presence -X- _ O
of -X- _ O
ambiguities -X- _ O
in -X- _ O
the -X- _ O
text -X- _ O
; -X- _ O
they -X- _ O
may -X- _ O
also -X- _ O
correlate -X- _ O
with -X- _ O
complex -X- _ O
linguistic -X- _ O
relationships -X- _ O
of -X- _ O
the -X- _ O
current -X- _ O
text -X- _ O
with -X- _ O
prior -X- _ O
sentenceswhich -X- _ O
are -X- _ O
two -X- _ O
driving -X- _ O
forces -X- _ O
in -X- _ O
the -X- _ O
theories -X- _ O
given -X- _ O
above -X- _ O
. -X- _ O

Concretely -X- _ O
, -X- _ O
we -X- _ O
posit -X- _ O
the -X- _ O
relationship -X- _ O
between -X- _ O
texts -X- _ O
information -X- _ O
- -X- _ O
theoretic -X- _ O
attributes -X- _ O
and -X- _ O
its -X- _ O
observed -X- _ O
wrap -X- _ B-MetricName
- -X- _ I-MetricName
up -X- _ I-MetricName
times -X- _ I-MetricName
can -X- _ O
provide -X- _ O
an -X- _ O
indication -X- _ O
of -X- _ O
the -X- _ O
presence -X- _ O
( -X- _ O
or -X- _ O
lack -X- _ O
) -X- _ O
of -X- _ O
several -X- _ O
cognitive -X- _ O
processes -X- _ O
that -X- _ O
are -X- _ O
potentially -X- _ O
a -X- _ O
part -X- _ O
of -X- _ O
sentence -X- _ O
wrap -X- _ O
- -X- _ O
up -X- _ O
. -X- _ O

Second -X- _ O
, -X- _ O
Rayner -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2000 -X- _ O
) -X- _ O
suggest -X- _ O
they -X- _ O
might -X- _ O
involve -X- _ O
attempts -X- _ O
to -X- _ O
resolve -X- _ O
previously -X- _ O
postponed -X- _ O
comprehension -X- _ O
problems -X- _ O
, -X- _ O
which -X- _ O
could -X- _ O
have -X- _ O
been -X- _ O
deferred -X- _ O
in -X- _ O
the -X- _ O
hope -X- _ O
that -X- _ O
upcoming -X- _ O
words -X- _ O
would -X- _ O
resolve -X- _ O
the -X- _ O
problem -X- _ O
. -X- _ O

First -X- _ O
, -X- _ O
Just -X- _ O
and -X- _ O
Carpenter -X- _ O
( -X- _ O
1980 -X- _ O
) -X- _ O
hypothesize -X- _ O
that -X- _ O
wrap -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
up -X- _ I-HyperparameterName
effects -X- _ I-HyperparameterName
include -X- _ O
actions -X- _ O
such -X- _ O
as -X- _ O
the -X- _ O
constructions -X- _ O
of -X- _ O
inter -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
clause -X- _ I-HyperparameterName
relations -X- _ I-HyperparameterName
. -X- _ O

Which -X- _ O
cognitive -X- _ O
processes -X- _ O
are -X- _ O
encompassed -X- _ O
by -X- _ O
the -X- _ O
term -X- _ O
wrap -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
up -X- _ I-HyperparameterName
effects -X- _ I-HyperparameterName
? -X- _ O
Several -X- _ O
theories -X- _ O
have -X- _ O
been -X- _ O
posited -X- _ O
. -X- _ O

2.2 -X- _ O
Wrap -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
up -X- _ I-HyperparameterName
Effects -X- _ I-HyperparameterName
It -X- _ O
remains -X- _ O
unclear -X- _ O
what -X- _ O
exactly -X- _ O
occurs -X- _ O
in -X- _ O
the -X- _ O
mind -X- _ O
of -X- _ O
the -X- _ O
reader -X- _ O
at -X- _ O
the -X- _ O
end -X- _ O
of -X- _ O
a -X- _ O
sentence -X- _ O
or -X- _ O
clause -X- _ O
. -X- _ O

Yet -X- _ O
unfortunately -X- _ O
, -X- _ O
these -X- _ O
wrap -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
up -X- _ I-HyperparameterName
effects -X- _ I-HyperparameterName
have -X- _ O
received -X- _ O
relatively -X- _ O
little -X- _ O
attention -X- _ O
in -X- _ O
the -X- _ O
psycholinguistic -X- _ O
community -X- _ O
: -X- _ O
Most -X- _ O
reading -X- _ O
time -X- _ O
studies -X- _ O
simply -X- _ O
exclude -X- _ O
sentence -X- _ O
- -X- _ O
final -X- _ O
( -X- _ O
or -X- _ O
even -X- _ O
clause -X- _ O
- -X- _ O
final -X- _ O
) -X- _ O
words -X- _ O
from -X- _ O
their -X- _ O
analyses -X- _ O
, -X- _ O
claiming -X- _ O
that -X- _ O
the -X- _ O
( -X- _ O
poorly -X- _ O
- -X- _ O
understood -X- _ O
) -X- _ O
effects -X- _ O
are -X- _ O
confounding -X- _ O
factors -X- _ O
in -X- _ O
understanding -X- _ O
the -X- _ O
reading -X- _ O
process -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
Frank -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Wilcox -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

Specifically -X- _ O
, -X- _ O
in -X- _ O
comparison -X- _ O
to -X- _ O
sentence -X- _ O
- -X- _ O
medial -X- _ O
words -X- _ O
, -X- _ O
sentenceor -X- _ O
clause -X- _ O
- -X- _ O
final -X- _ O
words -X- _ O
are -X- _ O
associated -X- _ O
with -X- _ O
increased -X- _ O
RTs -X- _ B-MethodName
in -X- _ O
selfpaced -X- _ O
studies -X- _ O
( -X- _ O
Just -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
1982 -X- _ O
; -X- _ O
Hill -X- _ O
and -X- _ O
Murray -X- _ O
, -X- _ O
2000 -X- _ O
) -X- _ O
and -X- _ O
both -X- _ O
increased -X- _ O
fixation -X- _ B-MetricName
and -X- _ O
regression -X- _ B-MetricName
times -X- _ I-MetricName
in -X- _ O
eye -X- _ B-TaskName
- -X- _ I-TaskName
tracking -X- _ I-TaskName
studies -X- _ I-TaskName
( -X- _ O
Rayner -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2000 -X- _ O
; -X- _ O
Camblin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2007 -X- _ O
) -X- _ O
. -X- _ O

This -X- _ B-TaskName
RTprocessing -X- _ I-TaskName
effort -X- _ O
relationship -X- _ O
then -X- _ O
allows -X- _ O
us -X- _ O
to -X- _ O
identify -X- _ O
relationships -X- _ O
between -X- _ O
a -X- _ O
words -X- _ O
processing -X- _ O
load -X- _ O
and -X- _ O
its -X- _ O
attributes -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
surprisal -X- _ O
or -X- _ O
length)which -X- _ O
in -X- _ O
turn -X- _ O
hints -X- _ O
at -X- _ O
the -X- _ O
underlying -X- _ O
cognitive -X- _ O
processes -X- _ O
involved -X- _ O
in -X- _ O
comprehension -X- _ O
. -X- _ O

Many -X- _ O
pyscholinguistic -X- _ O
studies -X- _ O
make -X- _ O
use -X- _ O
of -X- _ O
this -X- _ O
notion -X- _ O
, -X- _ O
taking -X- _ O
per -X- _ B-TaskName
- -X- _ I-TaskName
word -X- _ I-TaskName
RTs -X- _ I-TaskName
in -X- _ O
self -X- _ B-TaskName
- -X- _ I-TaskName
paced -X- _ I-TaskName
reading -X- _ I-TaskName
( -X- _ I-TaskName
SPR -X- _ I-TaskName
) -X- _ I-TaskName
or -X- _ O
eyetracking -X- _ B-TaskName
studies -X- _ I-TaskName
to -X- _ O
be -X- _ O
a -X- _ O
direct -X- _ O
reflection -X- _ O
of -X- _ O
the -X- _ O
processing -X- _ B-MethodName
load -X- _ I-MethodName
of -X- _ I-MethodName
that -X- _ I-MethodName
word -X- _ I-MethodName
( -X- _ O
e.g. -X- _ O
, -X- _ O
Smith -X- _ O
and -X- _ O
Levy -X- _ O
, -X- _ O
2013 -X- _ O
; -X- _ O
Van -X- _ O
Schijndel -X- _ O
and -X- _ O
Linzen -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

Here -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
briefly -X- _ O
describe -X- _ O
overarching -X- _ O
themes -X- _ O
that -X- _ O
are -X- _ O
relevant -X- _ O
for -X- _ O
understanding -X- _ O
wrap -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
up -X- _ I-HyperparameterName
effects -X- _ I-HyperparameterName
. -X- _ O

Such -X- _ O
findings -X- _ O
lend -X- _ O
support -X- _ O
to -X- _ O
several -X- _ O
prior -X- _ O
hypotheses -X- _ O
regarding -X- _ O
which -X- _ O
processes -X- _ O
may -X- _ O
underlie -X- _ O
wrap -X- _ O
- -X- _ O
up -X- _ O
effects20 -X- _ O
. -X- _ O

This -X- _ O
result -X- _ O
suggests -X- _ O
that -X- _ O
the -X- _ O
nature -X- _ O
of -X- _ O
cognitive -X- _ O
processes -X- _ O
involved -X- _ O
during -X- _ O
the -X- _ O
reading -X- _ O
of -X- _ O
these -X- _ O
boundary -X- _ O
words -X- _ O
may -X- _ O
indeed -X- _ O
be -X- _ O
different -X- _ O
than -X- _ O
those -X- _ O
at -X- _ O
other -X- _ O
positions -X- _ O
. -X- _ O

We -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
surprisals -X- _ O
of -X- _ O
prior -X- _ O
context -X- _ O
is -X- _ O
often -X- _ O
predictive -X- _ O
of -X- _ O
sentenceand -X- _ O
clause -X- _ B-MethodName
- -X- _ I-MethodName
final -X- _ I-MethodName
reading -X- _ I-MethodName
times -X- _ I-MethodName
( -X- _ I-MethodName
RTs -X- _ I-MethodName
) -X- _ I-MethodName
, -X- _ O
while -X- _ O
not -X- _ O
adding -X- _ O
significant -X- _ O
predictive -X- _ O
power -X- _ O
to -X- _ O
models -X- _ O
of -X- _ O
sentencemedial -X- _ B-MethodName
RTs -X- _ I-MethodName
. -X- _ O

Using -X- _ O
surprisal -X- _ O
estimates -X- _ O
from -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
language -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
search -X- _ O
for -X- _ O
a -X- _ O
link -X- _ O
between -X- _ O
wrapup -X- _ B-HyperparameterName
effects -X- _ I-HyperparameterName
and -X- _ O
the -X- _ O
information -X- _ O
content -X- _ O
within -X- _ O
a -X- _ O
sentence -X- _ O
. -X- _ O

We -X- _ O
follow -X- _ O
the -X- _ O
long -X- _ O
line -X- _ O
of -X- _ O
work -X- _ O
that -X- _ O
has -X- _ O
connected -X- _ O
information -X- _ B-MethodName
- -X- _ I-MethodName
theoretic -X- _ I-MethodName
measures -X- _ I-MethodName
and -X- _ O
psychometric -X- _ B-DatasetName
data -X- _ I-DatasetName
( -X- _ O
Frank -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Goodkind -X- _ O
and -X- _ O
Bicknell -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Wilcox -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Meister -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
, -X- _ O
inter -X- _ O
alia -X- _ O
) -X- _ O
, -X- _ O
employing -X- _ O
similar -X- _ O
methods -X- _ O
to -X- _ O
build -X- _ O
models -X- _ O
of -X- _ O
sentenceand -X- _ O
clause -X- _ B-TaskName
- -X- _ I-TaskName
final -X- _ I-TaskName
RTs -X- _ I-TaskName
. -X- _ O

Specifically -X- _ O
, -X- _ O
we -X- _ O
study -X- _ O
whether -X- _ O
informationtheoretic -X- _ O
concepts -X- _ O
( -X- _ O
such -X- _ O
as -X- _ O
surprisal -X- _ O
) -X- _ O
provide -X- _ O
insights -X- _ O
into -X- _ O
the -X- _ O
cognitive -X- _ O
processes -X- _ O
that -X- _ O
occur -X- _ O
at -X- _ O
a -X- _ O
sentences -X- _ O
boundary -X- _ O
. -X- _ O

This -X- _ O
work -X- _ O
addresses -X- _ O
this -X- _ O
gap -X- _ O
, -X- _ O
using -X- _ O
several -X- _ O
large -X- _ O
corpora -X- _ O
of -X- _ O
reading -X- _ O
time -X- _ O
data -X- _ O
. -X- _ O

Second -X- _ O
, -X- _ O
the -X- _ O
few -X- _ O
studies -X- _ O
on -X- _ O
wrap -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
up -X- _ I-HyperparameterName
effects -X- _ I-HyperparameterName
rely -X- _ O
on -X- _ O
small -X- _ O
datasets -X- _ O
, -X- _ O
none -X- _ O
of -X- _ O
which -X- _ O
analyze -X- _ O
naturalistic -X- _ B-DatasetName
text -X- _ I-DatasetName
( -X- _ O
Just -X- _ O
and -X- _ O
Carpenter -X- _ O
, -X- _ O
1980 -X- _ O
; -X- _ O
Rayner -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2000 -X- _ O
; -X- _ O
Kuperberg -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
. -X- _ O

First -X- _ O
, -X- _ O
most -X- _ O
studies -X- _ O
of -X- _ O
online -X- _ O
processing -X- _ O
omit -X- _ O
data -X- _ O
from -X- _ O
these -X- _ O
words -X- _ O
to -X- _ O
explicitly -X- _ O
control -X- _ O
for -X- _ O
the -X- _ O
confounding -X- _ O
factors -X- _ O
wrap -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
up -X- _ I-HyperparameterName
effects -X- _ I-HyperparameterName
introduce -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
Smith -X- _ O
and -X- _ O
Levy -X- _ O
, -X- _ O
2013 -X- _ O
; -X- _ O
Goodkind -X- _ O
and -X- _ O
Bicknell -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

This -X- _ O
is -X- _ O
likely -X- _ O
( -X- _ O
at -X- _ O
least -X- _ O
in -X- _ O
part -X- _ O
) -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
dearth -X- _ O
of -X- _ O
analyses -X- _ O
targeting -X- _ O
naturalistic -X- _ O
sentence -X- _ O
- -X- _ O
final -X- _ O
reading -X- _ O
behavior -X- _ O
. -X- _ O

One -X- _ O
behavior -X- _ O
revealed -X- _ O
by -X- _ O
such -X- _ O
studies -X- _ O
is -X- _ O
the -X- _ O
tendency -X- _ O
for -X- _ O
humans -X- _ O
to -X- _ O
spend -X- _ O
more -X- _ O
time1on -X- _ O
the -X- _ O
last -X- _ O
word -X- _ O
of -X- _ O
a -X- _ O
sentence -X- _ O
or -X- _ O
clause -X- _ O
. -X- _ O

Indeed -X- _ O
, -X- _ O
studies -X- _ O
analyzing -X- _ O
reading -X- _ O
times -X- _ O
have -X- _ O
been -X- _ O
employed -X- _ O
to -X- _ O
explore -X- _ O
a -X- _ O
number -X- _ O
of -X- _ O
psycholinguistic -X- _ B-MethodName
theories -X- _ I-MethodName
( -X- _ O
e.g. -X- _ O
, -X- _ O
Smith -X- _ O
and -X- _ O
Levy -X- _ O
, -X- _ O
2013 -X- _ O
; -X- _ O
Futrell -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Van -X- _ O
Schijndel -X- _ O
and -X- _ O
Linzen -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

Ergo -X- _ O
, -X- _ O
examining -X- _ O
where -X- _ O
a -X- _ O
reader -X- _ O
spends -X- _ O
their -X- _ O
time -X- _ O
should -X- _ O
help -X- _ O
us -X- _ O
to -X- _ O
understand -X- _ O
the -X- _ O
nature -X- _ O
of -X- _ O
language -X- _ B-TaskName
comprehension -X- _ I-TaskName
processes -X- _ O
themselves -X- _ O
. -X- _ O

The -X- _ O
rate -X- _ O
at -X- _ O
which -X- _ O
humans -X- _ O
choose -X- _ O
to -X- _ O
read -X- _ O
text -X- _ O
( -X- _ O
and -X- _ O
process -X- _ O
its -X- _ O
information -X- _ O
) -X- _ O
should -X- _ O
be -X- _ O
determined -X- _ O
by -X- _ O
their -X- _ O
goal -X- _ O
of -X- _ O
understanding -X- _ O
it -X- _ O
. -X- _ O

Consequently -X- _ O
, -X- _ O
it -X- _ O
presents -X- _ O
a -X- _ O
unique -X- _ O
opportunity -X- _ O
to -X- _ O
gain -X- _ O
a -X- _ O
better -X- _ O
understanding -X- _ O
of -X- _ O
how -X- _ O
humans -X- _ O
comprehend -X- _ O
written -X- _ O
language -X- _ O
. -X- _ O

This -X- _ O
lends -X- _ O
support -X- _ O
to -X- _ O
several -X- _ O
prior -X- _ O
hypotheses -X- _ O
about -X- _ O
the -X- _ O
processes -X- _ O
involved -X- _ O
in -X- _ O
wrap -X- _ O
- -X- _ O
up -X- _ O
effects -X- _ O
. -X- _ O

We -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
information -X- _ O
in -X- _ O
prior -X- _ O
contexts -X- _ O
is -X- _ O
often -X- _ O
predictive -X- _ O
of -X- _ O
sentenceand -X- _ O
clause -X- _ O
- -X- _ O
final -X- _ O
RTs -X- _ B-MetricName
( -X- _ O
while -X- _ O
not -X- _ O
of -X- _ O
sentence -X- _ B-MetricName
- -X- _ I-MetricName
medial -X- _ I-MetricName
RTs -X- _ I-MetricName
) -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
attempt -X- _ O
to -X- _ O
learn -X- _ O
more -X- _ O
about -X- _ O
these -X- _ O
processes -X- _ O
by -X- _ O
examining -X- _ O
the -X- _ O
relationship -X- _ O
between -X- _ O
wrap -X- _ O
- -X- _ O
up -X- _ O
effects -X- _ O
and -X- _ O
information -X- _ B-MethodName
- -X- _ I-MethodName
theoretic -X- _ I-MethodName
quantities -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
word -X- _ O
and -X- _ O
context -X- _ O
surprisals -X- _ O
. -X- _ O

Consequently -X- _ O
, -X- _ O
the -X- _ O
understanding -X- _ O
of -X- _ O
the -X- _ O
cognitive -X- _ O
processes -X- _ O
that -X- _ O
might -X- _ O
be -X- _ O
involved -X- _ O
in -X- _ O
these -X- _ O
wrap -X- _ O
- -X- _ O
up -X- _ O
effects -X- _ O
is -X- _ O
limited -X- _ O
. -X- _ O

Results -X- _ O
show -X- _ O
DKT -X- _ B-MethodName
outperforms -X- _ O
baselines -X- _ O
under -X- _ O
all -X- _ O
settings -X- _ O
and -X- _ O
gets -X- _ O
the -X- _ O
smallest -X- _ O
varying -X- _ O
degrees -X- _ O
of -X- _ O
performance -X- _ O
drop -X- _ O
, -X- _ O
which -X- _ O
proves -X- _ O
the -X- _ O
robustness -X- _ O
and -X- _ O
stability -X- _ O
of -X- _ O
our -X- _ O
method -X- _ O
. -X- _ O

A.2 -X- _ O
Effect -X- _ O
of -X- _ O
IND -X- _ O
Data -X- _ O
We -X- _ O
analyze -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
IND -X- _ O
data -X- _ O
for -X- _ O
OOD -X- _ B-TaskName
discovery -X- _ I-TaskName
from -X- _ O
two -X- _ O
perspectives -X- _ O
, -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
IND -X- _ B-MethodName
classes -X- _ O
and -X- _ O
samples -X- _ O
per -X- _ O
class -X- _ O
. -X- _ O

It -X- _ O
designed -X- _ O
a -X- _ O
pseudo -X- _ B-MethodName
label -X- _ I-MethodName
alignment -X- _ I-MethodName
strategy -X- _ O
to -X- _ O
produce -X- _ O
aligned -X- _ O
cluster -X- _ O
assignments -X- _ O
for -X- _ O
better -X- _ O
representation -X- _ O
learning -X- _ O
. -X- _ O

And -X- _ O
the -X- _ O
IND -X- _ O
pretraining -X- _ O
objectives -X- _ O
uses -X- _ O
CE -X- _ B-MethodName
+ -X- _ I-MethodName
SCL -X- _ I-MethodName
proposed -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
. -X- _ O

A -X- _ O
Appendix -X- _ O
A.1 -X- _ O
Baselines -X- _ O
The -X- _ O
details -X- _ O
of -X- _ O
baselines -X- _ O
are -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
PTK -X- _ O
- -X- _ O
means -X- _ O
A -X- _ O
method -X- _ O
based -X- _ O
on -X- _ O
k -X- _ B-MethodName
- -X- _ I-MethodName
means -X- _ I-MethodName
with -X- _ O
IND -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
. -X- _ O

We -X- _ O
hope -X- _ O
to -X- _ O
explore -X- _ O
more -X- _ O
selfsupervised -X- _ O
representation -X- _ O
learning -X- _ O
methods -X- _ O
for -X- _ O
OOD -X- _ B-TaskName
discovery -X- _ I-TaskName
in -X- _ O
the -X- _ O
future.50 -X- _ O
. -X- _ O

Experiments -X- _ O
and -X- _ O
analysis -X- _ O
on -X- _ O
two -X- _ O
benchmarks -X- _ O
demonstrate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
DKT -X- _ B-MethodName
for -X- _ O
OOD -X- _ B-DatasetName
discovery -X- _ I-DatasetName
. -X- _ O

5 -X- _ O
Conclusion -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
disentangled -X- _ B-MethodName
knowledge -X- _ I-MethodName
transfer -X- _ I-MethodName
method -X- _ I-MethodName
( -X- _ O
DKT -X- _ O
) -X- _ O
via -X- _ O
a -X- _ O
unified -X- _ B-MethodName
multi -X- _ I-MethodName
- -X- _ I-MethodName
head -X- _ I-MethodName
contrastive -X- _ I-MethodName
learning -X- _ I-MethodName
framework -X- _ I-MethodName
to -X- _ O
transfer -X- _ B-TaskName
disentangled -X- _ I-TaskName
IND -X- _ I-TaskName
intent -X- _ I-TaskName
representations -X- _ I-TaskName
to -X- _ I-TaskName
OOD -X- _ I-TaskName
clustering -X- _ I-TaskName
. -X- _ O

We -X- _ O
argue -X- _ O
that -X- _ O
this -X- _ O
reects -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
decoupling -X- _ O
, -X- _ O
that -X- _ O
is -X- _ O
, -X- _ O
instance -X- _ O
- -X- _ O
level -X- _ O
head -X- _ O
decouples -X- _ O
the -X- _ O
uniqueness -X- _ O
of -X- _ O
each -X- _ O
sample -X- _ O
, -X- _ O
and -X- _ O
cluster -X- _ O
- -X- _ O
level -X- _ O
head -X- _ O
decouples -X- _ O
the -X- _ O
category -X- _ O
characteristics -X- _ O
of -X- _ O
each -X- _ O
sample -X- _ O
. -X- _ O

We -X- _ O
can -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
output -X- _ O
obtained -X- _ O
by -X- _ O
instance -X- _ O
- -X- _ O
level -X- _ O
head -X- _ O
forms -X- _ O
a -X- _ O
narrow -X- _ O
and -X- _ O
long -X- _ O
cluster -X- _ O
distribution -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
output -X- _ O
obtained -X- _ O
by -X- _ O
cluster -X- _ O
- -X- _ O
level -X- _ O
head -X- _ O
forms -X- _ O
a -X- _ O
more -X- _ O
compact -X- _ O
and -X- _ O
uniform -X- _ O
cluster -X- _ O
distribution -X- _ O
. -X- _ O

Results -X- _ O
show -X- _ O
all -X- _ O
the -X- _ O
losses -X- _ O
contribute -X- _ O
to -X- _ O
the -X- _ O
performance -X- _ O
especially -X- _ O
SCL -X- _ B-MethodName
, -X- _ O
ILCL -X- _ B-MethodName
and -X- _ O
CLCL -X- _ B-MethodName
, -X- _ O
which -X- _ O
confirms -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
unified -X- _ O
contrastive -X- _ O
framework -X- _ O
. -X- _ O

Ablation -X- _ O
Study -X- _ O
To -X- _ O
understand -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
different -X- _ O
objectives -X- _ O
of -X- _ O
DKT -X- _ B-MethodName
, -X- _ O
we -X- _ O
perform -X- _ O
abalation -X- _ B-MethodName
study -X- _ I-MethodName
in -X- _ O
Tab -X- _ O
4 -X- _ O
by -X- _ O
removing -X- _ O
each -X- _ O
loss -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
DeepAligned -X- _ B-MethodName
incorrectly -X- _ O
groups -X- _ O
accept_reservation -X- _ B-HyperparameterName
intents -X- _ O
into -X- _ O
cancel_reservation -X- _ B-HyperparameterName
( -X- _ O
14% -X- _ B-MetricValue
error -X- _ B-MetricName
rate -X- _ O
) -X- _ O
vs -X- _ O
DKT(7% -X- _ B-MethodName
) -X- _ O
, -X- _ O
which -X- _ O
proves -X- _ O
DKT -X- _ B-MethodName
helps -X- _ O
separate -X- _ O
semantically -X- _ O
similar -X- _ O
OOD -X- _ O
intents -X- _ O
. -X- _ O

similar -X- _ O
OOD -X- _ O
intents -X- _ O
, -X- _ O
DeepAligned -X- _ B-MethodName
is -X- _ O
probably -X- _ O
confused -X- _ O
but -X- _ O
our -X- _ O
DKT -X- _ B-MethodName
can -X- _ O
effectively -X- _ O
distinguish -X- _ O
them -X- _ O
. -X- _ O

The -X- _ O
larger -X- _ O
the -X- _ O
number -X- _ O
, -X- _ O
the -X- _ O
deeper -X- _ O
the -X- _ O
color -X- _ O
. -X- _ O

The -X- _ O
percentage -X- _ O
values -X- _ O
along -X- _ O
the -X- _ O
diagonal -X- _ O
represent -X- _ O
how -X- _ O
many -X- _ O
samples -X- _ O
are -X- _ O
correctly -X- _ O
clustered -X- _ O
into -X- _ O
the -X- _ O
corresponding -X- _ O
class -X- _ O
. -X- _ O

KT -X- _ B-MethodName
denotes -X- _ O
only -X- _ O
using -X- _ O
single -X- _ O
MLP -X- _ B-MethodName
head -X- _ O
. -X- _ O

Error -X- _ O
Analysis -X- _ O
We -X- _ O
further -X- _ O
analyze -X- _ O
the -X- _ O
error -X- _ O
cases -X- _ O
of -X- _ O
DeepAligned -X- _ B-MethodName
and -X- _ O
DKT -X- _ B-MethodName
in -X- _ O
Fig -X- _ O
5 -X- _ O
. -X- _ O

Besides -X- _ O
, -X- _ O
Section -X- _ O
4 -X- _ O
further -X- _ O
explore -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
different -X- _ O
layer -X- _ O
and -X- _ O
representations -X- _ O
after -X- _ O
MLP -X- _ B-MethodName
ggets -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
. -X- _ O

We -X- _ O
find -X- _ O
both -X- _ O
DeepAligned -X- _ B-MethodName
and -X- _ O
KT -X- _ B-MethodName
have -X- _ O
some -X- _ O
mixed -X- _ O
OOD -X- _ B-MethodName
clusters -X- _ O
while -X- _ O
DKT -X- _ B-MethodName
forms -X- _ O
clearly -X- _ O
separate -X- _ O
decision -X- _ O
boundaries -X- _ O
between -X- _ O
clusters -X- _ O
, -X- _ O
which -X- _ O
shows -X- _ O
our -X- _ O
proposed -X- _ O
DKT -X- _ B-MethodName
obtains -X- _ O
discriminative -X- _ O
OOD -X- _ B-MethodName
representations -X- _ O
for -X- _ O
OOD -X- _ B-TaskName
discovery -X- _ I-TaskName
. -X- _ O

Note -X- _ O
that -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
representation -X- _ O
following -X- _ O
the -X- _ O
pooling -X- _ B-HyperparameterName
layer -X- _ I-HyperparameterName
for -X- _ O
fair -X- _ O
comparison -X- _ O
. -X- _ O

Visualization -X- _ O
To -X- _ O
confirm -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
DKT -X- _ B-MethodName
, -X- _ O
we -X- _ O
perform -X- _ O
OOD -X- _ O
intent -X- _ B-TaskName
representation -X- _ I-TaskName
visualization -X- _ I-TaskName
of -X- _ O
DeepAligned -X- _ B-MethodName
, -X- _ O
KT -X- _ B-MethodName
and -X- _ O
DKT -X- _ B-MethodName
in -X- _ O
Fig -X- _ O
3 -X- _ O
. -X- _ O

We -X- _ O
find -X- _ O
Disentangled -X- _ B-MethodName
KT -X- _ I-MethodName
significantly -X- _ O
outperforms -X- _ O
KT -X- _ B-MethodName
both -X- _ O
on -X- _ O
two -X- _ O
settings -X- _ O
, -X- _ O
which -X- _ O
proves -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
representation -X- _ B-MethodName
disentanglement -X- _ I-MethodName
for -X- _ O
knowledge -X- _ B-TaskName
transfer -X- _ I-TaskName
. -X- _ O

4 -X- _ O
Qualitative -X- _ O
Analysis -X- _ O
Effect -X- _ O
of -X- _ O
Disentangled -X- _ O
Intent -X- _ O
Representations -X- _ O
Tab -X- _ O
3 -X- _ O
shows -X- _ O
performance -X- _ O
comparison -X- _ O
of -X- _ O
DKT -X- _ B-MethodName
and -X- _ O
KT -X- _ B-MethodName
under -X- _ O
two -X- _ O
settings -X- _ O
. -X- _ O

Comparing -X- _ O
Unsup -X- _ O
DKT -X- _ B-MethodName
with -X- _ O
Semi -X- _ B-MethodName
- -X- _ I-MethodName
sup -X- _ I-MethodName
DKT -X- _ I-MethodName
, -X- _ O
the -X- _ O
latter -X- _ O
significantly -X- _ O
outperforms -X- _ O
the -X- _ O
former -X- _ O
by -X- _ O
23.56%(ACC -X- _ B-MetricValue
) -X- _ O
, -X- _ O
33.79%(ARI -X- _ B-MetricValue
) -X- _ O
, -X- _ O
20.30%(NMI -X- _ B-MetricValue
) -X- _ O
, -X- _ O
which -X- _ O
demonstrates -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
IND -X- _ O
pre -X- _ O
- -X- _ O
training(see -X- _ O
details -X- _ O
in -X- _ O
appendix -X- _ O
A.2 -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
results -X- _ O
prove -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
disentangled -X- _ B-MethodName
knowledge -X- _ I-MethodName
transfer -X- _ I-MethodName
for -X- _ O
OOD -X- _ B-TaskName
discovery -X- _ I-TaskName
. -X- _ O

Similar -X- _ O
improvements -X- _ O
are -X- _ O
observed -X- _ O
on -X- _ O
other -X- _ O
datasets -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
Semi -X- _ B-MethodName
- -X- _ I-MethodName
sup -X- _ I-MethodName
setting -X- _ O
on -X- _ O
CLINC10% -X- _ B-DatasetName
, -X- _ O
DKT -X- _ B-MethodName
outperforms -X- _ O
the -X- _ O
previous -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
theart -X- _ O
DeepAligned -X- _ O
by -X- _ O
2.67%(ACC -X- _ B-MetricValue
) -X- _ O
, -X- _ O
5.35%(ARI -X- _ B-MetricValue
) -X- _ O
, -X- _ O
2.84%(NMI -X- _ B-MetricValue
) -X- _ O
. -X- _ O

Under -X- _ O
both -X- _ O
unsupervised -X- _ B-MethodName
and -X- _ O
semi -X- _ B-MethodName
- -X- _ I-MethodName
supervised -X- _ I-MethodName
settings -X- _ O
, -X- _ O
our -X- _ O
proposed -X- _ O
DKT -X- _ B-MethodName
consistently -X- _ O
outperforms -X- _ O
all -X- _ O
the -X- _ O
baselines -X- _ O
. -X- _ O

3.5 -X- _ O
Main -X- _ O
Results -X- _ O
Table -X- _ O
1 -X- _ O
shows -X- _ O
the -X- _ O
performance -X- _ O
comparison -X- _ O
of -X- _ O
different -X- _ O
models -X- _ O
on -X- _ O
two -X- _ O
datasets -X- _ O
. -X- _ O

The -X- _ O
pre -X- _ B-MethodName
- -X- _ I-MethodName
training -X- _ I-MethodName
stage -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
lasts -X- _ O
about -X- _ O
30 -X- _ O
minutes -X- _ O
and -X- _ O
clustering -X- _ O
runs -X- _ O
for -X- _ O
10 -X- _ O
minutes -X- _ O
on -X- _ O
CLINC-10% -X- _ B-DatasetName
, -X- _ O
both -X- _ O
using -X- _ O
a -X- _ O
single -X- _ O
Tesla -X- _ O
T4 -X- _ O
GPU(16 -X- _ O
GB -X- _ O
of -X- _ O
memory -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
SC -X- _ B-HyperparameterName
of -X- _ O
validation -X- _ O
OOD -X- _ B-DatasetName
data -X- _ I-DatasetName
( -X- _ O
still -X- _ O
unlabeled -X- _ O
data -X- _ O
) -X- _ O
to -X- _ O
choose -X- _ O
the -X- _ O
best -X- _ O
checkpoint -X- _ O
. -X- _ O

As -X- _ O
6https://github.com/google-research/bertfor -X- _ O
the -X- _ O
cluster -X- _ O
- -X- _ O
level -X- _ O
contrastive -X- _ O
head -X- _ O
, -X- _ O
the -X- _ O
dimensionality -X- _ O
of -X- _ O
the -X- _ O
column -X- _ O
space -X- _ O
is -X- _ O
naturally -X- _ O
set -X- _ O
to -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
IND -X- _ O
classes -X- _ O
/ -X- _ O
OOD -X- _ O
clusters -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
cluster -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
level -X- _ I-HyperparameterName
temperature -X- _ I-HyperparameterName
parameter -X- _ I-HyperparameterName
= -X- _ O
1.0 -X- _ B-HyperparameterValue
is -X- _ O
used -X- _ O
for -X- _ O
all -X- _ O
datasets -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
instance -X- _ O
- -X- _ O
level -X- _ O
contrastive -X- _ O
head -X- _ O
, -X- _ O
the -X- _ O
dimensionality -X- _ B-HyperparameterName
of -X- _ O
the -X- _ O
row -X- _ O
space -X- _ O
is -X- _ O
set -X- _ O
to -X- _ O
128 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
the -X- _ O
temperatures -X- _ B-HyperparameterName
of -X- _ O
SCL -X- _ B-DatasetName
and -X- _ O
instance -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
level -X- _ I-HyperparameterName
CL -X- _ I-HyperparameterName
are -X- _ O
0.5 -X- _ B-HyperparameterValue
. -X- _ O

Notably -X- _ O
, -X- _ O
We -X- _ O
use -X- _ O
dropout -X- _ B-MethodName
( -X- _ O
Gao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
to -X- _ O
construct -X- _ O
augmented -X- _ O
examples -X- _ O
for -X- _ O
contrastive -X- _ B-TaskName
learning -X- _ I-TaskName
with -X- _ O
dropout -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
0.1 -X- _ B-HyperparameterValue
. -X- _ O

The -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
is -X- _ O
5e-5 -X- _ B-HyperparameterValue
in -X- _ O
the -X- _ O
pre -X- _ B-MethodName
- -X- _ I-MethodName
training -X- _ I-MethodName
phase -X- _ O
and -X- _ O
0.0003 -X- _ B-HyperparameterValue
in -X- _ O
the -X- _ O
clustering -X- _ O
phase -X- _ O
. -X- _ O

During -X- _ O
the -X- _ O
pre -X- _ B-MethodName
- -X- _ I-MethodName
training -X- _ I-MethodName
phase -X- _ O
, -X- _ O
the -X- _ O
training -X- _ B-HyperparameterName
batch -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
is -X- _ O
128 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
during -X- _ O
the -X- _ O
clustering -X- _ O
phase -X- _ O
, -X- _ O
the -X- _ O
training -X- _ B-HyperparameterName
batch -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
is -X- _ O
512 -X- _ B-HyperparameterValue
for -X- _ O
CLINC-10% -X- _ B-DatasetName
, -X- _ O
CLINC-30% -X- _ B-DatasetName
, -X- _ O
Banking-10% -X- _ B-DatasetName
, -X- _ O
and -X- _ O
400 -X- _ B-HyperparameterValue
for -X- _ O
CLINC-20% -X- _ B-DatasetName
. -X- _ O

Moreover -X- _ O
, -X- _ O
we -X- _ O
freeze -X- _ O
all -X- _ O
but -X- _ O
the -X- _ O
last -X- _ O
transformer -X- _ O
layer -X- _ O
parameters -X- _ O
to -X- _ O
achieve -X- _ O
better -X- _ O
performance -X- _ O
with -X- _ O
BERT -X- _ B-MethodName
backbone -X- _ O
, -X- _ O
and -X- _ O
speed -X- _ O
up -X- _ O
the -X- _ O
training -X- _ O
procedure -X- _ O
as -X- _ O
suggested -X- _ O
in -X- _ O
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

3.4 -X- _ O
Implementation -X- _ O
Details -X- _ O
For -X- _ O
a -X- _ O
fair -X- _ O
comparison -X- _ O
with -X- _ O
previous -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
pre -X- _ B-MethodName
- -X- _ I-MethodName
trained -X- _ I-MethodName
BERT -X- _ I-MethodName
model -X- _ I-MethodName
( -X- _ O
bert -X- _ B-MethodName
- -X- _ I-MethodName
base -X- _ I-MethodName
- -X- _ I-MethodName
uncased6 -X- _ I-MethodName
, -X- _ O
with -X- _ O
12 -X- _ B-MethodName
- -X- _ I-MethodName
layer -X- _ I-MethodName
transformer -X- _ I-MethodName
) -X- _ O
as -X- _ O
our -X- _ O
network -X- _ O
backbone -X- _ O
, -X- _ O
and -X- _ O
add -X- _ O
a -X- _ O
pooling -X- _ B-HyperparameterName
layer -X- _ I-HyperparameterName
to -X- _ O
get -X- _ O
intent -X- _ O
representation(dimension=768 -X- _ B-HyperparameterName
) -X- _ O
. -X- _ O

To -X- _ O
calculate -X- _ O
ACC -X- _ B-MetricName
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
Hungarian -X- _ B-MethodName
algorithm -X- _ I-MethodName
( -X- _ O
Kuhn -X- _ O
, -X- _ O
1955 -X- _ O
) -X- _ O
to -X- _ O
obtain -X- _ O
the -X- _ O
mapping -X- _ O
between -X- _ O
the -X- _ O
predicted -X- _ O
classes -X- _ O
and -X- _ O
groundtruth -X- _ O
classes -X- _ O
. -X- _ O

3.3 -X- _ O
Evaluation -X- _ O
Metrics -X- _ O
We -X- _ O
adopt -X- _ O
three -X- _ O
widely -X- _ O
used -X- _ O
metrics -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
clustering -X- _ O
results -X- _ O
: -X- _ O
Accuracy -X- _ B-MetricName
( -X- _ I-MetricName
ACC -X- _ I-MetricName
) -X- _ I-MetricName
, -X- _ O
Normalized -X- _ B-MetricName
Mutual -X- _ I-MetricName
Information -X- _ I-MetricName
( -X- _ I-MetricName
NMI -X- _ I-MetricName
) -X- _ I-MetricName
, -X- _ O
and -X- _ O
Adjusted -X- _ B-MetricName
Rand -X- _ I-MetricName
Index -X- _ I-MetricName
( -X- _ I-MetricName
ARI -X- _ I-MetricName
) -X- _ I-MetricName
. -X- _ O

For -X- _ O
fairness -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
BERT -X- _ B-MethodName
backbone -X- _ O
as -X- _ O
the -X- _ O
baselines -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
report -X- _ O
the -X- _ O
unsupervised -X- _ O
results -X- _ O
( -X- _ O
without -X- _ O
IND -X- _ B-MethodName
pretraining -X- _ I-MethodName
) -X- _ O
of -X- _ O
these -X- _ O
methods -X- _ O
for -X- _ O
a -X- _ O
comprehensive -X- _ O
comparison -X- _ O
. -X- _ O

3.2 -X- _ O
Baselines -X- _ O
We -X- _ O
mainly -X- _ O
compare -X- _ O
our -X- _ O
method -X- _ O
with -X- _ O
semisupervised -X- _ B-MethodName
baselines -X- _ I-MethodName
: -X- _ O
PTK -X- _ B-TaskName
- -X- _ I-TaskName
means -X- _ I-TaskName
( -X- _ O
k -X- _ B-MethodName
- -X- _ I-MethodName
means -X- _ I-MethodName
with -X- _ O
IND -X- _ B-MethodName
pre -X- _ I-MethodName
- -X- _ I-MethodName
training -X- _ I-MethodName
) -X- _ O
, -X- _ O
DeepCluster -X- _ B-TaskName
( -X- _ O
Caron -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
and -X- _ O
two -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
OOD -X- _ B-TaskName
discovery -X- _ I-TaskName
methods -X- _ O
CDAC+ -X- _ B-MethodName
( -X- _ O
Lin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
DeepAligned -X- _ B-MethodName
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
real -X- _ O
scenarios -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
use -X- _ O
OOD -X- _ B-TaskName
detection -X- _ I-TaskName
models -X- _ O
( -X- _ O
Xu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Zeng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
to -X- _ O
collect -X- _ O
high -X- _ O
- -X- _ O
quality -X- _ O
OOD -X- _ O
data -X- _ O
for -X- _ O
OOD -X- _ B-TaskName
intent -X- _ I-TaskName
discovery -X- _ I-TaskName
. -X- _ O

Different -X- _ O
from -X- _ O
previous -X- _ O
work -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
assume -X- _ O
that -X- _ O
the -X- _ O
unlabeled -X- _ O
data -X- _ O
only -X- _ O
contains -X- _ O
OOD -X- _ B-DatasetName
data -X- _ I-DatasetName
instead -X- _ O
of -X- _ O
a -X- _ O
mixture -X- _ O
of -X- _ O
IND -X- _ O
and -X- _ O
OOD -X- _ O
, -X- _ O
aiming -X- _ O
to -X- _ O
fairly -X- _ O
evaluate -X- _ O
the -X- _ O
OOD -X- _ B-MetricName
clustering -X- _ I-MetricName
performance.48 -X- _ I-MetricName
. -X- _ O

For -X- _ O
each -X- _ O
run -X- _ O
, -X- _ O
all -X- _ O
the -X- _ O
models -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
divided -X- _ O
dataset -X- _ O
. -X- _ O

To -X- _ O
avoid -X- _ O
the -X- _ O
randomness -X- _ O
of -X- _ O
splitting -X- _ O
IND -X- _ B-DatasetName
/ -X- _ I-DatasetName
OOD -X- _ I-DatasetName
, -X- _ O
we -X- _ O
average -X- _ O
results -X- _ O
over -X- _ O
three -X- _ O
random -X- _ O
runs -X- _ O
. -X- _ O

Note -X- _ O
that -X- _ O
we -X- _ O
only -X- _ O
use -X- _ O
the -X- _ O
IND -X- _ B-DatasetName
data -X- _ I-DatasetName
for -X- _ O
pretraining -X- _ B-MethodName
and -X- _ O
use -X- _ O
OOD -X- _ B-DatasetName
data -X- _ I-DatasetName
for -X- _ O
clustering -X- _ B-MethodName
. -X- _ O

To -X- _ O
construct -X- _ O
IND -X- _ B-DatasetName
/ -X- _ I-DatasetName
OOD -X- _ I-DatasetName
data -X- _ O
, -X- _ O
we -X- _ O
ramdomly -X- _ O
divided -X- _ O
the -X- _ O
two -X- _ O
datasets -X- _ O
in -X- _ O
three -X- _ O
ramdom -X- _ O
runs -X- _ O
, -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
specified -X- _ O
OOD -X- _ B-MethodName
ratio(10% -X- _ B-HyperparameterName
, -X- _ O
20% -X- _ B-HyperparameterValue
, -X- _ O
30% -X- _ B-HyperparameterValue
for -X- _ O
CLINC -X- _ B-DatasetName
, -X- _ O
10% -X- _ B-HyperparameterValue
for -X- _ O
Banking -X- _ B-DatasetName
) -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
rest -X- _ O
is -X- _ O
IND -X- _ B-MethodName
data -X- _ I-MethodName
. -X- _ O

CLINC -X- _ B-DatasetName
contains -X- _ O
22,500 -X- _ B-HyperparameterValue
queries -X- _ B-HyperparameterName
covering -X- _ O
150 -X- _ B-HyperparameterValue
intents -X- _ B-HyperparameterName
and -X- _ O
Banking -X- _ B-DatasetName
contains -X- _ O
13,083 -X- _ B-HyperparameterValue
customer -X- _ B-HyperparameterName
service -X- _ I-HyperparameterName
queries -X- _ I-HyperparameterName
with -X- _ O
77 -X- _ B-HyperparameterValue
intents -X- _ B-HyperparameterName
. -X- _ O

3 -X- _ O
Experiment -X- _ O
3.1 -X- _ O
Datasets -X- _ O
We -X- _ O
show -X- _ O
the -X- _ O
detailed -X- _ O
statistics -X- _ O
of -X- _ O
CLINC(Larson -X- _ B-DatasetName
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
BANKING(Casanueva -X- _ B-DatasetName
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
datasets -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
. -X- _ O

Combining -X- _ O
the -X- _ O
two -X- _ O
stages -X- _ O
, -X- _ O
our -X- _ O
proposed -X- _ O
unified -X- _ B-MethodName
contrastive -X- _ I-MethodName
learning -X- _ I-MethodName
framework -X- _ I-MethodName
can -X- _ O
effectively -X- _ O
bridge -X- _ O
the -X- _ O
gap -X- _ O
between -X- _ O
IND -X- _ B-MethodName
pre -X- _ I-MethodName
- -X- _ I-MethodName
training -X- _ I-MethodName
and -X- _ O
OOD -X- _ B-MethodName
clustering -X- _ I-MethodName
. -X- _ O

Generally -X- _ O
, -X- _ O
the -X- _ O
instance -X- _ B-TaskName
- -X- _ I-TaskName
CL -X- _ I-TaskName
focuses -X- _ O
on -X- _ O
distinguishing -X- _ O
different -X- _ O
intent -X- _ O
samples -X- _ O
while -X- _ O
the -X- _ O
cluster -X- _ B-TaskName
- -X- _ I-TaskName
CL -X- _ I-TaskName
identifies -X- _ O
distinct -X- _ O
OOD -X- _ B-MethodName
categories -X- _ O
. -X- _ O

For -X- _ O
inference -X- _ O
, -X- _ O
we -X- _ O
only -X- _ O
use -X- _ O
the -X- _ O
clusterlevel -X- _ O
contrastive -X- _ O
head -X- _ O
and -X- _ O
compute -X- _ O
the -X- _ O
argmax -X- _ O
to -X- _ O
get -X- _ O
the -X- _ O
cluster -X- _ O
results -X- _ O
without -X- _ O
additional -X- _ O
K -X- _ B-MethodName
- -X- _ I-MethodName
means -X- _ I-MethodName
. -X- _ O

For -X- _ O
training -X- _ O
, -X- _ O
we -X- _ O
simply -X- _ O
add -X- _ O
the -X- _ O
above -X- _ O
objectives -X- _ O
in -X- _ O
the -X- _ O
experiments -X- _ O
. -X- _ O

Following -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
add -X- _ O
a -X- _ O
regularization -X- _ B-HyperparameterName
item -X- _ I-HyperparameterName
to -X- _ O
avoid -X- _ O
the -X- _ O
trivial -X- _ O
solution -X- _ O
that -X- _ O
most -X- _ O
instances -X- _ O
are -X- _ O
assigned -X- _ O
to -X- _ O
the -X- _ O
single -X- _ O
cluster -X- _ O
. -X- _ O

Then -X- _ O
we -X- _ O
regard -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
column -X- _ O
of -X- _ O
the -X- _ O
matrix -X- _ O
as -X- _ O
the -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
cluster -X- _ O
representationyiand -X- _ B-HyperparameterName
construct -X- _ I-HyperparameterName
cluster -X- _ I-HyperparameterName
- -X- _ I-HyperparameterName
level -X- _ I-HyperparameterName
CL(CLCL -X- _ I-HyperparameterName
) -X- _ I-HyperparameterName
as -X- _ O
4we -X- _ O
set -X- _ O
it -X- _ O
to -X- _ O
0.5 -X- _ B-HyperparameterValue
in -X- _ O
the -X- _ O
experiments -X- _ O
. -X- _ O

Specifically -X- _ O
, -X- _ O
given -X- _ O
an -X- _ O
OOD -X- _ O
cluster -X- _ O
- -X- _ O
level -X- _ O
latent -X- _ O
vector -X- _ O
gi -X- _ O
, -X- _ O
we -X- _ O
firstly -X- _ O
project -X- _ O
it -X- _ O
to -X- _ O
a -X- _ O
vector -X- _ O
with -X- _ O
dimension -X- _ B-HyperparameterName
K -X- _ B-HyperparameterValue
which -X- _ O
equals -X- _ O
to -X- _ O
the -X- _ O
pre -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
defined -X- _ I-HyperparameterName
cluster -X- _ I-HyperparameterName
number.5Suppose -X- _ I-HyperparameterName
we -X- _ O
input -X- _ O
a -X- _ O
batch -X- _ O
of -X- _ O
OOD -X- _ O
samples -X- _ O
so -X- _ O
we -X- _ O
can -X- _ O
get -X- _ O
a -X- _ O
feature -X- _ O
matrix -X- _ O
of -X- _ O
NK -X- _ O
. -X- _ O

On -X- _ O
top -X- _ O
of -X- _ O
the -X- _ O
cluster -X- _ O
- -X- _ O
level -X- _ O
head -X- _ O
g -X- _ O
, -X- _ O
we -X- _ O
perform -X- _ O
contrastive -X- _ B-MethodName
clustering -X- _ I-MethodName
following -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

Then -X- _ O
, -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
the -X- _ O
instancelevel -X- _ O
headf -X- _ O
, -X- _ O
we -X- _ O
perform -X- _ O
instance -X- _ B-MethodName
- -X- _ I-MethodName
level -X- _ I-MethodName
contrastive -X- _ I-MethodName
learning(ILCL -X- _ I-MethodName
) -X- _ I-MethodName
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
` -X- _ O
ins -X- _ O
i;j= logexp -X- _ O
( -X- _ O
sim -X- _ O
( -X- _ O
fi;fj)= -X- _ O
) -X- _ O
P2N -X- _ O
k=11[k6 -X- _ O
= -X- _ O
i]exp -X- _ O
( -X- _ O
sim -X- _ O
( -X- _ O
fi;fk)= -X- _ O
) -X- _ O
wherefjdenotes -X- _ O
the -X- _ B-MethodName
dropout -X- _ I-MethodName
- -X- _ I-MethodName
augmented -X- _ I-MethodName
OOD -X- _ I-MethodName
sample -X- _ I-MethodName
and -X- _ O
denotes -X- _ O
temperature4 -X- _ O
. -X- _ O

Specifically -X- _ O
, -X- _ O
given -X- _ O
an -X- _ O
OOD -X- _ B-MethodName
example -X- _ O
xi -X- _ O
, -X- _ O
we -X- _ O
firstly -X- _ O
use -X- _ O
the -X- _ B-MethodName
pre -X- _ I-MethodName
- -X- _ I-MethodName
trained -X- _ I-MethodName
BERT -X- _ I-MethodName
encoder -X- _ O
and -X- _ O
transformation -X- _ O
heads -X- _ O
to -X- _ O
get -X- _ O
OOD -X- _ B-MethodName
intent -X- _ O
latent -X- _ O
vectorsfiandgi -X- _ O
. -X- _ O

Thus -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
an -X- _ O
end -X- _ B-MethodName
- -X- _ I-MethodName
to -X- _ I-MethodName
- -X- _ I-MethodName
end -X- _ I-MethodName
contrastive -X- _ I-MethodName
clustering -X- _ I-MethodName
method -X- _ I-MethodName
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
to -X- _ O
jointly -X- _ B-MethodName
learn -X- _ I-MethodName
representations -X- _ I-MethodName
and -X- _ O
cluster -X- _ B-MethodName
assignments -X- _ I-MethodName
. -X- _ O

Previous -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
model -X- _ O
DeepAligned -X- _ B-MethodName
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
iteratively -X- _ O
repeats -X- _ O
the -X- _ O
two -X- _ O
stages -X- _ O
which -X- _ O
results -X- _ O
in -X- _ O
poor -X- _ O
clustering -X- _ B-MetricName
efficiency -X- _ I-MetricName
and -X- _ O
accuracy -X- _ B-MetricName
. -X- _ O

OOD -X- _ B-MethodName
Clustering -X- _ I-MethodName
The -X- _ O
key -X- _ O
challenge -X- _ O
of -X- _ O
OOD -X- _ B-MethodName
clustering -X- _ I-MethodName
is -X- _ O
how -X- _ O
to -X- _ O
learn -X- _ B-TaskName
intent -X- _ I-TaskName
representations -X- _ I-TaskName
and -X- _ O
cluster -X- _ B-TaskName
assignments -X- _ I-TaskName
. -X- _ O

Section -X- _ O
4 -X- _ O
confirms -X- _ O
both -X- _ O
the -X- _ O
objectives -X- _ O
improve -X- _ O
the -X- _ O
performance -X- _ O
and -X- _ O
SCL -X- _ O
has -X- _ O
a -X- _ O
larger -X- _ O
effect -X- _ O
. -X- _ O

On -X- _ O
top -X- _ O
of -X- _ O
the -X- _ O
class -X- _ O
- -X- _ O
level -X- _ O
headg -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
cross -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
entropy -X- _ I-HyperparameterName
classification -X- _ I-HyperparameterName
loss -X- _ I-HyperparameterName
to -X- _ O
learn -X- _ O
class(cluster)-wise -X- _ O
distinction -X- _ O
. -X- _ O

Therefore -X- _ O
, -X- _ O
SCL -X- _ O
helps -X- _ O
maximize -X- _ O
inter -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
class -X- _ I-HyperparameterName
variance -X- _ I-HyperparameterName
and -X- _ O
minimize -X- _ O
intra -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
class -X- _ I-HyperparameterName
variance -X- _ I-HyperparameterName
, -X- _ O
further -X- _ O
improves -X- _ O
OOD -X- _ B-MethodName
clustering -X- _ I-MethodName
. -X- _ O

We -X- _ O
evaluate -X- _ O
both -X- _ O
unsupervised -X- _ B-MethodName
and -X- _ O
semi -X- _ B-MethodName
- -X- _ I-MethodName
supervised -X- _ I-MethodName
methods -X- _ O
. -X- _ O

For -X- _ O
simplicity -X- _ O
, -X- _ O
we -X- _ O
set -X- _ O
both -X- _ O
the -X- _ O
input -X- _ O
dimension -X- _ O
and -X- _ O
output -X- _ B-HyperparameterName
dim -X- _ I-HyperparameterName
to -X- _ O
768 -X- _ B-HyperparameterValue
, -X- _ O
same -X- _ O
as -X- _ O
the -X- _ O
hidden -X- _ O
state -X- _ O
dim -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
- -X- _ I-MethodName
base.47 -X- _ I-MethodName
. -X- _ O

3In -X- _ O
the -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
two -X- _ B-HyperparameterValue
separate -X- _ B-HyperparameterName
two -X- _ I-HyperparameterName
- -X- _ I-HyperparameterName
layer -X- _ I-HyperparameterName
nonlinear -X- _ I-HyperparameterName
MLPs -X- _ I-HyperparameterName
for -X- _ O
head -X- _ O
fandg -X- _ O
. -X- _ O

Following -X- _ O
Gao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
; -X- _ O
Yan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
employ -X- _ O
simple -X- _ O
dropout -X- _ B-HyperparameterName
( -X- _ O
Srivastava -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
as -X- _ O
data -X- _ B-MethodName
augmentation -X- _ I-MethodName
. -X- _ O

IND -X- _ O
Pre -X- _ O
- -X- _ O
training -X- _ O
Different -X- _ O
from -X- _ O
existing -X- _ O
methods -X- _ O
that -X- _ O
regard -X- _ O
IND -X- _ B-TaskName
pre -X- _ I-TaskName
- -X- _ I-TaskName
training -X- _ I-TaskName
as -X- _ O
a -X- _ O
single -X- _ O
intent -X- _ B-TaskName
classification -X- _ I-TaskName
task -X- _ I-TaskName
, -X- _ O
we -X- _ O
formulate -X- _ O
it -X- _ O
as -X- _ O
an -X- _ O
instancewise -X- _ B-TaskName
discriminative -X- _ I-TaskName
task -X- _ I-TaskName
and -X- _ O
a -X- _ O
class -X- _ B-TaskName
- -X- _ I-TaskName
wise -X- _ I-TaskName
classification -X- _ I-TaskName
task -X- _ I-TaskName
via -X- _ O
contrastive -X- _ B-TaskName
learning -X- _ I-TaskName
. -X- _ O

Then -X- _ O
we -X- _ O
decouple -X- _ B-MethodName
the -X- _ I-MethodName
intent -X- _ I-MethodName
representations -X- _ I-MethodName
into -X- _ O
two -X- _ O
independent -X- _ O
subspaces -X- _ O
and -X- _ O
use -X- _ O
a -X- _ O
unified -X- _ B-MethodName
contrastive -X- _ I-MethodName
learning -X- _ I-MethodName
framework -X- _ I-MethodName
to -X- _ O
perform -X- _ O
both -X- _ O
IND -X- _ B-TaskName
pre -X- _ I-TaskName
- -X- _ I-TaskName
training -X- _ I-TaskName
and -X- _ O
OOD -X- _ B-TaskName
clustering -X- _ I-TaskName
. -X- _ O

backbone -X- _ O
to -X- _ O
extract -X- _ O
intent -X- _ O
representations -X- _ O
as -X- _ O
the -X- _ O
previous -X- _ O
work -X- _ O
DeepAligned -X- _ B-TaskName
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
firstly -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
IND -X- _ B-MethodName
Pre -X- _ I-MethodName
-training -X- _ I-MethodName
IND -X- _ O
/ -X- _ O
OOD -X- _ O
IntentsOOD -X- _ O
Clustering -X- _ O
Intent -X- _ O
Representation -X- _ O
Pooling -X- _ O
LayerInstance -X- _ O
-level -X- _ O
Head -X- _ O
Instance -X- _ O
-level -X- _ O
Head -X- _ O
Cluster -X- _ O
-level -X- _ O
Head -X- _ O
BERTSCL -X- _ O
CLCL -X- _ O
ILCL -X- _ O
CE -X- _ O
Shared -X- _ O
LayerObjective -X- _ O
LayerFigure -X- _ O
2 -X- _ O
: -X- _ O
The -X- _ O
overall -X- _ O
architecture -X- _ O
of -X- _ O
our -X- _ O
DKT -X- _ O
. -X- _ O

Overall -X- _ O
Architecture -X- _ O
Fig -X- _ O
2 -X- _ O
shows -X- _ O
the -X- _ O
overall -X- _ O
architecture -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
DKT -X- _ B-MethodName
model -X- _ I-MethodName
. -X- _ O

Generally -X- _ O
, -X- _ O
OOD -X- _ B-MethodName
discovery -X- _ O
includes -X- _ O
two -X- _ O
stages -X- _ O
, -X- _ O
IND -X- _ B-MethodName
pre -X- _ I-MethodName
- -X- _ I-MethodName
training -X- _ I-MethodName
which -X- _ O
aims -X- _ O
to -X- _ O
obtain -X- _ O
a -X- _ O
decent -X- _ O
intent -X- _ O
representation -X- _ O
via -X- _ O
labeled -X- _ O
IND -X- _ B-DatasetName
data -X- _ I-DatasetName
, -X- _ O
and -X- _ O
OOD -X- _ B-MethodName
clustering -X- _ I-MethodName
which -X- _ O
aims -X- _ O
to -X- _ O
group -X- _ O
OOD -X- _ O
intents -X- _ O
into -X- _ O
different -X- _ O
clusters -X- _ O
. -X- _ O

Note -X- _ O
that -X- _ O
IND -X- _ B-DatasetName
data -X- _ I-DatasetName
has -X- _ O
no -X- _ O
overlapping -X- _ O
with -X- _ O
OOD -X- _ B-DatasetName
data -X- _ I-DatasetName
. -X- _ O

( -X- _ O
3 -X- _ O
) -X- _ O
Experiments -X- _ O
and -X- _ O
analysis -X- _ O
on -X- _ O
two -X- _ O
benchmark -X- _ O
datasets -X- _ O
demonstrate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
method -X- _ O
for -X- _ O
OOD -X- _ B-MethodName
discovery -X- _ O
. -X- _ O

( -X- _ O
2 -X- _ O
) -X- _ O
We -X- _ O
propose -X- _ O
a -X- _ O
unified -X- _ B-MethodName
multihead -X- _ I-MethodName
contrastive -X- _ I-MethodName
learning -X- _ I-MethodName
framework -X- _ O
to -X- _ O
bridge -X- _ O
the -X- _ O
gap -X- _ O
between -X- _ O
IND -X- _ B-MethodName
pre -X- _ I-MethodName
- -X- _ I-MethodName
training -X- _ I-MethodName
and -X- _ O
OOD -X- _ B-MethodName
clustering -X- _ I-MethodName
. -X- _ O

Our -X- _ O
contributions -X- _ O
are -X- _ O
three -X- _ O
- -X- _ O
fold -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
We -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
disentangled -X- _ O
knowledge -X- _ O
transfer -X- _ O
method -X- _ O
for -X- _ O
OOD -X- _ O
discovery -X- _ O
to -X- _ O
better -X- _ O
leverage -X- _ O
prior -X- _ O
IND -X- _ O
knowledge -X- _ O
. -X- _ O

Section -X- _ O
4 -X- _ O
demonstrates -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
multi -X- _ B-TaskName
- -X- _ I-TaskName
head -X- _ I-TaskName
disentanglement -X- _ I-TaskName
. -X- _ O

Besides -X- _ O
, -X- _ O
the -X- _ O
two -X- _ O
independent -X- _ O
heads -X- _ O
decouple -X- _ O
the -X- _ O
instanceand -X- _ O
cluster -X- _ O
- -X- _ O
level -X- _ O
contrastive -X- _ O
learning -X- _ O
to -X- _ O
learn -X- _ O
disentangled -X- _ O
intent -X- _ O
representations -X- _ O
for -X- _ O
better -X- _ O
knowledge -X- _ B-TaskName
transfer -X- _ I-TaskName
. -X- _ O

Using -X- _ O
the -X- _ O
unified -X- _ O
contrastive -X- _ B-HyperparameterName
objectives -X- _ I-HyperparameterName
for -X- _ O
pre -X- _ B-MethodName
- -X- _ I-MethodName
training -X- _ I-MethodName
and -X- _ O
clustering -X- _ B-MethodName
bridges -X- _ O
the -X- _ O
gap -X- _ O
between -X- _ O
the -X- _ O
two -X- _ O
stages -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
OOD -X- _ B-MethodName
clustering -X- _ O
stage -X- _ O
, -X- _ O
we -X- _ O
employ -X- _ O
similar -X- _ O
objectives -X- _ O
for -X- _ O
these -X- _ O
two -X- _ O
heads -X- _ O
where -X- _ O
fis -X- _ O
still -X- _ O
used -X- _ O
for -X- _ O
instance -X- _ O
- -X- _ O
level -X- _ O
contrastive -X- _ B-TaskName
learning -X- _ I-TaskName
and -X- _ O
gis -X- _ O
used -X- _ O
to -X- _ O
perform -X- _ O
class(cluster)-level -X- _ O
contrastive -X- _ B-TaskName
learning -X- _ I-TaskName
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
IND -X- _ B-MethodName
pre -X- _ I-MethodName
- -X- _ I-MethodName
training -X- _ I-MethodName
stage -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
head -X- _ O
fto -X- _ O
perform -X- _ O
supervised -X- _ B-MethodName
instance -X- _ I-MethodName
- -X- _ I-MethodName
level -X- _ I-MethodName
contrastive -X- _ I-MethodName
learning -X- _ I-MethodName
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Khosla -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Gunel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Zeng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
head -X- _ O
gto -X- _ O
compute -X- _ O
traditional -X- _ O
classification -X- _ B-HyperparameterName
loss -X- _ I-HyperparameterName
like -X- _ O
cross -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
entropy -X- _ I-HyperparameterName
. -X- _ O

Specifically -X- _ O
, -X- _ O
we -X- _ O
firstly -X- _ O
learn -X- _ O
intent -X- _ O
features -X- _ O
using -X- _ O
a -X- _ O
context -X- _ O
encoder -X- _ O
like -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
then -X- _ O
add -X- _ O
two -X- _ B-HyperparameterValue
independent -X- _ O
transformation -X- _ B-HyperparameterName
heads -X- _ I-HyperparameterName
( -X- _ O
instance -X- _ O
- -X- _ O
level -X- _ O
head -X- _ O
fand -X- _ O
class -X- _ O
- -X- _ O
level -X- _ O
head -X- _ O
g -X- _ O
) -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
. -X- _ O

Different -X- _ O
from -X- _ O
existing -X- _ O
OOD -X- _ B-MethodName
discovery -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
equip -X- _ O
the -X- _ O
traditional -X- _ O
IND -X- _ B-MethodName
pre -X- _ I-MethodName
- -X- _ I-MethodName
training -X- _ I-MethodName
stage -X- _ O
with -X- _ O
a -X- _ O
similar -X- _ O
contrastive -X- _ B-HyperparameterName
objective -X- _ I-HyperparameterName
as -X- _ O
the -X- _ O
clustering -X- _ O
stage -X- _ O
. -X- _ O

fied -X- _ O
contrastive -X- _ B-TaskName
learning -X- _ I-TaskName
framework -X- _ O
. -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
Fig -X- _ O
1 -X- _ O
, -X- _ O
we -X- _ O
decouple -X- _ O
the -X- _ O
pre -X- _ B-MethodName
- -X- _ I-MethodName
trained -X- _ I-MethodName
intent -X- _ O
representations -X- _ O
into -X- _ O
two -X- _ O
independent -X- _ O
subspaces -X- _ O
, -X- _ O
instance -X- _ O
- -X- _ O
level -X- _ O
and -X- _ O
class(cluster)-level -X- _ O
using -X- _ O
a -X- _ O
uni-46 -X- _ O
. -X- _ O

The -X- _ O
main -X- _ O
intuition -X- _ O
is -X- _ O
how -X- _ O
to -X- _ O
perform -X- _ O
better -X- _ O
knowledge -X- _ B-TaskName
transfer -X- _ I-TaskName
. -X- _ O

To -X- _ O
solve -X- _ O
the -X- _ O
issues -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
Disentangled -X- _ B-MethodName
Knowledge -X- _ I-MethodName
Transfer -X- _ I-MethodName
method -X- _ I-MethodName
( -X- _ I-MethodName
DKT -X- _ I-MethodName
) -X- _ I-MethodName
via -X- _ O
a -X- _ O
unified -X- _ O
multi -X- _ B-MethodName
- -X- _ I-MethodName
head -X- _ I-MethodName
contrastive -X- _ I-MethodName
learning -X- _ I-MethodName
framework -X- _ I-MethodName
to -X- _ O
transfer -X- _ O
disentangled -X- _ B-MethodName
IND -X- _ I-MethodName
intent -X- _ I-MethodName
representations -X- _ I-MethodName
to -X- _ O
OOD -X- _ B-MethodName
clustering -X- _ I-MethodName
. -X- _ O

Decoupling -X- _ B-MethodName
different -X- _ O
levels -X- _ O
of -X- _ O
intent -X- _ O
features -X- _ O
helps -X- _ O
better -X- _ O
knowledge -X- _ B-HyperparameterName
transferability -X- _ I-HyperparameterName
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
there -X- _ O
exist -X- _ O
two -X- _ O
levels -X- _ O
of -X- _ O
intent -X- _ O
features -X- _ O
, -X- _ O
instancelevel -X- _ O
and -X- _ O
class -X- _ O
- -X- _ O
level -X- _ O
knowledge -X- _ O
in -X- _ O
the -X- _ O
pre -X- _ B-MethodName
- -X- _ I-MethodName
trained -X- _ I-MethodName
IND -X- _ I-MethodName
classifier -X- _ I-MethodName
. -X- _ O

Considering -X- _ O
the -X- _ O
entanglement -X- _ B-TaskName
of -X- _ I-TaskName
the -X- _ I-TaskName
intent -X- _ I-TaskName
representation -X- _ I-TaskName
, -X- _ O
simply -X- _ O
transferring -X- _ O
IND -X- _ O
features -X- _ O
may -X- _ O
harm -X- _ O
OOD -X- _ O
clustering -X- _ O
. -X- _ O

Besides -X- _ O
, -X- _ O
previous -X- _ O
work -X- _ O
only -X- _ O
transfer -X- _ B-TaskName
a -X- _ I-TaskName
single -X- _ I-TaskName
intent -X- _ I-TaskName
representation -X- _ I-TaskName
from -X- _ O
the -X- _ O
pre -X- _ B-MethodName
- -X- _ I-MethodName
trained -X- _ I-MethodName
IND -X- _ O
classifier -X- _ O
to -X- _ O
OOD -X- _ O
clustering -X- _ B-MethodName
. -X- _ O

The -X- _ O
different -X- _ O
learning -X- _ O
objectives -X- _ O
make -X- _ O
it -X- _ O
hard -X- _ O
to -X- _ O
transfer -X- _ O
prior -X- _ O
IND -X- _ B-MethodName
knowledge -X- _ O
to -X- _ O
OOD -X- _ B-MethodName
. -X- _ O

However -X- _ O
, -X- _ O
all -X- _ O
of -X- _ O
these -X- _ O
methods -X- _ O
ignore -X- _ O
the -X- _ O
matching -X- _ O
between -X- _ O
IND -X- _ B-MethodName
pre -X- _ I-MethodName
- -X- _ I-MethodName
training -X- _ I-MethodName
stage -X- _ O
and -X- _ O
OOD -X- _ B-MethodName
clustering -X- _ I-MethodName
stage -X- _ O
because -X- _ O
they -X- _ O
formulate -X- _ O
IND -X- _ B-MethodName
pre -X- _ I-MethodName
- -X- _ I-MethodName
training -X- _ I-MethodName
as -X- _ O
the -X- _ O
classification -X- _ O
task -X- _ O
while -X- _ O
OOD -X- _ O
clustering -X- _ O
as -X- _ O
the -X- _ O
text -X- _ O
clustering -X- _ O
task -X- _ O
. -X- _ O

Further -X- _ O
, -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
proposes -X- _ O
an -X- _ O
iterative -X- _ O
clustering -X- _ O
method -X- _ O
, -X- _ O
DeepAligned -X- _ B-MethodName
, -X- _ O
to -X- _ O
obtain -X- _ O
pseudo -X- _ B-MethodName
supervised -X- _ I-MethodName
signals -X- _ I-MethodName
using -X- _ O
K -X- _ B-MethodName
- -X- _ I-MethodName
means -X- _ I-MethodName
( -X- _ O
MacQueen -X- _ O
, -X- _ O
1967 -X- _ O
) -X- _ O
. -X- _ O

intent -X- _ O
classifier -X- _ O
then -X- _ O
uses -X- _ O
intent -X- _ O
representations -X- _ O
to -X- _ O
perform -X- _ O
a -X- _ O
pairwise -X- _ B-MethodName
clustering -X- _ I-MethodName
algorithm -X- _ I-MethodName
( -X- _ O
Chang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
Lin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
firstly -X- _ O
pre -X- _ B-MethodName
- -X- _ I-MethodName
trains -X- _ I-MethodName
a -X- _ O
BERT -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
IND -X- _ O
The -X- _ O
first -X- _ O
three -X- _ O
authors -X- _ O
contribute -X- _ O
equally -X- _ O
. -X- _ O

Therefore -X- _ O
, -X- _ O
recent -X- _ O
work -X- _ O
( -X- _ O
Lin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
focus -X- _ O
more -X- _ O
on -X- _ O
the -X- _ O
semi -X- _ B-MethodName
- -X- _ I-MethodName
supervised -X- _ I-MethodName
setting -X- _ I-MethodName
where -X- _ O
they -X- _ O
firstly -X- _ O
pre -X- _ B-MethodName
- -X- _ I-MethodName
train -X- _ I-MethodName
an -X- _ O
in -X- _ O
- -X- _ O
domain -X- _ O
intent -X- _ O
classifier -X- _ O
then -X- _ O
perform -X- _ O
clustering -X- _ B-MethodName
algorithms -X- _ I-MethodName
on -X- _ O
extracted -X- _ O
OOD -X- _ O
intent -X- _ O
representations -X- _ O
by -X- _ O
the -X- _ O
pre -X- _ B-MethodName
- -X- _ I-MethodName
trained -X- _ I-MethodName
IND -X- _ I-MethodName
intent -X- _ O
classifier -X- _ O
. -X- _ O

Previous -X- _ B-MethodName
unsupervised -X- _ I-MethodName
OOD -X- _ I-MethodName
discovery -X- _ I-MethodName
models -X- _ O
( -X- _ O
Hakkani -X- _ O
- -X- _ O
Tr -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Padmasundari -X- _ O
and -X- _ O
Bangalore -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Shi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
only -X- _ O
model -X- _ O
OOD -X- _ O
data -X- _ O
but -X- _ O
ignore -X- _ O
prior -X- _ O
knowledge -X- _ O
of -X- _ O
in -X- _ O
- -X- _ O
domain -X- _ O
data -X- _ O
thus -X- _ O
suffer -X- _ O
from -X- _ O
poor -X- _ O
performance -X- _ O
. -X- _ O

Experiments -X- _ O
and -X- _ O
analysis -X- _ O
on -X- _ O
two -X- _ O
benchmark -X- _ O
datasets -X- _ O
show -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
method.1 -X- _ O
1 -X- _ O
Introduction -X- _ O
Out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
domain -X- _ O
( -X- _ O
OOD -X- _ B-MethodName
) -X- _ O
intent -X- _ O
discovery -X- _ O
aims -X- _ O
to -X- _ O
group -X- _ O
new -X- _ O
unknown -X- _ O
intents -X- _ O
into -X- _ O
different -X- _ O
clusters -X- _ O
, -X- _ O
which -X- _ O
helps -X- _ O
improve -X- _ O
the -X- _ O
dialogue -X- _ O
system -X- _ O
for -X- _ O
future -X- _ O
development -X- _ O
. -X- _ O

We -X- _ O
aim -X- _ O
to -X- _ O
bridge -X- _ O
the -X- _ O
gap -X- _ O
between -X- _ O
IND -X- _ B-TaskName
pre -X- _ I-TaskName
- -X- _ I-TaskName
training -X- _ I-TaskName
and -X- _ O
OOD -X- _ B-TaskName
clustering -X- _ I-TaskName
. -X- _ O

Different -X- _ O
from -X- _ O
existing -X- _ O
work -X- _ O
based -X- _ O
on -X- _ O
shared -X- _ O
intent -X- _ O
representation -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
disentangled -X- _ B-MethodName
knowledge -X- _ I-MethodName
transfer -X- _ I-MethodName
method -X- _ I-MethodName
via -X- _ O
a -X- _ O
unified -X- _ B-MethodName
multi -X- _ I-MethodName
- -X- _ I-MethodName
head -X- _ I-MethodName
contrastive -X- _ I-MethodName
learning -X- _ I-MethodName
framework -X- _ I-MethodName
. -X- _ O

The -X- _ O
key -X- _ O
challenge -X- _ O
is -X- _ O
how -X- _ O
to -X- _ O
transfer -X- _ O
prior -X- _ O
IND -X- _ B-TaskName
knowledge -X- _ I-TaskName
to -X- _ O
OOD -X- _ B-TaskName
clustering -X- _ I-TaskName
. -X- _ O

In -X- _ O
our -X- _ O
experience -X- _ O
, -X- _ O
a -X- _ O
key -X- _ O
challenge -X- _ O
in -X- _ O
this -X- _ O
setting -X- _ O
is -X- _ O
that -X- _ O
the -X- _ O
generated -X- _ O
text -X- _ O
can -X- _ O
be -X- _ O
unnatural -X- _ O
, -X- _ O
possibly -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
constraints -X- _ O
imposed -X- _ O
on -X- _ O
the -X- _ O
search -X- _ O
space -X- _ O
. -X- _ O

A -X- _ O
key -X- _ O
direction -X- _ O
for -X- _ O
future -X- _ O
work -X- _ O
is -X- _ O
extending -X- _ O
our -X- _ O
approach -X- _ O
to -X- _ O
settings -X- _ O
where -X- _ O
such -X- _ O
a -X- _ O
grammar -X- _ O
is -X- _ O
not -X- _ O
available -X- _ O
. -X- _ O

In -X- _ O
a -X- _ O
realistic -X- _ O
application -X- _ O
, -X- _ O
the -X- _ O
semantic -X- _ B-MethodName
parsing -X- _ I-MethodName
model -X- _ I-MethodName
can -X- _ O
be -X- _ O
trained -X- _ O
on -X- _ O
a -X- _ O
combination -X- _ O
of -X- _ O
synthetic -X- _ O
data -X- _ O
and -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
data -X- _ O
, -X- _ O
enabling -X- _ O
our -X- _ O
approach -X- _ O
to -X- _ O
be -X- _ O
used -X- _ O
in -X- _ O
conjunction -X- _ O
with -X- _ O
the -X- _ O
synthetic -X- _ O
grammar -X- _ O
. -X- _ O

A -X- _ O
key -X- _ O
design -X- _ O
choice -X- _ O
in -X- _ O
our -X- _ O
approach -X- _ O
is -X- _ O
to -X- _ O
construct -X- _ B-MethodName
a -X- _ I-MethodName
synthetic -X- _ I-MethodName
grammar -X- _ I-MethodName
from -X- _ O
which -X- _ O
counterfactual -X- _ O
explanations -X- _ O
are -X- _ O
generated -X- _ O
. -X- _ O

While -X- _ O
any -X- _ O
explanations -X- _ O
are -X- _ O
already -X- _ O
very -X- _ O
useful -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
personalizing -X- _ B-MethodName
explanations -X- _ I-MethodName
can -X- _ O
further -X- _ O
improve -X- _ O
performance -X- _ O
. -X- _ O

Our -X- _ O
experiments -X- _ O
demonstrate -X- _ O
how -X- _ O
our -X- _ O
explanations -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
to -X- _ O
significantly -X- _ O
improve -X- _ O
the -X- _ O
usability -X- _ O
of -X- _ O
semantic -X- _ B-MethodName
parsers -X- _ I-MethodName
when -X- _ O
they -X- _ O
are -X- _ O
limited -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
their -X- _ O
semantic -X- _ B-TaskName
understanding -X- _ I-TaskName
. -X- _ O

4 -X- _ O
Conclusion -X- _ O
We -X- _ O
have -X- _ O
proposed -X- _ O
a -X- _ O
technique -X- _ O
for -X- _ O
explaining -X- _ O
how -X- _ O
users -X- _ O
can -X- _ O
adapt -X- _ O
their -X- _ O
utterances -X- _ O
to -X- _ O
interact -X- _ O
with -X- _ O
a -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
interface -X- _ I-TaskName
. -X- _ O

Thus -X- _ O
, -X- _ O
personalizing -X- _ B-MethodName
the -X- _ I-MethodName
explanation -X- _ I-MethodName
to -X- _ O
the -X- _ O
user -X- _ O
based -X- _ O
on -X- _ O
their -X- _ O
utterance -X- _ O
helps -X- _ O
improve -X- _ O
performance -X- _ O
. -X- _ O

The -X- _ O
remaining -X- _ O
approaches -X- _ O
performed -X- _ O
similarly -X- _ O
; -X- _ O
our -X- _ O
explanations -X- _ O
led -X- _ O
to -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
, -X- _ O
followed -X- _ O
closely -X- _ O
by -X- _ O
the -X- _ O
ablation -X- _ B-MethodName
without -X- _ O
the -X- _ O
demonstration -X- _ O
, -X- _ O
with -X- _ O
a -X- _ O
wider -X- _ O
gap -X- _ O
to -X- _ O
the -X- _ O
ablation -X- _ B-MethodName
that -X- _ O
ignores -X- _ O
the -X- _ O
user -X- _ O
utterance -X- _ O
. -X- _ O

Users -X- _ O
not -X- _ O
provided -X- _ O
any -X- _ O
explanations -X- _ O
performed -X- _ O
very -X- _ O
poorly -X- _ O
overall -X- _ O
. -X- _ O

Table -X- _ O
1 -X- _ O
shows -X- _ O
the -X- _ O
success -X- _ O
rate -X- _ O
across -X- _ O
all -X- _ O
users -X- _ O
and -X- _ O
the -X- _ O
last -X- _ O
10 -X- _ B-HyperparameterValue
tasks -X- _ B-HyperparameterName
; -X- _ O
we -X- _ O
restrict -X- _ O
to -X- _ O
the -X- _ O
last -X- _ O
10 -X- _ O
to -X- _ O
give -X- _ O
the -X- _ O
user -X- _ O
time -X- _ O
to -X- _ O
learn -X- _ O
to -X- _ O
improve -X- _ O
their -X- _ O
performance -X- _ O
. -X- _ O

We -X- _ O
collected -X- _ O
50 -X- _ B-HyperparameterValue
user -X- _ B-HyperparameterName
responses.116 -X- _ I-HyperparameterName
. -X- _ O

We -X- _ O
run -X- _ O
an -X- _ O
AMT -X- _ B-MethodName
study -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
first -X- _ O
phase -X- _ O
of -X- _ O
our -X- _ O
study -X- _ O
in -X- _ O
Section -X- _ O
3.2 -X- _ O
, -X- _ O
except -X- _ O
immediately -X- _ O
after -X- _ O
providing -X- _ O
a -X- _ O
command -X- _ O
for -X- _ O
a -X- _ O
task -X- _ O
, -X- _ O
each -X- _ O
user -X- _ O
is -X- _ O
shown -X- _ O
an -X- _ O
explanation -X- _ O
for -X- _ O
their -X- _ O
command -X- _ O
and -X- _ O
that -X- _ O
task -X- _ O
. -X- _ O

3.3 -X- _ O
Usefulness -X- _ O
of -X- _ O
Explanations -X- _ O
Next -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
whether -X- _ O
providing -X- _ O
explanations -X- _ O
can -X- _ O
make -X- _ O
it -X- _ O
easier -X- _ O
for -X- _ O
users -X- _ O
to -X- _ O
provide -X- _ O
commands -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
understood -X- _ O
by -X- _ O
our -X- _ O
semantic -X- _ B-MethodName
parser -X- _ I-MethodName
. -X- _ O

Our -X- _ O
approach -X- _ O
also -X- _ O
outperforms -X- _ O
the -X- _ O
ablation -X- _ O
without -X- _ O
the -X- _ O
goal -X- _ O
constraint -X- _ O
, -X- _ O
demonstrating -X- _ O
the -X- _ O
usefulness -X- _ O
of -X- _ O
this -X- _ O
constraint -X- _ O
. -X- _ O

Our -X- _ O
approach -X- _ O
significantly -X- _ O
outperforms -X- _ O
GPT-2 -X- _ B-MethodName
, -X- _ O
which -X- _ O
is -X- _ O
unsurprising -X- _ O
since -X- _ O
this -X- _ O
ablation -X- _ B-MethodName
makes -X- _ O
no -X- _ O
effort -X- _ O
to -X- _ O
preserve -X- _ O
the -X- _ O
users -X- _ O
intent -X- _ O
. -X- _ O

In -X- _ O
Table -X- _ O
1 -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
the -X- _ O
fraction -X- _ O
of -X- _ O
times -X- _ O
users -X- _ O
in -X- _ O
the -X- _ O
second -X- _ O
phase -X- _ O
selected -X- _ O
each -X- _ O
explanation -X- _ O
, -X- _ O
averaged -X- _ O
across -X- _ O
both -X- _ O
users -X- _ O
and -X- _ O
tasks -X- _ O
. -X- _ O

In -X- _ O
particular -X- _ O
, -X- _ O
for -X- _ O
each -X- _ O
of -X- _ O
our -X- _ O
17 -X- _ B-HyperparameterValue
tasks -X- _ B-HyperparameterName
, -X- _ O
we -X- _ O
show -X- _ O
each -X- _ O
participant -X- _ O
a -X- _ O
single -X- _ O
command -X- _ O
for -X- _ O
that -X- _ O
task -X- _ O
( -X- _ O
chosen -X- _ O
randomly -X- _ O
from -X- _ O
the -X- _ O
127 -X- _ O
commands -X- _ O
in -X- _ O
the -X- _ O
first -X- _ O
phase -X- _ O
) -X- _ O
, -X- _ O
along -X- _ O
with -X- _ O
the -X- _ O
three -X- _ O
generated -X- _ O
explanations -X- _ O
and -X- _ O
the -X- _ O
video -X- _ O
of -X- _ O
the -X- _ O
agent -X- _ O
achieving -X- _ O
that -X- _ O
task -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
second -X- _ O
phase -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
a -X- _ O
second -X- _ O
AMT -X- _ B-MethodName
study -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
correctness -X- _ O
of -X- _ O
these -X- _ O
explanations -X- _ O
. -X- _ O

Next -X- _ O
, -X- _ O
for -X- _ O
each -X- _ O
user -X- _ O
instruction -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
the -X- _ O
counterfactual -X- _ O
explanation -X- _ O
according -X- _ O
to -X- _ O
our -X- _ O
algorithm -X- _ O
and -X- _ O
the -X- _ O
two -X- _ O
ablations -X- _ B-MethodName
described -X- _ O
above -X- _ O
. -X- _ O

For -X- _ O
each -X- _ O
of -X- _ O
our -X- _ O
17 -X- _ O
tasks -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
the -X- _ O
user -X- _ O
a -X- _ O
video -X- _ O
of -X- _ O
the -X- _ O
BabyAI -X- _ B-TaskName
agent -X- _ O
achieving -X- _ O
the -X- _ O
task -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
ask -X- _ O
them -X- _ O
to -X- _ O
provide -X- _ O
a -X- _ O
single -X- _ O
command -X- _ O
that -X- _ O
encodes -X- _ O
the -X- _ O
goal -X- _ O
. -X- _ O

Usefulness -X- _ O
: -X- _ O
The -X- _ O
percentage -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
user -X- _ I-HyperparameterName
utterances -X- _ I-HyperparameterName
correctly -X- _ O
parsed -X- _ O
( -X- _ O
averaged -X- _ O
across -X- _ O
the -X- _ O
last -X- _ O
10 -X- _ B-HyperparameterValue
tasks -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
users -X- _ O
are -X- _ O
given -X- _ O
explanations -X- _ O
generated -X- _ O
by -X- _ O
the -X- _ O
corresponding -X- _ B-MethodName
approach -X- _ I-MethodName
. -X- _ O

Then -X- _ O
, -X- _ O
our -X- _ O
experiment -X- _ O
proceeds -X- _ O
in -X- _ O
two -X- _ O
phases -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
Task -X- _ O
1 -X- _ O
has -X- _ O
the -X- _ O
simple -X- _ O
goal -X- _ O
go -X- _ O
to -X- _ O
the -X- _ O
green -X- _ O
ball -X- _ O
, -X- _ O
while -X- _ O
Task -X- _ O
10 -X- _ O
has -X- _ O
the -X- _ O
more -X- _ O
complex -X- _ O
goal -X- _ O
pick -X- _ O
up -X- _ O
a -X- _ O
green -X- _ O
key -X- _ O
, -X- _ O
then -X- _ O
put -X- _ O
the -X- _ O
yellow -X- _ O
box -X- _ O
next -X- _ O
to -X- _ O
the -X- _ O
grey -X- _ O
ball -X- _ O
. -X- _ O

We -X- _ O
selected -X- _ O
17 -X- _ O
BabyAI -X- _ B-TaskName
tasks -X- _ O
by -X- _ O
randomly -X- _ B-MethodName
sampling -X- _ I-MethodName
BabyAI -X- _ B-TaskName
levels -X- _ O
until -X- _ O
we -X- _ O
obtain -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
tasks -X- _ O
of -X- _ O
varying -X- _ O
difficulty -X- _ O
. -X- _ O

Intuitively -X- _ O
, -X- _ O
this -X- _ O
ablation -X- _ B-MetricName
measures -X- _ O
the -X- _ O
usefulness -X- _ O
of -X- _ O
specializing -X- _ O
the -X- _ O
explanation -X- _ O
to -X- _ O
the -X- _ O
users -X- _ O
utterance -X- _ O
. -X- _ O

The -X- _ O
second -X- _ O
ablation -X- _ B-MetricName
ignores -X- _ O
s0 -X- _ O
, -X- _ O
and -X- _ O
returns -X- _ O
an -X- _ O
explanation -X- _ O
ssuch -X- _ O
thatf(s)2y0 -X- _ O
; -X- _ O
we -X- _ O
choose -X- _ O
sto -X- _ O
minimize -X- _ O
perplexity -X- _ B-MetricName
according -X- _ O
to -X- _ O
GPT-2 -X- _ B-MethodName
. -X- _ O

Intuitively -X- _ O
, -X- _ O
this -X- _ O
ablation -X- _ B-MetricName
evaluates -X- _ O
the -X- _ O
usefulness -X- _ B-MetricName
of -X- _ O
the -X- _ O
goal -X- _ O
constraint -X- _ O
. -X- _ O

3.2 -X- _ O
Correctness -X- _ O
of -X- _ O
Explanations -X- _ O
We -X- _ O
evaluate -X- _ O
whether -X- _ O
our -X- _ O
explanations -X- _ O
are -X- _ O
valid -X- _ O
paraphrases -X- _ O
of -X- _ O
the -X- _ O
users -X- _ O
original -X- _ O
command -X- _ O
. -X- _ O

Handling -X- _ B-TaskName
the -X- _ I-TaskName
goal -X- _ I-TaskName
constraint -X- _ I-TaskName
is -X- _ O
more -X- _ O
challenging -X- _ O
, -X- _ O
since -X- _ O
the -X- _ O
denotation -X- _ O
can -X- _ O
be -X- _ O
nondeterministic -X- _ O
in -X- _ O
particular -X- _ O
, -X- _ O
multiple -X- _ O
different -X- _ O
trajectories -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
to -X- _ O
achieve -X- _ O
a -X- _ O
single -X- _ O
goal -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
multiple -X- _ O
paths -X- _ O
the -X- _ O
agent -X- _ O
can -X- _ O
take -X- _ O
to -X- _ O
a -X- _ O
given -X- _ O
object -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
generate -X- _ O
1000 -X- _ B-HyperparameterValue
training -X- _ B-HyperparameterName
examples -X- _ I-HyperparameterName
( -X- _ O
s;)consisting -X- _ O
of -X- _ O
an -X- _ O
utterance -X- _ O
salong -X- _ O
with -X- _ O
a -X- _ O
program -X- _ O
, -X- _ O
and -X- _ O
train -X- _ O
TranX -X- _ O
( -X- _ O
Yin -X- _ O
and -X- _ O
Neubig -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
to -X- _ O
predict=f(s -X- _ O
) -X- _ O
. -X- _ O

Since -X- _ O
utterances -X- _ O
in -X- _ O
this -X- _ O
grammar -X- _ O
correspond -X- _ O
one -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
one -X- _ O
with -X- _ O
programs -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
generate -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O

Next -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
a -X- _ O
semantic -X- _ B-MethodName
parser -X- _ I-MethodName
to -X- _ O
understand -X- _ B-TaskName
commands -X- _ I-TaskName
from -X- _ O
this -X- _ O
grammar -X- _ O
. -X- _ O

This -X- _ O
task -X- _ O
comes -X- _ O
with -X- _ O
a -X- _ O
context -X- _ O
- -X- _ O
free -X- _ O
grammar -X- _ O
of -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
commands -X- _ I-TaskName
, -X- _ O
which -X- _ O
we -X- _ O
use -X- _ O
as -X- _ O
the115 -X- _ O
. -X- _ O

In -X- _ O
our -X- _ O
setup -X- _ O
, -X- _ O
s0is -X- _ O
a -X- _ O
natural -X- _ B-HyperparameterName
language -X- _ I-HyperparameterName
command -X- _ I-HyperparameterName
, -X- _ O
and -X- _ O
y0 -X- _ O
is -X- _ O
a -X- _ O
demonstration -X- _ O
in -X- _ O
the -X- _ O
form -X- _ O
of -X- _ O
a -X- _ O
trajectory -X- _ O
the -X- _ O
agent -X- _ O
could -X- _ O
take -X- _ O
to -X- _ O
achieve -X- _ O
the -X- _ O
desired -X- _ O
goal -X- _ O
. -X- _ O

Atomic -X- _ O
commands -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
going -X- _ O
to -X- _ O
, -X- _ O
picking -X- _ O
up -X- _ O
, -X- _ O
or -X- _ O
putting -X- _ O
down -X- _ O
an -X- _ O
object -X- _ O
) -X- _ O
can -X- _ O
then -X- _ O
be -X- _ O
composed -X- _ O
in -X- _ O
sequence -X- _ O
to -X- _ O
achieve -X- _ O
complex -X- _ O
goals -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
task -X- _ O
, -X- _ O
the -X- _ O
human -X- _ O
can -X- _ O
provide -X- _ O
commands -X- _ O
to -X- _ O
an -X- _ O
agent -X- _ O
navigating -X- _ O
a -X- _ O
maze -X- _ O
of -X- _ O
rooms -X- _ O
containing -X- _ O
keys -X- _ O
, -X- _ O
boxes -X- _ O
, -X- _ O
and -X- _ O
balls -X- _ O
. -X- _ O

3.1 -X- _ O
BabyAI -X- _ B-TaskName
Task -X- _ O
We -X- _ O
evaluate -X- _ O
our -X- _ O
approach -X- _ O
on -X- _ O
BabyAI -X- _ B-TaskName
( -X- _ O
ChevalierBoisvert -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
adapted -X- _ O
to -X- _ O
our -X- _ O
setting -X- _ O
. -X- _ O

3 -X- _ O
Experiments -X- _ O
We -X- _ O
perform -X- _ O
two -X- _ O
user -X- _ O
studies -X- _ O
to -X- _ O
demonstrate -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
correctness -X- _ O
: -X- _ O
our -X- _ O
explanations -X- _ O
preserve -X- _ O
the -X- _ O
users -X- _ O
original -X- _ O
intent -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
ii -X- _ O
) -X- _ O
usefulness -X- _ O
: -X- _ O
our -X- _ O
explanations -X- _ O
improve -X- _ O
user -X- _ O
performance -X- _ O
. -X- _ O

In -X- _ O
practice -X- _ O
, -X- _ O
we -X- _ O
may -X- _ O
be -X- _ O
able -X- _ O
to -X- _ O
exploit -X- _ O
the -X- _ O
structure -X- _ O
of -X- _ O
the -X- _ O
constraint -X- _ O
to -X- _ O
prune -X- _ B-MethodName
the -X- _ I-MethodName
search -X- _ I-MethodName
space -X- _ I-MethodName
. -X- _ O

Finally -X- _ O
, -X- _ O
we -X- _ O
want -X- _ O
to -X- _ O
ensure -X- _ O
that -X- _ O
the -X- _ O
provided -X- _ O
explanation -X- _ O
successfully -X- _ O
evaluates -X- _ O
to -X- _ O
the -X- _ O
users -X- _ O
desired -X- _ O
denotation -X- _ O
y0 -X- _ O
. -X- _ O

Then -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
cosine -X- _ B-MetricName
similarity -X- _ I-MetricName
in -X- _ O
this -X- _ O
embedding -X- _ B-HyperparameterName
space -X- _ I-HyperparameterName
to -X- _ O
measure -X- _ O
semantic -X- _ B-MetricName
similarity -X- _ I-MetricName
. -X- _ O

To -X- _ O
ensure -X- _ O
that -X- _ O
our -X- _ O
explanations -X- _ O
are -X- _ O
natural -X- _ O
, -X- _ O
we -X- _ O
restrict -X- _ O
to -X- _ O
sentences -X- _ O
generated -X- _ O
by -X- _ O
a -X- _ O
context -X- _ O
- -X- _ O
free -X- _ O
grammar -X- _ O
( -X- _ O
CFG -X- _ B-MethodName
) -X- _ O
C -X- _ O
. -X- _ O

A -X- _ O
key -X- _ O
challenge -X- _ O
in -X- _ O
generating -X- _ B-TaskName
natural -X- _ I-TaskName
language -X- _ I-TaskName
expressions -X- _ I-TaskName
is -X- _ O
how -X- _ O
to -X- _ O
generate -X- _ O
expressions -X- _ O
that -X- _ O
appear -X- _ O
natural -X- _ O
to -X- _ O
the -X- _ O
human -X- _ O
user -X- _ O
. -X- _ O

The -X- _ O
goal -X- _ O
is -X- _ O
that -X- _ O
examining -X- _ O
sshould -X- _ O
help -X- _ O
the -X- _ O
user -X- _ O
provide -X- _ O
utterances -X- _ O
that -X- _ O
are -X- _ O
more -X- _ O
likely -X- _ O
to -X- _ O
be -X- _ O
correctly -X- _ O
processed -X- _ O
in -X- _ O
future -X- _ O
interactions -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
context -X- _ O
, -X- _ O
our -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
provide -X- _ O
explanations -X- _ O
to -X- _ O
the -X- _ O
user -X- _ O
to -X- _ O
help -X- _ O
them -X- _ O
understand -X- _ O
what -X- _ O
utterances -X- _ O
can -X- _ O
be -X- _ O
correctly -X- _ O
understood -X- _ O
and -X- _ O
executed -X- _ O
by -X- _ O
the -X- _ O
underlying -X- _ O
system -X- _ O
. -X- _ O

We -X- _ O
consider -X- _ O
the -X- _ O
problem -X- _ O
of -X- _ O
computing -X- _ O
counterfactual -X- _ O
explanations -X- _ O
for -X- _ O
a -X- _ O
semantic -X- _ B-MethodName
parsing -X- _ I-MethodName
model -X- _ I-MethodName
f -X- _ O
: -X- _ O
! -X- _ O
. -X- _ O

To -X- _ O
address -X- _ O
this -X- _ O
challenge -X- _ O
, -X- _ O
we -X- _ O
define -X- _ B-MethodName
a -X- _ I-MethodName
search -X- _ I-MethodName
space -X- _ I-MethodName
over -X- _ I-MethodName
counterfactual -X- _ I-MethodName
explanations -X- _ I-MethodName
for -X- _ O
semantic -X- _ B-MethodName
parsing -X- _ I-MethodName
such -X- _ O
that -X- _ O
search -X- _ O
is -X- _ O
tractable -X- _ O
. -X- _ O

In -X- _ O
contrast -X- _ O
, -X- _ O
semantic -X- _ B-MethodName
parsing -X- _ I-MethodName
has -X- _ O
highly -X- _ O
structured -X- _ O
outputs -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
programs -X- _ O
) -X- _ O
, -X- _ O
requiring -X- _ O
significantly -X- _ O
different -X- _ O
search -X- _ O
procedures -X- _ O
to -X- _ O
find -X- _ O
an -X- _ O
explanation -X- _ O
that -X- _ O
produces -X- _ O
the -X- _ O
correct -X- _ O
output -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
even -X- _ O
for -X- _ O
these -X- _ O
approaches -X- _ O
, -X- _ O
the -X- _ O
output -X- _ O
space -X- _ O
is -X- _ O
typically -X- _ O
small -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
a -X- _ O
binary -X- _ B-HyperparameterName
sentiment -X- _ I-HyperparameterName
label -X- _ I-HyperparameterName
) -X- _ O
. -X- _ O

For -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
processing -X- _ I-TaskName
tasks -X- _ I-TaskName
, -X- _ O
a -X- _ O
key -X- _ O
challenge -X- _ O
is -X- _ O
that -X- _ O
the -X- _ O
input -X- _ O
space -X- _ O
is -X- _ O
discrete -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
a -X- _ O
natural -X- _ O
language -X- _ O
utterance -X- _ O
) -X- _ O
; -X- _ O
for -X- _ O
such -X- _ O
settings -X- _ O
, -X- _ O
there -X- _ O
has -X- _ O
been -X- _ O
work -X- _ O
on -X- _ O
algorithms -X- _ O
for -X- _ O
searching -X- _ O
over -X- _ O
combinatorial -X- _ O
spaces -X- _ O
of -X- _ O
counterfactual -X- _ O
explanations -X- _ O
( -X- _ O
Ross -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021b -X- _ O
; -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Ross -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021a -X- _ O
) -X- _ O
. -X- _ O

There -X- _ O
has -X- _ O
also -X- _ O
been -X- _ O
work -X- _ O
on -X- _ O
leveraging -X- _ B-TaskName
natural -X- _ I-TaskName
language -X- _ I-TaskName
descriptions -X- _ I-TaskName
to -X- _ O
help -X- _ O
generate -X- _ B-TaskName
counterfactual -X- _ I-TaskName
explanations -X- _ I-TaskName
for -X- _ I-TaskName
image -X- _ I-TaskName
classifiers -X- _ I-TaskName
( -X- _ O
Hendricks -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
not -X- _ O
tailored -X- _ O
at -X- _ O
counterfactual -X- _ O
predictions -X- _ O
for -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
tasks -X- _ I-TaskName
; -X- _ O
specifically -X- _ O
, -X- _ O
while -X- _ O
their -X- _ O
approach -X- _ O
produces -X- _ O
counterfactual -X- _ O
explanations -X- _ O
in -X- _ O
natural -X- _ O
language -X- _ O
, -X- _ O
they -X- _ O
are -X- _ O
for -X- _ O
image -X- _ O
predictions -X- _ O
rather -X- _ O
than -X- _ O
text -X- _ O
predictions -X- _ O
. -X- _ O

There -X- _ O
has -X- _ O
been -X- _ O
interest -X- _ O
in -X- _ O
improving -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
semantic -X- _ B-MethodName
parsers -X- _ I-MethodName
through -X- _ O
interaction -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
; -X- _ O
our -X- _ O
approach -X- _ O
is -X- _ O
complementary -X- _ O
to -X- _ O
this -X- _ O
line -X- _ O
of -X- _ O
work -X- _ O
, -X- _ O
since -X- _ O
it -X- _ O
aims -X- _ O
to -X- _ O
make -X- _ O
the -X- _ O
system -X- _ O
more -X- _ O
transparent -X- _ O
to -X- _ O
the -X- _ O
user -X- _ O
. -X- _ O

In -X- _ O
contrast -X- _ O
, -X- _ O
our -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
explain -X- _ O
how -X- _ O
the -X- _ O
input -X- _ O
can -X- _ O
be -X- _ O
changed -X- _ O
to -X- _ O
achieve -X- _ O
a -X- _ O
desired -X- _ O
outcome -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
called -X- _ O
a -X- _ O
counterfactual -X- _ O
explanation -X- _ O
( -X- _ O
Wachter -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Ustun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

There -X- _ O
has -X- _ O
been -X- _ O
a -X- _ O
great -X- _ O
deal -X- _ O
of -X- _ O
recent -X- _ O
interest -X- _ O
in -X- _ O
providing -X- _ O
explanations -X- _ O
of -X- _ O
black -X- _ B-MethodName
- -X- _ I-MethodName
box -X- _ I-MethodName
machine -X- _ I-MethodName
learning -X- _ I-MethodName
models -X- _ I-MethodName
, -X- _ O
focusing -X- _ O
on -X- _ O
explaining -X- _ O
why -X- _ O
the -X- _ O
model -X- _ O
makes -X- _ O
an -X- _ O
individual -X- _ O
prediction -X- _ O
( -X- _ O
Ribeiro -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Lei -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Ribeiro -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Alvarez -X- _ O
- -X- _ O
Melis -X- _ O
and -X- _ O
Jaakkola -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
or -X- _ O
achieving -X- _ O
better -X- _ O
understanding -X- _ O
of -X- _ O
the -X- _ O
limitations -X- _ B-TaskName
of -X- _ I-TaskName
models -X- _ I-TaskName
( -X- _ O
Wallace -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Ribeiro -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
both -X- _ O
cases -X- _ O
, -X- _ O
the -X- _ O
user -X- _ O
provides -X- _ O
a -X- _ O
demonstration -X- _ O
where -X- _ O
the -X- _ O
agent -X- _ O
navigates -X- _ O
next -X- _ O
to -X- _ O
the -X- _ O
blue -X- _ O
ball -X- _ O
, -X- _ O
upon -X- _ O
which -X- _ O
our -X- _ O
approach -X- _ O
generates -X- _ O
the -X- _ O
explanation -X- _ O
shown -X- _ O
. -X- _ O

The -X- _ O
second -X- _ O
command -X- _ O
uses -X- _ O
the -X- _ O
construct -X- _ O
top -X- _ O
right -X- _ O
that -X- _ O
does -X- _ O
not -X- _ O
exist -X- _ O
in -X- _ O
the -X- _ O
language -X- _ O
. -X- _ O

The -X- _ O
first -X- _ O
command -X- _ O
corresponds -X- _ O
to -X- _ O
a -X- _ O
valid -X- _ O
program -X- _ O
, -X- _ O
but -X- _ O
can -X- _ O
not -X- _ O
be -X- _ O
understood -X- _ O
by -X- _ O
the -X- _ O
semantic -X- _ B-MethodName
parser -X- _ I-MethodName
due -X- _ O
to -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
the -X- _ O
terminology -X- _ O
circle -X- _ O
instead -X- _ O
of -X- _ O
ball -X- _ O
. -X- _ O

In -X- _ O
Figure -X- _ O
1 -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
an -X- _ O
example -X- _ O
of -X- _ O
a -X- _ O
BabyAI -X- _ B-TaskName
task -X- _ O
along -X- _ O
with -X- _ O
a -X- _ O
user -X- _ O
- -X- _ O
provided -X- _ O
utterance -X- _ O
commanding -X- _ O
the -X- _ O
agent -X- _ O
to -X- _ O
go -X- _ O
to -X- _ O
the -X- _ O
blue -X- _ O
ball -X- _ O
. -X- _ O

We -X- _ O
evaluate -X- _ O
our -X- _ O
approach -X- _ O
on -X- _ O
the -X- _ O
BabyAI -X- _ B-TaskName
environment -X- _ O
( -X- _ O
Chevalier -X- _ O
- -X- _ O
Boisvert -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
human -X- _ O
can -X- _ O
provide -X- _ O
a -X- _ O
virtual -X- _ O
agent -X- _ O
with -X- _ O
commands -X- _ O
to -X- _ O
achieve -X- _ O
complex -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
pick -X- _ O
up -X- _ O
the -X- _ O
green -X- _ O
ball -X- _ O
and -X- _ O
place -X- _ O
it -X- _ O
next -X- _ O
to -X- _ O
the -X- _ O
blue -X- _ O
box -X- _ O
. -X- _ O

Intuitively -X- _ O
, -X- _ O
this -X- _ O
explanation -X- _ O
enables -X- _ O
the -X- _ O
user -X- _ O
to -X- _ O
modify -X- _ O
their -X- _ O
language -X- _ O
to -X- _ O
reliably -X- _ O
achieve -X- _ O
their -X- _ O
goals -X- _ O
in -X- _ O
future -X- _ O
interactions -X- _ O
with -X- _ O
the -X- _ O
system -X- _ O
. -X- _ O

Then -X- _ O
, -X- _ O
we -X- _ O
compute -X- _ O
an -X- _ O
alternative -X- _ O
utterance -X- _ O
that -X- _ O
the -X- _ O
semantic -X- _ B-MethodName
parser -X- _ I-MethodName
correctly -X- _ O
processes -X- _ O
while -X- _ O
being -X- _ O
as -X- _ O
similar -X- _ O
as -X- _ O
possible -X- _ O
to -X- _ O
the -X- _ O
original -X- _ O
utterance -X- _ O
. -X- _ O

To -X- _ O
this -X- _ O
end -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
the -X- _ O
human -X- _ O
additionally -X- _ O
provide -X- _ O
the -X- _ O
desired -X- _ O
result -X- _ O
. -X- _ O

mand -X- _ O
in -X- _ O
the -X- _ O
form -X- _ O
of -X- _ O
a -X- _ O
natural -X- _ O
language -X- _ O
utterance -X- _ O
. -X- _ O

As -X- _ O
an -X- _ O
example -X- _ O
, -X- _ O
suppose -X- _ O
a -X- _ O
bank -X- _ O
is -X- _ O
using -X- _ O
a -X- _ O
machine -X- _ B-MethodName
learning -X- _ I-MethodName
model -X- _ O
to -X- _ O
help -X- _ O
decide -X- _ O
whether -X- _ O
to -X- _ O
provide -X- _ O
a -X- _ O
loan -X- _ O
to -X- _ O
an -X- _ O
individual -X- _ O
; -X- _ O
if -X- _ O
that -X- _ O
individual -X- _ O
is -X- _ O
denied -X- _ O
the -X- _ O
loan -X- _ O
, -X- _ O
then -X- _ O
the -X- _ O
bank -X- _ O
can -X- _ O
provide -X- _ O
them -X- _ O
with -X- _ O
a -X- _ O
counterfactual -X- _ O
explanation -X- _ O
describing -X- _ O
how -X- _ O
they -X- _ O
could -X- _ O
change -X- _ O
their -X- _ O
covariates -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
increase -X- _ O
their -X- _ O
income -X- _ O
) -X- _ O
to -X- _ O
qualify -X- _ O
for -X- _ O
a -X- _ O
loan -X- _ O
. -X- _ O

In -X- _ O
particular -X- _ O
, -X- _ O
given -X- _ O
a -X- _ O
prediction -X- _ O
for -X- _ O
a -X- _ O
specific -X- _ O
input -X- _ O
, -X- _ O
they -X- _ O
tell -X- _ O
the -X- _ O
user -X- _ O
how -X- _ O
they -X- _ O
could -X- _ O
have -X- _ O
minimally -X- _ O
modified -X- _ O
that -X- _ O
input -X- _ O
to -X- _ O
achieve -X- _ O
a -X- _ O
different -X- _ O
outcome -X- _ O
. -X- _ O

We -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
algorithm -X- _ O
for -X- _ O
computing -X- _ B-MethodName
counterfactual -X- _ I-MethodName
explanations -X- _ I-MethodName
for -X- _ O
semantic -X- _ O
parsers -X- _ O
. -X- _ O

These -X- _ O
explanations -X- _ O
are -X- _ O
designed -X- _ O
to -X- _ O
describe -X- _ O
alternative -X- _ O
outcomes -X- _ O
to -X- _ O
the -X- _ O
user -X- _ O
. -X- _ O

Instead -X- _ O
, -X- _ O
we -X- _ O
consider -X- _ O
an -X- _ O
alternative -X- _ O
form -X- _ O
of -X- _ O
explanation -X- _ O
called -X- _ O
a -X- _ O
counterfactual -X- _ O
explanation -X- _ O
( -X- _ O
Wachter -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
this -X- _ O
approach -X- _ O
also -X- _ O
suffers -X- _ O
from -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
showing -X- _ O
a -X- _ O
decision -X- _ B-MethodName
tree -X- _ I-MethodName
or -X- _ O
regression -X- _ B-MethodName
model -X- _ I-MethodName
is -X- _ O
likely -X- _ O
not -X- _ O
useful -X- _ O
to -X- _ O
an -X- _ O
end -X- _ O
user -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
case -X- _ O
of -X- _ O
semantic -X- _ B-TaskName
parsing -X- _ I-TaskName
, -X- _ O
such -X- _ O
models -X- _ O
may -X- _ O
achieve -X- _ O
suboptimal -X- _ O
performance -X- _ O
, -X- _ O
and -X- _ O
furthermore -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
clear -X- _ O
that -X- _ O
the -X- _ O
structure -X- _ O
of -X- _ O
these -X- _ O
models -X- _ O
would -X- _ O
be -X- _ O
useful -X- _ O
to -X- _ O
end -X- _ O
users -X- _ O
. -X- _ O

The -X- _ O
first -X- _ O
technique -X- _ O
is -X- _ O
to -X- _ O
use -X- _ O
models -X- _ O
that -X- _ O
are -X- _ O
intrinsically -X- _ O
explainable -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
linear -X- _ B-MethodName
regression -X- _ I-MethodName
or -X- _ O
decision -X- _ B-MethodName
trees -X- _ I-MethodName
. -X- _ O

Generally -X- _ O
speaking -X- _ O
, -X- _ O
a -X- _ O
range -X- _ O
of -X- _ O
techniques -X- _ O
have -X- _ O
recently -X- _ O
been -X- _ O
developed -X- _ O
for -X- _ O
explaining -X- _ B-TaskName
machine -X- _ I-TaskName
learning -X- _ I-TaskName
models -X- _ I-TaskName
. -X- _ O

Thus -X- _ O
, -X- _ O
an -X- _ O
important -X- _ O
problem -X- _ O
is -X- _ O
to -X- _ O
devise -X- _ O
techniques -X- _ O
for -X- _ O
explaining -X- _ O
these -X- _ O
models -X- _ O
. -X- _ O

One -X- _ O
approach -X- _ O
to -X- _ O
addressing -X- _ O
this -X- _ O
issue -X- _ O
is -X- _ O
to -X- _ O
develop -X- _ O
increasingly -X- _ O
powerful -X- _ O
models -X- _ O
for -X- _ O
understanding -X- _ B-TaskName
natural -X- _ I-TaskName
language -X- _ I-TaskName
( -X- _ O
Gardner -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Yin -X- _ O
and -X- _ O
Neubig -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

Thus -X- _ O
, -X- _ O
human -X- _ O
users -X- _ O
can -X- _ O
have -X- _ O
trouble -X- _ O
providing -X- _ O
complex -X- _ O
compositional -X- _ O
commands -X- _ O
in -X- _ O
the -X- _ O
form -X- _ O
of -X- _ O
natural -X- _ O
language -X- _ O
to -X- _ O
such -X- _ O
systems -X- _ O
. -X- _ O

For -X- _ O
informal -X- _ O
sentences -X- _ O
, -X- _ O
the -X- _ O
smaller -X- _ O
the -X- _ O
XLM -X- _ B-MethodName
- -X- _ I-MethodName
R -X- _ I-MethodName
score -X- _ O
is -X- _ O
better -X- _ O
, -X- _ O
higher -X- _ O
is -X- _ O
better -X- _ O
for -X- _ O
formal -X- _ O
sentences.270 -X- _ O
. -X- _ O

The -X- _ O
data -X- _ O
used -X- _ O
for -X- _ O
evaluation -X- _ O
are -X- _ O
1000 -X- _ B-HyperparameterValue
sentences -X- _ B-HyperparameterName
from -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
and -X- _ O
the -X- _ O
corresponding -X- _ O
1000 -X- _ B-HyperparameterValue
human -X- _ B-HyperparameterName
references -X- _ I-HyperparameterName
. -X- _ O

The -X- _ O
drop -X- _ O
we -X- _ O
see -X- _ O
using -X- _ O
mBART -X- _ B-MethodName
is -X- _ O
rather -X- _ O
small -X- _ O
, -X- _ O
suggesting -X- _ O
mBART -X- _ B-MethodName
is -X- _ O
a -X- _ O
viable -X- _ O
option -X- _ O
. -X- _ O

The -X- _ O
performance -X- _ O
of -X- _ O
BART -X- _ B-MethodName
and -X- _ O
English -X- _ O
data -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
as -X- _ O
a -X- _ O
sort -X- _ O
of -X- _ O
upperbound -X- _ O
, -X- _ O
as -X- _ O
these -X- _ O
are -X- _ O
best -X- _ O
conditions -X- _ O
( -X- _ O
monolingual -X- _ O
model -X- _ O
, -X- _ O
and -X- _ O
gold -X- _ O
parallel -X- _ O
data -X- _ O
) -X- _ O
. -X- _ O

Parallel -X- _ B-MethodName
data -X- _ I-MethodName
augmentation -X- _ I-MethodName
for -X- _ O
formality -X- _ O
style -X- _ O
transfer -X- _ O
. -X- _ O

The -X- _ O
adaptation -X- _ O
strategies -X- _ O
with -X- _ O
auxiliary -X- _ O
parallel -X- _ O
data -X- _ O
from -X- _ O
a -X- _ O
different -X- _ O
language -X- _ O
are -X- _ O
effective -X- _ O
, -X- _ O
yielding -X- _ O
competitive -X- _ O
results -X- _ O
and -X- _ O
outperforming -X- _ O
more -X- _ O
classic -X- _ O
IBT -X- _ O
- -X- _ O
based -X- _ O
approaches -X- _ O
without -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
parallel -X- _ O
data -X- _ O
. -X- _ O

These -X- _ O
strategies -X- _ O
target -X- _ O
language -X- _ O
and -X- _ O
task -X- _ O
adaptation -X- _ O
, -X- _ O
and -X- _ O
can -X- _ O
be -X- _ O
combined -X- _ O
to -X- _ O
adapt -X- _ O
mBART -X- _ B-MethodName
for -X- _ O
multilingual -X- _ O
formality -X- _ O
transfer -X- _ O
. -X- _ O

We -X- _ O
have -X- _ O
also -X- _ O
proposed -X- _ O
two -X- _ O
adaptation -X- _ B-MethodName
training -X- _ I-MethodName
strategies -X- _ I-MethodName
that -X- _ O
can -X- _ O
be -X- _ O
applied -X- _ O
in -X- _ O
a -X- _ O
cross -X- _ B-MethodName
- -X- _ I-MethodName
lingual -X- _ I-MethodName
transfer -X- _ I-MethodName
strategy -X- _ I-MethodName
. -X- _ O

The -X- _ O
results -X- _ O
for -X- _ O
the -X- _ O
formal -X- _ B-TaskName
- -X- _ I-TaskName
to -X- _ I-TaskName
- -X- _ I-TaskName
informal -X- _ I-TaskName
direction -X- _ O
are -X- _ O
considerably -X- _ O
worsethe -X- _ O
task -X- _ O
is -X- _ O
more -X- _ O
difficult -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
translated -X- _ O
informal -X- _ O
text -X- _ O
is -X- _ O
lower -X- _ O
. -X- _ O

6 -X- _ O
Conclusions -X- _ O
Fine -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
a -X- _ I-MethodName
pre -X- _ I-MethodName
- -X- _ I-MethodName
trained -X- _ I-MethodName
multilingual -X- _ I-MethodName
model -X- _ I-MethodName
with -X- _ O
machine -X- _ O
translated -X- _ O
training -X- _ O
data -X- _ O
yields -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
theart -X- _ O
results -X- _ O
for -X- _ O
transferring -X- _ B-TaskName
informal -X- _ I-TaskName
to -X- _ I-TaskName
formal -X- _ I-TaskName
text -X- _ I-TaskName
. -X- _ O

BLEU -X- _ B-MetricName
scores -X- _ O
of -X- _ O
F!I -X- _ O
are -X- _ O
always -X- _ O
lower -X- _ O
than -X- _ O
the -X- _ O
opposite -X- _ O
; -X- _ O
the -X- _ O
COMET -X- _ B-MetricName
score -X- _ O
of -X- _ O
INPUT -X- _ O
in -X- _ O
F -X- _ O
! -X- _ O
I -X- _ O
is -X- _ O
higher -X- _ O
than -X- _ O
I!F -X- _ O
, -X- _ O
but -X- _ O
scores -X- _ O
of -X- _ O
both -X- _ O
systems -X- _ O
for -X- _ O
F -X- _ O
! -X- _ O
I -X- _ O
drop -X- _ O
after -X- _ O
transforming -X- _ O
the -X- _ O
source -X- _ O
sentence -X- _ O
into -X- _ O
the -X- _ O
target -X- _ O
style -X- _ O
. -X- _ O

We -X- _ O
pick -X- _ O
M1.1 -X- _ O
and -X- _ O
M1.2 -X- _ O
from -X- _ O
Table -X- _ O
1 -X- _ O
since -X- _ O
they -X- _ O
are -X- _ O
both -X- _ O
fine -X- _ B-MethodName
- -X- _ I-MethodName
tuned -X- _ I-MethodName
using -X- _ I-MethodName
parallel -X- _ I-MethodName
data -X- _ I-MethodName
in -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
. -X- _ O

For -X- _ O
INPUT -X- _ O
( -X- _ O
source -X- _ O
copy -X- _ O
) -X- _ O
, -X- _ O
BLEU -X- _ B-MetricName
scores -X- _ O
are -X- _ O
almost -X- _ O
the -X- _ O
same -X- _ O
swapping -X- _ O
sources -X- _ O
and -X- _ O
references -X- _ O
but -X- _ O
COMET -X- _ B-MetricName
ones -X- _ O
are -X- _ O
not -X- _ O
, -X- _ O
probably -X- _ O
due -X- _ O
to -X- _ O
COMET -X- _ B-MetricName
being -X- _ O
trained -X- _ O
to -X- _ O
prefer -X- _ O
a -X- _ O
formal -X- _ O
/ -X- _ O
better -X- _ O
generated -X- _ O
sentence -X- _ O
; -X- _ O
compared -X- _ O
to -X- _ O
INPUT -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
gain -X- _ O
of -X- _ O
BART -X- _ B-MethodName
and -X- _ O
mBART -X- _ B-MethodName
in -X- _ O
I!F -X- _ O
is -X- _ O
larger -X- _ O
than -X- _ O
the -X- _ O
opposite -X- _ O
direction -X- _ O
on -X- _ O
both -X- _ O
metrics -X- _ O
. -X- _ O

Figure -X- _ O
2 -X- _ O
shows -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
content -X- _ O
preservation -X- _ O
. -X- _ O

We -X- _ B-MethodName
fine -X- _ I-MethodName
- -X- _ I-MethodName
tune -X- _ I-MethodName
BART -X- _ I-MethodName
( -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
mBART-50 -X- _ B-MethodName
( -X- _ O
Tang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
with -X- _ O
English -X- _ O
parallel -X- _ O
data -X- _ O
( -X- _ O
GYAFC)265 -X- _ B-DatasetName
. -X- _ O

For -X- _ O
the -X- _ O
F -X- _ O
! -X- _ O
I -X- _ O
direction -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
see -X- _ O
that -X- _ O
M1.1 -X- _ O
has -X- _ O
the -X- _ O
worst -X- _ O
performance -X- _ O
on -X- _ O
style -X- _ O
strength -X- _ O
( -X- _ O
its -X- _ O
output -X- _ O
is -X- _ O
almost -X- _ O
identical -X- _ O
to -X- _ O
the -X- _ O
source -X- _ O
) -X- _ O
, -X- _ O
while -X- _ O
M2.1 -X- _ O
, -X- _ O
M3.1 -X- _ O
and -X- _ O
M3.2 -X- _ O
generate -X- _ O
the -X- _ O
same -X- _ O
output -X- _ O
with -X- _ O
the -X- _ O
lowest -X- _ O
regression -X- _ B-MetricName
score -X- _ I-MetricName
. -X- _ O

When -X- _ O
looking -X- _ O
at -X- _ O
content -X- _ O
, -X- _ O
most -X- _ O
outputs -X- _ O
contain -X- _ O
more -X- _ O
or -X- _ O
less -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
source -X- _ O
sentence -X- _ O
; -X- _ O
Multi -X- _ B-MethodName
- -X- _ I-MethodName
Task -X- _ I-MethodName
system -X- _ I-MethodName
achieves -X- _ O
the -X- _ O
highest -X- _ O
BLEU -X- _ B-MetricName
score -X- _ O
but -X- _ O
our -X- _ O
systems -X- _ O
( -X- _ O
except -X- _ O
for -X- _ O
M3.3 -X- _ O
) -X- _ O
have -X- _ O
higher -X- _ O
COMET -X- _ B-MetricName
scores -X- _ O
, -X- _ O
with -X- _ O
M3.1 -X- _ O
achieving -X- _ O
the -X- _ O
highest -X- _ O
score -X- _ O
. -X- _ O

DLSM -X- _ B-MethodName
and -X- _ O
Rule -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
systems -X- _ I-MethodName
fail -X- _ O
to -X- _ O
transfer -X- _ B-TaskName
the -X- _ I-TaskName
formality -X- _ I-TaskName
style -X- _ I-TaskName
while -X- _ O
others -X- _ O
are -X- _ O
successful -X- _ O
to -X- _ O
some -X- _ O
extent -X- _ O
: -X- _ O
our -X- _ O
M1.1 -X- _ O
yields -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
style -X- _ O
strength -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
low -X- _ O
performance -X- _ O
on -X- _ O
style -X- _ B-MetricName
accuracy -X- _ I-MetricName
shows -X- _ O
that -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
data -X- _ O
is -X- _ O
necessary -X- _ O
, -X- _ O
even -X- _ O
if -X- _ O
it -X- _ O
comes -X- _ O
from -X- _ O
a -X- _ O
different -X- _ O
language -X- _ O
. -X- _ O

Results -X- _ O
for -X- _ O
D4show -X- _ O
that -X- _ O
language -X- _ B-TaskName
adaptationtraining -X- _ I-TaskName
helps -X- _ O
with -X- _ O
content -X- _ B-TaskName
preservation -X- _ I-TaskName
, -X- _ O
especially -X- _ O
for -X- _ O
Portuguese -X- _ O
, -X- _ O
confirming -X- _ O
this -X- _ O
curbs -X- _ O
the -X- _ O
problem -X- _ O
of -X- _ O
language -X- _ O
underrepresentation -X- _ O
in -X- _ O
pre -X- _ B-MethodName
- -X- _ I-MethodName
training -X- _ I-MethodName
. -X- _ O

Interestingly -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
task -X- _ O
adaptation -X- _ O
strategies -X- _ O
is -X- _ O
reversed -X- _ O
compared -X- _ O
to -X- _ O
D2 -X- _ O
: -X- _ O
it -X- _ O
is -X- _ O
here -X- _ O
better -X- _ O
to -X- _ O
adapt -X- _ O
cross -X- _ B-MethodName
attention -X- _ I-MethodName
in -X- _ O
the -X- _ O
English -X- _ O
model -X- _ O
rather -X- _ O
than -X- _ O
fine -X- _ B-MethodName
- -X- _ I-MethodName
tune -X- _ I-MethodName
the -X- _ O
target -X- _ O
language -X- _ B-MethodName
model -X- _ I-MethodName
directly -X- _ O
. -X- _ O

The -X- _ O
performance -X- _ O
improvement -X- _ O
on -X- _ O
Portuguese -X- _ O
is -X- _ O
particularly -X- _ O
noticeable -X- _ O
( -X- _ O
compare -X- _ O
M3.1 -X- _ O
trained -X- _ O
with -X- _ O
EN -X- _ O
data -X- _ O
only -X- _ O
with -X- _ O
other -X- _ O
M3.X -X- _ O
models -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
mostly -X- _ O
due -X- _ O
to -X- _ O
this -X- _ O
language -X- _ O
being -X- _ O
less -X- _ O
represented -X- _ O
than -X- _ O
the -X- _ O
others -X- _ O
in -X- _ O
mBART -X- _ B-MethodName
. -X- _ O

This -X- _ O
suggests -X- _ O
that -X- _ O
the -X- _ O
former -X- _ O
can -X- _ O
better -X- _ O
transfer -X- _ B-MethodName
task -X- _ I-MethodName
and -X- _ I-MethodName
domain -X- _ I-MethodName
knowledge -X- _ I-MethodName
. -X- _ O

The -X- _ O
results -X- _ O
of -X- _ O
fine -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
the -X- _ O
target -X- _ O
languages -X- _ O
model -X- _ O
with -X- _ O
English -X- _ O
parallel -X- _ O
data -X- _ O
are -X- _ O
generally -X- _ O
better -X- _ O
than -X- _ O
inserting -X- _ O
the -X- _ O
EN -X- _ O
models -X- _ O
cross -X- _ B-MethodName
- -X- _ I-MethodName
attention -X- _ I-MethodName
module -X- _ I-MethodName
into -X- _ O
the -X- _ O
target -X- _ O
languages -X- _ O
model -X- _ O
. -X- _ O

This -X- _ O
could -X- _ O
be -X- _ O
due -X- _ O
to -X- _ O
this -X- _ O
direction -X- _ O
being -X- _ O
harder -X- _ O
in -X- _ O
general -X- _ O
, -X- _ O
since -X- _ O
there -X- _ O
is -X- _ O
more -X- _ O
variation -X- _ O
in -X- _ O
informal -X- _ O
texts -X- _ O
, -X- _ O
but -X- _ O
it -X- _ O
could -X- _ O
also -X- _ O
be -X- _ O
made -X- _ O
worse -X- _ O
by -X- _ O
the -X- _ O
bad -X- _ O
quality -X- _ O
of -X- _ O
the -X- _ O
informal -X- _ O
counterpart -X- _ O
in -X- _ O
the -X- _ O
translated -X- _ O
pairs -X- _ O
. -X- _ O

The -X- _ O
F -X- _ O
! -X- _ O
I -X- _ O
results -X- _ O
, -X- _ O
instead -X- _ O
, -X- _ O
are -X- _ O
rather -X- _ O
poor -X- _ O
and -X- _ O
on -X- _ O
Italian -X- _ O
even -X- _ O
worse -X- _ O
than -X- _ O
IBT -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
models -X- _ I-MethodName
( -X- _ O
M2.1 -X- _ O
) -X- _ O
. -X- _ O

Results -X- _ O
in -X- _ O
D1show -X- _ O
that -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
mBART -X- _ B-MethodName
with -X- _ O
pseudo -X- _ O
- -X- _ O
parallel -X- _ O
data -X- _ O
yields -X- _ O
the -X- _ O
best -X- _ O
overall -X- _ O
performance -X- _ O
in -X- _ O
the -X- _ O
I!F -X- _ O
direction -X- _ O
. -X- _ O

The -X- _ O
first -X- _ O
three -X- _ O
settings -X- _ O
all -X- _ O
contain -X- _ O
gold -X- _ O
English -X- _ O
parallel -X- _ O
data -X- _ O
. -X- _ O

As -X- _ O
overall -X- _ O
score -X- _ O
, -X- _ O
following -X- _ O
previous -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
compute -X- _ O
the -X- _ O
harmonic -X- _ B-MetricName
mean -X- _ I-MetricName
( -X- _ O
HM -X- _ O
) -X- _ O
of -X- _ O
style -X- _ B-MetricName
accuracy -X- _ I-MetricName
and -X- _ O
BLEU -X- _ B-MetricName
. -X- _ O

We -X- _ O
also -X- _ O
use -X- _ O
a -X- _ O
style -X- _ B-MethodName
regressor -X- _ I-MethodName
from -X- _ O
Briakou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021a -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
XLM -X- _ B-MethodName
- -X- _ I-MethodName
R -X- _ I-MethodName
( -X- _ O
Conneau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
is -X- _ O
shown -X- _ O
to -X- _ O
correlate -X- _ O
well -X- _ O
with -X- _ O
human -X- _ O
judgments.7We -X- _ O
calculate -X- _ O
BLEU -X- _ B-MetricName
and -X- _ O
COMET -X- _ B-MetricName
( -X- _ O
Rei -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
to -X- _ O
assess -X- _ O
content -X- _ O
preservation -X- _ O
. -X- _ O

We -X- _ O
fine -X- _ B-MethodName
- -X- _ I-MethodName
tune -X- _ I-MethodName
mBERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
with -X- _ O
Briakou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021b)s -X- _ O
pseudo -X- _ O
- -X- _ O
parallel -X- _ O
corpora -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
style -X- _ B-MetricName
accuracy -X- _ I-MetricName
of -X- _ O
the -X- _ O
outputs -X- _ O
. -X- _ O

Evaluation -X- _ O
Following -X- _ O
previous -X- _ O
work -X- _ O
( -X- _ O
Luo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Sancheti -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
assess -X- _ O
style -X- _ O
strength -X- _ O
and -X- _ O
content -X- _ O
preservation -X- _ O
. -X- _ O

We -X- _ O
train -X- _ O
the -X- _ O
language -X- _ O
adaptation -X- _ O
modules -X- _ O
with -X- _ O
generic -X- _ O
texts -X- _ O
separately -X- _ O
for -X- _ O
each -X- _ O
language -X- _ O
for -X- _ O
200k -X- _ B-HyperparameterValue
training -X- _ B-HyperparameterName
steps -X- _ I-HyperparameterName
with -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
32 -X- _ B-HyperparameterValue
, -X- _ O
accumulating -X- _ O
gradients -X- _ O
over -X- _ O
8 -X- _ B-HyperparameterValue
update -X- _ B-HyperparameterName
steps -X- _ I-HyperparameterName
, -X- _ O
and -X- _ O
set -X- _ O
it -X- _ O
to -X- _ O
1 -X- _ O
for -X- _ O
other -X- _ O
training -X- _ O
. -X- _ O

We -X- _ O
train -X- _ O
the -X- _ O
model -X- _ O
using -X- _ O
the -X- _ O
Adam -X- _ B-MethodName
optimiser -X- _ O
( -X- _ O
Kingma -X- _ O
and -X- _ O
Ba -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
with -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
1e-5 -X- _ B-HyperparameterValue
for -X- _ O
all -X- _ O
experiments -X- _ O
. -X- _ O

4 -X- _ O
Experiments -X- _ O
All -X- _ O
experiments -X- _ O
are -X- _ O
implemented -X- _ O
atop -X- _ O
Transformers -X- _ B-MethodName
( -X- _ O
Wolf -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
using -X- _ O
mBART -X- _ B-MethodName
- -X- _ I-MethodName
large-50 -X- _ I-MethodName
( -X- _ O
Tang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
task -X- _ O
adaptation -X- _ O
modules -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
have -X- _ O
two -X- _ O
settings -X- _ O
: -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
the -X- _ O
module -X- _ O
is -X- _ O
from -X- _ O
the -X- _ O
English -X- _ O
model -X- _ O
( -X- _ O
X -X- _ O
+ -X- _ O
EN -X- _ O
cross -X- _ O
- -X- _ O
attn -X- _ O
) -X- _ O
; -X- _ O
( -X- _ O
ii -X- _ O
) -X- _ O
fine -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
the -X- _ O
model -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
with -X- _ O
English -X- _ O
parallel -X- _ O
data -X- _ O
( -X- _ O
X -X- _ O
+ -X- _ O
EN -X- _ O
data -X- _ O
) -X- _ O
. -X- _ O

Multilingual -X- _ B-TaskName
TST -X- _ I-TaskName
process -X- _ I-TaskName
For -X- _ O
the -X- _ O
language -X- _ B-TaskName
adaptation -X- _ I-TaskName
modules -X- _ O
we -X- _ O
have -X- _ O
two -X- _ O
settings -X- _ O
: -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
adaptation -X- _ O
modules -X- _ O
AE -X- _ O
son -X- _ O
the -X- _ O
encoder -X- _ O
come -X- _ O
from -X- _ O
the -X- _ O
model -X- _ O
trained -X- _ O
with -X- _ O
source -X- _ O
style -X- _ O
texts -X- _ O
, -X- _ O
and -X- _ O
modules -X- _ O
AD -X- _ O
ton -X- _ O
the -X- _ O
decoder -X- _ O
come -X- _ O
from -X- _ O
the -X- _ O
model -X- _ O
trained -X- _ O
with -X- _ O
target -X- _ O
style -X- _ O
texts -X- _ O
( -X- _ O
M2.X -X- _ O
, -X- _ O
Table -X- _ O
1 -X- _ O
) -X- _ O
; -X- _ O
( -X- _ O
ii -X- _ O
) -X- _ O
both -X- _ O
AE -X- _ O
andADare -X- _ O
from -X- _ O
a -X- _ O
model -X- _ O
trained -X- _ O
with -X- _ O
generic -X- _ O
texts -X- _ O
( -X- _ O
M3.X -X- _ B-DatasetName
) -X- _ O
, -X- _ O
so -X- _ O
there -X- _ O
are -X- _ O
no -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
styles -X- _ O
for -X- _ O
the -X- _ O
adaptation -X- _ O
modules -X- _ O
. -X- _ O

task -X- _ B-TaskName
adaptation -X- _ I-TaskName
module -X- _ O
) -X- _ O
while -X- _ O
the -X- _ O
other -X- _ O
parameters -X- _ O
are -X- _ O
fixed -X- _ O
, -X- _ O
thus -X- _ O
limiting -X- _ O
computational -X- _ O
cost -X- _ O
and -X- _ O
catastrophic -X- _ O
forgetting -X- _ O
. -X- _ O

Following -X- _ O
Stickland -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021b -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
only -X- _ O
update -X- _ O
the -X- _ O
parameters -X- _ O
of -X- _ O
the -X- _ O
decoders -X- _ O
crossattention -X- _ B-MethodName
( -X- _ O
i.e -X- _ O
. -X- _ O

3.2 -X- _ O
Task -X- _ O
Adaptation -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1(b -X- _ O
) -X- _ O
, -X- _ O
after -X- _ O
training -X- _ O
the -X- _ O
language -X- _ O
adaptation -X- _ O
module -X- _ O
we -X- _ O
fine -X- _ B-MethodName
- -X- _ I-MethodName
tune -X- _ I-MethodName
the -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
auxiliary -X- _ O
English -X- _ O
parallel -X- _ O
data -X- _ O
with -X- _ O
the -X- _ O
aim -X- _ O
of -X- _ O
making -X- _ O
the -X- _ O
model -X- _ O
adapt -X- _ O
to -X- _ O
the -X- _ O
specific -X- _ O
task -X- _ O
of -X- _ O
formality -X- _ B-TaskName
transfer -X- _ I-TaskName
. -X- _ O

During -X- _ O
language -X- _ O
adaptation -X- _ O
training -X- _ O
, -X- _ O
the -X- _ O
parameters -X- _ O
of -X- _ O
the -X- _ O
adaptation -X- _ O
module -X- _ O
are -X- _ O
updated -X- _ O
while -X- _ O
the -X- _ O
other -X- _ O
parameters -X- _ O
stay -X- _ O
frozen -X- _ O
. -X- _ O

Each -X- _ O
language -X- _ O
has -X- _ O
its -X- _ O
own -X- _ O
separate -X- _ O
adaptation -X- _ O
module -X- _ O
. -X- _ O

where -X- _ O
Aare -X- _ O
the -X- _ O
parameters -X- _ O
of -X- _ O
adaptation -X- _ O
module -X- _ O
A -X- _ O
, -X- _ O
Tis -X- _ O
a -X- _ O
sentence -X- _ O
in -X- _ O
target -X- _ O
language -X- _ O
and -X- _ O
gis -X- _ O
the -X- _ O
noise -X- _ O
function -X- _ O
that -X- _ O
masks -X- _ O
30% -X- _ B-HyperparameterValue
of -X- _ O
the -X- _ O
words -X- _ B-HyperparameterName
in -X- _ O
the -X- _ O
sentence -X- _ O
. -X- _ O

In -X- _ O
1(b -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
cross -X- _ B-MethodName
- -X- _ I-MethodName
attention -X- _ I-MethodName
of -X- _ O
mBART -X- _ B-MethodName
is -X- _ O
trained -X- _ O
with -X- _ O
auxiliary -X- _ O
English -X- _ O
parallel -X- _ O
data -X- _ O
to -X- _ O
adapt -X- _ O
to -X- _ O
the -X- _ O
TST -X- _ B-TaskName
task -X- _ O
. -X- _ O

In -X- _ O
1(a -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
feed -X- _ B-MethodName
- -X- _ I-MethodName
forward -X- _ I-MethodName
network -X- _ I-MethodName
of -X- _ O
each -X- _ O
transformer -X- _ O
layer -X- _ O
or -X- _ O
the -X- _ O
inserted -X- _ O
adapter -X- _ O
layer -X- _ O
is -X- _ O
trained -X- _ O
with -X- _ O
monolingual -X- _ O
data -X- _ O
to -X- _ O
adapt -X- _ O
to -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
. -X- _ O

Following -X- _ O
Bapna -X- _ O
and -X- _ O
Firat -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
ADAPT -X- _ B-MethodName
moduleAiat -X- _ O
layericonsists -X- _ O
of -X- _ O
a -X- _ O
layernormalization -X- _ B-MethodName
LN -X- _ I-MethodName
of -X- _ O
the -X- _ O
input -X- _ O
xi2Rhfollowed -X- _ O
by -X- _ O
a -X- _ O
down -X- _ O
- -X- _ O
projection -X- _ O
Wdown2Rhh -X- _ O
, -X- _ O
a -X- _ O
non -X- _ O
- -X- _ O
linearity -X- _ O
and -X- _ O
an -X- _ O
up -X- _ O
- -X- _ O
projection -X- _ O
Wup2Rhhcombined -X- _ O
with -X- _ O
a -X- _ O
residual -X- _ O
connection -X- _ O
with -X- _ O
the -X- _ O
input -X- _ O
xi -X- _ O
: -X- _ O
A(xi -X- _ O
) -X- _ O
= -X- _ O
WupRELU -X- _ B-MethodName
( -X- _ O
WdownLN(xi -X- _ O
) -X- _ O
) -X- _ O
+ -X- _ O
xi(1 -X- _ O
) -X- _ O
Language -X- _ O
adaptation -X- _ O
training -X- _ O
Following -X- _ O
mBARTs -X- _ B-MethodName
pretraining -X- _ I-MethodName
, -X- _ O
we -X- _ O
conduct -X- _ O
the -X- _ O
language -X- _ O
adaptation -X- _ O
training -X- _ O
on -X- _ O
a -X- _ O
denoising -X- _ O
task -X- _ O
, -X- _ O
which -X- _ O
aims -X- _ O
to -X- _ O
reconstruct -X- _ O
text -X- _ O
from -X- _ O
a -X- _ O
corrupted -X- _ O
version -X- _ O
: -X- _ O
L -X- _ O
A= X -X- _ O
log(Tjg(T -X- _ O
) -X- _ O
; -X- _ O
A -X- _ O
) -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
4https://webscope.sandbox.yahoo.com/ -X- _ O
catalog.php?datatype=l&did=11 -X- _ O
5Sentences -X- _ O
with -X- _ O
< 0:5are -X- _ O
considered -X- _ O
informal -X- _ O
while -X- _ O
> -X- _ O
1:0are -X- _ O
formal -X- _ O
in -X- _ O
our -X- _ O
experiments -X- _ O
. -X- _ O

Inspired -X- _ O
by -X- _ O
previous -X- _ O
work -X- _ O
( -X- _ O
Houlsby -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Bapna -X- _ O
and -X- _ O
Firat -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
an -X- _ O
adapter -X- _ B-MethodName
( -X- _ O
ADAPT -X- _ O
; -X- _ O
~50 -X- _ O
M -X- _ O
parameters -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
inserted -X- _ O
into -X- _ O
each -X- _ O
layer -X- _ O
of -X- _ O
the -X- _ O
Transformer -X- _ B-MethodName
encoder -X- _ I-MethodName
and -X- _ I-MethodName
decoder -X- _ I-MethodName
, -X- _ O
after -X- _ O
the -X- _ O
feed -X- _ B-MethodName
- -X- _ I-MethodName
forward -X- _ I-MethodName
block -X- _ I-MethodName
. -X- _ O

3.1 -X- _ O
Language -X- _ B-MethodName
Adaptation -X- _ I-MethodName
As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1(a -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
a -X- _ O
module -X- _ O
for -X- _ O
language -X- _ O
adaptation -X- _ O
. -X- _ O

Language -X- _ O
- -X- _ O
specific -X- _ O
formality -X- _ O
non -X- _ O
- -X- _ O
parallel -X- _ O
data -X- _ O
Following -X- _ O
Rao -X- _ O
and -X- _ O
Tetreault -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
and -X- _ O
Briakou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021b -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
crawl -X- _ O
the -X- _ O
domain -X- _ O
data -X- _ O
in -X- _ O
target -X- _ O
language -X- _ O
from -X- _ O
Yahoo -X- _ O
Answers.4We -X- _ O
then -X- _ O
use -X- _ O
the -X- _ O
style -X- _ B-MethodName
regressor -X- _ I-MethodName
from -X- _ O
Briakou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021a -X- _ O
) -X- _ O
to -X- _ O
predict -X- _ O
formality -X- _ O
score -X- _ O
of -X- _ O
the -X- _ O
sentence -X- _ O
to -X- _ O
automatically -X- _ O
select -X- _ O
sentences -X- _ O
in -X- _ O
each -X- _ O
style -X- _ O
direction.5 -X- _ O
Language -X- _ O
- -X- _ O
specific -X- _ O
generic -X- _ O
non -X- _ O
- -X- _ O
parallel -X- _ O
data -X- _ O
5 -X- _ B-HyperparameterValue
M -X- _ I-HyperparameterValue
sentences -X- _ B-HyperparameterName
containing -X- _ O
5 -X- _ O
to -X- _ O
30 -X- _ O
words -X- _ O
for -X- _ O
each -X- _ O
language -X- _ O
randomly -X- _ O
selected -X- _ O
from -X- _ O
News -X- _ O
Crawl.6 -X- _ O
3 -X- _ O
Adaptation -X- _ B-MethodName
Training -X- _ I-MethodName
To -X- _ O
adapt -X- _ O
mBART -X- _ B-MethodName
to -X- _ O
multilingual -X- _ B-TaskName
TST -X- _ I-TaskName
, -X- _ O
we -X- _ O
employ -X- _ O
two -X- _ O
adaptation -X- _ O
training -X- _ O
strategies -X- _ O
that -X- _ O
target -X- _ O
language -X- _ O
and -X- _ O
task -X- _ O
respectively -X- _ O
. -X- _ O

This -X- _ O
dataset -X- _ O
contains -X- _ O
pseudo -X- _ O
- -X- _ O
parallel -X- _ O
corpora -X- _ O
in -X- _ O
each -X- _ O
language -X- _ O
, -X- _ O
obtained -X- _ O
via -X- _ O
machine -X- _ O
translating -X- _ O
the -X- _ O
English -X- _ O
GYAFC -X- _ B-DatasetName
pairs -X- _ O
. -X- _ O

Multilingual -X- _ O
formality -X- _ O
data -X- _ O
XFORMAL -X- _ B-DatasetName
( -X- _ O
Briakou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021b -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
benchmark -X- _ O
for -X- _ O
multilingual -X- _ O
formality -X- _ O
transfer -X- _ O
, -X- _ O
which -X- _ O
provides -X- _ O
an -X- _ O
evaluation -X- _ O
set -X- _ O
that -X- _ O
consists -X- _ O
of -X- _ O
four -X- _ O
formal -X- _ O
rewrites -X- _ O
of -X- _ O
informal -X- _ O
sentences -X- _ O
in -X- _ O
BR -X- _ B-TaskName
- -X- _ I-TaskName
PT -X- _ I-TaskName
, -X- _ O
FR -X- _ B-TaskName
, -X- _ O
and -X- _ O
IT -X- _ B-TaskName
. -X- _ O

3The -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
monolingual -X- _ I-HyperparameterName
sentences -X- _ I-HyperparameterName
used -X- _ O
in -X- _ O
mBART50s -X- _ B-MethodName
pre -X- _ O
- -X- _ O
training -X- _ O
is -X- _ O
only -X- _ O
49,446 -X- _ B-HyperparameterValue
for -X- _ O
Portuguese -X- _ O
, -X- _ O
for -X- _ O
example -X- _ O
, -X- _ O
versus -X- _ O
36,797,950 -X- _ B-HyperparameterValue
for -X- _ O
French -X- _ O
and -X- _ O
226,457 -X- _ B-HyperparameterValue
for -X- _ O
Italian.are -X- _ O
provided -X- _ O
for -X- _ O
training -X- _ O
, -X- _ O
validation -X- _ O
, -X- _ O
and -X- _ O
test -X- _ O
. -X- _ O

English -X- _ O
formality -X- _ O
data -X- _ O
GYAFC -X- _ B-DatasetName
( -X- _ O
Rao -X- _ O
and -X- _ O
Tetreault -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
is -X- _ O
an -X- _ O
English -X- _ O
dataset -X- _ O
of -X- _ O
aligned -X- _ O
formal -X- _ O
and -X- _ O
informal -X- _ O
sentences -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
adaptation -X- _ O
strategies -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
collect -X- _ O
formality -X- _ O
and -X- _ O
generic -X- _ O
non -X- _ O
- -X- _ O
parallel -X- _ O
data -X- _ O
. -X- _ O

For -X- _ O
TST -X- _ B-MethodName
fine -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
, -X- _ O
we -X- _ O
use -X- _ O
parallel -X- _ O
training -X- _ O
data -X- _ O
, -X- _ O
namely -X- _ O
formal -X- _ O
/ -X- _ O
informal -X- _ O
aligned -X- _ O
sentences -X- _ O
( -X- _ O
both -X- _ O
manually -X- _ O
produced -X- _ O
for -X- _ O
English -X- _ O
and -X- _ O
machine -X- _ O
translated -X- _ O
for -X- _ O
three -X- _ O
other -X- _ O
languages -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
second -X- _ O
step -X- _ O
, -X- _ O
we -X- _ O
address -X- _ O
the -X- _ O
task -X- _ O
at -X- _ O
hand -X- _ O
through -X- _ O
finetuning -X- _ B-MethodName
cross -X- _ B-MethodName
- -X- _ I-MethodName
attention -X- _ I-MethodName
with -X- _ O
auxiliary -X- _ O
gold -X- _ O
parallel -X- _ O
English -X- _ O
data -X- _ O
adapting -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
the -X- _ O
TST -X- _ B-TaskName
task -X- _ I-TaskName
. -X- _ O

In -X- _ O
the -X- _ O
first -X- _ O
adaptation -X- _ O
step -X- _ O
, -X- _ O
we -X- _ O
address -X- _ O
the -X- _ O
problem -X- _ O
of -X- _ O
some -X- _ O
languages -X- _ O
being -X- _ O
not -X- _ O
well -X- _ O
represented -X- _ O
in -X- _ O
mBART -X- _ B-MethodName
, -X- _ O
which -X- _ O
preliminary -X- _ O
experiments -X- _ O
have -X- _ O
shown -X- _ O
to -X- _ O
hurt -X- _ O
our -X- _ O
downstream -X- _ O
task.3We -X- _ O
conduct -X- _ O
a -X- _ O
language -X- _ B-MethodName
adaptation -X- _ I-MethodName
denoising -X- _ I-MethodName
training -X- _ I-MethodName
using -X- _ O
unlabelled -X- _ O
data -X- _ O
for -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
. -X- _ O

We -X- _ O
still -X- _ O
run -X- _ O
comparison -X- _ O
models -X- _ O
that -X- _ O
use -X- _ O
it -X- _ O
. -X- _ O

We -X- _ O
avoid -X- _ O
iterative -X- _ B-TaskName
back -X- _ I-TaskName
- -X- _ I-TaskName
translation -X- _ I-TaskName
( -X- _ I-TaskName
IBT -X- _ I-TaskName
) -X- _ I-TaskName
( -X- _ O
Hoang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
often -X- _ O
used -X- _ O
in -X- _ O
previous -X- _ O
TST -X- _ B-TaskName
work -X- _ O
( -X- _ O
Prabhumoye -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Lample -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Yi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Lai -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021a -X- _ O
) -X- _ O
, -X- _ O
since -X- _ O
it -X- _ O
has -X- _ O
been -X- _ O
shown -X- _ O
to -X- _ O
be -X- _ O
computationally -X- _ O
costly -X- _ O
( -X- _ O
stn -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Stickland -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021a -X- _ O
) -X- _ O
. -X- _ O

Next -X- _ O
, -X- _ O
in -X- _ O
view -X- _ O
of -X- _ O
the -X- _ O
common -X- _ O
situation -X- _ O
where -X- _ O
parallel -X- _ O
data -X- _ O
for -X- _ O
a -X- _ O
target -X- _ O
language -X- _ O
is -X- _ O
not -X- _ O
available -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
two -X- _ B-MethodName
- -X- _ I-MethodName
step -X- _ I-MethodName
adaptation -X- _ I-MethodName
training -X- _ I-MethodName
approach -X- _ I-MethodName
on -X- _ O
mBART -X- _ B-MethodName
that -X- _ O
enables -X- _ O
modular -X- _ B-TaskName
multilingual -X- _ I-TaskName
TST -X- _ I-TaskName
. -X- _ O

We -X- _ O
release -X- _ O
our -X- _ O
code -X- _ O
and -X- _ O
hopefully -X- _ O
foster -X- _ O
the -X- _ O
research -X- _ O
progress.2 -X- _ O
2 -X- _ O
Approach -X- _ O
and -X- _ O
Data -X- _ O
As -X- _ O
a -X- _ O
base -X- _ O
experiment -X- _ O
aimed -X- _ O
at -X- _ O
exploring -X- _ O
the -X- _ O
contribution -X- _ O
of -X- _ O
mBART -X- _ O
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Tang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
for -X- _ O
multilingual -X- _ B-TaskName
style -X- _ I-TaskName
transfer -X- _ I-TaskName
, -X- _ O
we -X- _ O
fine -X- _ B-MethodName
- -X- _ I-MethodName
tune -X- _ I-MethodName
this -X- _ O
model -X- _ O
with -X- _ O
parallel -X- _ O
data -X- _ O
specifically -X- _ O
developed -X- _ O
for -X- _ O
style -X- _ O
transfer -X- _ O
in -X- _ O
English -X- _ O
( -X- _ O
original -X- _ O
) -X- _ O
and -X- _ O
three -X- _ O
other -X- _ O
languages -X- _ O
( -X- _ O
machine -X- _ O
translated -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
obtain -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
results -X- _ O
in -X- _ O
all -X- _ O
three -X- _ O
target -X- _ O
languages -X- _ O
, -X- _ O
and -X- _ O
propose -X- _ O
a -X- _ O
modular -X- _ O
methodology -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
applied -X- _ O
to -X- _ O
other -X- _ O
style -X- _ B-TaskName
transfer -X- _ I-TaskName
tasks -X- _ I-TaskName
as -X- _ O
well -X- _ O
as -X- _ O
to -X- _ O
other -X- _ O
languages -X- _ O
. -X- _ O

Language -X- _ O
specificities -X- _ O
are -X- _ O
addressed -X- _ O
through -X- _ O
adapter -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
strategies -X- _ I-MethodName
( -X- _ O
Pfeiffer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
stn -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
work -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
multilingual -X- _ B-MethodName
large -X- _ I-MethodName
model -X- _ I-MethodName
mBART -X- _ I-MethodName
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
to -X- _ O
model -X- _ O
style -X- _ B-TaskName
transfer -X- _ I-TaskName
in -X- _ O
a -X- _ O
multilingual -X- _ O
fashion -X- _ O
exploiting -X- _ O
available -X- _ O
parallel -X- _ O
data -X- _ O
of -X- _ O
one -X- _ O
language -X- _ O
( -X- _ O
English -X- _ O
) -X- _ O
to -X- _ O
transfer -X- _ O
the -X- _ O
task -X- _ O
and -X- _ O
domain -X- _ O
knowledge -X- _ O
to -X- _ O
other -X- _ O
target -X- _ O
languages -X- _ O
. -X- _ O

But -X- _ O
most -X- _ O
importantly -X- _ O
, -X- _ O
the -X- _ O
neural -X- _ O
models -X- _ O
developed -X- _ O
by -X- _ O
Briakou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021b -X- _ O
) -X- _ O
do -X- _ O
not -X- _ O
take -X- _ O
advantage -X- _ O
of -X- _ O
two -X- _ O
recent -X- _ O
findings -X- _ O
: -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
pre -X- _ B-MethodName
- -X- _ I-MethodName
trained -X- _ I-MethodName
models -X- _ I-MethodName
, -X- _ O
especially -X- _ O
the -X- _ O
sequence -X- _ B-MethodName
- -X- _ I-MethodName
to -X- _ I-MethodName
- -X- _ I-MethodName
sequence -X- _ I-MethodName
model -X- _ I-MethodName
BART -X- _ I-MethodName
( -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
have -X- _ O
proved -X- _ O
to -X- _ O
help -X- _ O
substantially -X- _ O
with -X- _ O
content -X- _ B-TaskName
preservation -X- _ I-TaskName
in -X- _ O
style -X- _ B-TaskName
transfer -X- _ I-TaskName
( -X- _ O
Lai -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021b -X- _ O
) -X- _ O
; -X- _ O
( -X- _ O
ii -X- _ O
) -X- _ O
Multilingual -X- _ B-TaskName
Neural -X- _ I-TaskName
Machine -X- _ I-TaskName
Translation -X- _ I-TaskName
( -X- _ O
Johnson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Aharoni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
Multilingual -X- _ B-TaskName
Text -X- _ I-TaskName
Summarization -X- _ I-TaskName
( -X- _ O
Hasan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
have -X- _ O
achieved -X- _ O
impressive -X- _ O
results -X- _ O
leveraging -X- _ O
multilingual -X- _ O
models -X- _ O
which -X- _ O
allow -X- _ O
for -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
knowledge -X- _ I-TaskName
transfer -X- _ I-TaskName
. -X- _ O

Since -X- _ O
machine -X- _ B-MethodName
translation -X- _ I-MethodName
systems -X- _ I-MethodName
are -X- _ O
usually -X- _ O
trained -X- _ O
with -X- _ O
formal -X- _ O
texts -X- _ O
like -X- _ O
news -X- _ O
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
informal -X- _ O
texts -X- _ O
are -X- _ O
harder -X- _ O
to -X- _ O
translate -X- _ O
, -X- _ O
or -X- _ O
might -X- _ O
end -X- _ O
up -X- _ O
more -X- _ O
formal -X- _ O
when -X- _ O
translated -X- _ O
. -X- _ O

One -X- _ O
reason -X- _ O
for -X- _ O
the -X- _ O
poor -X- _ O
performance -X- _ O
could -X- _ O
be -X- _ O
the -X- _ O
low -X- _ O
quality -X- _ O
( -X- _ O
observed -X- _ O
upon -X- _ O
our -X- _ O
own -X- _ O
manual -X- _ O
inspection -X- _ O
) -X- _ O
of -X- _ O
the -X- _ O
pseudo -X- _ O
- -X- _ O
parallel -X- _ O
data -X- _ O
, -X- _ O
especially -X- _ O
the -X- _ O
informal -X- _ O
side -X- _ O
. -X- _ O

Briakou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021b -X- _ O
) -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
models -X- _ O
trained -X- _ O
on -X- _ O
translated -X- _ O
parallel -X- _ O
data -X- _ O
do -X- _ O
not -X- _ O
outperform -X- _ O
a -X- _ O
simple -X- _ O
rule -X- _ O
- -X- _ O
based -X- _ O
system -X- _ O
based -X- _ O
on -X- _ O
handcrafted -X- _ O
transformations -X- _ O
, -X- _ O
especially -X- _ O
on -X- _ O
content -X- _ B-TaskName
preservation -X- _ I-TaskName
, -X- _ O
and -X- _ O
conclude -X- _ O
that -X- _ O
formality -X- _ B-TaskName
transfer -X- _ I-TaskName
on -X- _ O
languages -X- _ O
other -X- _ O
than -X- _ O
English -X- _ O
is -X- _ O
particularly -X- _ O
challenging -X- _ O
. -X- _ O

On -X- _ O
these -X- _ O
, -X- _ O
they -X- _ O
test -X- _ O
several -X- _ O
monolingual -X- _ B-TaskName
TST -X- _ I-TaskName
baseline -X- _ O
models -X- _ O
developed -X- _ O
using -X- _ O
language -X- _ B-MethodName
- -X- _ I-MethodName
specific -X- _ I-MethodName
pairs -X- _ I-MethodName
obtained -X- _ O
by -X- _ O
machine -X- _ O
translating -X- _ O
GYAFC -X- _ B-DatasetName
, -X- _ O
a -X- _ O
English -X- _ O
corpus -X- _ O
for -X- _ O
formality -X- _ B-TaskName
transfer -X- _ I-TaskName
( -X- _ O
Rao -X- _ O
and -X- _ O
Tetreault -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

For -X- _ O
these -X- _ O
languages -X- _ O
the -X- _ O
authors -X- _ O
have -X- _ O
manually -X- _ O
created -X- _ O
evaluation -X- _ O
datasets -X- _ O
. -X- _ O

Indeed -X- _ O
, -X- _ O
mostly -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
availability -X- _ O
of -X- _ O
parallel -X- _ B-MethodName
training -X- _ I-MethodName
and -X- _ O
evaluation -X- _ O
data -X- _ O
, -X- _ O
almost -X- _ O
all -X- _ O
prior -X- _ O
TST -X- _ B-TaskName
work -X- _ O
focuses -X- _ O
on -X- _ O
monolingual -X- _ O
( -X- _ O
English -X- _ O
) -X- _ O
text -X- _ O
( -X- _ O
Rao -X- _ O
and -X- _ O
Tetreault -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Prabhumoye -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Cao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020).1As -X- _ O
a -X- _ O
first -X- _ O
step -X- _ O
towards -X- _ O
multilingual -X- _ B-TaskName
style -X- _ I-TaskName
transfer -X- _ I-TaskName
, -X- _ O
Briakou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021b -X- _ O
) -X- _ O
have -X- _ O
released -X- _ O
XFORMAL -X- _ B-DatasetName
, -X- _ O
a -X- _ O
benchmark -X- _ O
1Parallel -X- _ O
data -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
refers -X- _ O
to -X- _ O
sentence -X- _ O
pairs -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
language -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
content -X- _ O
but -X- _ O
different -X- _ O
formality.of -X- _ O
multiple -X- _ O
formal -X- _ B-MethodName
reformulations -X- _ I-MethodName
of -X- _ O
informal -X- _ O
text -X- _ O
in -X- _ O
Brazilian -X- _ O
Portuguese -X- _ O
( -X- _ O
BR -X- _ O
- -X- _ O
PT -X- _ O
) -X- _ O
, -X- _ O
French -X- _ O
( -X- _ O
FR -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
Italian -X- _ O
( -X- _ O
IT -X- _ O
) -X- _ O
. -X- _ O

formality -X- _ B-TaskName
transfer -X- _ I-TaskName
, -X- _ O
because -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
recent -X- _ O
work -X- _ O
has -X- _ O
shown -X- _ O
that -X- _ O
polarity -X- _ O
swap -X- _ O
is -X- _ O
less -X- _ O
of -X- _ O
a -X- _ O
style -X- _ B-TaskName
transfer -X- _ I-TaskName
task -X- _ I-TaskName
, -X- _ O
since -X- _ O
meaning -X- _ O
is -X- _ O
altered -X- _ O
in -X- _ O
the -X- _ O
transformation -X- _ O
( -X- _ O
Lai -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021a -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
ii -X- _ O
) -X- _ O
data -X- _ O
in -X- _ O
multiple -X- _ O
languages -X- _ O
has -X- _ O
recently -X- _ O
become -X- _ O
available -X- _ O
for -X- _ O
formality -X- _ B-TaskName
transfer -X- _ I-TaskName
( -X- _ O
Briakou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021b -X- _ O
) -X- _ O
. -X- _ O

$ -X- _ O
It -X- _ O
all -X- _ O
depends -X- _ O
on -X- _ O
when -X- _ O
you -X- _ O
are -X- _ O
ready -X- _ O
. -X- _ O
) -X- _ O
are -X- _ O
considered -X- _ O
as -X- _ O
instances -X- _ O
of -X- _ O
TST -X- _ B-TaskName
. -X- _ O

Traditionally -X- _ O
, -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
swapping -X- _ B-TaskName
the -X- _ I-TaskName
polarity -X- _ I-TaskName
of -X- _ I-TaskName
a -X- _ I-TaskName
sentence -X- _ I-TaskName
( -X- _ O
e.g -X- _ O
. -X- _ O

1 -X- _ O
Introduction -X- _ O
Text -X- _ B-TaskName
style -X- _ I-TaskName
transfer -X- _ I-TaskName
( -X- _ I-TaskName
TST -X- _ I-TaskName
) -X- _ I-TaskName
is -X- _ O
a -X- _ O
text -X- _ B-TaskName
generation -X- _ I-TaskName
task -X- _ I-TaskName
where -X- _ O
a -X- _ O
given -X- _ O
sentence -X- _ O
must -X- _ O
get -X- _ O
rewritten -X- _ O
changing -X- _ O
its -X- _ O
style -X- _ O
while -X- _ O
preserving -X- _ O
its -X- _ O
meaning -X- _ O
. -X- _ O

Our -X- _ O
approach -X- _ O
achieves -X- _ O
competitive -X- _ O
performance -X- _ O
without -X- _ O
monolingual -X- _ B-TaskName
task -X- _ I-TaskName
- -X- _ O
specific -X- _ O
parallel -X- _ O
data -X- _ O
and -X- _ O
can -X- _ O
be -X- _ O
applied -X- _ O
to -X- _ O
other -X- _ O
style -X- _ B-TaskName
transfer -X- _ I-TaskName
tasks -X- _ I-TaskName
as -X- _ O
well -X- _ O
as -X- _ O
to -X- _ O
other -X- _ O
languages -X- _ O
. -X- _ O

Besides -X- _ O
, -X- _ O
in -X- _ O
view -X- _ O
of -X- _ O
the -X- _ O
general -X- _ O
scarcity -X- _ O
of -X- _ O
parallel -X- _ O
data -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
modular -X- _ O
approach -X- _ O
for -X- _ O
multilingual -X- _ B-TaskName
formality -X- _ I-TaskName
transfer -X- _ I-TaskName
, -X- _ O
which -X- _ O
consists -X- _ O
of -X- _ O
two -X- _ O
training -X- _ O
strategies -X- _ O
that -X- _ O
target -X- _ O
adaptation -X- _ O
to -X- _ O
both -X- _ O
language -X- _ O
and -X- _ O
task -X- _ O
. -X- _ O

Using -X- _ O
machine -X- _ O
translated -X- _ O
data -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
gold -X- _ O
aligned -X- _ O
English -X- _ O
sentences -X- _ O
yields -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
theart -X- _ O
results -X- _ O
in -X- _ O
the -X- _ O
three -X- _ O
target -X- _ O
languages -X- _ O
we -X- _ O
consider -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
for -X- _ O
all -X- _ O
the -X- _ O
combinations -X- _ O
we -X- _ O
tried -X- _ O
, -X- _ O
the -X- _ O
results -X- _ O
barely -X- _ O
changed -X- _ O
both -X- _ O
at -X- _ O
the -X- _ O
form -X- _ O
- -X- _ O
split -X- _ O
setting -X- _ O
and -X- _ O
the -X- _ O
lemma -X- _ B-MethodName
- -X- _ I-MethodName
split -X- _ I-MethodName
setting.202 -X- _ I-MethodName
. -X- _ O

Number -X- _ O
of -X- _ O
LSTM -X- _ B-HyperparameterName
layers -X- _ I-HyperparameterName
= -X- _ O
1 -X- _ B-HyperparameterValue
During -X- _ O
training -X- _ O
, -X- _ O
we -X- _ O
experimented -X- _ O
with -X- _ O
several -X- _ O
values -X- _ O
for -X- _ O
the -X- _ O
hyper -X- _ O
- -X- _ O
parameters -X- _ O
detailed -X- _ O
above -X- _ O
. -X- _ O

Since -X- _ O
the -X- _ O
LSTM -X- _ B-MethodName
algorithm -X- _ O
was -X- _ O
implemented -X- _ O
on -X- _ O
DyNet -X- _ B-MethodName
, -X- _ O
there -X- _ O
was -X- _ O
no -X- _ O
need -X- _ O
of -X- _ O
the -X- _ O
GPU -X- _ O
, -X- _ O
and -X- _ O
all -X- _ O
the -X- _ O
calculations -X- _ O
were -X- _ O
done -X- _ O
using -X- _ O
only -X- _ O
the -X- _ O
CPU -X- _ O
. -X- _ O

This -X- _ O
leaves -X- _ O
room -X- _ O
for -X- _ O
exploration -X- _ O
of -X- _ O
bootstrapping -X- _ B-MethodName
and -X- _ O
augmentation -X- _ B-MethodName
methods -X- _ O
or -X- _ O
more -X- _ O
sophisticated -X- _ O
modeling -X- _ O
to -X- _ O
improve -X- _ O
results -X- _ O
. -X- _ O

It -X- _ O
starts -X- _ O
improve -X- _ O
marginally -X- _ O
with -X- _ O
more -X- _ O
than -X- _ O
2,000 -X- _ B-HyperparameterValue
examples -X- _ B-HyperparameterName
, -X- _ O
although -X- _ O
its -X- _ O
performance -X- _ O
remains -X- _ O
far -X- _ O
from -X- _ O
satisfactory -X- _ O
. -X- _ O

This -X- _ O
work -X- _ O
is -X- _ O
intended -X- _ O
to -X- _ O
encourage -X- _ O
the -X- _ O
community -X- _ O
to -X- _ O
extend -X- _ O
the -X- _ O
annotation -X- _ O
of -X- _ O
different -X- _ O
languages -X- _ O
to -X- _ O
include -X- _ O
phenomena -X- _ O
such -X- _ O
as -X- _ O
polypersonal -X- _ B-TaskName
agreement -X- _ I-TaskName
and -X- _ O
others -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
dealt -X- _ O
with -X- _ O
using -X- _ O
a -X- _ O
hierarchical -X- _ B-MethodName
annotation -X- _ I-MethodName
, -X- _ O
ultimately -X- _ O
leading -X- _ O
to -X- _ O
more -X- _ O
complete -X- _ O
and -X- _ O
consistent -X- _ O
benchmarks -X- _ O
for -X- _ O
studying -X- _ O
non -X- _ O
- -X- _ O
trivial -X- _ O
and -X- _ O
less -X- _ O
- -X- _ O
explored -X- _ O
areas -X- _ O
of -X- _ O
computational -X- _ B-TaskName
morphology -X- _ I-TaskName
. -X- _ O

Our -X- _ O
experiments -X- _ O
with -X- _ O
a -X- _ O
standard -X- _ B-TaskName
reinflection -X- _ I-TaskName
model -X- _ O
on -X- _ O
the -X- _ O
old -X- _ O
and -X- _ O
new -X- _ O
Georgian -X- _ O
datasets -X- _ O
shows -X- _ O
that -X- _ O
the -X- _ O
old -X- _ O
UniMorph -X- _ B-DatasetName
dataset -X- _ O
does -X- _ O
not -X- _ O
generalize -X- _ O
well -X- _ O
to -X- _ O
the -X- _ O
new -X- _ O
testset -X- _ O
, -X- _ O
due -X- _ O
to -X- _ O
its -X- _ O
partial -X- _ O
coverage -X- _ O
. -X- _ O

We -X- _ O
apply -X- _ O
it -X- _ O
to -X- _ O
Georgian -X- _ B-DatasetName
, -X- _ O
and -X- _ O
construct -X- _ O
a -X- _ O
corresponding -X- _ O
new -X- _ O
dataset -X- _ O
that -X- _ O
is -X- _ O
large -X- _ O
, -X- _ O
balanced -X- _ O
, -X- _ O
complete -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
grammatical -X- _ O
phenomena -X- _ O
in -X- _ O
the -X- _ O
Georgian -X- _ O
verb -X- _ O
system -X- _ O
and -X- _ O
verified -X- _ O
by -X- _ O
native -X- _ O
- -X- _ O
speakers -X- _ O
. -X- _ O

This -X- _ O
revised -X- _ O
schema -X- _ O
caters -X- _ O
for -X- _ O
complex -X- _ B-TaskName
marking -X- _ I-TaskName
phenomena -X- _ I-TaskName
including -X- _ O
multiple -X- _ B-TaskName
pronominal -X- _ I-TaskName
agreement -X- _ I-TaskName
. -X- _ O

8For -X- _ O
learning -X- _ O
curves -X- _ O
on -X- _ O
the -X- _ O
splits -X- _ O
see -X- _ O
Appendix -X- _ O
A.6 -X- _ O
Conclusion -X- _ O
This -X- _ O
paper -X- _ O
proposes -X- _ O
a -X- _ O
transition -X- _ O
of -X- _ O
the -X- _ O
UniMorph -X- _ B-DatasetName
annotation -X- _ B-MethodName
standard -X- _ I-MethodName
to -X- _ O
a -X- _ O
layered -X- _ B-MethodName
hierarchical -X- _ I-MethodName
annotation -X- _ I-MethodName
of -X- _ O
features -X- _ O
. -X- _ O

Interestingly -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
managed -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
correct -X- _ O
subject -X- _ O
and -X- _ O
object -X- _ O
affixes -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
time -X- _ O
. -X- _ O

We -X- _ O
conclude -X- _ O
that -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
our -X- _ O
datasets -X- _ O
include -X- _ O
lemmas -X- _ B-HyperparameterName
from -X- _ O
diverse -X- _ O
classes -X- _ O
that -X- _ O
may -X- _ O
have -X- _ O
derivational -X- _ O
relations -X- _ O
makes -X- _ O
the -X- _ O
inflection -X- _ O
task -X- _ O
significantly -X- _ O
harder -X- _ O
. -X- _ O

change -X- _ O
of -X- _ O
voice -X- _ O
in -X- _ O
addition -X- _ O
to -X- _ O
the -X- _ O
change -X- _ O
of -X- _ O
TAM -X- _ B-MethodName
) -X- _ O
. -X- _ O

Sometimes -X- _ O
the -X- _ O
errors -X- _ O
were -X- _ O
due -X- _ O
to -X- _ O
inflection -X- _ O
to -X- _ O
an -X- _ O
incorrect -X- _ O
TAM -X- _ B-MethodName
combination -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
lexeme -X- _ O
, -X- _ O
and -X- _ O
sometimes -X- _ O
the -X- _ O
inflection -X- _ O
was -X- _ O
done -X- _ O
to -X- _ O
the -X- _ O
correct -X- _ O
TAM -X- _ B-MethodName
but -X- _ O
to -X- _ O
a -X- _ O
different -X- _ O
derivationally -X- _ O
- -X- _ O
related -X- _ O
lemma -X- _ B-HyperparameterName
( -X- _ O
e.g -X- _ O
. -X- _ O

In -X- _ O
many -X- _ O
cases -X- _ O
the -X- _ O
model -X- _ O
succeeded -X- _ O
in -X- _ O
copying -X- _ O
and -X- _ O
modifying -X- _ O
the -X- _ O
verb -X- _ O
stem -X- _ O
, -X- _ O
but -X- _ O
failed -X- _ O
to -X- _ O
output -X- _ O
the -X- _ O
other -X- _ O
morphemes -X- _ O
correctly -X- _ O
. -X- _ O

Error -X- _ O
Analysis -X- _ O
To -X- _ O
provide -X- _ O
insights -X- _ O
into -X- _ O
the -X- _ O
challenge -X- _ O
of -X- _ O
reinflecting -X- _ B-TaskName
morphologically -X- _ I-TaskName
complex -X- _ I-TaskName
forms -X- _ I-TaskName
, -X- _ O
we -X- _ O
manually -X- _ O
sampled -X- _ O
the -X- _ O
erroneous -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
trained -X- _ O
and -X- _ O
tested -X- _ O
over -X- _ O
our -X- _ O
lemmasplit -X- _ O
data -X- _ O
, -X- _ O
to -X- _ O
draw -X- _ O
insights -X- _ O
on -X- _ O
the -X- _ O
points -X- _ O
of -X- _ O
failure -X- _ O
. -X- _ O

Although -X- _ O
the -X- _ O
accuracy -X- _ B-MetricName
over -X- _ O
the -X- _ O
lemma -X- _ B-HyperparameterName
split -X- _ O
data -X- _ O
is -X- _ O
negligible -X- _ O
, -X- _ O
the -X- _ O
average -X- _ O
edit -X- _ B-MetricName
distance -X- _ I-MetricName
in -X- _ O
that -X- _ O
case -X- _ O
points -X- _ O
again -X- _ O
to -X- _ O
the -X- _ O
conclusion -X- _ O
that -X- _ O
generalization -X- _ O
from -X- _ O
UniMorph -X- _ B-DatasetName
to -X- _ O
our -X- _ O
data -X- _ O
is -X- _ O
harder -X- _ O
that -X- _ O
the -X- _ O
other -X- _ O
way -X- _ O
around -X- _ O
. -X- _ O

The -X- _ O
results -X- _ O
also -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
splitting -X- _ O
method -X- _ O
is -X- _ O
crucial -X- _ O
for -X- _ O
success -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
, -X- _ O
as -X- _ O
it -X- _ O
inflects -X- _ O
easily -X- _ O
to -X- _ O
unseen -X- _ O
forms -X- _ O
, -X- _ O
but -X- _ O
much -X- _ O
harder -X- _ O
when -X- _ O
inflecting -X- _ O
forms -X- _ O
in -X- _ O
a -X- _ O
previously -X- _ O
unseen -X- _ O
lemma.8These -X- _ B-HyperparameterName
results -X- _ O
corroborate -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
Goldman -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
regarding -X- _ O
the -X- _ O
difficulty -X- _ O
of -X- _ O
lemma -X- _ B-HyperparameterName
- -X- _ O
split -X- _ O
data -X- _ O
. -X- _ O

Generalization -X- _ B-MethodName
from -X- _ O
our -X- _ O
data -X- _ O
to -X- _ O
UniMorphs -X- _ B-DatasetName
set -X- _ O
is -X- _ O
a -X- _ O
lot -X- _ O
better -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
generalizes -X- _ O
poorly -X- _ O
from -X- _ O
the -X- _ O
original -X- _ O
partial -X- _ O
data -X- _ O
to -X- _ O
the -X- _ O
forms -X- _ O
in -X- _ O
our -X- _ O
test -X- _ O
set -X- _ O
which -X- _ O
reflect -X- _ O
the -X- _ O
entire -X- _ O
Georgian -X- _ B-TaskName
inflectional -X- _ I-TaskName
system -X- _ O
. -X- _ O

It -X- _ O
shows -X- _ O
that -X- _ O
the -X- _ O
models -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
new -X- _ O
data -X- _ O
( -X- _ O
top -X- _ O
line -X- _ O
combination -X- _ O
) -X- _ O
is -X- _ O
largely -X- _ O
on -X- _ O
par -X- _ O
comparing -X- _ O
to -X- _ O
its -X- _ O
performance -X- _ O
over -X- _ O
training -X- _ O
and -X- _ O
testing -X- _ O
on -X- _ O
UniMorphs -X- _ B-DatasetName
original -X- _ O
data -X- _ O
( -X- _ O
bottom -X- _ O
combination -X- _ O
) -X- _ O
. -X- _ O

6This -X- _ O
is -X- _ O
the -X- _ O
splitting -X- _ O
method -X- _ O
used -X- _ O
in -X- _ O
SIGMORPHONs -X- _ B-TaskName
shared -X- _ O
tasks -X- _ O
on -X- _ O
reinflection -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
Cotterell -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

To -X- _ O
assess -X- _ O
the -X- _ O
generalization -X- _ B-TaskName
capacity -X- _ O
we -X- _ O
varied -X- _ O
the -X- _ O
sources -X- _ O
of -X- _ O
both -X- _ O
the -X- _ O
train -X- _ O
and -X- _ O
test -X- _ O
sets.7 -X- _ O
We -X- _ O
report -X- _ O
2 -X- _ O
evaluation -X- _ O
metrics -X- _ O
: -X- _ O
accuracy -X- _ B-MetricName
over -X- _ O
exact -X- _ B-MetricName
matches -X- _ I-MetricName
, -X- _ O
and -X- _ O
average -X- _ B-MetricName
edit -X- _ I-MetricName
distance -X- _ I-MetricName
from -X- _ O
gold -X- _ O
. -X- _ O

Following -X- _ O
Goldman -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
one -X- _ O
dataset -X- _ O
employed -X- _ O
an -X- _ O
easier -X- _ O
formsplit -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
no -X- _ O
forms -X- _ O
appear -X- _ O
in -X- _ O
both -X- _ O
train -X- _ O
and -X- _ O
test,6 -X- _ O
and -X- _ O
the -X- _ O
other -X- _ O
with -X- _ O
the -X- _ O
more -X- _ O
challenging -X- _ O
lemmasplit -X- _ B-TaskName
, -X- _ O
where -X- _ O
lemmas -X- _ B-HyperparameterName
from -X- _ O
train -X- _ O
, -X- _ O
dev -X- _ O
and -X- _ O
test -X- _ O
are -X- _ O
disjoint -X- _ O
. -X- _ O

5 -X- _ O
Experiments -X- _ O
To -X- _ O
assess -X- _ O
the -X- _ O
usability -X- _ O
of -X- _ O
our -X- _ O
dataset -X- _ O
, -X- _ O
we -X- _ O
trained -X- _ O
a -X- _ O
standard -X- _ B-TaskName
reinflection -X- _ I-TaskName
model -X- _ O
, -X- _ O
the -X- _ O
character -X- _ O
- -X- _ O
level -X- _ O
LSTM -X- _ B-MethodName
of -X- _ O
Silfverberg -X- _ O
and -X- _ O
Hulden -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
on -X- _ O
our -X- _ O
data.5We -X- _ O
sampled -X- _ O
from -X- _ O
our -X- _ O
data -X- _ O
2 -X- _ O
datasets -X- _ O
for -X- _ O
training -X- _ O
morphological -X- _ B-TaskName
reinflection -X- _ I-TaskName
models -X- _ O
, -X- _ O
containing -X- _ O
train -X- _ O
, -X- _ O
validation -X- _ O
and -X- _ O
test -X- _ O
sets -X- _ O
in -X- _ O
sizes -X- _ O
8 -X- _ O
k -X- _ O
, -X- _ O
1k -X- _ O
and -X- _ O
1kexamples -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O

For -X- _ O
comparison -X- _ O
, -X- _ O
the -X- _ O
current -X- _ O
UniMorph -X- _ B-DatasetName
data -X- _ O
has -X- _ O
fewer -X- _ O
lemmas -X- _ B-HyperparameterName
, -X- _ O
3,300 -X- _ B-HyperparameterValue
forms -X- _ O
, -X- _ O
and -X- _ O
includes -X- _ O
only -X- _ O
verbs -X- _ O
that -X- _ O
are -X- _ O
transitive.4 -X- _ O
3We -X- _ O
based -X- _ O
the -X- _ O
list -X- _ O
of -X- _ O
verbs -X- _ O
on -X- _ O
those -X- _ O
whose -X- _ O
inflection -X- _ O
tables -X- _ O
appear -X- _ O
on -X- _ O
Hewitt -X- _ O
( -X- _ O
1995 -X- _ O
) -X- _ O
and -X- _ O
added -X- _ O
some -X- _ O
commonly -X- _ O
- -X- _ O
used -X- _ O
verbs -X- _ O
suggested -X- _ O
by -X- _ O
native -X- _ O
speakers -X- _ O
. -X- _ O

The -X- _ O
data -X- _ O
is -X- _ O
quite -X- _ O
evenly -X- _ O
balanced -X- _ O
across -X- _ O
the -X- _ O
classes -X- _ O
, -X- _ O
with -X- _ O
more -X- _ O
verbs -X- _ O
drawn -X- _ O
from -X- _ O
the -X- _ O
more -X- _ O
frequent -X- _ O
transitive -X- _ O
class -X- _ O
. -X- _ O

In -X- _ O
total -X- _ O
, -X- _ O
we -X- _ O
produced -X- _ O
21,054 -X- _ B-HyperparameterValue
verb -X- _ B-HyperparameterName
forms -X- _ I-HyperparameterName
, -X- _ O
of -X- _ O
118 -X- _ B-HyperparameterValue
lemmata -X- _ B-HyperparameterName
. -X- _ O

Table -X- _ O
3 -X- _ O
summarizes -X- _ O
the -X- _ O
statistics -X- _ O
over -X- _ O
our -X- _ O
annotated -X- _ O
data -X- _ O
. -X- _ O

On -X- _ O
average -X- _ O
, -X- _ O
at -X- _ O
least -X- _ O
one -X- _ O
speaker -X- _ O
was -X- _ O
uncertain -X- _ O
in -X- _ O
about -X- _ O
5% -X- _ B-HyperparameterValue
of -X- _ O
the -X- _ O
forms -X- _ O
, -X- _ O
but -X- _ O
a -X- _ O
disagreement -X- _ O
that -X- _ O
necessitated -X- _ O
a -X- _ O
majority -X- _ O
vote -X- _ O
occurred -X- _ O
only -X- _ O
on -X- _ O
about -X- _ O
0.7% -X- _ B-HyperparameterValue
of -X- _ O
the -X- _ O
cases -X- _ O
. -X- _ O

In -X- _ O
cases -X- _ O
where -X- _ O
speakers -X- _ O
were -X- _ O
unsure -X- _ O
we -X- _ O
used -X- _ O
a -X- _ O
Georgian -X- _ B-MethodName
morphological -X- _ I-MethodName
analyzer -X- _ I-MethodName
( -X- _ O
Doborjginidze -X- _ O
and -X- _ O
Lobzhanidze -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
for -X- _ O
consultation -X- _ O
. -X- _ O

Hence -X- _ O
, -X- _ O
we -X- _ O
ran -X- _ O
our -X- _ O
data -X- _ O
through -X- _ O
3 -X- _ O
native -X- _ O
Georgian -X- _ O
speakers -X- _ O
to -X- _ O
assert -X- _ O
its -X- _ O
correctness -X- _ O
, -X- _ O
or -X- _ O
fix -X- _ O
when -X- _ O
needed -X- _ O
. -X- _ O

This -X- _ O
automatic -X- _ B-TaskName
generation -X- _ I-TaskName
of -X- _ O
Georgian -X- _ O
verbs -X- _ O
is -X- _ O
prone -X- _ O
to -X- _ O
some -X- _ O
errors -X- _ O
, -X- _ O
for -X- _ O
instance -X- _ O
, -X- _ O
in -X- _ O
accounting -X- _ O
for -X- _ O
idiosyncratic -X- _ O
phonologically -X- _ O
- -X- _ O
conditioned -X- _ O
stem -X- _ O
changes -X- _ O
. -X- _ O

On -X- _ O
the -X- _ O
right -X- _ O
we -X- _ O
present -X- _ O
our -X- _ O
proposed -X- _ O
hierarchical -X- _ B-MethodName
structure -X- _ I-MethodName
, -X- _ O
which -X- _ O
is -X- _ O
more -X- _ O
transparent -X- _ O
, -X- _ O
and -X- _ O
also -X- _ O
ammenable -X- _ O
for -X- _ O
compositional -X- _ B-TaskName
generalization -X- _ I-TaskName
. -X- _ O

All -X- _ O
examples -X- _ O
save -X- _ O
Hebrew -X- _ O
are -X- _ O
not -X- _ O
included -X- _ O
in -X- _ O
the -X- _ O
UniMorph -X- _ B-DatasetName
inflection -X- _ O
tables -X- _ O
, -X- _ O
presumably -X- _ O
due -X- _ O
to -X- _ O
their -X- _ O
lack -X- _ O
of -X- _ O
transparency -X- _ O
. -X- _ O

On -X- _ O
the -X- _ O
left -X- _ O
we -X- _ O
present -X- _ O
the -X- _ O
flat -X- _ O
structure -X- _ O
currently -X- _ O
employed -X- _ O
in -X- _ O
UniMorph -X- _ B-DatasetName
. -X- _ O

We -X- _ O
selected -X- _ O
a -X- _ O
list -X- _ O
of -X- _ O
118 -X- _ B-HyperparameterValue
verb -X- _ B-HyperparameterName
lemmata -X- _ I-HyperparameterName
from -X- _ O
all -X- _ O
differ2Although -X- _ O
not -X- _ O
explicitly -X- _ O
shown -X- _ O
here -X- _ O
, -X- _ O
annotation -X- _ O
of -X- _ O
case -X- _ O
stacking -X- _ O
is -X- _ O
also -X- _ O
possible -X- _ O
with -X- _ O
our -X- _ O
approach -X- _ O
, -X- _ O
while -X- _ O
nonhierarchical -X- _ O
annotations -X- _ O
do -X- _ O
not -X- _ O
account -X- _ O
for -X- _ O
such -X- _ O
cases -X- _ O
. -X- _ O

Data -X- _ O
Annotation -X- _ O
A -X- _ O
key -X- _ O
contribution -X- _ O
of -X- _ O
this -X- _ O
work -X- _ O
is -X- _ O
the -X- _ O
creation -X- _ O
of -X- _ O
a -X- _ O
new -X- _ O
dataset -X- _ O
for -X- _ O
Georgian -X- _ O
that -X- _ O
follows -X- _ O
the -X- _ O
layered -X- _ O
annotation -X- _ O
schema -X- _ O
and -X- _ O
addresses -X- _ O
the -X- _ O
other -X- _ O
shortcomings -X- _ O
just -X- _ O
described -X- _ O
. -X- _ O

Additional -X- _ O
issues -X- _ O
with -X- _ O
the -X- _ O
current -X- _ O
morphological -X- _ O
data -X- _ O
in -X- _ O
UniMorph -X- _ B-DatasetName
for -X- _ O
Georgian -X- _ O
verbs -X- _ O
are -X- _ O
: -X- _ O
sparsity -X- _ O
, -X- _ O
as -X- _ O
it -X- _ O
includes -X- _ O
only -X- _ O
47 -X- _ B-HyperparameterValue
inflection -X- _ B-HyperparameterName
tables -X- _ I-HyperparameterName
; -X- _ O
lack -X- _ O
of -X- _ O
diversity -X- _ B-MetricName
, -X- _ O
as -X- _ O
all -X- _ O
table -X- _ O
are -X- _ O
from -X- _ O
the -X- _ O
transitive -X- _ O
class -X- _ O
; -X- _ O
and -X- _ O
lack -X- _ O
of -X- _ O
accuracy -X- _ B-MetricName
, -X- _ O
as -X- _ O
the -X- _ O
data -X- _ O
was -X- _ O
produced -X- _ O
automatically -X- _ O
without -X- _ O
verification -X- _ O
by -X- _ O
native -X- _ O
speakers -X- _ O
. -X- _ O

The -X- _ O
Georgian -X- _ B-DatasetName
data -X- _ O
in -X- _ O
UniMorph -X- _ B-DatasetName
follows -X- _ O
the -X- _ O
convention -X- _ O
of -X- _ O
including -X- _ O
objects -X- _ O
only -X- _ O
in -X- _ O
third -X- _ O
person -X- _ O
singular -X- _ O
thus -X- _ O
failing -X- _ O
to -X- _ O
provide -X- _ O
a -X- _ O
comprehensive -X- _ O
coverage -X- _ O
of -X- _ O
the -X- _ O
wordforms -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
attested -X- _ O
in -X- _ O
the -X- _ O
language -X- _ O
. -X- _ O

The -X- _ O
characteristic -X- _ O
most -X- _ O
essential -X- _ O
to -X- _ O
this -X- _ O
work -X- _ O
is -X- _ O
that -X- _ O
Georgian -X- _ B-DatasetName
verbs -X- _ O
always -X- _ O
agree -X- _ O
on -X- _ O
person -X- _ O
and -X- _ O
number -X- _ O
with -X- _ O
the -X- _ O
direct -X- _ O
and -X- _ O
indirect -X- _ O
objects -X- _ O
, -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
the -X- _ O
subject -X- _ O
- -X- _ O
verb -X- _ O
agreement -X- _ O
. -X- _ O

Each -X- _ O
series -X- _ O
has -X- _ O
its -X- _ O
own -X- _ O
morpho -X- _ O
- -X- _ O
syntactic -X- _ O
characteristics -X- _ O
, -X- _ O
most -X- _ O
notably -X- _ O
split -X- _ O
- -X- _ O
ergativity -X- _ O
is -X- _ O
manifested -X- _ O
in -X- _ O
the -X- _ O
aorist -X- _ O
. -X- _ O

The -X- _ O
verbs -X- _ O
are -X- _ O
inflected -X- _ O
to -X- _ O
reflect -X- _ O
12 -X- _ B-HyperparameterValue
Tense -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
AspectMood -X- _ I-HyperparameterName
( -X- _ I-HyperparameterName
TAM -X- _ I-HyperparameterName
) -X- _ I-HyperparameterName
combinations -X- _ O
( -X- _ O
traditionally -X- _ O
known -X- _ O
asscreeves -X- _ O
) -X- _ O
sorted -X- _ O
into -X- _ O
4 -X- _ B-HyperparameterValue
series -X- _ B-HyperparameterName
: -X- _ O
present -X- _ O
and -X- _ O
future -X- _ O
, -X- _ O
aorist -X- _ O
, -X- _ O
perfective -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
imperative -X- _ O
. -X- _ O

The -X- _ O
Georgian -X- _ B-MethodName
verbal -X- _ I-MethodName
paradigm -X- _ I-MethodName
is -X- _ O
divided -X- _ O
into -X- _ O
5 -X- _ B-HyperparameterValue
classes -X- _ B-HyperparameterName
known -X- _ O
as -X- _ O
: -X- _ O
transitive -X- _ O
, -X- _ O
intransitive -X- _ O
, -X- _ O
medial -X- _ O
, -X- _ O
indirect -X- _ O
and -X- _ O
stative -X- _ O
( -X- _ O
Hewitt -X- _ O
, -X- _ O
1995 -X- _ O
) -X- _ O
. -X- _ O

4 -X- _ O
A -X- _ O
Case -X- _ O
Study -X- _ O
from -X- _ O
Georgian -X- _ O
Linguistic -X- _ O
Background -X- _ O
Georgian -X- _ B-DatasetName
is -X- _ O
an -X- _ O
agglutinative -X- _ O
language -X- _ O
with -X- _ O
a -X- _ O
verbal -X- _ O
system -X- _ O
that -X- _ O
makes -X- _ O
a -X- _ O
vast -X- _ O
use -X- _ O
of -X- _ O
affixes -X- _ O
to -X- _ O
convey -X- _ O
a -X- _ O
wide -X- _ O
array -X- _ O
of -X- _ O
meanings -X- _ O
, -X- _ O
both -X- _ O
inflectional -X- _ O
and -X- _ O
derivational -X- _ O
( -X- _ O
see -X- _ O
Table -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
resemblance -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
schema -X- _ O
to -X- _ O
ideas -X- _ O
in -X- _ O
other -X- _ O
fields -X- _ O
of -X- _ O
theoretical -X- _ O
linguistics -X- _ O
, -X- _ O
most -X- _ O
prominently -X- _ O
to -X- _ O
the -X- _ O
f -X- _ O
- -X- _ O
structure -X- _ O
in -X- _ O
LFG -X- _ B-DatasetName
( -X- _ O
Bresnan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
and -X- _ O
to -X- _ O
the -X- _ O
nested -X- _ B-MethodName
Attribute -X- _ I-MethodName
- -X- _ I-MethodName
Value -X- _ I-MethodName
matrices -X- _ I-MethodName
in -X- _ O
HPSG -X- _ B-DatasetName
( -X- _ O
Pollard -X- _ O
and -X- _ O
Sag -X- _ O
, -X- _ O
1994 -X- _ O
) -X- _ O
, -X- _ O
points -X- _ O
to -X- _ O
a -X- _ O
natural -X- _ O
interface -X- _ O
with -X- _ O
further -X- _ O
syntactic -X- _ B-MethodName
and -X- _ I-MethodName
semantic -X- _ I-MethodName
annotations -X- _ I-MethodName
downstream -X- _ O
. -X- _ O

The -X- _ O
proposed -X- _ O
schema -X- _ O
thus -X- _ O
facilitates -X- _ O
the -X- _ O
annotation -X- _ O
of -X- _ O
the -X- _ O
poorly -X- _ O
- -X- _ O
treated -X- _ O
or -X- _ O
untreated -X- _ O
phenomena -X- _ O
as -X- _ O
illustrated -X- _ O
in -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
languages -X- _ O
that -X- _ O
mark -X- _ O
multiple -X- _ O
arguments -X- _ O
, -X- _ O
different -X- _ O
kinds -X- _ O
of -X- _ O
arguments -X- _ O
can -X- _ O
be -X- _ O
marked -X- _ O
with -X- _ O
their -X- _ O
feature -X- _ B-MethodName
- -X- _ I-MethodName
bundles -X- _ I-MethodName
without -X- _ O
conflicts -X- _ O
. -X- _ O

That -X- _ O
is -X- _ O
, -X- _ O
each -X- _ O
arguments -X- _ O
featurebundle -X- _ O
os -X- _ O
specifically -X- _ O
marked -X- _ O
with -X- _ O
the -X- _ O
argument -X- _ O
it -X- _ O
belongs -X- _ O
to -X- _ O
, -X- _ O
and -X- _ O
is -X- _ O
decomposed -X- _ O
into -X- _ O
the -X- _ O
primitive -X- _ O
features -X- _ O
licensed -X- _ O
by -X- _ O
the -X- _ O
UniMorph -X- _ B-DatasetName
scheme -X- _ O
. -X- _ O

Here -X- _ O
we -X- _ O
employ -X- _ O
these -X- _ O
structures -X- _ O
to -X- _ O
organize -X- _ B-MethodName
the -X- _ I-MethodName
features -X- _ I-MethodName
of -X- _ I-MethodName
morphologically -X- _ I-MethodName
- -X- _ I-MethodName
marked -X- _ I-MethodName
arguments -X- _ I-MethodName
hierarchically -X- _ I-MethodName
, -X- _ O
so -X- _ O
an -X- _ O
argument -X- _ O
is -X- _ O
characterized -X- _ O
by -X- _ O
a -X- _ O
feature -X- _ O
composite -X- _ O
of -X- _ O
all -X- _ O
features -X- _ O
pertaining -X- _ O
to -X- _ O
that -X- _ O
argument -X- _ O
. -X- _ O

That -X- _ O
is -X- _ O
, -X- _ O
a -X- _ O
general -X- _ O
feature -X- _ O
annotation -X- _ O
looks -X- _ O
as -X- _ O
in -X- _ O
( -X- _ O
2a -X- _ O
) -X- _ O
. -X- _ O

Anderson -X- _ O
suggests -X- _ O
to -X- _ O
arrange -X- _ O
the -X- _ O
morphosyntactic -X- _ O
representation -X- _ O
( -X- _ O
MSR -X- _ B-TaskName
) -X- _ O
of -X- _ O
words -X- _ O
in -X- _ O
a -X- _ O
hierarchy -X- _ O
( -X- _ O
dubbed -X- _ O
layers -X- _ O
) -X- _ O
of -X- _ O
features -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
sense -X- _ O
that -X- _ O
every -X- _ O
element -X- _ O
of -X- _ O
the -X- _ O
unordered -X- _ O
set -X- _ O
of -X- _ O
features -X- _ O
can -X- _ O
be -X- _ O
composed -X- _ O
of -X- _ O
another -X- _ O
unordered -X- _ O
set -X- _ O
of -X- _ O
features -X- _ O
. -X- _ O

3 -X- _ O
The -X- _ O
Proposed -X- _ O
Schema -X- _ O
We -X- _ O
propose -X- _ O
to -X- _ O
extend -X- _ O
the -X- _ O
UniMorph -X- _ B-DatasetName
annotation -X- _ O
schema -X- _ O
to -X- _ O
cover -X- _ O
multiple -X- _ O
pronominal -X- _ O
featurebundles -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
word -X- _ O
- -X- _ O
form -X- _ O
, -X- _ O
via -X- _ O
a -X- _ O
layering -X- _ O
approach -X- _ O
, -X- _ O
originally -X- _ O
proposed -X- _ O
for -X- _ O
morphological -X- _ B-TaskName
systems -X- _ I-TaskName
by -X- _ O
Anderson -X- _ O
( -X- _ O
1992 -X- _ O
) -X- _ O
. -X- _ O

For -X- _ O
these -X- _ O
reasons -X- _ O
, -X- _ O
we -X- _ O
set -X- _ O
out -X- _ O
to -X- _ O
extend -X- _ O
the -X- _ O
UniMorph -X- _ B-DatasetName
annotation -X- _ O
schema -X- _ O
to -X- _ O
accommodate -X- _ O
all -X- _ O
such -X- _ O
cases -X- _ O
and -X- _ O
to -X- _ O
enable -X- _ O
a -X- _ O
proper -X- _ O
coverage -X- _ O
of -X- _ O
languages -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
Georgian -X- _ B-DatasetName
and -X- _ O
many -X- _ O
others.197 -X- _ O
. -X- _ O

We -X- _ O
argue -X- _ O
that -X- _ O
the -X- _ O
lack -X- _ O
of -X- _ O
transparency -X- _ O
and -X- _ O
usability -X- _ O
are -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
misrepresentation -X- _ O
of -X- _ O
the -X- _ O
inherently -X- _ B-MethodName
hierarchical -X- _ I-MethodName
andcompositional -X- _ I-MethodName
structure -X- _ I-MethodName
of -X- _ O
the -X- _ O
features -X- _ O
in -X- _ O
such -X- _ O
forms -X- _ O
. -X- _ O

The -X- _ O
crux -X- _ O
of -X- _ O
the -X- _ O
matter -X- _ O
is -X- _ O
that -X- _ O
in -X- _ O
the -X- _ O
current -X- _ O
annotation -X- _ O
schema -X- _ O
, -X- _ O
complex -X- _ B-MethodName
features -X- _ I-MethodName
assigned -X- _ I-MethodName
to -X- _ I-MethodName
additional -X- _ I-MethodName
arguments -X- _ I-MethodName
are -X- _ O
treated -X- _ O
as -X- _ O
a -X- _ O
single -X- _ O
nondecomposable -X- _ O
feature -X- _ O
, -X- _ O
that -X- _ O
lack -X- _ O
any -X- _ O
internal -X- _ O
structure -X- _ O
, -X- _ O
unlike -X- _ O
the -X- _ O
features -X- _ O
of -X- _ O
the -X- _ O
main -X- _ O
( -X- _ O
so -X- _ O
- -X- _ O
called -X- _ O
internal -X- _ O
) -X- _ O
argument -X- _ O
, -X- _ O
that -X- _ O
are -X- _ O
individually -X- _ O
spelled -X- _ O
out -X- _ O
. -X- _ O

Secondly -X- _ O
, -X- _ O
and -X- _ O
possibly -X- _ O
due -X- _ O
to -X- _ O
this -X- _ O
lack -X- _ O
of -X- _ O
transparency -X- _ O
, -X- _ O
this -X- _ O
annotation -X- _ O
hack -X- _ O
is -X- _ O
hardly -X- _ O
ever -X- _ O
used -X- _ O
in -X- _ O
practice -X- _ O
. -X- _ O

ARGAC -X- _ O
2Sis -X- _ O
an -X- _ O
opaque -X- _ O
string -X- _ O
, -X- _ O
that -X- _ O
does -X- _ O
not -X- _ O
decompose -X- _ O
into -X- _ O
the -X- _ O
known -X- _ O
features -X- _ O
licensed -X- _ O
by -X- _ O
the -X- _ O
UniMorph -X- _ B-TaskName
features -X- _ O
list -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
ACC -X- _ O
, -X- _ O
2,SG -X- _ O
) -X- _ O
. -X- _ O

First -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
sufficiently -X- _ O
transparent -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
at -X- _ O
least -X- _ O
two -X- _ O
shortcomings -X- _ O
to -X- _ O
this -X- _ O
solution -X- _ O
. -X- _ O

Most -X- _ O
relevant -X- _ O
to -X- _ O
our -X- _ O
work -X- _ O
is -X- _ O
the -X- _ O
assumption -X- _ O
that -X- _ O
every -X- _ O
feature -X- _ O
set -X- _ O
includes -X- _ O
at -X- _ O
most -X- _ O
one -X- _ O
pronominal -X- _ O
feature -X- _ O
bundle -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
person -X- _ O
- -X- _ O
gender -X- _ O
- -X- _ O
number).However -X- _ O
, -X- _ O
this -X- _ O
assumption -X- _ O
does -X- _ O
not -X- _ O
apply -X- _ O
to -X- _ O
verbs -X- _ O
with -X- _ O
object -X- _ O
concords -X- _ O
, -X- _ O
as -X- _ O
exhibited -X- _ O
in -X- _ O
Georgian -X- _ B-DatasetName
( -X- _ O
see -X- _ O
Table -X- _ O
1 -X- _ O
) -X- _ O
, -X- _ O
Inuit -X- _ B-DatasetName
and -X- _ O
many -X- _ O
Bantu -X- _ O
languages -X- _ O
inter -X- _ O
alia -X- _ O
, -X- _ O
nor -X- _ O
does -X- _ O
it -X- _ O
apply -X- _ O
to -X- _ O
possessed -X- _ O
nouns -X- _ O
that -X- _ O
mark -X- _ O
the -X- _ O
features -X- _ O
of -X- _ O
both -X- _ O
the -X- _ O
possessor -X- _ O
and -X- _ O
the -X- _ O
possessee -X- _ O
. -X- _ O

Although -X- _ O
the -X- _ O
features -X- _ O
were -X- _ O
designed -X- _ O
to -X- _ O
apply -X- _ O
cross -X- _ O
- -X- _ O
lingually -X- _ O
, -X- _ O
some -X- _ O
blind -X- _ O
- -X- _ O
spots -X- _ O
exist -X- _ O
. -X- _ O

The -X- _ O
inflection -X- _ O
tables -X- _ O
are -X- _ O
meant -X- _ O
to -X- _ O
be -X- _ O
exhaustive -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
covering -X- _ O
all -X- _ O
possible -X- _ O
forms -X- _ O
of -X- _ O
a -X- _ O
lemma -X- _ B-HyperparameterName
, -X- _ O
regardless -X- _ O
of -X- _ O
usability -X- _ O
. -X- _ O

2 -X- _ O
The -X- _ O
Problem -X- _ O
: -X- _ O
Multiple -X- _ B-TaskName
Arguments -X- _ I-TaskName
Models -X- _ O
of -X- _ O
morphological -X- _ B-TaskName
reinfection -X- _ I-TaskName
are -X- _ O
trained -X- _ O
to -X- _ O
generate -X- _ O
forms -X- _ O
within -X- _ O
a -X- _ O
lemma -X- _ B-HyperparameterName
L -X- _ O
, -X- _ O
given -X- _ O
another -X- _ O
form -X- _ O
and -X- _ O
the -X- _ O
features -X- _ O
of -X- _ O
source -X- _ O
iand -X- _ O
target -X- _ O
jforms -X- _ O
: -X- _ O
  -X- _ O
featL -X- _ O
i -X- _ O
, -X- _ O
formL -X- _ O
i -X- _ O
, -X- _ O
featL -X- _ O
j,___ -X- _ O
7formL -X- _ O
j -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
for -X- _ O
the -X- _ O
Russian -X- _ O
lemma -X- _ O
: -X- _ O
reinflecting -X- _ O
from -X- _ O
( -X- _ O
PRS;1;S -X- _ O
G -X- _ O
, -X- _ O
) -X- _ O
to -X- _ O
( -X- _ O
IMP;2;S -X- _ O
G -X- _ O
, -X- _ O
) -X- _ O
will -X- _ O
be -X- _ O
represented -X- _ O
as:  -X- _ O
PRS;1;S -X- _ O
G,,IMP;2;S -X- _ O
G,___ -X- _ O
7 -X- _ O
Standardly -X- _ O
, -X- _ O
the -X- _ O
data -X- _ O
for -X- _ O
training -X- _ O
morphological -X- _ O
models -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Makarov -X- _ O
and -X- _ O
Clematide -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
is -X- _ O
taken -X- _ O
from -X- _ B-DatasetName
UniMorph -X- _ I-DatasetName
( -X- _ O
McCarthy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
multilingual -X- _ O
morphological -X- _ O
dataset -X- _ O
in -X- _ O
which -X- _ O
words -X- _ O
are -X- _ O
grouped -X- _ O
by -X- _ O
lemma -X- _ O
into -X- _ O
inflection -X- _ O
tables -X- _ O
, -X- _ O
each -X- _ O
word -X- _ O
is -X- _ O
tagged -X- _ O
with -X- _ O
an -X- _ O
unordered -X- _ O
set -X- _ O
of -X- _ O
morphological -X- _ O
features -X- _ O
. -X- _ O

We -X- _ O
therefore -X- _ O
call -X- _ O
to -X- _ O
apply -X- _ O
layered -X- _ O
annotation -X- _ O
to -X- _ O
all -X- _ O
currently -X- _ O
existing -X- _ O
morphological -X- _ O
data -X- _ O
in -X- _ O
UniMorph -X- _ B-DatasetName
, -X- _ O
to -X- _ O
more -X- _ O
consistently -X- _ O
and -X- _ O
transparently -X- _ O
capture -X- _ O
the -X- _ O
linguistic -X- _ O
reality -X- _ O
and -X- _ O
morphological -X- _ O
complexity -X- _ O
reflected -X- _ O
in -X- _ O
the -X- _ O
worlds -X- _ O
languages -X- _ O
. -X- _ O

We -X- _ O
conclude -X- _ O
that -X- _ O
our -X- _ O
annotation -X- _ O
approach -X- _ O
provides -X- _ O
a -X- _ O
more -X- _ O
complete -X- _ O
representation -X- _ O
of -X- _ O
linguistic -X- _ O
behaviors -X- _ O
, -X- _ O
and -X- _ O
that -X- _ O
our -X- _ O
proposed -X- _ O
Georgian -X- _ B-DatasetName
dataset -X- _ O
provides -X- _ O
a -X- _ O
much -X- _ O
better -X- _ O
depiction -X- _ O
of -X- _ O
the -X- _ O
morphological -X- _ O
phenomena -X- _ O
that -X- _ O
exist -X- _ O
in -X- _ O
the -X- _ O
data -X- _ O
and -X- _ O
the -X- _ O
computational -X- _ O
challenge -X- _ O
reflected -X- _ O
therein -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
new -X- _ O
dataset -X- _ O
to -X- _ O
train -X- _ O
a -X- _ O
standard -X- _ B-TaskName
morphological -X- _ I-TaskName
reinflection -X- _ I-TaskName
model -X- _ O
( -X- _ O
Silfverberg -X- _ O
and -X- _ O
Hulden -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
and -X- _ O
show -X- _ O
that -X- _ O
training -X- _ O
on -X- _ O
the -X- _ O
Georgian -X- _ B-TaskName
inflections -X- _ I-TaskName
currently -X- _ O
available -X- _ O
in -X- _ O
UniMorph -X- _ B-DatasetName
is -X- _ O
not -X- _ O
sufficient -X- _ O
for -X- _ O
generalizing -X- _ O
to -X- _ O
the -X- _ O
more -X- _ O
inclusive -X- _ O
set -X- _ O
of -X- _ O
inflections -X- _ O
that -X- _ O
are -X- _ O
allowed -X- _ O
by -X- _ O
the -X- _ O
new -X- _ O
scheme -X- _ O
. -X- _ O

We -X- _ O
create -X- _ O
a -X- _ O
new -X- _ O
human -X- _ O
- -X- _ O
verified -X- _ O
dataset -X- _ O
for -X- _ O
Georgian -X- _ O
, -X- _ O
that -X- _ O
covers -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
grammatical -X- _ O
phenomena -X- _ O
in -X- _ O
Georgian -X- _ O
verbs -X- _ O
, -X- _ O
and -X- _ O
includes -X- _ O
118 -X- _ B-HyperparameterValue
lemmas -X- _ B-HyperparameterName
, -X- _ O
adding -X- _ O
up -X- _ O
to -X- _ O
about -X- _ O
21kverb -X- _ B-HyperparameterValue
forms -X- _ B-HyperparameterName
, -X- _ O
compared -X- _ O
with -X- _ O
the -X- _ O
47 -X- _ B-HyperparameterValue
lemmas -X- _ B-HyperparameterName
and -X- _ O
3.3kverb -X- _ B-HyperparameterValue
forms -X- _ B-MethodName
, -X- _ O
some -X- _ O
of -X- _ O
which -X- _ O
are -X- _ O
erroneous -X- _ O
, -X- _ O
currently -X- _ O
available -X- _ O
in -X- _ O
the -X- _ O
Georgian -X- _ B-DatasetName
UniMorph.196 -X- _ I-DatasetName
. -X- _ O

We -X- _ O
apply -X- _ O
the -X- _ O
suggested -X- _ O
solution -X- _ O
to -X- _ O
Georgian -X- _ O
, -X- _ O
an -X- _ O
agglutinative -X- _ O
language -X- _ O
with -X- _ O
a -X- _ O
convoluted -X- _ B-MethodName
verbal -X- _ I-MethodName
system -X- _ I-MethodName
, -X- _ O
that -X- _ O
indicates -X- _ O
both -X- _ O
subjects -X- _ O
and -X- _ O
objects -X- _ O
with -X- _ O
true -X- _ O
affixes -X- _ O
( -X- _ O
rather -X- _ O
than -X- _ O
clitics -X- _ O
that -X- _ O
are -X- _ O
omittable -X- _ O
from -X- _ O
the -X- _ O
inflection -X- _ O
tables -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
organize -X- _ O
the -X- _ O
features -X- _ O
of -X- _ O
multiple -X- _ O
arguments -X- _ O
in -X- _ O
a -X- _ O
hierarchical -X- _ O
structure -X- _ O
, -X- _ O
rather -X- _ O
than -X- _ O
the -X- _ O
current -X- _ O
flat -X- _ O
structure -X- _ O
that -X- _ O
accommodates -X- _ O
only -X- _ O
subject -X- _ O
concords -X- _ O
. -X- _ O

Following -X- _ O
Anderson -X- _ O
( -X- _ O
1992 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
so -X- _ O
- -X- _ O
called -X- _ O
layered -X- _ B-MethodName
annotation -X- _ I-MethodName
of -X- _ I-MethodName
features -X- _ I-MethodName
, -X- _ O
where -X- _ O
the -X- _ O
inflectional -X- _ O
features -X- _ O
take -X- _ O
the -X- _ O
form -X- _ O
of -X- _ O
ahierarchical -X- _ O
structure -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
spirit -X- _ O
of -X- _ O
formal -X- _ O
linguistic -X- _ O
frameworks -X- _ O
as -X- _ O
that -X- _ O
of -X- _ O
Johnson -X- _ O
( -X- _ O
1988 -X- _ O
) -X- _ O
; -X- _ O
Pollard -X- _ O
and -X- _ O
Sag -X- _ O
( -X- _ O
1994 -X- _ O
) -X- _ O
; -X- _ O
Shieber -X- _ O
( -X- _ O
2003 -X- _ O
) -X- _ O
; -X- _ O
Bresnan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
general -X- _ O
solution -X- _ O
for -X- _ O
annotating -X- _ O
such -X- _ O
structures -X- _ O
, -X- _ O
thus -X- _ O
extending -X- _ O
the -X- _ O
UniMorph -X- _ B-DatasetName
annotation -X- _ O
schema -X- _ O
to -X- _ O
fully -X- _ O
cover -X- _ O
a -X- _ O
wider -X- _ O
range -X- _ O
of -X- _ O
morphologically -X- _ B-TaskName
- -X- _ I-TaskName
complex -X- _ I-TaskName
argumentmarking -X- _ I-TaskName
phenomena -X- _ O
. -X- _ O

As -X- _ O
a -X- _ O
result -X- _ O
, -X- _ O
languages -X- _ O
exhibiting -X- _ O
such -X- _ O
phenomena -X- _ O
are -X- _ O
under -X- _ O
- -X- _ O
represented -X- _ O
in -X- _ O
UniMorph -X- _ B-DatasetName
, -X- _ O
and -X- _ O
when -X- _ O
they -X- _ O
are -X- _ O
, -X- _ O
the -X- _ O
inflection -X- _ O
tables -X- _ O
for -X- _ O
these -X- _ O
languages -X- _ O
are -X- _ O
often -X- _ O
incomplete -X- _ O
. -X- _ O

Concretely -X- _ O
, -X- _ O
in -X- _ O
some -X- _ O
cases -X- _ O
it -X- _ O
is -X- _ O
completely -X- _ O
impossible -X- _ O
to -X- _ O
annotate -X- _ O
parts -X- _ O
of -X- _ O
the -X- _ O
inflectional -X- _ O
paradigm -X- _ O
with -X- _ O
a -X- _ O
flat -X- _ O
bundle -X- _ O
, -X- _ O
as -X- _ O
is -X- _ O
the -X- _ O
case -X- _ O
with -X- _ O
case -X- _ O
stacking -X- _ O
, -X- _ O
and -X- _ O
in -X- _ O
other -X- _ O
cases -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
polypersonal -X- _ O
agreement -X- _ O
, -X- _ O
the -X- _ O
annotation -X- _ O
solutions -X- _ O
provided -X- _ O
are -X- _ O
unnatural -X- _ O
, -X- _ O
non -X- _ O
- -X- _ O
transparent -X- _ O
, -X- _ O
and -X- _ O
are -X- _ O
barely -X- _ O
used -X- _ O
in -X- _ O
practice -X- _ O
. -X- _ O

the -X- _ O
series -X- _ O
of -X- _ O
SIGMORPHON -X- _ B-DatasetName
shared -X- _ O
tasks -X- _ O
: -X- _ O
https -X- _ O
: -X- _ O
//sigmorphon.github.io -X- _ O
/ -X- _ O
sharedtasks -X- _ O
/ -X- _ O
and -X- _ O
diverse -X- _ O
inflection -X- _ O
patterns -X- _ O
that -X- _ O
make -X- _ O
them -X- _ O
less -X- _ O
compatible -X- _ O
with -X- _ O
the -X- _ O
flat -X- _ O
feature -X- _ O
- -X- _ O
sets -X- _ O
in -X- _ O
the -X- _ O
UniMorph -X- _ B-DatasetName
schema -X- _ O
. -X- _ O

While -X- _ O
western -X- _ O
languages -X- _ O
are -X- _ O
widely -X- _ O
represented -X- _ O
in -X- _ O
UniMorph -X- _ B-DatasetName
, -X- _ O
many -X- _ O
morphologically -X- _ O
rich -X- _ O
languages -X- _ O
( -X- _ O
Tsarfaty -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2010 -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
exhibit -X- _ O
rich -X- _ O
1Cf -X- _ O
. -X- _ O

1 -X- _ O
Introduction -X- _ O
In -X- _ O
recent -X- _ O
years -X- _ O
, -X- _ O
morphological -X- _ B-DatasetName
( -X- _ I-DatasetName
re)inflection -X- _ I-DatasetName
tasks -X- _ I-DatasetName
have -X- _ O
gained -X- _ O
a -X- _ O
lot -X- _ O
of -X- _ O
attention -X- _ O
in -X- _ O
NLP.1Subsequently -X- _ B-TaskName
, -X- _ O
several -X- _ O
multi -X- _ O
- -X- _ O
lingual -X- _ O
morphological -X- _ O
datasets -X- _ O
have -X- _ O
emerged -X- _ O
to -X- _ O
allow -X- _ O
for -X- _ O
the -X- _ O
supervised -X- _ O
training -X- _ O
of -X- _ O
morphological -X- _ O
models -X- _ O
, -X- _ O
most -X- _ O
notably -X- _ O
UniMorph -X- _ O
( -X- _ O
McCarthy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
that -X- _ O
organizes -X- _ O
words -X- _ O
into -X- _ O
inflectional -X- _ O
tables -X- _ O
, -X- _ O
annotating -X- _ O
each -X- _ O
inflected -X- _ O
word -X- _ O
- -X- _ O
form -X- _ O
with -X- _ O
its -X- _ O
respective -X- _ O
feature -X- _ O
- -X- _ O
set -X- _ O
. -X- _ O

Expanding -X- _ O
the -X- _ O
other -X- _ O
languages -X- _ O
in -X- _ O
UniMorph -X- _ B-DatasetName
to -X- _ O
this -X- _ O
schema -X- _ O
is -X- _ O
expected -X- _ O
to -X- _ O
improve -X- _ O
both -X- _ O
the -X- _ O
coverage -X- _ O
, -X- _ O
consistency -X- _ O
and -X- _ O
interpretability -X- _ O
of -X- _ O
this -X- _ O
benchmark -X- _ O
. -X- _ O

Experiments -X- _ O
with -X- _ O
a -X- _ O
standard -X- _ O
reinflection -X- _ O
model -X- _ O
show -X- _ O
that -X- _ O
generalization -X- _ O
is -X- _ O
easy -X- _ O
when -X- _ O
the -X- _ O
data -X- _ O
is -X- _ O
split -X- _ O
at -X- _ O
the -X- _ O
form -X- _ O
level -X- _ O
, -X- _ O
but -X- _ O
extremely -X- _ O
hard -X- _ O
when -X- _ O
splitting -X- _ O
along -X- _ O
lemma -X- _ O
lines -X- _ O
. -X- _ O

The -X- _ O
dataset -X- _ O
has -X- _ O
4 -X- _ O
times -X- _ O
more -X- _ O
tables -X- _ O
and -X- _ O
6 -X- _ O
times -X- _ O
more -X- _ O
verb -X- _ O
forms -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
existing -X- _ O
UniMorph -X- _ B-DatasetName
dataset -X- _ O
, -X- _ O
covering -X- _ O
all -X- _ O
possible -X- _ O
variants -X- _ O
of -X- _ O
argument -X- _ O
marking -X- _ O
, -X- _ O
demonstrating -X- _ O
the -X- _ O
adequacy -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
scheme -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
address -X- _ O
this -X- _ O
phenomenon -X- _ O
, -X- _ O
by -X- _ O
expanding -X- _ O
the -X- _ O
UniMorph -X- _ B-DatasetName
annotation -X- _ O
schema -X- _ O
to -X- _ O
hierarchical -X- _ O
feature -X- _ O
structure -X- _ O
that -X- _ O
naturally -X- _ O
accommodates -X- _ O
complex -X- _ O
argument -X- _ O
marking -X- _ O
. -X- _ O

We -X- _ O
apply -X- _ O
this -X- _ O
extended -X- _ O
schema -X- _ O
to -X- _ O
one -X- _ O
such -X- _ O
language -X- _ O
, -X- _ O
Georgian -X- _ B-DatasetName
, -X- _ O
and -X- _ O
provide -X- _ O
a -X- _ O
human -X- _ O
- -X- _ O
verified -X- _ O
, -X- _ O
accurate -X- _ O
and -X- _ O
balanced -X- _ O
morphological -X- _ O
dataset -X- _ O
for -X- _ O
Georgian -X- _ O
verbs -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
the -X- _ O
flat -X- _ O
structure -X- _ O
of -X- _ O
the -X- _ O
current -X- _ O
morphological -X- _ B-MethodName
annotation -X- _ I-MethodName
schema -X- _ I-MethodName
makes -X- _ O
the -X- _ O
treatment -X- _ O
of -X- _ O
some -X- _ O
languages -X- _ O
quirky -X- _ O
, -X- _ O
if -X- _ O
not -X- _ O
impossible -X- _ O
, -X- _ O
specifically -X- _ O
in -X- _ O
cases -X- _ O
of -X- _ O
polypersonal -X- _ O
agreement -X- _ O
, -X- _ O
where -X- _ O
verbs -X- _ O
agree -X- _ O
with -X- _ O
multiple -X- _ O
arguments -X- _ O
using -X- _ O
true -X- _ O
affixes -X- _ O
. -X- _ O

Experimental -X- _ O
results -X- _ O
demonstrate -X- _ O
the -X- _ O
superiority -X- _ O
of -X- _ O
the -X- _ O
proposed -X- _ O
model -X- _ O
under -X- _ O
both -X- _ O
the -X- _ O
ofine -X- _ O
and -X- _ O
the -X- _ O
online -X- _ B-MethodName
settings -X- _ I-MethodName
. -X- _ O

For -X- _ O
time -X- _ O
- -X- _ O
variability -X- _ O
, -X- _ O
we -X- _ O
explored -X- _ O
a -X- _ O
new -X- _ O
online -X- _ B-MethodName
setting -X- _ I-MethodName
, -X- _ O
where -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
expected -X- _ O
to -X- _ O
be -X- _ O
updated -X- _ O
to -X- _ O
new -X- _ O
evolutional -X- _ O
patterns -X- _ O
emerging -X- _ O
over -X- _ O
time -X- _ O
. -X- _ O

For -X- _ O
length -X- _ O
- -X- _ O
diversity -X- _ O
, -X- _ O
CEN -X- _ B-MethodName
adopts -X- _ O
a -X- _ O
length -X- _ B-MethodName
- -X- _ I-MethodName
aware -X- _ I-MethodName
CNN -X- _ I-MethodName
to -X- _ O
learn -X- _ O
evolutional -X- _ O
patterns -X- _ O
of -X- _ O
different -X- _ O
lengths -X- _ O
and -X- _ O
is -X- _ O
trained -X- _ O
under -X- _ O
a -X- _ O
curriculum -X- _ B-MethodName
learning -X- _ I-MethodName
strategy -X- _ I-MethodName
. -X- _ O

6 -X- _ O
Conclusions -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
proposed -X- _ O
Complex -X- _ B-MethodName
Evolutional -X- _ I-MethodName
Network -X- _ I-MethodName
( -X- _ I-MethodName
CEN -X- _ I-MethodName
) -X- _ I-MethodName
for -X- _ O
TKG -X- _ B-TaskName
reasoning -X- _ I-TaskName
, -X- _ O
which -X- _ O
deals -X- _ O
with -X- _ O
two -X- _ O
challenges -X- _ O
in -X- _ O
modeling -X- _ O
the -X- _ O
complex -X- _ O
evolutional -X- _ O
patterns -X- _ O
: -X- _ O
length -X- _ O
- -X- _ O
diversity -X- _ O
and -X- _ O
timevariability -X- _ O
. -X- _ O

CEN(-LA -X- _ B-MethodName
) -X- _ I-MethodName
denotes -X- _ O
the -X- _ O
model -X- _ O
replacing -X- _ O
the -X- _ O
length -X- _ B-MethodName
- -X- _ I-MethodName
aware -X- _ I-MethodName
CNN -X- _ I-MethodName
with -X- _ O
a -X- _ O
traditional -X- _ O
CNN -X- _ B-MethodName
. -X- _ O

The -X- _ O
underperformance -X- _ O
of -X- _ O
CEN(-CL -X- _ B-MethodName
) -X- _ I-MethodName
demonstrates -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
the -X- _ O
curriculum -X- _ O
learning -X- _ O
strategy -X- _ O
. -X- _ O

CEN(CL -X- _ O
) -X- _ O
denotes -X- _ O
CEN -X- _ B-MethodName
without -X- _ O
the -X- _ O
curriculum -X- _ O
learning -X- _ O
strategy -X- _ O
. -X- _ O

To -X- _ O
investigate -X- _ O
the -X- _ O
contributions -X- _ O
of -X- _ O
curriculum -X- _ O
learning -X- _ O
strategy -X- _ O
and -X- _ O
the -X- _ O
lengthaware -X- _ B-MethodName
CNN -X- _ I-MethodName
, -X- _ O
we -X- _ O
conduct -X- _ O
ablation -X- _ B-MethodName
studies -X- _ I-MethodName
for -X- _ O
CENon -X- _ B-MethodName
the -X- _ O
test -X- _ O
set -X- _ O
of -X- _ O
ICEWS14 -X- _ B-DatasetName
under -X- _ O
the -X- _ O
traditional -X- _ O
ofine -X- _ O
setting -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
. -X- _ O

TR -X- _ B-MethodName
unit -X- _ I-MethodName
limits -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
adapt -X- _ O
to -X- _ O
new -X- _ O
knowledge -X- _ O
and -X- _ O
is -X- _ O
not -X- _ O
suitable -X- _ O
for -X- _ O
this -X- _ O
dataset -X- _ O
. -X- _ O

It -X- _ O
is -X- _ O
because -X- _ O
that -X- _ O
the -X- _ O
time -X- _ O
interval -X- _ O
between -X- _ O
two -X- _ O
adjacent -X- _ O
timestamps -X- _ O
in -X- _ O
WIKI -X- _ B-DatasetName
( -X- _ O
one -X- _ O
year -X- _ O
) -X- _ O
is -X- _ O
much -X- _ O
larger -X- _ O
than -X- _ O
ICEWS -X- _ B-DatasetName
datasets -X- _ O
( -X- _ O
one -X- _ O
day -X- _ O
) -X- _ O
and -X- _ O
contains -X- _ O
more -X- _ O
time -X- _ O
- -X- _ O
variable -X- _ O
evolutional -X- _ O
patterns -X- _ O
. -X- _ O

On -X- _ O
WIKI -X- _ B-DatasetName
, -X- _ O
CEN(-TR -X- _ B-MethodName
) -X- _ I-MethodName
gets -X- _ O
better -X- _ O
performance -X- _ O
. -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
, -X- _ O
on -X- _ O
ICEWS -X- _ B-DatasetName
datasets -X- _ O
CEN -X- _ B-MethodName
outperforms -X- _ O
CEN(-TR -X- _ B-MethodName
) -X- _ I-MethodName
( -X- _ O
CEN -X- _ O
without -X- _ O
TR -X- _ O
unit -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
implies -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
TR -X- _ B-MethodName
unit -X- _ O
to -X- _ O
balance -X- _ O
the -X- _ O
knowledge -X- _ O
of -X- _ O
new -X- _ O
evolutional -X- _ O
patterns -X- _ O
and -X- _ O
the -X- _ O
existing -X- _ O
ones -X- _ O
. -X- _ O

Thus -X- _ O
, -X- _ O
it -X- _ O
can -X- _ O
not -X- _ O
be -X- _ O
directly -X- _ O
compared -X- _ O
with -X- _ O
the -X- _ O
baselines -X- _ O
designed -X- _ O
for -X- _ O
the -X- _ O
ofine -X- _ O
setting -X- _ O
. -X- _ O

Under -X- _ O
the -X- _ O
online -X- _ B-MethodName
setting -X- _ I-MethodName
, -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
updated -X- _ O
via -X- _ O
historical -X- _ O
facts -X- _ O
at -X- _ O
the -X- _ O
testset -X- _ O
. -X- _ O

Results -X- _ O
under -X- _ O
the -X- _ O
Online -X- _ B-MethodName
Setting -X- _ I-MethodName
. -X- _ O

Whereas -X- _ O
, -X- _ O
CEN -X- _ B-MethodName
recalls -X- _ O
more -X- _ O
answer -X- _ O
entities -X- _ O
by -X- _ O
aggregating -X- _ O
the -X- _ O
information -X- _ O
from -X- _ O
multiple -X- _ O
evolutional -X- _ O
patterns -X- _ O
, -X- _ O
which -X- _ O
may -X- _ O
be -X- _ O
the -X- _ O
reason -X- _ O
for -X- _ O
its -X- _ O
high -X- _ O
performance -X- _ O
on -X- _ O
Hits@3 -X- _ B-TaskName
and -X- _ O
Hits@10 -X- _ O
. -X- _ O

On -X- _ O
ICEWS -X- _ B-DatasetName
datasets -X- _ O
, -X- _ O
CEN -X- _ B-MethodName
underperforms -X- _ O
TITer -X- _ B-MethodName
on -X- _ O
Hits@1 -X- _ B-TaskName
because -X- _ O
TITer -X- _ B-MethodName
retrieves -X- _ O
the -X- _ O
answer -X- _ O
through -X- _ O
explicit -X- _ O
paths -X- _ O
, -X- _ O
which -X- _ O
usually -X- _ O
gets -X- _ O
high -X- _ O
Hits@1 -X- _ B-TaskName
. -X- _ O

CEN -X- _ B-MethodName
consistently -X- _ O
outperforms -X- _ O
the293 -X- _ O
. -X- _ O

The -X- _ O
results -X- _ O
under -X- _ O
the -X- _ O
traditional -X- _ O
ofine -X- _ O
setting -X- _ O
are -X- _ O
presented -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
. -X- _ O

The -X- _ O
experiments -X- _ O
are -X- _ O
carried -X- _ O
out -X- _ O
on -X- _ O
Tesla -X- _ O
V100 -X- _ O
. -X- _ O

We -X- _ O
fine -X- _ O
tune -X- _ O
the -X- _ O
pre -X- _ B-MethodName
- -X- _ I-MethodName
trained -X- _ I-MethodName
CEN -X- _ I-MethodName
fromT1 -X- _ O
+ -X- _ O
1 -X- _ O
toT3and -X- _ O
report -X- _ O
the -X- _ O
results -X- _ O
at -X- _ O
the -X- _ O
test -X- _ O
timestamps -X- _ O
( -X- _ O
T2toT3 -X- _ O
) -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
online -X- _ O
setting -X- _ O
, -X- _ O
we -X- _ O
set -X- _ O
the -X- _ O
max -X- _ B-HyperparameterName
epochs -X- _ I-HyperparameterName
of -X- _ O
the -X- _ O
fine -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
at -X- _ O
each -X- _ O
timestamp -X- _ O
to -X- _ O
30 -X- _ B-HyperparameterValue
. -X- _ O

The -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
RGCN -X- _ I-HyperparameterName
layers -X- _ I-HyperparameterName
is -X- _ O
set -X- _ O
to -X- _ O
2 -X- _ B-HyperparameterValue
and -X- _ O
the -X- _ O
dropout -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
for -X- _ O
each -X- _ O
layer -X- _ O
to -X- _ O
0.2 -X- _ B-HyperparameterValue
. -X- _ O

Adam -X- _ B-MethodName
( -X- _ O
Kingma -X- _ O
and -X- _ O
Ba -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
is -X- _ O
adopted -X- _ O
for -X- _ O
parameter -X- _ O
learning -X- _ O
with -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
0.001 -X- _ B-HyperparameterValue
on -X- _ O
all -X- _ O
datasets -X- _ O
. -X- _ O

The -X- _ O
dimension -X- _ B-HyperparameterName
dof -X- _ I-HyperparameterName
relation -X- _ I-HyperparameterName
representations -X- _ I-HyperparameterName
and -X- _ I-HyperparameterName
entity -X- _ I-HyperparameterName
representations -X- _ I-HyperparameterName
is -X- _ O
set -X- _ O
to -X- _ O
200 -X- _ B-HyperparameterValue
on -X- _ O
all -X- _ O
datasets -X- _ O
. -X- _ O

For -X- _ O
all -X- _ O
datasets -X- _ O
, -X- _ O
the -X- _ O
kernel -X- _ B-HyperparameterName
width -X- _ I-HyperparameterName
Mis -X- _ O
set -X- _ O
to -X- _ O
3 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
Cis -X- _ O
set -X- _ O
to -X- _ O
50 -X- _ O
. -X- _ O

The -X- _ O
maximum -X- _ B-HyperparameterName
length -X- _ I-HyperparameterName
Kfor -X- _ O
all -X- _ O
datasets -X- _ O
is -X- _ O
set -X- _ O
to -X- _ B-HyperparameterValue
10 -X- _ I-HyperparameterValue
. -X- _ O

In -X- _ O
the -X- _ O
experiments -X- _ O
, -X- _ O
the -X- _ O
optimal -X- _ B-HyperparameterName
minimum -X- _ I-HyperparameterName
lengths -X- _ I-HyperparameterName
of -X- _ O
evolutional -X- _ O
patterns -X- _ O
^kfor -X- _ O
ICEWS14 -X- _ B-DatasetName
, -X- _ O
ICEWS18 -X- _ B-DatasetName
, -X- _ O
WIKI -X- _ B-DatasetName
are -X- _ O
3 -X- _ B-HyperparameterValue
, -X- _ O
3 -X- _ B-HyperparameterValue
, -X- _ O
2 -X- _ B-HyperparameterValue
, -X- _ O
respectively -X- _ O
. -X- _ O

Under -X- _ O
this -X- _ O
timeaware -X- _ B-MethodName
filtered -X- _ I-MethodName
setting -X- _ I-MethodName
, -X- _ O
only -X- _ O
o3will -X- _ O
be -X- _ O
considered -X- _ O
as -X- _ O
a -X- _ O
correct -X- _ O
answer -X- _ O
and -X- _ O
thus -X- _ O
removed -X- _ O
from -X- _ O
the -X- _ O
ranking -X- _ O
list -X- _ O
of -X- _ O
candidate -X- _ O
answers -X- _ O
. -X- _ O

Note -X- _ O
that -X- _ O
, -X- _ O
following -X- _ O
Han -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020b -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
an -X- _ O
improved -X- _ O
filtered -X- _ O
setting -X- _ O
where -X- _ O
the -X- _ O
timestamps -X- _ O
of -X- _ O
facts -X- _ O
are -X- _ O
considered -X- _ O
, -X- _ O
called -X- _ O
time -X- _ B-MethodName
- -X- _ I-MethodName
aware -X- _ I-MethodName
filtered -X- _ I-MethodName
setting -X- _ I-MethodName
. -X- _ O

We -X- _ O
averaged -X- _ O
the -X- _ O
metrics -X- _ O
over -X- _ O
five -X- _ O
runs -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
MRR -X- _ B-MetricName
( -X- _ I-MetricName
Mean -X- _ I-MetricName
Reciprocal -X- _ I-MetricName
Rank -X- _ I-MetricName
) -X- _ I-MetricName
and -X- _ O
Hits@{1,3,10 -X- _ B-MetricName
} -X- _ O
as -X- _ O
the -X- _ O
metrics -X- _ O
for -X- _ O
TKG -X- _ B-TaskName
reasoning -X- _ I-TaskName
. -X- _ O

We -X- _ O
adopt -X- _ O
three -X- _ O
widelyused -X- _ O
datasets -X- _ O
, -X- _ O
ICEWS14 -X- _ B-DatasetName
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021b -X- _ O
) -X- _ O
, -X- _ O
ICEWS18 -X- _ B-DatasetName
( -X- _ O
Jin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
WIKI -X- _ B-DatasetName
( -X- _ O
Leblay -X- _ O
and -X- _ O
Chekol -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
to -X- _ O
evaluate -X- _ O
CEN -X- _ B-MethodName
. -X- _ O

Thus -X- _ O
, -X- _ O
the -X- _ O
time -X- _ O
complexity -X- _ O
of -X- _ O
CEN -X- _ B-MethodName
is -X- _ O
O(m2jEj+m).5 -X- _ O
Experiments -X- _ O
Experimental -X- _ O
Setup -X- _ O
. -X- _ O

Then -X- _ O
, -X- _ O
the -X- _ O
time -X- _ O
complexity -X- _ O
of -X- _ O
the -X- _ O
RGCN -X- _ B-MethodName
at -X- _ O
a -X- _ O
timestamp -X- _ O
tisO(jEj -X- _ O
) -X- _ O
, -X- _ O
wherejEjis -X- _ O
the -X- _ O
maximum -X- _ O
number -X- _ O
of -X- _ O
facts -X- _ O
at -X- _ O
timestamps -X- _ O
in -X- _ O
history -X- _ O
. -X- _ O

We -X- _ O
view -X- _ O
the -X- _ O
computational -X- _ O
complexities -X- _ O
of -X- _ O
the -X- _ O
RGCN -X- _ B-MethodName
unit -X- _ O
and -X- _ O
ConvTransE -X- _ B-MethodName
as -X- _ O
constants -X- _ O
. -X- _ O

4.4 -X- _ O
Analysis -X- _ O
on -X- _ O
Computational -X- _ O
Complexity -X- _ O
We -X- _ O
analyze -X- _ O
the -X- _ O
computational -X- _ O
complexity -X- _ O
of -X- _ O
CEN -X- _ B-MethodName
. -X- _ O

We -X- _ O
apply -X- _ O
an -X- _ O
L2regularization -X- _ B-MethodName
constraint -X- _ O
between -X- _ O
two -X- _ O
temporally -X- _ O
adjacent -X- _ O
models -X- _ O
to -X- _ O
smooth -X- _ O
the -X- _ O
drastic -X- _ O
change -X- _ O
of -X- _ O
the -X- _ O
parameters -X- _ O
. -X- _ O

Furthermore -X- _ O
, -X- _ O
to -X- _ O
balance -X- _ O
the -X- _ O
knowledge -X- _ O
of -X- _ O
new -X- _ O
evolutional -X- _ O
patterns -X- _ O
and -X- _ O
the -X- _ O
existing -X- _ O
ones -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
Temporal -X- _ B-MethodName
Regularization -X- _ I-MethodName
unit -X- _ O
( -X- _ O
TR -X- _ B-MethodName
unit -X- _ O
) -X- _ O
( -X- _ O
Daruna -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

Thus -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
the -X- _ O
bottom -X- _ O
of -X- _ O
Figure -X- _ O
2 -X- _ O
, -X- _ O
for -X- _ O
timestamp -X- _ O
t+ -X- _ O
1(T1 -X- _ O
< -X- _ O
t+ -X- _ O
1 -X- _ O
< -X- _ O
T -X- _ O
3),Model^K -X- _ O
tis -X- _ O
finetuned -X- _ B-MethodName
to -X- _ O
get -X- _ O
Model^K -X- _ O
t+1by -X- _ O
predicting -X- _ O
the -X- _ O
facts -X- _ O
in -X- _ O
the -X- _ O
KG -X- _ B-MethodName
at -X- _ O
the -X- _ O
last -X- _ O
timestamp -X- _ O
Gtwith -X- _ O
historical -X- _ O
KG -X- _ B-MethodName
sequences -X- _ O
as -X- _ O
inputs -X- _ O
. -X- _ O

4.3 -X- _ O
Online -X- _ B-MethodName
Learning -X- _ I-MethodName
for -X- _ O
Time -X- _ O
- -X- _ O
variability -X- _ O
To -X- _ O
handle -X- _ O
the -X- _ O
time -X- _ O
- -X- _ O
variability -X- _ O
of -X- _ O
evolutional -X- _ O
patterns -X- _ O
, -X- _ O
one -X- _ O
simple -X- _ O
and -X- _ O
direct -X- _ O
method -X- _ O
is -X- _ O
to -X- _ O
update -X- _ O
the -X- _ O
model -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
newly -X- _ O
occurred -X- _ O
facts -X- _ O
. -X- _ O

Note -X- _ O
that -X- _ O
, -X- _ O
curriculum -X- _ O
learning -X- _ O
is -X- _ O
conducted -X- _ O
under -X- _ O
the -X- _ O
traditional -X- _ O
ofine -X- _ O
setting -X- _ O
andModel^Kis -X- _ O
used -X- _ O
as -X- _ O
the -X- _ O
pre -X- _ B-MethodName
- -X- _ I-MethodName
trained -X- _ I-MethodName
model -X- _ I-MethodName
for -X- _ O
online -X- _ B-MethodName
learning -X- _ I-MethodName
. -X- _ O

The -X- _ O
model -X- _ O
stops -X- _ O
the -X- _ O
curriculum -X- _ O
and -X- _ O
gets -X- _ O
the -X- _ O
optimal -X- _ O
^Kwhen -X- _ B-HyperparameterValue
the -X- _ O
MRR -X- _ B-MetricName
metric -X- _ I-MetricName
decreases -X- _ O
or -X- _ O
the -X- _ O
length -X- _ O
is -X- _ O
up -X- _ O
to -X- _ O
maximum -X- _ B-HyperparameterName
length -X- _ I-HyperparameterName
K -X- _ B-HyperparameterValue
. -X- _ O

As -X- _ O
shown -X- _ O
at -X- _ O
the -X- _ O
top -X- _ O
of -X- _ O
Figure -X- _ O
2 -X- _ O
, -X- _ O
we -X- _ O
start -X- _ O
from -X- _ O
the -X- _ O
minimum -X- _ B-HyperparameterName
length -X- _ I-HyperparameterName
^k(^k= -X- _ B-HyperparameterValue
1for -X- _ O
example -X- _ O
) -X- _ O
and -X- _ O
gradually -X- _ O
move -X- _ O
on -X- _ O
to -X- _ O
longer -X- _ O
history -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
. -X- _ O

choose -X- _ O
the -X- _ O
maximum -X- _ O
length -X- _ O
of -X- _ O
evolutional -X- _ O
patterns -X- _ O
is -X- _ O
vital -X- _ O
to -X- _ O
CEN -X- _ B-MethodName
. -X- _ O

Similar -X- _ O
to -X- _ O
human -X- _ O
learning -X- _ O
procedures -X- _ O
, -X- _ O
the -X- _ O
models -X- _ O
can -X- _ O
benefit -X- _ O
from -X- _ O
an -X- _ O
easy -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
difficult -X- _ O
curriculum -X- _ O
. -X- _ O

4.2 -X- _ O
Curriculum -X- _ O
Learning -X- _ O
for -X- _ O
Length -X- _ O
- -X- _ O
diversity -X- _ O
Longer -X- _ O
historical -X- _ O
KG -X- _ B-MethodName
sequences -X- _ O
contain -X- _ O
more -X- _ O
historical -X- _ O
facts -X- _ O
and -X- _ O
longer -X- _ O
evolutional -X- _ O
patterns -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
more -X- _ O
challenging -X- _ O
to -X- _ O
learn -X- _ O
. -X- _ O

Then -X- _ O
we -X- _ O
seen -X- _ O
it -X- _ O
as -X- _ O
a -X- _ O
multi -X- _ B-TaskName
- -X- _ I-TaskName
class -X- _ I-TaskName
learning -X- _ I-TaskName
problem -X- _ I-TaskName
and -X- _ O
use -X- _ O
the -X- _ O
cross -X- _ B-MethodName
- -X- _ I-MethodName
entropy -X- _ I-MethodName
as -X- _ O
its -X- _ O
objective -X- _ O
function -X- _ O
. -X- _ O

Then -X- _ O
, -X- _ O
each -X- _ O
vector -X- _ O
is -X- _ O
fed -X- _ O
into -X- _ O
a -X- _ O
shared -X- _ O
1 -X- _ O
- -X- _ O
layer -X- _ O
Fully -X- _ B-MethodName
Connected -X- _ I-MethodName
Network -X- _ I-MethodName
( -X- _ I-MethodName
FCN -X- _ I-MethodName
) -X- _ I-MethodName
withW32RCddas -X- _ O
its -X- _ O
parameters -X- _ O
and -X- _ O
the -X- _ O
final -X- _ O
score -X- _ O
of -X- _ O
a -X- _ O
candidate -X- _ O
entity -X- _ O
ois -X- _ O
the -X- _ O
sum -X- _ O
of -X- _ O
the -X- _ O
logits -X- _ O
from -X- _ O
multiple -X- _ O
evoltional -X- _ O
representations -X- _ O
: -X- _ O
PK -X- _ O
k=1mk(s -X- _ O
; -X- _ O
r -X- _ O
; -X- _ O
t -X- _ O
q)W3ok -X- _ O
, -X- _ O
where -X- _ O
okis -X- _ O
the -X- _ O
evolutional -X- _ O
representation -X- _ O
of -X- _ O
length -X- _ O
kforo -X- _ O
. -X- _ O

For -X- _ O
historical -X- _ O
KG -X- _ B-MethodName
sequence -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
k -X- _ B-HyperparameterValue
, -X- _ O
kthchannel -X- _ O
with -X- _ O
Cdifferent -X- _ B-HyperparameterValue
kernels -X- _ B-HyperparameterName
of -X- _ O
size2Mis -X- _ B-HyperparameterName
used -X- _ O
to -X- _ O
decode -X- _ O
the -X- _ O
concatenation -X- _ O
ofsk -X- _ O
tqandr -X- _ O
. -X- _ O

To -X- _ O
distinguish -X- _ O
the -X- _ O
inuences -X- _ O
of -X- _ O
the -X- _ O
length -X- _ O
- -X- _ O
diverse -X- _ O
evolutional -X- _ O
patterns -X- _ O
, -X- _ O
we -X- _ O
design -X- _ O
a -X- _ O
length -X- _ B-MethodName
- -X- _ I-MethodName
aware -X- _ I-MethodName
CNN -X- _ I-MethodName
, -X- _ O
which -X- _ O
uses -X- _ O
Kseparate -X- _ O
channels -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
above -X- _ O
Kevolutional -X- _ O
representations -X- _ O
. -X- _ O

By -X- _ O
reusing -X- _ O
the -X- _ O
encoder -X- _ O
for -X- _ O
KG -X- _ B-MethodName
sequences -X- _ O
of -X- _ O
different -X- _ O
lengths -X- _ O
, -X- _ O
we -X- _ O
obtain -X- _ O
Kentity -X- _ O
evolution -X- _ O
representations -X- _ O
at -X- _ O
the -X- _ O
query -X- _ O
timestamp -X- _ O
: -X- _ O
fH1 -X- _ O
tq -X- _ O
; -X- _ O
: -X- _ O
: -X- _ O
: -X- _ O
; -X- _ O
Hk -X- _ O
tq -X- _ O
; -X- _ O
: -X- _ O
: -X- _ O
: -X- _ O
; -X- _ O
HK -X- _ O
tqg -X- _ O
. -X- _ O

For -X- _ O
the -X- _ O
initial -X- _ O
timestamp -X- _ O
tq 1,H2 -X- _ O
tq 2is -X- _ O
set -X- _ O
to -X- _ O
H.Ris -X- _ O
shared -X- _ O
across -X- _ O
timestamps -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
different -X- _ O
from -X- _ B-TaskName
REGCN -X- _ I-TaskName
. -X- _ O

Its -X- _ O
inputs -X- _ O
include -X- _ O
the -X- _ O
lastest -X- _ O
historical -X- _ O
KG -X- _ B-MethodName
sequences -X- _ O
of -X- _ O
lengths -X- _ O
from -X- _ O
1 -X- _ O
toK -X- _ O
, -X- _ O
initial -X- _ O
representations -X- _ O
of -X- _ O
entities -X- _ O
H2RjVjd -X- _ O
and -X- _ O
relation -X- _ O
representations -X- _ O
R2RjRjd -X- _ O
, -X- _ O
where -X- _ O
dis -X- _ O
the -X- _ O
dimension -X- _ O
of -X- _ O
the -X- _ O
representations -X- _ O
. -X- _ O

Then -X- _ O
, -X- _ O
the -X- _ O
evolutional -X- _ O
representation -X- _ O
decoder -X- _ O
calculates -X- _ O
the -X- _ O
scores -X- _ O
of -X- _ O
all -X- _ O
entities -X- _ O
for -X- _ O
the -X- _ O
query -X- _ O
based -X- _ O
on -X- _ O
these -X- _ O
representations -X- _ O
. -X- _ O

The -X- _ O
KG -X- _ B-MethodName
sequence -X- _ O
encoder -X- _ O
encodes -X- _ O
the -X- _ O
latest -X- _ O
historical -X- _ O
KG -X- _ B-MethodName
sequences -X- _ O
of -X- _ O
different -X- _ O
lengths -X- _ O
to -X- _ O
corresponding -X- _ O
evolutional -X- _ O
representations -X- _ O
of -X- _ O
entities -X- _ O
. -X- _ O

4.1 -X- _ O
Basic -X- _ O
CEN -X- _ B-MethodName
Model -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
, -X- _ O
the -X- _ O
basic -X- _ O
model -X- _ O
of -X- _ O
CEN -X- _ B-MethodName
contains -X- _ O
a -X- _ O
KG -X- _ B-MethodName
sequence -X- _ O
encoder -X- _ O
and -X- _ O
an -X- _ O
evolutional -X- _ O
representation -X- _ O
decoder -X- _ O
. -X- _ O

Specifically -X- _ O
, -X- _ O
CEN -X- _ B-MethodName
consists -X- _ O
of -X- _ O
a -X- _ O
basic -X- _ O
model -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
a -X- _ O
curriculum -X- _ B-MethodName
learning -X- _ I-MethodName
strategy -X- _ I-MethodName
for -X- _ O
the -X- _ O
former -X- _ O
challenge -X- _ O
and -X- _ O
an -X- _ O
online -X- _ B-MethodName
learning -X- _ I-MethodName
strategy -X- _ I-MethodName
for -X- _ O
the -X- _ O
latter -X- _ O
challenge -X- _ O
. -X- _ O

4 -X- _ O
Methodology -X- _ O
We -X- _ O
propose -X- _ O
CEN -X- _ B-MethodName
to -X- _ O
deal -X- _ O
with -X- _ O
the -X- _ O
length -X- _ O
- -X- _ O
diversity -X- _ O
and -X- _ O
time -X- _ O
- -X- _ O
variability -X- _ O
challenges -X- _ O
of -X- _ O
evolutional -X- _ O
pat-291 -X- _ O
. -X- _ O

Under -X- _ O
the -X- _ O
traditional -X- _ O
ofine -X- _ O
setting -X- _ O
, -X- _ O
models -X- _ O
are -X- _ O
trained -X- _ O
only -X- _ O
using -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
( -X- _ O
tqT1 -X- _ O
) -X- _ O
, -X- _ O
while -X- _ O
under -X- _ O
the -X- _ O
online -X- _ O
setting -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
will -X- _ O
be -X- _ O
updated -X- _ O
by -X- _ O
KGs -X- _ B-MethodName
before -X- _ O
tq(T1 -X- _ O
< -X- _ O
tqT3 -X- _ O
) -X- _ O
continually -X- _ O
. -X- _ O

Glean -X- _ B-TaskName
( -X- _ O
Deng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
introduces -X- _ O
event -X- _ O
descriptions -X- _ O
to -X- _ O
enrich -X- _ O
the -X- _ O
information -X- _ O
of -X- _ O
the -X- _ O
entities -X- _ O
. -X- _ O

Unlike -X- _ O
the -X- _ O
query -X- _ O
- -X- _ O
specific -X- _ O
models -X- _ O
, -X- _ O
entire -X- _ O
graph -X- _ O
based -X- _ O
models -X- _ O
encode -X- _ O
the -X- _ O
latest -X- _ O
historical -X- _ O
KG -X- _ B-MethodName
sequence -X- _ O
of -X- _ O
a -X- _ O
fixed -X- _ O
- -X- _ O
length -X- _ O
. -X- _ O

CluSTeR -X- _ B-TaskName
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021a -X- _ O
) -X- _ O
and -X- _ O
TITer -X- _ B-TaskName
( -X- _ O
Sun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
both -X- _ O
adopt -X- _ O
reinforcement -X- _ O
learning -X- _ O
to -X- _ O
discover -X- _ O
evolutional -X- _ O
patterns -X- _ O
in -X- _ O
query -X- _ O
- -X- _ O
related -X- _ O
paths -X- _ O
of -X- _ O
a -X- _ O
fixed -X- _ O
length -X- _ O
. -X- _ O

xERTE -X- _ B-TaskName
( -X- _ O
Han -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
learns -X- _ O
to -X- _ O
find -X- _ O
the -X- _ O
query -X- _ O
- -X- _ O
related -X- _ O
subgraphs -X- _ O
of -X- _ O
a -X- _ O
fixed -X- _ O
hop -X- _ O
number -X- _ O
. -X- _ O

CyGNet -X- _ B-TaskName
( -X- _ O
Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
captures -X- _ O
repetitive -X- _ O
patterns -X- _ O
by -X- _ O
modeling -X- _ O
repetitive -X- _ O
facts -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
RE -X- _ B-TaskName
- -X- _ I-TaskName
NET -X- _ I-TaskName
( -X- _ O
Jin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
captures -X- _ O
the -X- _ O
evolutional -X- _ O
patterns -X- _ O
implied -X- _ O
in -X- _ O
the -X- _ O
subgraph -X- _ O
sequences -X- _ O
of -X- _ O
a -X- _ O
fixed -X- _ O
length -X- _ O
specific -X- _ O
to -X- _ O
the -X- _ O
query -X- _ O
. -X- _ O

Query -X- _ B-MethodName
- -X- _ I-MethodName
specific -X- _ I-MethodName
models -X- _ I-MethodName
focus -X- _ O
on -X- _ O
modeling -X- _ O
the -X- _ O
query -X- _ O
- -X- _ O
specific -X- _ O
history -X- _ O
. -X- _ O

TKG -X- _ B-TaskName
Reasoning -X- _ I-TaskName
under -X- _ O
the -X- _ O
extrapolation -X- _ O
setting -X- _ O
This -X- _ O
setting -X- _ O
aims -X- _ O
to -X- _ O
predict -X- _ O
facts -X- _ O
at -X- _ O
future -X- _ O
timestamps -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
categorized -X- _ O
into -X- _ O
two -X- _ O
groups -X- _ O
: -X- _ O
query -X- _ B-MethodName
- -X- _ I-MethodName
specific -X- _ I-MethodName
and -X- _ O
entire -X- _ B-MethodName
graph -X- _ I-MethodName
based -X- _ I-MethodName
models -X- _ I-MethodName
. -X- _ O

Above -X- _ O
all -X- _ O
, -X- _ O
they -X- _ O
can -X- _ O
not -X- _ O
obtain -X- _ O
the -X- _ O
representations -X- _ O
of -X- _ O
the -X- _ O
unseen -X- _ O
timestamps -X- _ O
and -X- _ O
are -X- _ O
not -X- _ O
suitable -X- _ O
for -X- _ O
the -X- _ O
extrapolation -X- _ O
setting -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
TTransE -X- _ B-DatasetName
( -X- _ O
Leblay -X- _ O
and -X- _ O
Chekol -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
extends -X- _ O
TransE -X- _ B-DatasetName
( -X- _ O
Bordes -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
by -X- _ O
adding -X- _ O
the -X- _ O
temporal -X- _ O
constraints -X- _ O
; -X- _ O
HyTE -X- _ B-DatasetName
( -X- _ O
Dasgupta -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
projects -X- _ O
the -X- _ O
entities -X- _ O
and -X- _ O
relations -X- _ O
to -X- _ O
time -X- _ O
- -X- _ O
aware -X- _ O
hyperplanes -X- _ O
to -X- _ O
generate -X- _ O
representationsfor -X- _ O
different -X- _ O
timestamps -X- _ O
. -X- _ O

In -X- _ O
what -X- _ O
follows -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
introduce -X- _ O
related -X- _ O
work -X- _ O
on -X- _ O
both -X- _ O
settings -X- _ O
: -X- _ O
TKG -X- _ B-TaskName
Reasoning -X- _ I-TaskName
under -X- _ O
the -X- _ O
interpolation -X- _ O
setting -X- _ O
. -X- _ O

This -X- _ O
paper -X- _ O
focus -X- _ O
on -X- _ O
the -X- _ O
extrapolation -X- _ B-TaskName
setting -X- _ O
. -X- _ O

2 -X- _ O
Related -X- _ O
Work -X- _ O
The -X- _ O
TKG -X- _ B-TaskName
reasoning -X- _ I-TaskName
task -X- _ O
primarily -X- _ O
has -X- _ O
two -X- _ O
settings -X- _ O
, -X- _ O
interpolation -X- _ B-TaskName
and -X- _ O
extrapolation -X- _ B-TaskName
. -X- _ O

Experiments -X- _ O
demonstrate -X- _ O
that -X- _ O
the -X- _ O
proposed -X- _ O
CEN -X- _ B-MethodName
model -X- _ O
achieves -X- _ O
better -X- _ O
performance -X- _ O
on -X- _ O
TKG -X- _ B-MethodName
reasoning -X- _ O
under -X- _ O
both -X- _ O
the -X- _ O
traditional -X- _ O
ofine -X- _ O
and -X- _ O
the -X- _ O
proposed -X- _ O
online -X- _ O
settings -X- _ O
. -X- _ O

For -X- _ O
time -X- _ O
- -X- _ O
variability -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
learn -X- _ O
the -X- _ O
model -X- _ O
under -X- _ O
an -X- _ O
online -X- _ O
setting -X- _ O
to -X- _ O
adapt -X- _ O
to -X- _ O
the -X- _ O
changes -X- _ O
of -X- _ O
evolutional -X- _ O
patterns -X- _ O
. -X- _ O

For -X- _ O
length -X- _ O
- -X- _ O
diversity -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
lengthaware -X- _ O
CNN -X- _ B-MethodName
to -X- _ O
learn -X- _ O
evolutional -X- _ O
patterns -X- _ O
with -X- _ O
different -X- _ O
lengths -X- _ O
in -X- _ O
a -X- _ O
curriculum -X- _ O
learning -X- _ O
manner -X- _ O
. -X- _ O

In -X- _ O
general -X- _ O
, -X- _ O
this -X- _ O
paper -X- _ O
makes -X- _ O
the -X- _ O
following -X- _ O
contributions -X- _ O
: -X- _ O
We -X- _ O
address -X- _ O
, -X- _ O
for -X- _ O
the -X- _ O
first -X- _ O
time -X- _ O
, -X- _ O
the -X- _ O
problems -X- _ O
of -X- _ O
length -X- _ O
- -X- _ O
diversity -X- _ O
and -X- _ O
time -X- _ O
- -X- _ O
variability -X- _ O
of -X- _ O
evolutional -X- _ O
patterns -X- _ O
for -X- _ O
TKG -X- _ B-MethodName
reasoning -X- _ O
. -X- _ O

For -X- _ O
time -X- _ O
- -X- _ O
variability -X- _ O
, -X- _ O
we -X- _ O
learn -X- _ O
CEN -X- _ B-MethodName
under -X- _ O
an -X- _ O
online -X- _ O
setting -X- _ O
and -X- _ O
combine -X- _ O
CEN -X- _ B-MethodName
with -X- _ O
a -X- _ O
temporal -X- _ O
regularization -X- _ O
unit -X- _ O
to -X- _ O
alleviate -X- _ O
the -X- _ O
catastrophic -X- _ O
forgetting -X- _ O
problem -X- _ O
( -X- _ O
Mccloskey -X- _ O
and -X- _ O
Cohen -X- _ O
, -X- _ O
1989 -X- _ O
) -X- _ O
. -X- _ O

Besides -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
via -X- _ O
an -X- _ O
easy -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
difficult -X- _ O
curriculum -X- _ O
learning -X- _ O
strategy -X- _ O
incrementally -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
length -X- _ O
of -X- _ O
KG -X- _ B-MethodName
sequences -X- _ O
. -X- _ O

For -X- _ O
length -X- _ O
- -X- _ O
diversity -X- _ O
, -X- _ O
CEN -X- _ B-MethodName
learns -X- _ O
evolutional -X- _ O
patterns -X- _ O
from -X- _ O
historical -X- _ O
KG -X- _ B-MethodName
sequences -X- _ O
of -X- _ O
different -X- _ O
lengths -X- _ O
via -X- _ O
an -X- _ O
Relational -X- _ B-MethodName
Graph -X- _ I-MethodName
Neural -X- _ I-MethodName
Network -X- _ I-MethodName
( -X- _ I-MethodName
RGCN -X- _ I-MethodName
) -X- _ I-MethodName
based -X- _ O
KG -X- _ B-MethodName
sequence -X- _ O
encoder -X- _ O
and -X- _ O
a -X- _ O
length -X- _ O
- -X- _ O
aware -X- _ O
Convolutional -X- _ B-MethodName
Neural -X- _ I-MethodName
Network -X- _ I-MethodName
( -X- _ I-MethodName
CNN -X- _ I-MethodName
) -X- _ I-MethodName
based -X- _ O
evolutional -X- _ O
representation -X- _ O
decoder -X- _ O
. -X- _ O

Upon -X- _ O
the -X- _ O
above -X- _ O
observations -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
Complex -X- _ B-MethodName
Evolutional -X- _ I-MethodName
Network -X- _ I-MethodName
( -X- _ I-MethodName
CEN -X- _ I-MethodName
) -X- _ I-MethodName
to -X- _ O
deal -X- _ O
with -X- _ O
the -X- _ O
above -X- _ O
two -X- _ O
challenges -X- _ O
. -X- _ O

Previous -X- _ O
models -X- _ O
extract -X- _ O
evolutional -X- _ O
patterns -X- _ O
of -X- _ O
a -X- _ O
fixed -X- _ O
length -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
not -X- _ O
handle -X- _ O
evolutional -X- _ O
patterns -X- _ O
of -X- _ O
diverse -X- _ O
lengths -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
they -X- _ O
all -X- _ O
ignore -X- _ O
the -X- _ O
length -X- _ O
- -X- _ O
diversity -X- _ O
and -X- _ O
time -X- _ O
- -X- _ O
variability -X- _ O
of -X- _ O
evolutional -X- _ O
patterns -X- _ O
. -X- _ O

Therefore -X- _ O
, -X- _ O
the -X- _ O
entire -X- _ B-MethodName
graph -X- _ I-MethodName
based -X- _ I-MethodName
models -X- _ I-MethodName
( -X- _ O
Deng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021a -X- _ O
) -X- _ O
take -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
entire -X- _ O
KGs -X- _ B-MethodName
as -X- _ O
the -X- _ O
input -X- _ O
and -X- _ O
encode -X- _ O
evolutional -X- _ O
patterns -X- _ O
among -X- _ O
them -X- _ O
, -X- _ O
which -X- _ O
exhibit -X- _ O
superiority -X- _ O
to -X- _ O
the -X- _ O
query -X- _ B-MethodName
- -X- _ I-MethodName
specific -X- _ I-MethodName
models -X- _ I-MethodName
. -X- _ O

This -X- _ O
kind -X- _ O
of -X- _ O
models -X- _ O
may -X- _ O
inevitably -X- _ O
neglect -X- _ O
some -X- _ O
useful -X- _ O
evolutional -X- _ O
patterns -X- _ O
. -X- _ O

The -X- _ O
first -X- _ O
kind -X- _ O
of -X- _ O
models -X- _ O
( -X- _ O
Jin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021a -X- _ O
; -X- _ O
Sun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Han -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
extract -X- _ O
useful -X- _ O
structures -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
paths -X- _ O
or -X- _ O
subgraphs -X- _ O
) -X- _ O
for -X- _ O
each -X- _ O
individual -X- _ O
query -X- _ O
from -X- _ O
the -X- _ O
historical -X- _ O
KG -X- _ B-MethodName
sequence -X- _ O
and -X- _ O
further -X- _ O
predict -X- _ O
the -X- _ O
future -X- _ O
facts -X- _ O
by -X- _ O
mining -X- _ O
evolutional -X- _ O
patterns -X- _ O
from -X- _ O
these -X- _ O
structures -X- _ O
. -X- _ O

There -X- _ O
are -X- _ O
two -X- _ O
kinds -X- _ O
of -X- _ O
models -X- _ O
to -X- _ O
model -X- _ O
evolutional -X- _ O
patterns -X- _ O
, -X- _ O
namely -X- _ O
, -X- _ O
query -X- _ O
- -X- _ O
specific -X- _ O
and -X- _ O
entire -X- _ O
graph -X- _ B-MethodName
based -X- _ I-MethodName
models -X- _ I-MethodName
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
[ -X- _ O
( -X- _ O
COVID-19 -X- _ O
, -X- _ O
Infect -X- _ O
, -X- _ O
A -X- _ O
, -X- _ O
2021 -X- _ O
- -X- _ O
12 -X- _ O
- -X- _ O
21 -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
A -X- _ O
, -X- _ O
Discuss -X- _ O
with -X- _ O
, -X- _ O
B -X- _ O
, -X- _ O
202112 -X- _ O
- -X- _ O
25 -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
B -X- _ O
, -X- _ O
Go -X- _ O
to -X- _ O
, -X- _ O
Shop -X- _ O
, -X- _ O
2021 -X- _ O
- -X- _ O
12 -X- _ O
- -X- _ O
28 -X- _ O
) -X- _ O
] -X- _ O
is -X- _ O
an -X- _ O
informative -X- _ O
evolutional -X- _ O
pattern -X- _ O
for -X- _ O
the -X- _ O
above -X- _ O
query -X- _ O
implied -X- _ O
in -X- _ O
historical -X- _ B-MethodName
KGs -X- _ I-MethodName
. -X- _ O

Such -X- _ O
facts -X- _ O
, -X- _ O
usually -X- _ O
temporally -X- _ O
adjacent -X- _ O
, -X- _ O
may -X- _ O
carry -X- _ O
informative -X- _ O
sequential -X- _ O
patterns -X- _ O
, -X- _ O
called -X- _ O
evolutional -X- _ O
patterns -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
. -X- _ O

To -X- _ O
predict -X- _ O
future -X- _ O
facts -X- _ O
, -X- _ O
one -X- _ O
challenge -X- _ O
is -X- _ O
to -X- _ O
dive -X- _ O
deep -X- _ O
into -X- _ O
the -X- _ O
related -X- _ O
historical -X- _ O
facts -X- _ O
, -X- _ O
which -X- _ O
reect -X- _ O
This -X- _ O
work -X- _ O
was -X- _ O
done -X- _ O
while -X- _ O
the -X- _ O
first -X- _ O
author -X- _ O
was -X- _ O
doing -X- _ O
internship -X- _ O
at -X- _ O
Baidu -X- _ O
Inc.the -X- _ O
preferences -X- _ O
of -X- _ O
the -X- _ O
related -X- _ O
entities -X- _ O
and -X- _ O
affect -X- _ O
their -X- _ O
future -X- _ O
behaviors -X- _ O
to -X- _ O
a -X- _ O
certain -X- _ O
degree -X- _ O
. -X- _ O

TKG -X- _ B-TaskName
reasoning -X- _ I-TaskName
aims -X- _ O
to -X- _ O
answer -X- _ O
queries -X- _ O
about -X- _ O
future -X- _ O
facts -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
( -X- _ O
COVID19 -X- _ O
, -X- _ O
New -X- _ O
medical -X- _ O
case -X- _ O
occur -X- _ O
, -X- _ O
? -X- _ O
, -X- _ O
2022 -X- _ O
- -X- _ O
1 -X- _ O
- -X- _ O
9 -X- _ O
) -X- _ O
. -X- _ O

A -X- _ O
TKG -X- _ B-MethodName
can -X- _ O
be -X- _ O
denoted -X- _ O
as -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
KGs -X- _ B-MethodName
with -X- _ O
timestamps -X- _ O
, -X- _ O
each -X- _ O
of -X- _ O
which -X- _ O
contains -X- _ O
all -X- _ O
facts -X- _ O
at -X- _ O
the -X- _ O
corresponding -X- _ O
timestamp -X- _ O
. -X- _ O

Each -X- _ O
fact -X- _ O
in -X- _ O
TKGs -X- _ B-MethodName
is -X- _ O
a -X- _ O
quadruple -X- _ O
( -X- _ O
subject -X- _ O
, -X- _ O
relation -X- _ O
, -X- _ O
object -X- _ O
, -X- _ O
timestamp -X- _ O
) -X- _ O
. -X- _ O

1 -X- _ O
Introduction -X- _ O
Temporal -X- _ B-MethodName
Knowledge -X- _ I-MethodName
Graph -X- _ I-MethodName
( -X- _ I-MethodName
TKG -X- _ I-MethodName
) -X- _ I-MethodName
( -X- _ O
Boschee -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Gottschalk -X- _ O
and -X- _ O
Demidova -X- _ O
, -X- _ O
2018 -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Zhao -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
has -X- _ O
emerged -X- _ O
as -X- _ O
a -X- _ O
very -X- _ O
active -X- _ O
research -X- _ O
area -X- _ O
over -X- _ O
the -X- _ O
last -X- _ O
few -X- _ O
years -X- _ O
. -X- _ O

Extensive -X- _ O
experiments -X- _ O
demonstrate -X- _ O
that -X- _ O
CEN -X- _ B-MethodName
obtains -X- _ O
substantial -X- _ O
performance -X- _ O
improvement -X- _ O
under -X- _ O
both -X- _ O
the -X- _ O
traditional -X- _ O
ofine -X- _ O
and -X- _ O
the -X- _ O
proposed -X- _ O
online -X- _ O
settings -X- _ O
. -X- _ O

Besides -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
learn -X- _ O
the -X- _ O
model -X- _ O
under -X- _ O
the -X- _ O
online -X- _ O
setting -X- _ O
so -X- _ O
that -X- _ O
it -X- _ O
can -X- _ O
adapt -X- _ O
to -X- _ O
the -X- _ O
changes -X- _ O
of -X- _ O
evolutional -X- _ O
patterns -X- _ O
over -X- _ O
time -X- _ O
. -X- _ O

Thus -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
new -X- _ O
model -X- _ O
, -X- _ O
called -X- _ O
Complex -X- _ B-MethodName
Evolutional -X- _ I-MethodName
Network -X- _ I-MethodName
( -X- _ I-MethodName
CEN -X- _ I-MethodName
) -X- _ I-MethodName
, -X- _ O
which -X- _ O
uses -X- _ O
a -X- _ O
length -X- _ O
- -X- _ O
aware -X- _ O
Convolutional -X- _ B-MethodName
Neural -X- _ I-MethodName
Network -X- _ I-MethodName
( -X- _ I-MethodName
CNN -X- _ I-MethodName
) -X- _ I-MethodName
to -X- _ O
handle -X- _ O
evolutional -X- _ O
patterns -X- _ O
of -X- _ O
different -X- _ O
lengths -X- _ O
via -X- _ O
an -X- _ O
easy -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
difficult -X- _ O
curriculum -X- _ O
learning -X- _ O
strategy -X- _ O
. -X- _ O

Existing -X- _ O
models -X- _ O
for -X- _ O
TKG -X- _ B-TaskName
reasoning -X- _ I-TaskName
focus -X- _ O
on -X- _ O
modeling -X- _ O
fact -X- _ O
sequences -X- _ O
of -X- _ O
a -X- _ O
fixed -X- _ O
length -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
not -X- _ O
discover -X- _ O
complex -X- _ O
evolutional -X- _ O
patterns -X- _ O
that -X- _ O
vary -X- _ O
in -X- _ O
length -X- _ O
. -X- _ O

One -X- _ O
key -X- _ O
of -X- _ O
this -X- _ O
task -X- _ O
is -X- _ O
to -X- _ O
mine -X- _ O
and -X- _ O
understand -X- _ O
evolutional -X- _ O
patterns -X- _ O
of -X- _ O
facts -X- _ O
from -X- _ O
these -X- _ O
sequences -X- _ O
. -X- _ O

TKG -X- _ B-MethodName
reasoning -X- _ I-MethodName
aims -X- _ O
to -X- _ O
predict -X- _ O
potential -X- _ O
facts -X- _ O
in -X- _ O
the -X- _ O
future -X- _ O
given -X- _ O
the -X- _ O
historical -X- _ O
KG -X- _ O
sequences -X- _ O
. -X- _ O

Both -X- _ O
methods -X- _ O
allow -X- _ O
adding -X- _ O
only -X- _ O
a -X- _ O
small -X- _ O
number -X- _ O
of -X- _ O
trainable -X- _ O
parameters -X- _ O
per -X- _ O
- -X- _ O
task -X- _ O
( -X- _ O
criteria -X- _ O
ii -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
each -X- _ O
task -X- _ O
can -X- _ O
be -X- _ O
added -X- _ O
without -X- _ O
revisiting -X- _ O
previous -X- _ O
ones -X- _ O
( -X- _ O
criteria -X- _ O
iii -X- _ O
) -X- _ O
. -X- _ O

2.Changing -X- _ O
the -X- _ O
same -X- _ O
set -X- _ O
of -X- _ O
parameters -X- _ O
for -X- _ O
every -X- _ O
tasks -X- _ O
( -X- _ O
task -X- _ O
- -X- _ O
invariance).3.The -X- _ O
changed -X- _ O
parameters -X- _ O
are -X- _ O
both -X- _ O
isolated -X- _ O
and -X- _ O
localized -X- _ O
across -X- _ O
the -X- _ O
entire -X- _ O
parameter -X- _ O
space -X- _ O
. -X- _ O

The -X- _ O
large -X- _ O
size -X- _ O
of -X- _ O
these -X- _ O
models -X- _ O
make -X- _ O
them -X- _ O
expensive -X- _ O
to -X- _ O
train -X- _ O
and -X- _ O
, -X- _ O
more -X- _ O
importantly -X- _ O
, -X- _ O
expensive -X- _ O
to -X- _ O
deploy -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
difference -X- _ O
of -X- _ O
opinion -X- _ O
it -X- _ O
is -X- _ O
unclear -X- _ O
which -X- _ O
method -X- _ O
is -X- _ O
actually -X- _ O
better -X- _ O
; -X- _ O
we -X- _ O
leave -X- _ O
this -X- _ O
to -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O

We -X- _ O
leave -X- _ O
it -X- _ O
to -X- _ O
future -X- _ O
work -X- _ O
to -X- _ O
examine -X- _ O
how -X- _ O
the -X- _ O
size -X- _ B-HyperparameterName
heuristic -X- _ I-HyperparameterName
may -X- _ O
hold -X- _ O
when -X- _ O
using -X- _ O
more -X- _ O
than -X- _ O
two -X- _ O
datasets -X- _ O
at -X- _ O
a -X- _ O
time -X- _ O
. -X- _ O

Datasets -X- _ O
are -X- _ O
ordered -X- _ O
in -X- _ O
descending -X- _ O
size -X- _ O
. -X- _ O

We -X- _ O
examine -X- _ O
two -X- _ O
works -X- _ O
in -X- _ O
depth -X- _ O
and -X- _ O
then -X- _ O
discuss -X- _ O
broader -X- _ O
themes -X- _ O
of -X- _ O
related -X- _ O
work -X- _ O
. -X- _ O

Although -X- _ O
this -X- _ O
section -X- _ O
is -X- _ O
not -X- _ O
crucial -X- _ O
to -X- _ O
the -X- _ O
main -X- _ O
result -X- _ O
of -X- _ O
our -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
include -X- _ O
it -X- _ O
to -X- _ O
help -X- _ O
readers -X- _ O
who -X- _ O
may -X- _ O
not -X- _ O
be -X- _ O
as -X- _ O
familiar -X- _ O
with -X- _ O
the -X- _ O
related -X- _ O
work -X- _ O
. -X- _ O

Our -X- _ O
work -X- _ O
aims -X- _ O
to -X- _ O
show -X- _ O
what -X- _ O
happens -X- _ O
in -X- _ O
practice -X- _ O
, -X- _ O
rather -X- _ O
than -X- _ O
proposing -X- _ O
a -X- _ O
theoretical -X- _ O
framework -X- _ O
. -X- _ O

We -X- _ O
thus -X- _ O
note -X- _ O
that -X- _ O
there -X- _ O
are -X- _ O
a -X- _ O
myriad -X- _ O
of -X- _ O
possible -X- _ O
explanations -X- _ O
( -X- _ O
and -X- _ O
the -X- _ O
answer -X- _ O
is -X- _ O
likely -X- _ O
a -X- _ O
complex -X- _ O
combination -X- _ O
of -X- _ O
possible -X- _ O
explanations -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
these -X- _ O
are -X- _ O
out -X- _ O
of -X- _ O
the -X- _ O
scope -X- _ O
of -X- _ O
this -X- _ O
work -X- _ O
. -X- _ O

One -X- _ O
potential -X- _ O
explanation -X- _ O
based -X- _ O
on -X- _ O
our -X- _ O
results -X- _ O
is -X- _ O
that -X- _ O
a -X- _ O
small -X- _ O
supporting -X- _ O
task -X- _ O
is -X- _ O
best -X- _ O
used -X- _ O
to -X- _ O
provide -X- _ O
a -X- _ O
good -X- _ O
ini-278 -X- _ O
. -X- _ O

We -X- _ O
find -X- _ O
that -X- _ O
on -X- _ O
almost -X- _ O
every -X- _ O
task -X- _ O
, -X- _ O
pairwise -X- _ O
approaches -X- _ O
are -X- _ O
better -X- _ O
than -X- _ O
MTL -X- _ B-MethodName
All -X- _ I-MethodName
. -X- _ O

Note -X- _ O
that -X- _ O
MTL -X- _ B-MethodName
Allwas -X- _ I-MethodName
run -X- _ O
with -X- _ O
three -X- _ O
different -X- _ O
sampling -X- _ O
methods -X- _ O
( -X- _ O
top -X- _ O
half -X- _ O
) -X- _ O
. -X- _ O

All -X- _ O
scores -X- _ O
are -X- _ O
the -X- _ O
average -X- _ O
of -X- _ O
5 -X- _ B-HyperparameterValue
random -X- _ B-HyperparameterName
seeds -X- _ I-HyperparameterName
. -X- _ O

Pairwise -X- _ B-TaskName
Oracle -X- _ I-TaskName
uses -X- _ O
the -X- _ O
best -X- _ O
supplementary -X- _ O
task -X- _ O
for -X- _ O
the -X- _ O
given -X- _ O
target -X- _ O
task -X- _ O
using -X- _ O
the -X- _ O
best -X- _ O
pairwise -X- _ O
method -X- _ O
( -X- _ O
STILTs -X- _ B-MethodName
or -X- _ O
MTL -X- _ B-MethodName
) -X- _ O
. -X- _ O

is -X- _ O
better -X- _ O
than -X- _ O
intermediate -X- _ B-MethodName
fine -X- _ I-MethodName
tuning -X- _ I-MethodName
when -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
is -X- _ O
smaller -X- _ O
than -X- _ O
the -X- _ O
supporting -X- _ O
task -X- _ O
and -X- _ O
vice -X- _ O
versa -X- _ O
. -X- _ O

Potential -X- _ O
theories -X- _ O
suggested -X- _ O
by -X- _ O
our -X- _ O
results -X- _ O
are -X- _ O
discussed -X- _ O
in -X- _ O
Appendix -X- _ O
C -X- _ O
, -X- _ O
and -X- _ O
are -X- _ O
left -X- _ O
to -X- _ O
guide -X- _ O
those -X- _ O
efforts -X- _ O
. -X- _ O

As -X- _ O
our -X- _ O
task -X- _ O
is -X- _ O
different -X- _ O
, -X- _ O
theoretical -X- _ O
explanations -X- _ O
for -X- _ O
how -X- _ O
these -X- _ O
methods -X- _ O
work -X- _ O
in -X- _ O
relation -X- _ O
to -X- _ O
each -X- _ O
other -X- _ O
will -X- _ O
need -X- _ O
to -X- _ O
be -X- _ O
explored -X- _ O
in -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O

Bold -X- _ O
scores -X- _ O
indicate -X- _ O
the -X- _ O
best -X- _ O
score -X- _ O
in -X- _ O
the -X- _ O
column -X- _ O
, -X- _ O
excluding -X- _ O
the -X- _ O
oracle -X- _ O
. -X- _ O

We -X- _ O
recognize -X- _ O
that -X- _ O
this -X- _ O
size -X- _ O
heuristic -X- _ O
is -X- _ O
not -X- _ O
an -X- _ O
absolute -X- _ O
law -X- _ O
, -X- _ O
but -X- _ O
merely -X- _ O
a -X- _ O
good -X- _ O
heuristic -X- _ O
that -X- _ O
does -X- _ O
so -X- _ O
with -X- _ O
high -X- _ O
accuracy -X- _ B-MetricName
: -X- _ O
there -X- _ O
are -X- _ O
still -X- _ O
other -X- _ O
pieces -X- _ O
to -X- _ O
this -X- _ O
puzzle -X- _ O
that -X- _ O
this -X- _ O
work -X- _ O
does -X- _ O
not -X- _ O
consider -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
dataset -X- _ B-HyperparameterName
similarity -X- _ I-HyperparameterName
. -X- _ O

Unfortunately -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
clear -X- _ O
answer -X- _ O
to -X- _ O
why -X- _ O
those -X- _ O
four -X- _ O
cells -X- _ O
are -X- _ O
misclassified -X- _ O
. -X- _ O

We -X- _ O
note -X- _ O
that -X- _ O
this -X- _ O
approach -X- _ O
does -X- _ O
not -X- _ O
hold -X- _ O
on -X- _ O
the -X- _ O
cells -X- _ O
that -X- _ O
have -X- _ O
no -X- _ O
statistically -X- _ O
significa -X- _ O
nt -X- _ O
difference -X- _ O
between -X- _ O
the -X- _ O
two -X- _ O
methods -X- _ O
: -X- _ O
but -X- _ O
for -X- _ O
almost -X- _ O
every -X- _ O
significant -X- _ O
cell -X- _ O
, -X- _ O
it -X- _ O
does -X- _ O
. -X- _ O

To -X- _ O
more -X- _ O
clearly -X- _ O
visualize -X- _ O
which -X- _ O
cells -X- _ O
it -X- _ O
fails -X- _ O
to -X- _ O
predict -X- _ O
accurately -X- _ O
, -X- _ O
those -X- _ O
four -X- _ O
cells -X- _ O
are -X- _ O
indicated -X- _ O
with -X- _ O
red -X- _ O
text -X- _ O
. -X- _ O

The -X- _ O
number -X- _ O
of -X- _ O
green -X- _ O
cells -X- _ O
in -X- _ O
a -X- _ O
row -X- _ O
is -X- _ O
highly -X- _ O
correlated -X- _ O
with -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
dataset -X- _ O
represented -X- _ O
by -X- _ O
that -X- _ O
row -X- _ O
. -X- _ O

We -X- _ O
note -X- _ O
that -X- _ O
although -X- _ O
some -X- _ O
differences -X- _ O
are -X- _ O
large -X- _ O
( -X- _ O
e.g -X- _ O
. -X- _ O

For -X- _ O
details -X- _ O
regarding -X- _ O
model -X- _ O
and -X- _ O
compute -X- _ O
parameters -X- _ O
, -X- _ O
see -X- _ O
Appendix -X- _ O
A -X- _ O
. -X- _ O

We -X- _ O
train -X- _ O
each -X- _ O
model -X- _ O
on -X- _ O
5 -X- _ B-HyperparameterValue
different -X- _ O
seeds -X- _ B-HyperparameterName
to -X- _ O
control -X- _ O
for -X- _ O
randomness -X- _ O
( -X- _ O
Dodge -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
implement -X- _ O
all -X- _ O
methods -X- _ O
described -X- _ O
in -X- _ O
their -X- _ O
paper -X- _ O
and -X- _ O
experimented -X- _ O
with -X- _ O
several -X- _ O
approaches -X- _ O
( -X- _ O
sampling -X- _ O
by -X- _ O
size -X- _ O
, -X- _ O
uniformity -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
) -X- _ O
. -X- _ O

Numbers -X- _ O
in -X- _ O
red -X- _ O
indicate -X- _ O
the -X- _ O
cells -X- _ O
where -X- _ O
the -X- _ O
size -X- _ B-HyperparameterName
heuristic -X- _ I-HyperparameterName
does -X- _ O
not -X- _ O
work -X- _ O
. -X- _ O

We -X- _ O
believe -X- _ O
that -X- _ O
this -X- _ O
analysis -X- _ O
will -X- _ O
help -X- _ O
NLP -X- _ B-TaskName
researchers -X- _ O
to -X- _ O
make -X- _ O
better -X- _ O
decisions -X- _ O
when -X- _ O
choosing272 -X- _ O
. -X- _ O

To -X- _ O
confirm -X- _ O
the -X- _ O
validity -X- _ O
of -X- _ O
the -X- _ O
size -X- _ B-HyperparameterName
heuristic -X- _ I-HyperparameterName
, -X- _ O
we -X- _ O
additionally -X- _ O
perform -X- _ O
a -X- _ O
targeted -X- _ O
experiment -X- _ O
varying -X- _ O
dataset -X- _ O
size -X- _ O
for -X- _ O
two -X- _ O
of -X- _ O
the -X- _ O
datasets -X- _ O
, -X- _ O
showing -X- _ O
that -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
crossover -X- _ O
point -X- _ O
in -X- _ O
performance -X- _ O
between -X- _ O
the -X- _ O
two -X- _ O
methods -X- _ O
when -X- _ O
the -X- _ O
dataset -X- _ O
sizes -X- _ O
are -X- _ O
equal -X- _ O
. -X- _ O

A.5 -X- _ O
SQuAD -X- _ O
F1 -X- _ O
Results -X- _ O
Figure -X- _ O
6 -X- _ O
: -X- _ O
Comparison -X- _ O
of -X- _ O
BitFit -X- _ B-MethodName
and -X- _ O
Full -X- _ B-MethodName
- -X- _ I-MethodName
FT -X- _ I-MethodName
with -X- _ O
BERT -X- _ B-MethodName
BASE -X- _ I-MethodName
F1 -X- _ B-MetricName
score -X- _ I-MetricName
on -X- _ O
SQuAD -X- _ B-DatasetName
validation -X- _ O
set.9 -X- _ O
. -X- _ O

Figure -X- _ O
5 -X- _ O
: -X- _ O
Change -X- _ O
in -X- _ O
bias -X- _ O
components -X- _ O
( -X- _ O
STS -X- _ B-TaskName
- -X- _ I-TaskName
B -X- _ I-TaskName
task -X- _ O
) -X- _ O
. -X- _ O

Figure -X- _ O
4 -X- _ O
: -X- _ O
Change -X- _ O
in -X- _ O
bias -X- _ O
components -X- _ O
( -X- _ O
MRPC -X- _ B-TaskName
task -X- _ O
) -X- _ O
. -X- _ O

Figure -X- _ O
3 -X- _ O
: -X- _ O
Change -X- _ O
in -X- _ O
bias -X- _ O
components -X- _ O
( -X- _ O
CoLA -X- _ B-TaskName
task -X- _ O
) -X- _ O
. -X- _ O

A.4 -X- _ O
Amount -X- _ O
of -X- _ O
change -X- _ O
in -X- _ O
bias -X- _ B-HyperparameterName
terms8 -X- _ I-HyperparameterName
. -X- _ O

For -X- _ O
all -X- _ O
the -X- _ O
experiments -X- _ O
we -X- _ O
used -X- _ O
the -X- _ O
common -X- _ O
train -X- _ O
: -X- _ O
dev -X- _ O
: -X- _ O
test -X- _ O
partition -X- _ O
of -X- _ O
GLUE -X- _ B-DatasetName
. -X- _ O

Learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
configurations -X- _ O
for -X- _ O
best -X- _ O
performing -X- _ O
models -X- _ O
are -X- _ O
in -X- _ O
Table -X- _ O
6 -X- _ O
. -X- _ O

The -X- _ O
metrics -X- _ O
that -X- _ O
we -X- _ O
used -X- _ O
to -X- _ O
evaluate -X- _ O
GLUE -X- _ B-DatasetName
Benchmark -X- _ O
are -X- _ O
in -X- _ O
Table -X- _ O
5 -X- _ O
. -X- _ O

We -X- _ O
test -X- _ O
our -X- _ O
approach -X- _ O
on -X- _ O
the -X- _ O
following -X- _ O
subset -X- _ O
of -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
tasks -X- _ O
: -X- _ O
The -X- _ O
Corpus -X- _ B-DatasetName
of -X- _ I-DatasetName
Linguistic -X- _ I-DatasetName
Acceptability -X- _ I-DatasetName
( -X- _ O
CoLA -X- _ B-DatasetName
; -X- _ O
Warstadt -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
) -X- _ O
, -X- _ O
The -X- _ O
Stanford -X- _ B-DatasetName
Sentiment -X- _ I-DatasetName
Treebank -X- _ I-DatasetName
( -X- _ O
SST2 -X- _ B-DatasetName
; -X- _ O
Socher -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2013 -X- _ O
) -X- _ O
) -X- _ O
, -X- _ O
The -X- _ O
Microsoft -X- _ B-DatasetName
Research -X- _ I-DatasetName
Paraphrase -X- _ I-DatasetName
Corpus -X- _ I-DatasetName
( -X- _ O
MRPC -X- _ B-DatasetName
; -X- _ O
Dolan -X- _ O
and -X- _ O
Brockett -X- _ O
( -X- _ O
2005 -X- _ O
) -X- _ O
) -X- _ O
, -X- _ O
The -X- _ O
Quora -X- _ B-DatasetName
Question -X- _ I-DatasetName
Pairs -X- _ I-DatasetName
( -X- _ O
QQP -X- _ B-DatasetName
; -X- _ O
Iyer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
) -X- _ O
, -X- _ O
The -X- _ O
Semantic -X- _ B-DatasetName
Textual -X- _ I-DatasetName
Similarity -X- _ I-DatasetName
Benchmark -X- _ I-DatasetName
( -X- _ O
STS -X- _ B-DatasetName
- -X- _ I-DatasetName
B -X- _ I-DatasetName
; -X- _ O
Cer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
) -X- _ O
, -X- _ O
The -X- _ O
Multi -X- _ B-DatasetName
- -X- _ I-DatasetName
Genre -X- _ I-DatasetName
Natural -X- _ I-DatasetName
Language -X- _ I-DatasetName
Inference -X- _ I-DatasetName
Corpus -X- _ I-DatasetName
( -X- _ O
MNLI -X- _ B-DatasetName
; -X- _ O
Bowman -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2015 -X- _ O
) -X- _ O
) -X- _ O
, -X- _ O
The -X- _ O
Stanford -X- _ B-DatasetName
Question -X- _ I-DatasetName
Answering -X- _ I-DatasetName
Dataset -X- _ I-DatasetName
( -X- _ O
QNLI -X- _ B-DatasetName
; -X- _ O
Rajpurkar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2016b -X- _ O
) -X- _ O
) -X- _ O
and -X- _ O
The -X- _ O
Recognizing -X- _ B-DatasetName
Textual -X- _ I-DatasetName
Entailment -X- _ I-DatasetName
( -X- _ O
RTE -X- _ B-DatasetName
; -X- _ O
Dagan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2005 -X- _ O
) -X- _ O
) -X- _ O
. -X- _ O

A.3 -X- _ O
GLUE -X- _ B-DatasetName
Benchmark -X- _ O
We -X- _ O
provide -X- _ O
information -X- _ O
on -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
tasks -X- _ O
we -X- _ O
evaluated -X- _ O
on -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
on -X- _ O
the -X- _ O
evaluation -X- _ O
metrics -X- _ O
. -X- _ O

BitFit -X- _ B-MethodName
allows -X- _ O
for -X- _ O
the -X- _ O
usage -X- _ O
of -X- _ O
bigger -X- _ O
learning -X- _ O
rates -X- _ O
, -X- _ O
and -X- _ O
overall -X- _ O
the -X- _ O
optimization -X- _ O
process -X- _ O
is -X- _ O
much -X- _ O
more -X- _ O
stable -X- _ O
, -X- _ O
when -X- _ O
comparedTask -X- _ O
Name -X- _ O
Metric -X- _ O
QNLI -X- _ B-TaskName
acc -X- _ B-MetricName
. -X- _ O

As -X- _ O
Mosbach -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
show -X- _ O
, -X- _ O
fine -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
BERT -X- _ B-TaskName
LARGE -X- _ I-TaskName
and -X- _ O
RoBERTa -X- _ B-TaskName
BASE -X- _ I-TaskName
is -X- _ O
a -X- _ O
unstable -X- _ O
due -X- _ O
to -X- _ O
vanishing -X- _ O
gradients -X- _ O
. -X- _ O

To -X- _ O
perform -X- _ O
classification -X- _ O
with -X- _ O
RoBERTa -X- _ B-MethodName
BASE -X- _ I-MethodName
, -X- _ O
we -X- _ O
follow -X- _ O
the -X- _ O
above -X- _ O
details -X- _ O
but -X- _ O
without -X- _ O
hyperparameter -X- _ O
search -X- _ O
over -X- _ O
the -X- _ O
learning -X- _ O
rates -X- _ O
, -X- _ O
for -X- _ O
bias -X- _ B-MethodName
- -X- _ I-MethodName
only -X- _ I-MethodName
fine -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
we -X- _ O
used -X- _ O
1e-4 -X- _ B-HyperparameterValue
as -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
and -X- _ O
for -X- _ O
full -X- _ B-MethodName
fine -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
we -X- _ O
used -X- _ O
1e-5 -X- _ B-HyperparameterValue
as -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
. -X- _ O

In -X- _ O
each -X- _ O
evaluation -X- _ O
we -X- _ O
report -X- _ O
XY -X- _ O
where -X- _ O
X -X- _ O
is -X- _ O
the -X- _ O
average -X- _ O
result -X- _ O
for -X- _ O
training -X- _ O
5 -X- _ O
models -X- _ O
with -X- _ O
5 -X- _ B-HyperparameterValue
different -X- _ O
random -X- _ B-HyperparameterName
seeds -X- _ I-HyperparameterName
, -X- _ O
Y -X- _ O
is -X- _ O
the -X- _ O
standard -X- _ B-HyperparameterName
deviation -X- _ I-HyperparameterName
. -X- _ O

We -X- _ O
did -X- _ O
not -X- _ O
perform -X- _ O
hyperparameter -X- _ O
optimization -X- _ O
beyond -X- _ O
the -X- _ O
minimal -X- _ O
search -X- _ O
over -X- _ O
4 -X- _ O
learning -X- _ O
rates -X- _ O
. -X- _ O

With -X- _ O
the -X- _ O
larger -X- _ O
learning -X- _ O
rates -X- _ O
, -X- _ O
the -X- _ O
bias -X- _ B-MethodName
- -X- _ I-MethodName
only -X- _ I-MethodName
fine -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
converged -X- _ O
in -X- _ O
8 -X- _ B-HyperparameterValue
or -X- _ O
fewer -X- _ O
epochs -X- _ B-HyperparameterName
for -X- _ O
most -X- _ O
tasks -X- _ O
, -X- _ O
and -X- _ O
up -X- _ O
to -X- _ O
20 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
on -X- _ O
the -X- _ O
others -X- _ O
. -X- _ O

For -X- _ O
full -X- _ O
finetuning -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
initial -X- _ O
learning -X- _ B-HyperparameterName
rates -X- _ I-HyperparameterName
in -X- _ O
{ -X- _ O
1e-5 -X- _ B-HyperparameterValue
, -X- _ O
2e-5 -X- _ B-HyperparameterValue
, -X- _ O
3e-5 -X- _ B-HyperparameterValue
, -X- _ O
5e-5 -X- _ B-HyperparameterValue
} -X- _ O
, -X- _ O
and -X- _ O
for -X- _ O
the -X- _ O
bias -X- _ O
- -X- _ O
only -X- _ O
experiments -X- _ O
we -X- _ O
used -X- _ O
initial -X- _ O
learning -X- _ B-HyperparameterName
rates -X- _ I-HyperparameterName
in -X- _ O
{ -X- _ O
1e-4 -X- _ B-HyperparameterValue
, -X- _ O
4e-4 -X- _ B-HyperparameterValue
, -X- _ O
7e-4 -X- _ B-HyperparameterValue
, -X- _ O
1e3}as -X- _ B-HyperparameterValue
the -X- _ O
smaller -X- _ O
rates -X- _ O
took -X- _ O
a -X- _ O
very -X- _ O
long -X- _ O
time -X- _ O
to -X- _ O
converge -X- _ O
on -X- _ O
some -X- _ O
of -X- _ O
the -X- _ O
tasks -X- _ O
. -X- _ O

We -X- _ O
optimize -X- _ O
using -X- _ O
AdamW -X- _ B-MethodName
( -X- _ O
Loshchilov -X- _ O
and -X- _ O
Hutter -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
with -X- _ O
batch -X- _ B-HyperparameterName
sizes -X- _ I-HyperparameterName
of -X- _ O
16 -X- _ B-HyperparameterValue
. -X- _ O

The -X- _ O
GLUE -X- _ B-DatasetName
tasks -X- _ O
are -X- _ O
fed -X- _ O
into -X- _ O
BERT -X- _ B-MethodName
using -X- _ O
the -X- _ O
standard -X- _ O
procedures -X- _ O
. -X- _ O

A.2 -X- _ O
Training -X- _ O
Details -X- _ O
To -X- _ O
perform -X- _ O
classification -X- _ O
with -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
we -X- _ O
follow -X- _ O
the -X- _ O
approach -X- _ O
of -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
attach -X- _ O
a -X- _ O
linear -X- _ O
layer -X- _ O
to -X- _ O
the -X- _ O
contextual -X- _ O
embedding -X- _ O
of -X- _ O
the -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
token -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
label -X- _ O
. -X- _ O

A -X- _ O
Appendices -X- _ O
A.1 -X- _ O
Layer -X- _ O
naming -X- _ O
For -X- _ O
convenience -X- _ O
, -X- _ O
we -X- _ O
relate -X- _ O
the -X- _ O
notation -X- _ O
used -X- _ O
in -X- _ O
the -X- _ O
paper -X- _ O
with -X- _ O
the -X- _ O
names -X- _ O
of -X- _ O
the -X- _ O
corresponding -X- _ O
parameters -X- _ O
in -X- _ O
the -X- _ O
popular -X- _ O
HuggingFace -X- _ O
( -X- _ O
Wolf -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
implementation -X- _ O
. -X- _ O

Masking -X- _ O
as -X- _ O
an -X- _ O
efficient -X- _ O
alternative -X- _ O
to -X- _ O
finetuning -X- _ B-MethodName
for -X- _ O
pretrained -X- _ B-TaskName
language -X- _ I-TaskName
models -X- _ I-TaskName
. -X- _ O

Besides -X- _ O
its -X- _ O
empirical -X- _ O
utility -X- _ O
, -X- _ O
the -X- _ O
remarkable -X- _ O
effectiveness -X- _ O
of -X- _ O
bias -X- _ O
- -X- _ O
only -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
raises -X- _ O
intriguing -X- _ O
questions -X- _ O
on -X- _ O
the -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
dynamics -X- _ O
of -X- _ O
pretrained -X- _ O
transformers -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
relation -X- _ O
between -X- _ O
the -X- _ O
bias -X- _ B-HyperparameterName
terms -X- _ I-HyperparameterName
and -X- _ O
transfer -X- _ O
between -X- _ O
LM -X- _ B-MethodName
and -X- _ O
new -X- _ O
tasks -X- _ O
. -X- _ O

It -X- _ O
also -X- _ O
allows -X- _ O
for -X- _ O
efficient -X- _ O
hardware -X- _ O
implementations -X- _ O
that -X- _ O
hard -X- _ O
- -X- _ O
wire -X- _ O
5Indeed -X- _ O
, -X- _ O
the -X- _ O
equations -X- _ O
in -X- _ O
the -X- _ O
paper -X- _ O
introducing -X- _ O
the -X- _ O
Transformer -X- _ B-MethodName
model -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
do -X- _ O
not -X- _ O
include -X- _ O
bias -X- _ B-HyperparameterName
terms -X- _ I-HyperparameterName
at -X- _ O
all -X- _ O
, -X- _ O
and -X- _ O
their -X- _ O
existence -X- _ O
in -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
models -X- _ O
might -X- _ O
as -X- _ O
well -X- _ O
be -X- _ O
a -X- _ O
fortunate -X- _ O
mistake.most -X- _ O
of -X- _ O
the -X- _ O
network -X- _ O
computation -X- _ O
with -X- _ O
the -X- _ O
pretrained -X- _ O
weights -X- _ O
, -X- _ O
while -X- _ O
only -X- _ O
allowing -X- _ O
few -X- _ O
changeable -X- _ O
parts -X- _ O
for -X- _ O
inference -X- _ O
time -X- _ O
. -X- _ O

The -X- _ O
focus -X- _ O
on -X- _ O
modifying -X- _ O
a -X- _ O
small -X- _ O
group -X- _ O
of -X- _ O
parameters -X- _ O
eases -X- _ O
deployment -X- _ O
, -X- _ O
as -X- _ O
the -X- _ O
vast -X- _ O
majority -X- _ O
of -X- _ O
the -X- _ O
parameters -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
are -X- _ O
shared -X- _ O
between -X- _ O
various -X- _ O
NLP -X- _ B-TaskName
tasks -X- _ O
. -X- _ O

The -X- _ O
method -X- _ O
focuses -X- _ O
the -X- _ O
finetuning -X- _ O
on -X- _ O
a -X- _ O
specific -X- _ O
fraction -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
parametersthe -X- _ O
biases -X- _ O
and -X- _ O
maintains -X- _ O
good -X- _ O
performance -X- _ O
in -X- _ O
all -X- _ O
GLUE -X- _ B-DatasetName
tasks -X- _ O
we -X- _ O
evaluated -X- _ O
on -X- _ O
. -X- _ O

6 -X- _ O
Conclusions -X- _ O
We -X- _ O
propose -X- _ O
BitFit -X- _ B-MethodName
, -X- _ O
a -X- _ O
novel -X- _ O
method -X- _ O
for -X- _ O
localized -X- _ O
, -X- _ O
fast -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
of -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
transformers -X- _ O
for -X- _ O
endtasks -X- _ O
. -X- _ O

Our -X- _ O
work -X- _ O
empirically -X- _ O
shows -X- _ O
the -X- _ O
importance -X- _ O
and -X- _ O
power -X- _ O
of -X- _ O
the -X- _ O
bias -X- _ O
parameters -X- _ O
to -X- _ O
substantially -X- _ O
change -X- _ O
the -X- _ O
networks -X- _ O
behavior -X- _ O
, -X- _ O
calling -X- _ O
for -X- _ O
further -X- _ O
analysis -X- _ O
and -X- _ O
attention -X- _ O
on -X- _ O
the -X- _ O
bias -X- _ B-HyperparameterName
terms -X- _ I-HyperparameterName
. -X- _ O

Finally -X- _ O
, -X- _ O
and -X- _ O
closest -X- _ O
to -X- _ O
our -X- _ O
work -X- _ O
, -X- _ O
Cai -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
demonstrate -X- _ O
that -X- _ O
bias -X- _ B-MethodName
- -X- _ I-MethodName
only -X- _ I-MethodName
fine -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
similar -X- _ O
to -X- _ O
ours -X- _ O
is -X- _ O
effective -X- _ O
also -X- _ O
for -X- _ O
adaptation -X- _ O
of -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
computer -X- _ O
vision -X- _ O
models -X- _ O
. -X- _ O

Michel -X- _ O
and -X- _ O
Neubig -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
finetuned -X- _ O
the -X- _ O
biases -X- _ O
of -X- _ O
the -X- _ O
output -X- _ O
softmax -X- _ O
in -X- _ O
an -X- _ O
NMT -X- _ B-TaskName
systems -X- _ O
, -X- _ O
to -X- _ O
personalize -X- _ O
the -X- _ O
output -X- _ O
vocabulary -X- _ O
, -X- _ O
and -X- _ O
Frankle -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
have -X- _ O
demonstrated -X- _ O
that -X- _ O
randomly -X- _ O
- -X- _ O
initialized -X- _ O
CNNs -X- _ B-MethodName
achieve -X- _ O
reasonable -X- _ O
accuracy -X- _ B-MetricName
after -X- _ O
training -X- _ O
the -X- _ O
batch -X- _ O
- -X- _ O
norm -X- _ O
layers -X- _ O
alone -X- _ O
. -X- _ O

They -X- _ O
demonstrate -X- _ O
that -X- _ O
the -X- _ O
last -X- _ O
layer -X- _ O
bias -X- _ O
values -X- _ O
are -X- _ O
responsible -X- _ O
for -X- _ O
the -X- _ O
predicted -X- _ O
class -X- _ O
, -X- _ O
and -X- _ O
propose -X- _ O
a -X- _ O
way -X- _ O
to -X- _ O
back -X- _ B-MethodName
- -X- _ I-MethodName
propagate -X- _ I-MethodName
their -X- _ O
importance -X- _ O
. -X- _ O

An -X- _ O
exception -X- _ O
is -X- _ O
the -X- _ O
work -X- _ O
of -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
who -X- _ O
analyzed -X- _ O
bias -X- _ B-HyperparameterName
terms -X- _ I-HyperparameterName
from -X- _ O
the -X- _ O
perspective -X- _ O
of -X- _ O
attribution -X- _ O
method -X- _ O
. -X- _ O

Bias -X- _ O
terms -X- _ O
Bias -X- _ B-HyperparameterName
terms -X- _ I-HyperparameterName
and -X- _ O
their -X- _ O
importance -X- _ O
are -X- _ O
rarely -X- _ O
discussed -X- _ O
in -X- _ O
the -X- _ O
literature.5Zhao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
describe -X- _ O
a -X- _ O
masking -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
fine -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
method -X- _ O
, -X- _ O
and -X- _ O
explicitly -X- _ O
mention -X- _ O
ignoring -X- _ O
the -X- _ O
bias -X- _ B-HyperparameterName
terms -X- _ I-HyperparameterName
, -X- _ O
as -X- _ O
handling -X- _ O
them -X- _ O
did -X- _ O
not -X- _ O
observe -X- _ O
a -X- _ O
positive -X- _ O
effect -X- _ O
on -X- _ O
performance -X- _ O
. -X- _ O

The -X- _ O
remarkable -X- _ O
success -X- _ O
of -X- _ O
those -X- _ O
works -X- _ O
have -X- _ O
sparked -X- _ O
interest -X- _ O
the -X- _ O
lottery -X- _ O
- -X- _ O
ticket -X- _ O
hypothesis -X- _ O
( -X- _ O
Frankle -X- _ O
and -X- _ O
Carbin -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Prasanna -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
): -X- _ O
the -X- _ O
conjecture -X- _ O
that -X- _ O
large -X- _ O
models -X- _ O
are -X- _ O
needed -X- _ O
in -X- _ O
pretraining -X- _ O
only -X- _ O
to -X- _ O
induce -X- _ O
( -X- _ O
in -X- _ O
high -X- _ O
probability -X- _ O
) -X- _ O
the -X- _ O
existing -X- _ O
of -X- _ O
sub -X- _ O
- -X- _ O
networks -X- _ O
initialized -X- _ O
with -X- _ O
the -X- _ O
correct -X- _ O
inductive -X- _ O
bias -X- _ O
for -X- _ O
learning -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
findings -X- _ O
that -X- _ O
those -X- _ O
sparse -X- _ O
networks -X- _ O
often -X- _ O
transfer -X- _ O
well -X- _ O
to -X- _ O
different -X- _ O
tasks -X- _ O
. -X- _ O

We -X- _ O
work -X- _ O
in -X- _ O
a -X- _ O
complementary -X- _ O
setting -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
entire -X- _ O
model -X- _ O
is -X- _ O
kept -X- _ O
, -X- _ O
but -X- _ O
only -X- _ O
some -X- _ O
parameters -X- _ O
are -X- _ O
updated -X- _ O
. -X- _ O

Gordon -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
have -X- _ O
demonstrated -X- _ O
that -X- _ O
overparmeterization -X- _ B-MethodName
can -X- _ O
be -X- _ O
exploited -X- _ O
in -X- _ O
finetuning -X- _ B-MethodName
: -X- _ O
pruned -X- _ O
network -X- _ O
perform4 -X- _ O
. -X- _ O

5 -X- _ O
Related -X- _ O
Work -X- _ O
The -X- _ O
problem -X- _ O
of -X- _ O
identifying -X- _ O
the -X- _ O
minimal -X- _ O
set -X- _ O
of -X- _ O
parameters -X- _ O
that -X- _ O
need -X- _ O
to -X- _ O
be -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
to -X- _ O
achieve -X- _ O
good -X- _ O
performance -X- _ O
in -X- _ O
end -X- _ B-TaskName
- -X- _ I-TaskName
tasks -X- _ I-TaskName
relates -X- _ O
both -X- _ O
to -X- _ O
practical -X- _ O
questions -X- _ O
of -X- _ O
model -X- _ O
compression -X- _ O
, -X- _ O
and -X- _ O
also -X- _ O
to -X- _ O
more -X- _ O
fundamental -X- _ O
question -X- _ O
on -X- _ O
the -X- _ O
nature -X- _ O
of -X- _ O
the -X- _ O
pre -X- _ B-MethodName
- -X- _ I-MethodName
training -X- _ I-MethodName
and -X- _ O
finetuning -X- _ B-MethodName
process -X- _ O
, -X- _ O
the -X- _ O
linguistic -X- _ O
knowledge -X- _ O
induced -X- _ O
by -X- _ O
each -X- _ O
of -X- _ O
them -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
extent -X- _ O
to -X- _ O
which -X- _ O
it -X- _ O
generalizes -X- _ O
to -X- _ O
different -X- _ O
tasks -X- _ O
. -X- _ O

conclude -X- _ O
that -X- _ O
BitFit -X- _ B-MethodName
is -X- _ O
a -X- _ O
worthwhile -X- _ O
targetted -X- _ O
finetuning -X- _ B-MethodName
method -X- _ O
in -X- _ O
small -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
medium -X- _ O
data -X- _ O
regimes -X- _ O
. -X- _ O

As -X- _ O
our -X- _ O
model -X- _ O
and -X- _ O
training -X- _ O
framework -X- _ O
are -X- _ O
different -X- _ O
from -X- _ O
their -X- _ O
methodology -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
not -X- _ O
compare -X- _ O
our -X- _ O
matrix -X- _ O
with -X- _ O
the -X- _ O
absolute -X- _ O
numbers -X- _ O
in -X- _ O
their -X- _ O
matrix -X- _ O
. -X- _ O

We -X- _ O
Figure -X- _ O
2 -X- _ O
: -X- _ O
Comparison -X- _ O
of -X- _ O
BitFit -X- _ B-MethodName
and -X- _ O
Full -X- _ B-MethodName
- -X- _ I-MethodName
FT -X- _ I-MethodName
with -X- _ O
BERT -X- _ B-MethodName
BASE -X- _ I-MethodName
exact -X- _ O
match -X- _ O
score -X- _ O
on -X- _ O
SQuAD -X- _ B-DatasetName
validation -X- _ O
set -X- _ O
. -X- _ O

The -X- _ O
results -X- _ O
on -X- _ O
Figure -X- _ O
2 -X- _ O
show -X- _ O
a -X- _ O
clear -X- _ O
trend -X- _ O
: -X- _ O
BitFit -X- _ B-MethodName
dominates -X- _ O
over -X- _ O
FullFT -X- _ B-TaskName
in -X- _ O
the -X- _ O
smaller -X- _ O
- -X- _ O
data -X- _ O
regime -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
trend -X- _ O
is -X- _ O
reversed -X- _ O
when -X- _ O
more -X- _ O
training -X- _ O
data -X- _ O
is -X- _ O
available -X- _ O
. -X- _ O

To -X- _ O
test -X- _ O
this -X- _ O
( -X- _ O
and -X- _ O
to -X- _ O
validate -X- _ O
another -X- _ O
token -X- _ O
- -X- _ O
level -X- _ O
task -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
on -X- _ O
increasing -X- _ O
- -X- _ O
sized -X- _ O
subsets -X- _ O
of -X- _ O
SQuAD -X- _ B-DatasetName
v1.0 -X- _ I-DatasetName
Rajpurkar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2016a -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
GLUE -X- _ B-DatasetName
results -X- _ O
suggest -X- _ O
a -X- _ O
reverse -X- _ O
correlation -X- _ O
between -X- _ O
BitFit -X- _ B-MethodName
ability -X- _ O
to -X- _ O
reach -X- _ O
Full -X- _ B-TaskName
- -X- _ I-TaskName
FT -X- _ I-TaskName
performance -X- _ O
, -X- _ O
and -X- _ O
training -X- _ O
set -X- _ O
size -X- _ O
. -X- _ O

Full -X- _ O
- -X- _ O
FT -X- _ B-TaskName
results -X- _ O
for -X- _ O
BERT -X- _ B-MethodName
BASE -X- _ I-MethodName
, -X- _ O
BERT -X- _ B-MethodName
LARGE -X- _ I-MethodName
and -X- _ O
RoBERTa -X- _ B-MethodName
BASE -X- _ I-MethodName
are -X- _ O
97.2 -X- _ B-MetricValue
, -X- _ O
97.4 -X- _ B-MetricValue
, -X- _ O
97.2 -X- _ B-MetricValue
, -X- _ O
while -X- _ O
BitFit -X- _ B-TaskName
results -X- _ O
are -X- _ O
97.2 -X- _ B-MetricValue
, -X- _ O
97.4 -X- _ B-MetricValue
, -X- _ O
97.1 -X- _ B-MetricValue
. -X- _ O

We -X- _ O
also -X- _ O
experimented -X- _ O
with -X- _ O
token -X- _ O
- -X- _ O
level -X- _ O
PTB -X- _ B-TaskName
POS -X- _ B-TaskName
- -X- _ I-TaskName
tagging -X- _ I-TaskName
. -X- _ O

The -X- _ O
GLUE -X- _ B-DatasetName
tasks -X- _ O
are -X- _ O
all -X- _ O
sentence -X- _ O
level -X- _ O
. -X- _ O

While -X- _ O
in -X- _ O
most -X- _ O
cases -X- _ O
full -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
reaches -X- _ O
nearly -X- _ O
100% -X- _ B-MetricValue
train -X- _ B-MetricName
accuracy -X- _ I-MetricName
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
generalization -X- _ O
gap -X- _ O
( -X- _ O
Shalev -X- _ O
- -X- _ O
Shwartz -X- _ O
and -X- _ O
Ben -X- _ O
- -X- _ O
David -X- _ O
, -X- _ O
2014)the -X- _ O
difference -X- _ O
between -X- _ O
training -X- _ O
error -X- _ O
and -X- _ O
test -X- _ O
erroris -X- _ O
substantially -X- _ O
smaller -X- _ O
for -X- _ O
the -X- _ O
BitFit -X- _ B-MethodName
models -X- _ O
. -X- _ O

As -X- _ O
expected -X- _ O
, -X- _ O
using -X- _ O
a -X- _ O
frozen -X- _ O
BERT -X- _ B-MethodName
BASE -X- _ I-MethodName
model -X- _ I-MethodName
yields -X- _ O
much -X- _ O
worse -X- _ O
results -X- _ O
. -X- _ O

Results -X- _ O
are -X- _ O
only -X- _ O
marginally -X- _ O
lower -X- _ O
than -X- _ O
when -X- _ O
tuning -X- _ O
all -X- _ O
bias -X- _ O
parameters -X- _ O
. -X- _ O

Table -X- _ O
3 -X- _ O
reports -X- _ O
devset -X- _ O
results -X- _ O
when -X- _ O
fine -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
only -X- _ O
the -X- _ O
b -X- _ O
( -X- _ O
) -X- _ O
qandb -X- _ O
( -X- _ O
) -X- _ O
m2 -X- _ O
bias -X- _ O
terms -X- _ O
, -X- _ O
for -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
BASE -X- _ I-MethodName
model -X- _ I-MethodName
. -X- _ O

In -X- _ O
contrast -X- _ O
, -X- _ O
bq -X- _ O
, -X- _ O
the -X- _ O
bias -X- _ O
of -X- _ O
the -X- _ O
queries -X- _ O
, -X- _ O
and -X- _ O
bm2 -X- _ O
, -X- _ O
the -X- _ O
bias -X- _ O
of -X- _ O
the -X- _ O
intermediate -X- _ O
MLP -X- _ B-MethodName
layers -X- _ I-MethodName
( -X- _ O
which -X- _ O
take -X- _ O
the -X- _ O
input -X- _ O
from -X- _ O
768 -X- _ O
- -X- _ O
dims -X- _ O
to -X- _ O
3072 -X- _ O
) -X- _ O
, -X- _ O
change -X- _ O
the -X- _ O
most -X- _ O
. -X- _ O

Reported -X- _ O
results -X- _ O
are -X- _ O
for -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
BASE -X- _ I-MethodName
model -X- _ O
. -X- _ O

Figure -X- _ O
1 -X- _ O
shows -X- _ O
the -X- _ O
change -X- _ O
per -X- _ O
bias -X- _ O
term -X- _ O
and -X- _ O
layer -X- _ O
, -X- _ O
for -X- _ O
the -X- _ O
RTE -X- _ B-TaskName
task -X- _ I-TaskName
( -X- _ O
other -X- _ O
tasks -X- _ O
look -X- _ O
very -X- _ O
similar -X- _ O
, -X- _ O
see -X- _ O
Appendix -X- _ O
A.4 -X- _ O
) -X- _ O
. -X- _ O

Fewer -X- _ O
bias -X- _ O
parameters -X- _ O
( -X- _ O
Table -X- _ O
3 -X- _ O
) -X- _ O
Can -X- _ O
we -X- _ O
finetune -X- _ O
on -X- _ O
only -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
the -X- _ O
bias -X- _ O
- -X- _ O
parameter -X- _ O
? -X- _ O
We -X- _ O
define -X- _ O
the -X- _ O
amount -X- _ O
of -X- _ O
change -X- _ O
in -X- _ O
a -X- _ O
bias -X- _ O
vector -X- _ O
bto -X- _ O
be1 -X- _ O
dim -X- _ O
( -X- _ O
b)b0bF1 -X- _ O
, -X- _ O
that -X- _ O
is -X- _ O
, -X- _ O
the -X- _ O
average -X- _ O
absolute -X- _ O
change -X- _ O
, -X- _ O
across -X- _ O
its -X- _ O
dimensions -X- _ O
, -X- _ O
between -X- _ O
the -X- _ O
initial -X- _ O
LM -X- _ B-MethodName
values -X- _ O
b0and -X- _ O
its -X- _ O
fine -X- _ B-MethodName
- -X- _ I-MethodName
tuned -X- _ I-MethodName
values -X- _ O
bF -X- _ O
. -X- _ O

The -X- _ O
results -X- _ O
are -X- _ O
substantially -X- _ O
worse -X- _ O
across -X- _ O
all -X- _ O
tasks -X- _ O
; -X- _ O
similar -X- _ O
patterns -X- _ O
are -X- _ O
observed -X- _ O
when -X- _ O
the -X- _ O
random -X- _ O
parameters -X- _ O
are -X- _ O
sampled -X- _ O
as -X- _ O
complete -X- _ O
rows -X- _ O
/ -X- _ O
columns -X- _ O
in -X- _ O
the -X- _ O
parameter -X- _ O
matrices -X- _ O
( -X- _ O
rand -X- _ O
row -X- _ O
/ -X- _ O
col -X- _ O
line -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
) -X- _ O
. -X- _ O

Are -X- _ O
bias -X- _ O
parameters -X- _ O
special -X- _ O
? -X- _ O
Are -X- _ O
the -X- _ O
bias -X- _ O
parameters -X- _ O
special -X- _ O
, -X- _ O
or -X- _ O
will -X- _ O
any -X- _ O
random -X- _ O
subset -X- _ O
do -X- _ O
? -X- _ O
We -X- _ O
randomly -X- _ O
sampled -X- _ O
the -X- _ O
same -X- _ O
amount -X- _ O
of -X- _ O
parameters -X- _ O
as -X- _ O
in -X- _ O
BitFit -X- _ B-MethodName
from -X- _ O
the -X- _ O
entire -X- _ O
model -X- _ O
, -X- _ O
and -X- _ B-MethodName
fine -X- _ I-MethodName
- -X- _ I-MethodName
tuned -X- _ I-MethodName
only -X- _ O
them -X- _ O
( -X- _ O
rand -X- _ O
uniform -X- _ O
line -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
results -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
trends -X- _ O
remain -X- _ O
consistent -X- _ O
. -X- _ O

Different -X- _ O
Base -X- _ O
- -X- _ O
models -X- _ O
( -X- _ O
Table -X- _ O
2 -X- _ O
) -X- _ O
We -X- _ O
repeat -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
LARGE -X- _ I-MethodName
results -X- _ O
on -X- _ O
different -X- _ O
base -X- _ O
- -X- _ O
models -X- _ O
( -X- _ O
the -X- _ O
smaller -X- _ O
BERT -X- _ B-MethodName
BASE -X- _ I-MethodName
and -X- _ O
the -X- _ O
better -X- _ O
performing -X- _ O
RoBERTa -X- _ B-MethodName
BASE -X- _ I-MethodName
) -X- _ O
. -X- _ O

Figure -X- _ O
1 -X- _ O
: -X- _ O
Change -X- _ O
in -X- _ O
bias -X- _ O
components -X- _ O
( -X- _ O
RTE -X- _ B-TaskName
task -X- _ I-TaskName
) -X- _ O
. -X- _ O

4QNLI -X- _ B-DatasetName
results -X- _ O
are -X- _ O
not -X- _ O
directly -X- _ O
comparable -X- _ O
, -X- _ O
as -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
benchmark -X- _ O
updated -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
since -X- _ O
then -X- _ O
. -X- _ O

3Appendix -X- _ O
A.3 -X- _ O
lists -X- _ O
the -X- _ O
tasks -X- _ O
and -X- _ O
evaluation -X- _ O
metrics -X- _ O
. -X- _ O

As -X- _ O
for -X- _ O
test -X- _ O
- -X- _ O
set -X- _ O
results -X- _ O
, -X- _ O
two -X- _ O
clear -X- _ O
wins -X- _ O
compared -X- _ O
to -X- _ O
Diff -X- _ B-MethodName
- -X- _ I-MethodName
Pruning -X- _ I-MethodName
and -X- _ O
4 -X- _ O
clear -X- _ O
wins -X- _ O
compared -X- _ O
to -X- _ O
Adapters -X- _ B-MethodName
while -X- _ O
using -X- _ O
45x -X- _ O
fewer -X- _ O
trainable -X- _ O
parameters -X- _ O
. -X- _ O

On -X- _ O
validation -X- _ O
set -X- _ O
, -X- _ O
BitFit -X- _ B-MethodName
outperforms -X- _ O
DiffPruning -X- _ B-MethodName
on -X- _ O
4 -X- _ O
out -X- _ O
of -X- _ O
9 -X- _ O
tasks -X- _ O
, -X- _ O
while -X- _ O
using -X- _ O
6x -X- _ O
fewer -X- _ O
trainable -X- _ O
parameters4 -X- _ O
. -X- _ O

This -X- _ O
experiment -X- _ O
used -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
LARGE -X- _ I-MethodName
model -X- _ I-MethodName
. -X- _ O

Table -X- _ O
1 -X- _ O
reports -X- _ O
the -X- _ O
dev -X- _ O
- -X- _ O
set -X- _ O
and -X- _ O
test -X- _ O
- -X- _ O
set -X- _ O
performance -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
Diff -X- _ B-MethodName
- -X- _ I-MethodName
Pruning -X- _ I-MethodName
and -X- _ O
Adapters -X- _ B-HyperparameterName
numbers -X- _ I-HyperparameterName
reported -X- _ O
by -X- _ O
Guo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
Houlsby -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
( -X- _ O
respectively -X- _ O
) -X- _ O
. -X- _ O

Comparison -X- _ O
to -X- _ O
Diff -X- _ B-MethodName
- -X- _ I-MethodName
Pruning -X- _ I-MethodName
and -X- _ O
Adapters -X- _ O
( -X- _ O
Table -X- _ O
1 -X- _ O
) -X- _ O
In -X- _ O
the -X- _ O
first -X- _ O
experiment -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
BitFit -X- _ B-MethodName
to -X- _ O
Diff -X- _ B-MethodName
- -X- _ I-MethodName
Pruning -X- _ I-MethodName
method -X- _ O
and -X- _ O
Adapters -X- _ O
method -X- _ O
, -X- _ O
when -X- _ O
using -X- _ O
a -X- _ O
fewer -X- _ O
number -X- _ O
of -X- _ O
parameters -X- _ O
. -X- _ O

Appendix -X- _ O
A.2 -X- _ O
lists -X- _ O
optimization -X- _ O
details -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
publicly -X- _ O
available -X- _ O
pre -X- _ B-MethodName
- -X- _ I-MethodName
trained -X- _ I-MethodName
BERT -X- _ I-MethodName
BASE -X- _ I-MethodName
, -X- _ O
BERT -X- _ B-MethodName
LARGE -X- _ I-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
and -X- _ O
RoBERTa -X- _ B-MethodName
BASE -X- _ I-MethodName
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
models -X- _ O
, -X- _ O
using -X- _ O
the -X- _ O
HuggingFace -X- _ O
( -X- _ O
Wolf -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
interface -X- _ O
and -X- _ O
implementation -X- _ O
. -X- _ O

We -X- _ O
evaluate -X- _ O
BitFit -X- _ B-MethodName
on -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
benchmark -X- _ I-DatasetName
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018).3Consistent -X- _ O
with -X- _ O
previous -X- _ O
work -X- _ O
( -X- _ O
Houlsby -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Guo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
we -X- _ O
exclude -X- _ O
the -X- _ O
WNLI -X- _ B-TaskName
task -X- _ O
, -X- _ O
on -X- _ O
which -X- _ O
BERT -X- _ B-MethodName
models -X- _ O
do -X- _ O
not -X- _ O
outperform -X- _ O
the -X- _ O
majority -X- _ O
baseline -X- _ O
. -X- _ O

bias -X- _ O
terms -X- _ O
b -X- _ O
( -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
achieve -X- _ O
transfer -X- _ B-MethodName
learning -X- _ I-MethodName
performance -X- _ O
which -X- _ O
is -X- _ O
comparable -X- _ O
( -X- _ O
and -X- _ O
sometimes -X- _ O
better -X- _ O
! -X- _ O
) -X- _ O
than -X- _ O
fine -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
of -X- _ O
the -X- _ O
entire -X- _ O
network -X- _ O
, -X- _ O
We -X- _ O
also -X- _ O
show -X- _ O
that -X- _ O
we -X- _ O
can -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
only -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
the -X- _ O
bias -X- _ O
parameters -X- _ O
, -X- _ O
namely -X- _ O
those -X- _ O
associated -X- _ O
with -X- _ O
the -X- _ O
query -X- _ O
and -X- _ O
the -X- _ O
second -X- _ B-MethodName
MLP -X- _ I-MethodName
layer -X- _ O
( -X- _ O
only -X- _ O
b -X- _ O
( -X- _ O
) -X- _ O
qandb -X- _ O
( -X- _ O
) -X- _ O
m2 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
still -X- _ O
achieve -X- _ O
accuracies -X- _ O
that -X- _ O
rival -X- _ O
full -X- _ O
- -X- _ O
model -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
. -X- _ O

We -X- _ O
show -X- _ O
that -X- _ O
by -X- _ O
freezing -X- _ O
all -X- _ O
the -X- _ O
parameters -X- _ O
W()andg()and -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
only -X- _ O
the -X- _ O
additive -X- _ O
2In -X- _ O
Appendix -X- _ O
A.1 -X- _ O
we -X- _ O
relate -X- _ O
this -X- _ O
notation -X- _ O
with -X- _ O
parameter -X- _ O
names -X- _ O
in -X- _ O
HuggingFace -X- _ O
implementation.2 -X- _ O
. -X- _ O

These -X- _ O
are -X- _ O
then -X- _ O
combined -X- _ O
using -X- _ O
an -X- _ O
attention -X- _ O
mechanism -X- _ O
that -X- _ O
does -X- _ O
not -X- _ O
involve -X- _ O
new -X- _ O
parameters -X- _ O
: -X- _ O
h -X- _ O
1 -X- _ O
= -X- _ O
att  -X- _ O
Q1,,K1,,V1 -X- _ O
, -X- _ O
, -X- _ O
.. -X- _ O
, -X- _ O
Qm,,Km,,Vm -X- _ O
, -X- _ O
l -X- _ O
and -X- _ O
then -X- _ O
fed -X- _ O
to -X- _ O
an -X- _ B-MethodName
MLP -X- _ I-MethodName
with -X- _ B-MethodName
layer -X- _ I-MethodName
- -X- _ I-MethodName
norm -X- _ I-MethodName
( -X- _ I-MethodName
LN -X- _ I-MethodName
): -X- _ O
h -X- _ O
2 -X- _ O
= -X- _ O
Dropout  -X- _ O
W -X- _ O
m1h -X- _ O
1+b -X- _ O
m1 -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
h -X- _ O
3 -X- _ O
= -X- _ O
g -X- _ O
LN1(h -X- _ O
2+x -X- _ O
) -X- _ O
+ -X- _ O
b -X- _ O
LN1(2 -X- _ O
) -X- _ O
h -X- _ O
4 -X- _ O
= -X- _ O
GELU  -X- _ O
W -X- _ O
m2h -X- _ O
3+b -X- _ O
m2 -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
h -X- _ O
5 -X- _ O
= -X- _ O
Dropout  -X- _ O
W -X- _ O
m3h -X- _ O
4+b -X- _ O
m3 -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
out -X- _ O
= -X- _ O
g -X- _ O
LN2(h -X- _ O
5+h -X- _ O
3 -X- _ O
) -X- _ O
+ -X- _ O
b -X- _ O
LN2(5 -X- _ O
) -X- _ O
The -X- _ O
collection -X- _ O
of -X- _ O
all -X- _ O
matrices -X- _ O
W -X- _ O
, -X- _ O
( -X- _ O
) -X- _ O
( -X- _ O
) -X- _ O
and -X- _ O
vectors -X- _ O
g -X- _ O
( -X- _ O
) -X- _ O
, -X- _ O
b -X- _ O
, -X- _ O
( -X- _ O
) -X- _ O
( -X- _ O
) -X- _ O
, -X- _ O
indicated -X- _ O
in -X- _ O
blue -X- _ O
and -X- _ O
purple -X- _ O
are -X- _ O
the -X- _ O
networks -X- _ O
parameters -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
subset -X- _ O
of -X- _ O
purple -X- _ O
vectors -X- _ O
b -X- _ O
, -X- _ O
( -X- _ O
) -X- _ O
( -X- _ O
) -X- _ O
are -X- _ O
the -X- _ O
bias -X- _ O
terms -X- _ O
.2 -X- _ O
The -X- _ B-HyperparameterName
bias -X- _ I-HyperparameterName
terms -X- _ I-HyperparameterName
are -X- _ O
additive -X- _ O
, -X- _ O
and -X- _ O
correspond -X- _ O
to -X- _ O
a -X- _ O
very -X- _ O
small -X- _ O
fraction -X- _ O
of -X- _ O
the -X- _ O
network -X- _ O
, -X- _ B-MethodName
in -X- _ I-MethodName
BERT -X- _ I-MethodName
BASE -X- _ O
and -X- _ B-MethodName
BERT -X- _ I-MethodName
LARGE -X- _ I-MethodName
bias -X- _ O
parameters -X- _ O
make -X- _ B-HyperparameterValue
up -X- _ I-HyperparameterValue
0.09% -X- _ I-HyperparameterValue
and -X- _ B-HyperparameterValue
0.08% -X- _ I-HyperparameterValue
of -X- _ O
the -X- _ B-HyperparameterName
total -X- _ I-HyperparameterName
number -X- _ I-HyperparameterName
of -X- _ I-HyperparameterName
parameters -X- _ I-HyperparameterName
in -X- _ O
each -X- _ O
model -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O

Concretely -X- _ O
, -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
encoder -X- _ I-MethodName
is -X- _ O
composed -X- _ O
of -X- _ O
Llayers -X- _ O
, -X- _ O
where -X- _ O
each -X- _ O
layer -X- _ O
starts -X- _ O
with -X- _ O
Mselfattention -X- _ O
heads -X- _ O
, -X- _ O
where -X- _ O
a -X- _ O
self -X- _ O
attention -X- _ O
head -X- _ B-HyperparameterName
( -X- _ O
m -X- _ O
, -X- _ O
) -X- _ O
haskey -X- _ B-HyperparameterName
, -X- _ O
query -X- _ B-HyperparameterName
andvalue -X- _ B-HyperparameterName
encoders -X- _ O
, -X- _ O
each -X- _ O
taking -X- _ O
the -X- _ O
form -X- _ O
of -X- _ O
a -X- _ O
linear -X- _ O
layer -X- _ O
: -X- _ O
Qm,(x -X- _ O
) -X- _ O
= -X- _ O
Wm -X- _ O
, -X- _ O
qx+bm -X- _ O
, -X- _ O
q -X- _ O
Km,(x -X- _ O
) -X- _ O
= -X- _ O
Wm -X- _ O
, -X- _ O
kx+bm -X- _ O
, -X- _ O
k -X- _ O
Vm,(x -X- _ O
) -X- _ O
= -X- _ O
Wm -X- _ O
, -X- _ O
vx+bm -X- _ O
, -X- _ O
v -X- _ O
Where -X- _ O
xis -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
former -X- _ O
encoder -X- _ O
layer -X- _ O
( -X- _ O
for -X- _ O
the -X- _ O
first -X- _ O
encoder -X- _ O
layer -X- _ O
xis -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
embedding -X- _ O
layer -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
approach -X- _ O
is -X- _ O
parameter -X- _ O
- -X- _ O
efficient -X- _ O
: -X- _ O
each -X- _ O
new -X- _ O
task -X- _ O
requires -X- _ O
storing -X- _ O
only -X- _ O
the -X- _ O
bias -X- _ B-HyperparameterName
terms -X- _ I-HyperparameterName
parameter -X- _ O
vectors -X- _ O
( -X- _ O
which -X- _ O
amount -X- _ O
to -X- _ O
less -X- _ B-HyperparameterValue
than -X- _ I-HyperparameterValue
0.1% -X- _ I-HyperparameterValue
of -X- _ O
the -X- _ O
total -X- _ B-HyperparameterName
number -X- _ I-HyperparameterName
of -X- _ I-HyperparameterName
parameters -X- _ I-HyperparameterName
) -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
final -X- _ O
linear -X- _ O
classifier -X- _ O
layer -X- _ O
. -X- _ O

( -X- _ O
iii -X- _ O
) -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
only -X- _ O
a -X- _ O
small -X- _ O
portion -X- _ O
of -X- _ O
the -X- _ O
models -X- _ O
parameters -X- _ O
. -X- _ O

( -X- _ O
ii -X- _ O
) -X- _ O
enable -X- _ O
tasks -X- _ O
to -X- _ O
arrive -X- _ O
in -X- _ O
a -X- _ O
stream -X- _ O
, -X- _ O
this -X- _ O
way -X- _ O
it -X- _ O
does -X- _ O
not -X- _ O
require -X- _ O
simultaneous -X- _ O
access -X- _ O
to -X- _ O
all -X- _ O
datasets -X- _ O
. -X- _ O

1Our -X- _ O
code -X- _ O
is -X- _ O
publicly -X- _ O
available -X- _ O
at -X- _ O
www.github.com/ -X- _ O
benzakenelad -X- _ O
/ -X- _ O
BitFitBitFit -X- _ O
has -X- _ O
three -X- _ O
key -X- _ O
properties -X- _ O
: -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
match -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
fully -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
model -X- _ O
. -X- _ O

3 -X- _ O
Bias -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
terms -X- _ I-HyperparameterName
Fine -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
( -X- _ O
BitFit -X- _ B-MethodName
) -X- _ O
We -X- _ O
propose -X- _ O
a -X- _ O
method -X- _ O
we -X- _ O
call -X- _ O
BitFit1(BIas -X- _ B-MethodName
- -X- _ B-MethodName
Term -X- _ I-MethodName
FIne -X- _ I-MethodName
- -X- _ I-MethodName
Tuning -X- _ I-MethodName
) -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
we -X- _ O
freeze -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
transformer -X- _ O
- -X- _ O
encoder -X- _ O
parameters -X- _ O
, -X- _ O
and -X- _ O
train -X- _ O
only -X- _ O
the -X- _ O
bias -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
terms -X- _ I-HyperparameterName
and -X- _ O
the -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
classification -X- _ O
layer -X- _ O
. -X- _ O

We -X- _ O
compare -X- _ O
against -X- _ O
Diff -X- _ B-MethodName
- -X- _ I-MethodName
Pruning -X- _ I-MethodName
and -X- _ O
Adapters -X- _ O
in -X- _ O
the -X- _ O
experiments -X- _ O
section -X- _ O
, -X- _ O
and -X- _ O
show -X- _ O
that -X- _ O
we -X- _ O
perform -X- _ O
favorably -X- _ O
on -X- _ O
many -X- _ O
tasks -X- _ O
while -X- _ O
also -X- _ O
satisfying -X- _ O
criteria -X- _ O
( -X- _ O
iv -X- _ O
) -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
Diff -X- _ B-MethodName
- -X- _ I-MethodName
Pruning -X- _ I-MethodName
is -X- _ O
more -X- _ O
parameter -X- _ O
efficient -X- _ O
than -X- _ O
the -X- _ O
Adapter -X- _ B-MethodName
method -X- _ I-MethodName
( -X- _ O
in -X- _ O
particular -X- _ O
, -X- _ O
it -X- _ O
adds -X- _ O
no -X- _ O
new -X- _ O
parameters -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
also -X- _ O
achieves -X- _ O
better -X- _ O
task -X- _ O
scores -X- _ O
. -X- _ O

The -X- _ O
Adapter -X- _ B-MethodName
method -X- _ I-MethodName
, -X- _ O
but -X- _ O
not -X- _ O
the -X- _ O
DiffPruning -X- _ B-MethodName
method -X- _ I-MethodName
, -X- _ O
also -X- _ O
supports -X- _ O
criteria -X- _ O
( -X- _ O
iv -X- _ O
) -X- _ O
. -X- _ O

They -X- _ O
also -X- _ O
partially -X- _ O
fulfill -X- _ O
criteria -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
, -X- _ O
suffering -X- _ O
only -X- _ O
a -X- _ O
small -X- _ O
drop -X- _ O
in -X- _ O
performance -X- _ O
compared -X- _ O
to -X- _ O
full -X- _ B-MethodName
fine -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
. -X- _ O

The -X- _ O
difference -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
vector -X- _ I-HyperparameterName
is -X- _ O
regularized -X- _ O
to -X- _ O
be -X- _ O
sparse -X- _ O
. -X- _ O

The -X- _ O
second -X- _ O
work -X- _ O
, -X- _ O
by -X- _ O
Guo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
( -X- _ O
Diff -X- _ O
- -X- _ O
Pruning -X- _ O
) -X- _ O
, -X- _ O
achieves -X- _ O
the -X- _ O
same -X- _ O
goal -X- _ O
by -X- _ O
adding -X- _ B-MethodName
a -X- _ I-MethodName
sparse -X- _ I-MethodName
, -X- _ I-MethodName
task -X- _ I-MethodName
- -X- _ I-MethodName
specific -X- _ I-MethodName
difference -X- _ I-MethodName
- -X- _ I-MethodName
vector -X- _ I-MethodName
to -X- _ I-MethodName
the -X- _ I-MethodName
original -X- _ I-MethodName
parameters -X- _ I-MethodName
, -X- _ O
which -X- _ O
remain -X- _ O
fixed -X- _ O
and -X- _ O
are -X- _ O
shared -X- _ O
between -X- _ O
tasks -X- _ O
. -X- _ O

The -X- _ O
first -X- _ O
work -X- _ O
, -X- _ O
by -X- _ O
Houlsby -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
( -X- _ O
Adapters -X- _ O
) -X- _ O
, -X- _ O
achieves -X- _ O
this -X- _ O
goal -X- _ O
by -X- _ O
injecting -X- _ B-MethodName
small -X- _ I-MethodName
, -X- _ I-MethodName
trainable -X- _ I-MethodName
task -X- _ I-MethodName
- -X- _ I-MethodName
specific -X- _ I-MethodName
adapter -X- _ I-MethodName
modules -X- _ I-MethodName
between -X- _ I-MethodName
the -X- _ I-MethodName
layers -X- _ I-MethodName
of -X- _ I-MethodName
the -X- _ I-MethodName
pre -X- _ I-MethodName
- -X- _ I-MethodName
trained -X- _ I-MethodName
model -X- _ I-MethodName
, -X- _ O
where -X- _ O
the -X- _ O
original -X- _ O
parameters -X- _ O
are -X- _ O
shared -X- _ O
between -X- _ O
tasks -X- _ O
. -X- _ O

Two -X- _ O
recent -X- _ O
works -X- _ O
have -X- _ O
demonstrated -X- _ O
that -X- _ O
adaptation -X- _ O
to -X- _ O
various -X- _ O
end -X- _ B-TaskName
- -X- _ I-TaskName
tasks -X- _ I-TaskName
can -X- _ O
in -X- _ O
fact -X- _ O
be -X- _ O
achieved -X- _ O
by -X- _ O
changing -X- _ O
only -X- _ O
a -X- _ O
small -X- _ O
subset -X- _ O
of -X- _ O
parameters -X- _ O
. -X- _ O

the -X- _ O
exposing -X- _ O
of -X- _ O
existing -X- _ O
capabilities -X- _ O
, -X- _ O
which -X- _ O
were -X- _ O
learned -X- _ O
during -X- _ O
the -X- _ O
pre -X- _ B-MethodName
- -X- _ I-MethodName
training -X- _ I-MethodName
process -X- _ O
. -X- _ O

The -X- _ O
feasibility -X- _ O
of -X- _ O
fulfilling -X- _ O
the -X- _ O
above -X- _ O
requirements -X- _ O
depends -X- _ O
on -X- _ O
a -X- _ O
fundamental -X- _ O
question -X- _ O
regarding -X- _ O
the -X- _ O
nature -X- _ O
of -X- _ O
the -X- _ O
fine -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
process -X- _ O
of -X- _ O
large -X- _ B-MethodName
pre -X- _ I-MethodName
- -X- _ I-MethodName
trained -X- _ I-MethodName
LMs -X- _ I-MethodName
: -X- _ O
to -X- _ O
what -X- _ O
extent -X- _ O
does -X- _ O
the -X- _ O
fine -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
process -X- _ O
induces -X- _ O
the -X- _ O
learning -X- _ O
of -X- _ O
new -X- _ O
capabilities -X- _ O
, -X- _ O
vs -X- _ O
. -X- _ O

Ideally -X- _ O
, -X- _ O
one -X- _ O
would -X- _ O
want -X- _ O
a -X- _ O
fine -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
method -X- _ O
that -X- _ O
: -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
matches -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
a -X- _ O
fully -X- _ O
fine -X- _ B-MethodName
- -X- _ I-MethodName
tuned -X- _ I-MethodName
model;1 -X- _ O
. -X- _ O

While -X- _ O
fine -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
per -X- _ O
- -X- _ O
task -X- _ O
is -X- _ O
very -X- _ O
effective -X- _ O
, -X- _ O
it -X- _ O
also -X- _ O
results -X- _ O
in -X- _ O
a -X- _ O
unique -X- _ O
, -X- _ O
large -X- _ O
model -X- _ O
for -X- _ O
each -X- _ O
pre -X- _ B-MetricValue
- -X- _ I-MetricValue
trained -X- _ I-MetricValue
task -X- _ I-MetricValue
, -X- _ O
making -X- _ O
it -X- _ O
hard -X- _ O
to -X- _ O
reason -X- _ O
about -X- _ O
what -X- _ O
was -X- _ O
changed -X- _ O
in -X- _ O
the -X- _ O
fine -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
process -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
hard -X- _ O
to -X- _ O
deploy -X- _ O
, -X- _ O
especially -X- _ O
as -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
tasks -X- _ O
increases -X- _ O
. -X- _ O

Then -X- _ O
, -X- _ O
a -X- _ O
taskspecific -X- _ O
classification -X- _ B-HyperparameterName
layer -X- _ I-HyperparameterName
( -X- _ O
here -X- _ O
we -X- _ O
consider -X- _ O
linear -X- _ B-HyperparameterName
classifiers -X- _ I-HyperparameterName
) -X- _ O
is -X- _ O
added -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
the -X- _ O
encoder -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
entire -X- _ O
network -X- _ O
( -X- _ O
encoder+task -X- _ O
specific -X- _ O
classifiers -X- _ O
) -X- _ O
is -X- _ O
trained -X- _ O
end -X- _ B-MethodName
- -X- _ I-MethodName
to -X- _ I-MethodName
- -X- _ I-MethodName
end -X- _ I-MethodName
to -X- _ O
minimize -X- _ O
the -X- _ O
task -X- _ O
loss -X- _ B-HyperparameterName
. -X- _ O

2 -X- _ O
Background -X- _ O
: -X- _ O
fine -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
and -X- _ O
parameter -X- _ B-MethodName
- -X- _ I-MethodName
efficient -X- _ I-MethodName
fine -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
In -X- _ O
transfer -X- _ B-MethodName
- -X- _ I-MethodName
learning -X- _ I-MethodName
via -X- _ O
model -X- _ O
fine -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
, -X- _ O
a -X- _ O
pretrained -X- _ B-MethodName
encoder -X- _ I-MethodName
network -X- _ I-MethodName
takes -X- _ O
the -X- _ O
input -X- _ O
and -X- _ O
produces -X- _ O
contextualized -X- _ O
representations -X- _ O
. -X- _ O

Additionally -X- _ O
, -X- _ O
it -X- _ O
opens -X- _ O
up -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
research -X- _ O
directions -X- _ O
regarding -X- _ O
the -X- _ O
role -X- _ O
of -X- _ O
bias -X- _ O
terms -X- _ O
in -X- _ O
pre -X- _ B-MethodName
- -X- _ I-MethodName
trained -X- _ I-MethodName
networks -X- _ I-MethodName
, -X- _ O
and -X- _ O
the -X- _ O
dynamics -X- _ O
of -X- _ O
the -X- _ O
fine -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
process -X- _ O
. -X- _ O

This -X- _ O
result -X- _ O
has -X- _ O
a -X- _ O
large -X- _ O
practical -X- _ O
utility -X- _ O
in -X- _ O
deploying -X- _ O
multi -X- _ B-MethodName
- -X- _ I-MethodName
task -X- _ I-MethodName
fine -X- _ I-MethodName
- -X- _ I-MethodName
tuned -X- _ I-MethodName
models -X- _ I-MethodName
in -X- _ O
memoryconstrained -X- _ O
environments -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
opens -X- _ O
the -X- _ O
way -X- _ O
to -X- _ O
trainable -X- _ O
hardware -X- _ O
implementations -X- _ O
in -X- _ O
which -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
parameters -X- _ O
are -X- _ O
fixed -X- _ O
. -X- _ O

Moreover -X- _ O
, -X- _ O
if -X- _ O
we -X- _ O
allow -X- _ O
the -X- _ O
tasks -X- _ O
to -X- _ O
suffer -X- _ O
a -X- _ O
small -X- _ O
degradation -X- _ O
in -X- _ O
performance -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
fine -X- _ B-MethodName
- -X- _ I-MethodName
tune -X- _ I-MethodName
only -X- _ O
two -X- _ O
bias -X- _ O
components -X- _ O
( -X- _ O
the -X- _ O
query -X- _ B-HyperparameterName
and -X- _ O
middle -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
of -X- _ I-HyperparameterName
- -X- _ I-HyperparameterName
MLP -X- _ I-HyperparameterName
bias -X- _ I-HyperparameterName
terms -X- _ I-HyperparameterName
) -X- _ O
, -X- _ O
amounting -X- _ O
to -X- _ O
half -X- _ O
of -X- _ O
the -X- _ O
bias -X- _ B-HyperparameterName
parameters -X- _ O
in -X- _ O
the -X- _ O
model -X- _ O
, -X- _ O
and -X- _ O
only -X- _ O
0.04% -X- _ B-HyperparameterValue
of -X- _ O
all -X- _ O
model -X- _ O
parameters -X- _ O
. -X- _ O

Specifically -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
freezing -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
network -X- _ O
and -X- _ O
fine -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
only -X- _ O
the -X- _ O
bias -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
terms -X- _ I-HyperparameterName
is -X- _ O
surprisingly -X- _ O
effective -X- _ O
. -X- _ O

4.For -X- _ O
small -X- _ O
to -X- _ O
medium -X- _ O
training -X- _ O
data -X- _ O
, -X- _ O
changing -X- _ O
only -X- _ O
these -X- _ O
parameters -X- _ O
reaches -X- _ O
the -X- _ O
same -X- _ O
task -X- _ O
accuracy -X- _ B-MetricName
as -X- _ O
full -X- _ B-MethodName
fine -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
, -X- _ O
and -X- _ O
sometimes -X- _ O
even -X- _ O
improves -X- _ O
results -X- _ O
. -X- _ O

We -X- _ O
present -X- _ O
a -X- _ O
simple -X- _ O
and -X- _ O
effective -X- _ O
approach -X- _ O
to -X- _ O
fine -X- _ O
tuning -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
has -X- _ O
the -X- _ O
following -X- _ O
benefits -X- _ O
: -X- _ O
1.Changing -X- _ O
very -X- _ O
few -X- _ O
parameters -X- _ O
per -X- _ O
fine -X- _ B-TaskName
- -X- _ I-TaskName
tuned -X- _ I-TaskName
task -X- _ I-TaskName
. -X- _ O

This -X- _ O
, -X- _ O
along -X- _ O
with -X- _ O
theoretical -X- _ O
questions -X- _ O
on -X- _ O
the -X- _ O
extent -X- _ O
to -X- _ O
which -X- _ O
finetuning -X- _ B-MethodName
must -X- _ O
change -X- _ O
the -X- _ O
original -X- _ O
model -X- _ O
, -X- _ O
has -X- _ O
led -X- _ O
researchers -X- _ O
to -X- _ O
consider -X- _ O
finetuning -X- _ B-MethodName
variants -X- _ O
where -X- _ O
one -X- _ O
identifies -X- _ O
a -X- _ O
small -X- _ O
subset -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
parameters -X- _ O
which -X- _ O
need -X- _ O
to -X- _ O
be -X- _ O
changed -X- _ O
for -X- _ O
good -X- _ O
performance -X- _ O
in -X- _ O
end -X- _ O
- -X- _ O
tasks -X- _ O
, -X- _ O
while -X- _ O
keeping -X- _ O
all -X- _ O
others -X- _ O
intact -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O

Under -X- _ O
the -X- _ O
common -X- _ O
paradigm -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
pre -X- _ B-MethodName
- -X- _ I-MethodName
trained -X- _ I-MethodName
on -X- _ O
large -X- _ O
, -X- _ O
annotated -X- _ O
corpora -X- _ O
with -X- _ O
the -X- _ O
LM -X- _ O
objective -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
finetuned -X- _ O
on -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
supervised -X- _ O
data -X- _ O
. -X- _ O

1 -X- _ O
Introduction -X- _ O
Large -X- _ O
pre -X- _ B-MethodName
- -X- _ I-MethodName
trained -X- _ I-MethodName
transformer -X- _ I-MethodName
based -X- _ I-MethodName
language -X- _ I-MethodName
models -X- _ I-MethodName
, -X- _ O
and -X- _ O
in -X- _ O
particular -X- _ O
bidirectional -X- _ B-MethodName
masked -X- _ I-MethodName
language -X- _ I-MethodName
models -X- _ I-MethodName
from -X- _ O
the -X- _ O
BERT -X- _ O
family -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Joshi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
are -X- _ O
responsible -X- _ O
for -X- _ O
significant -X- _ O
gains -X- _ O
in -X- _ O
many -X- _ O
NLP -X- _ B-TaskName
tasks -X- _ O
. -X- _ O

Besides -X- _ O
their -X- _ O
practical -X- _ O
utility -X- _ O
, -X- _ O
these -X- _ O
findings -X- _ O
are -X- _ O
relevant -X- _ O
for -X- _ O
the -X- _ O
question -X- _ O
of -X- _ O
understanding -X- _ O
the -X- _ O
commonly -X- _ O
- -X- _ O
used -X- _ O
process -X- _ O
of -X- _ O
finetuning -X- _ O
: -X- _ O
they -X- _ O
support -X- _ O
the -X- _ O
hypothesis -X- _ O
that -X- _ O
finetuning -X- _ O
is -X- _ O
mainly -X- _ O
about -X- _ O
exposing -X- _ O
knowledge -X- _ O
induced -X- _ O
by -X- _ O
language -X- _ B-MethodName
- -X- _ I-MethodName
modeling -X- _ I-MethodName
training -X- _ I-MethodName
, -X- _ O
rather -X- _ O
than -X- _ O
learning -X- _ O
new -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
linguistic -X- _ O
knowledge -X- _ O
. -X- _ O

For -X- _ O
larger -X- _ O
data -X- _ O
, -X- _ O
the -X- _ O
method -X- _ O
is -X- _ O
competitive -X- _ O
with -X- _ O
other -X- _ O
sparse -X- _ B-MethodName
fine -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
methods -X- _ O
. -X- _ O

We -X- _ O
show -X- _ O
that -X- _ O
with -X- _ O
small -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
medium -X- _ O
training -X- _ O
data -X- _ O
, -X- _ O
applying -X- _ O
BitFit -X- _ B-MethodName
on -X- _ O
pre -X- _ B-MethodName
- -X- _ I-MethodName
trained -X- _ I-MethodName
BERT -X- _ I-MethodName
models -X- _ I-MethodName
is -X- _ O
competitive -X- _ O
with -X- _ O
( -X- _ O
and -X- _ O
sometimes -X- _ O
better -X- _ O
than -X- _ O
) -X- _ O
fine -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
the -X- _ O
entire -X- _ O
model -X- _ O
. -X- _ O

RTE -X- _ B-DatasetName
is -X- _ O
compiled -X- _ O
from -X- _ O
these -X- _ O
sources -X- _ O
: -X- _ O
Dagan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2006 -X- _ O
) -X- _ O
; -X- _ O
Bar -X- _ O
Haim -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2006 -X- _ O
) -X- _ O
; -X- _ O
Giampiccolo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2007 -X- _ O
) -X- _ O
; -X- _ O
Bentivogli -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2009)282 -X- _ O
. -X- _ O

Dataset -X- _ O
Citation -X- _ O
Training -X- _ O
Size -X- _ O
MNLI -X- _ B-TaskName
Williams -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
392,662 -X- _ O
QQP -X- _ O
No -X- _ O
citation -X- _ O
, -X- _ O
link -X- _ O
here -X- _ O
363,846 -X- _ O
QNLI -X- _ O
Levesque -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2011 -X- _ O
) -X- _ O
104,743 -X- _ O
SST-2 -X- _ O
Socher -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2013 -X- _ O
) -X- _ O
67,349 -X- _ O
CoLA -X- _ O
Warstadt -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
8,551 -X- _ O
STS -X- _ O
- -X- _ O
B -X- _ O
Cer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
5,749 -X- _ O
MRPC -X- _ O
Dolan -X- _ O
and -X- _ O
Brockett -X- _ O
( -X- _ O
2005 -X- _ O
) -X- _ O
3,668 -X- _ O
RTE -X- _ O
Dagan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2006 -X- _ O
) -X- _ O
* -X- _ O
2,490 -X- _ O
WNLI -X- _ O
Levesque -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2011 -X- _ O
) -X- _ O
635 -X- _ O
Table -X- _ O
5 -X- _ O
: -X- _ O
Sizes -X- _ O
of -X- _ O
the -X- _ O
datasets -X- _ O
in -X- _ O
GLUE -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018b -X- _ O
) -X- _ O
in -X- _ O
descending -X- _ O
order -X- _ O
, -X- _ O
along -X- _ O
with -X- _ O
their -X- _ O
original -X- _ O
citations -X- _ O
. -X- _ O

F -X- _ B-DatasetName
GLUE -X- _ I-DatasetName
Dataset -X- _ B-HyperparameterName
Sizes -X- _ I-HyperparameterName
and -X- _ O
References -X- _ O
To -X- _ O
give -X- _ O
credit -X- _ O
to -X- _ O
the -X- _ O
original -X- _ O
authors -X- _ O
and -X- _ O
to -X- _ O
provide -X- _ O
the -X- _ O
exact -X- _ O
sizes -X- _ O
, -X- _ O
we -X- _ O
provide -X- _ O
Table -X- _ O
5.281 -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
Raffel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
is -X- _ O
the -X- _ O
only -X- _ O
one -X- _ O
whose -X- _ O
experiments -X- _ O
include -X- _ O
multiple -X- _ B-HyperparameterName
random -X- _ I-HyperparameterName
seeds -X- _ I-HyperparameterName
, -X- _ O
giving -X- _ O
more -X- _ O
credence -X- _ O
to -X- _ O
their -X- _ O
results -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
whether -X- _ O
finetuning -X- _ B-MethodName
after -X- _ O
MTL -X- _ B-MethodName
is -X- _ O
better -X- _ O
than -X- _ O
simply -X- _ O
MTL -X- _ B-MethodName
is -X- _ O
still -X- _ O
controversial -X- _ O
: -X- _ O
for -X- _ O
example -X- _ O
, -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019b -X- _ O
) -X- _ O
, -X- _ O
Raffel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
Talmor -X- _ O
and -X- _ O
Berant -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
say -X- _ O
that -X- _ O
fine -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
after -X- _ I-MethodName
MTL -X- _ I-MethodName
helps -X- _ O
but -X- _ O
Lourie -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
and -X- _ O
Phang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
say -X- _ O
that -X- _ O
it -X- _ O
does -X- _ O
nt -X- _ O
. -X- _ O

Since -X- _ O
fine -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
after -X- _ I-MethodName
MTL -X- _ I-MethodName
makes -X- _ O
the -X- _ O
MTL -X- _ B-MethodName
phase -X- _ O
an -X- _ O
intermediate -X- _ O
step -X- _ O
, -X- _ O
it -X- _ O
essential -X- _ O
combines -X- _ O
the -X- _ O
STILTs -X- _ B-MethodName
and -X- _ O
MTL -X- _ B-MethodName
methods -X- _ O
into -X- _ O
a -X- _ O
single -X- _ O
STILTs -X- _ B-MethodName
- -X- _ I-MethodName
like -X- _ I-MethodName
method -X- _ I-MethodName
. -X- _ O

Fine -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
after -X- _ O
MTL -X- _ B-MethodName
Many -X- _ O
papers -X- _ O
that -X- _ O
use -X- _ O
MTL -X- _ B-MethodName
Allalso -X- _ I-MethodName
perform -X- _ O
some -X- _ O
sort -X- _ O
of -X- _ O
fine -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
after -X- _ O
the -X- _ O
MTL -X- _ B-MethodName
phase -X- _ O
. -X- _ O

Thus -X- _ O
, -X- _ O
our -X- _ O
work -X- _ O
provides -X- _ O
additional -X- _ O
insight -X- _ O
into -X- _ O
how -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
dataset -X- _ O
is -X- _ O
important -X- _ O
for -X- _ O
transfer -X- _ B-MethodName
learning -X- _ I-MethodName
. -X- _ O

Our -X- _ O
size -X- _ B-HyperparameterName
heuristic -X- _ I-HyperparameterName
, -X- _ O
although -X- _ O
related -X- _ O
, -X- _ O
focuses -X- _ O
on -X- _ O
a -X- _ O
different -X- _ O
problem -X- _ O
: -X- _ O
whether -X- _ O
to -X- _ O
use -X- _ O
MTL -X- _ B-MethodName
or -X- _ O
STILTs -X- _ B-MethodName
. -X- _ O

Exploring -X- _ O
which -X- _ O
subsets -X- _ O
of -X- _ O
tasks -X- _ O
provide -X- _ O
the -X- _ O
best -X- _ O
transfer -X- _ O
with -X- _ O
which -X- _ O
method -X- _ O
would -X- _ O
be -X- _ O
valuable -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O
Dataset -X- _ B-HyperparameterName
Size -X- _ I-HyperparameterName
in -X- _ O
TL -X- _ B-MethodName
Dataset -X- _ O
size -X- _ O
has -X- _ O
been -X- _ O
used -X- _ O
often -X- _ O
in -X- _ O
transfer -X- _ O
learning -X- _ O
techniques -X- _ O
( -X- _ O
Sgaard -X- _ O
and -X- _ O
Bingel -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Pruksachatkun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
; -X- _ O
Poth -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O

Additionally -X- _ O
, -X- _ O
there -X- _ O
may -X- _ O
be -X- _ O
further -X- _ O
value -X- _ O
in -X- _ O
computing -X- _ O
this -X- _ O
power -X- _ O
set -X- _ O
: -X- _ O
Changpinyo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
showed -X- _ O
that -X- _ O
taking -X- _ O
the -X- _ O
pairwise -X- _ O
tasks -X- _ O
that -X- _ O
proved -X- _ O
beneficial -X- _ O
in -X- _ O
pairwise -X- _ B-MethodName
MTL -X- _ I-MethodName
and -X- _ O
combining -X- _ O
them -X- _ O
into -X- _ O
a -X- _ O
larger -X- _ O
MTL -X- _ O
set -X- _ O
( -X- _ O
an -X- _ O
Oracle -X- _ O
" -X- _ O
set -X- _ O
) -X- _ O
oftentimes -X- _ O
provides -X- _ O
higher -X- _ O
scores -X- _ O
than -X- _ O
pairwise -X- _ B-MethodName
MTL -X- _ I-MethodName
. -X- _ O

Although -X- _ O
it -X- _ O
is -X- _ O
possible -X- _ O
that -X- _ O
our -X- _ O
heuristic -X- _ O
may -X- _ O
extrapolate -X- _ O
to -X- _ O
transfer -X- _ B-MethodName
learning -X- _ I-MethodName
with -X- _ O
more -X- _ O
than -X- _ O
two -X- _ O
tasks -X- _ O
, -X- _ O
computing -X- _ O
the -X- _ O
power -X- _ O
set -X- _ O
of -X- _ O
the -X- _ O
possible -X- _ O
task -X- _ O
combinations -X- _ O
for -X- _ O
MTL -X- _ B-MethodName
and -X- _ O
STILTs -X- _ B-MethodName
would -X- _ O
be -X- _ O
extremely -X- _ O
time -X- _ O
and -X- _ O
resource -X- _ O
intensive -X- _ O
. -X- _ O

Combining -X- _ O
Helpful -X- _ O
Tasks -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
only -X- _ O
examine -X- _ O
the -X- _ O
difference -X- _ O
between -X- _ B-MethodName
pairwise -X- _ I-MethodName
MTL -X- _ I-MethodName
, -X- _ B-MethodName
STILTs -X- _ I-MethodName
or -X- _ O
MTL -X- _ B-MethodName
All -X- _ I-MethodName
, -X- _ O
due -X- _ O
to -X- _ O
time -X- _ O
and -X- _ O
space -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
more -X- _ O
work -X- _ O
is -X- _ O
needed -X- _ O
to -X- _ O
understand -X- _ O
the -X- _ O
training -X- _ O
dynamics -X- _ O
of -X- _ O
MTL -X- _ B-MethodName
All -X- _ I-MethodName
. -X- _ O

The -X- _ O
current -X- _ O
literature -X- _ O
( -X- _ O
and -X- _ O
our -X- _ O
work -X- _ O
) -X- _ O
seems -X- _ O
to -X- _ O
suggest -X- _ O
that -X- _ O
naively -X- _ B-MethodName
combining -X- _ I-MethodName
as -X- _ O
many -X- _ O
tasks -X- _ O
as -X- _ O
possible -X- _ O
may -X- _ O
not -X- _ O
be -X- _ O
the -X- _ O
best -X- _ O
approach -X- _ O
. -X- _ O

Additionally -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
follow -X- _ O
up -X- _ O
work -X- _ O
from -X- _ O
the -X- _ O
initial -X- _ O
STILTs -X- _ B-MethodName
paper -X- _ O
( -X- _ O
Phang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
they -X- _ O
find -X- _ O
that -X- _ O
although -X- _ O
MTL -X- _ B-MethodName
All -X- _ I-MethodName
has -X- _ O
a -X- _ O
slightly -X- _ O
higher -X- _ O
average -X- _ B-MetricValue
performance -X- _ I-MetricValue
in -X- _ O
the -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
setting -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
worse -X- _ O
than -X- _ O
the -X- _ O
pairwise -X- _ B-MethodName
approach -X- _ I-MethodName
in -X- _ O
75% -X- _ B-MetricValue
of -X- _ O
the -X- _ O
evaluated -X- _ O
tasks -X- _ O
. -X- _ O

MTL -X- _ B-MethodName
Allapproach -X- _ I-MethodName
for -X- _ O
all -X- _ O
but -X- _ O
one -X- _ O
task -X- _ O
. -X- _ O

Emphasis -X- _ O
changed -X- _ O
to -X- _ O
reect -X- _ O
the -X- _ O
best -X- _ O
score -X- _ O
in -X- _ O
the -X- _ O
models -X- _ O
column -X- _ O
instead -X- _ O
of -X- _ O
the -X- _ O
best -X- _ O
non -X- _ B-MethodName
- -X- _ I-MethodName
MTL -X- _ I-MethodName
score -X- _ O
. -X- _ O

SQuAD -X- _ B-DatasetName
NewsQA -X- _ B-DatasetName
SearchQA -X- _ B-DatasetName
TQA -X- _ B-DatasetName
- -X- _ I-DatasetName
G -X- _ I-DatasetName
TQA -X- _ B-DatasetName
- -X- _ I-DatasetName
W -X- _ I-DatasetName
HotpotQA -X- _ B-DatasetName
SQuAD -X- _ B-DatasetName
- -X- _ O
33.3 -X- _ B-MetricValue
39.2 -X- _ B-MetricValue
49.2 -X- _ B-MetricValue
34.5 -X- _ B-MetricValue
17.8 -X- _ B-MetricValue
NewsQA -X- _ B-DatasetName
59.6 -X- _ B-MetricValue
- -X- _ B-MetricValue
41.6 -X- _ I-MetricValue
44.2 -X- _ B-MetricValue
33.9 -X- _ B-MetricValue
16.5 -X- _ B-MetricValue
SearchQA -X- _ B-DatasetName
57 -X- _ B-MetricValue
31.4 -X- _ B-MetricValue
- -X- _ B-MetricValue
57.5 -X- _ I-MetricValue
39.6 -X- _ B-MetricValue
19.2 -X- _ B-MetricValue
TQA -X- _ B-DatasetName
- -X- _ I-DatasetName
G -X- _ I-DatasetName
57.7 -X- _ B-MetricValue
31.8 -X- _ B-MetricValue
49.5 -X- _ B-MetricValue
- -X- _ B-MetricValue
41.4 -X- _ I-MetricValue
19.1 -X- _ B-MetricValue
TQA -X- _ B-DatasetName
- -X- _ I-DatasetName
W -X- _ I-DatasetName
57.6 -X- _ B-MetricValue
31.7 -X- _ B-MetricValue
44.4 -X- _ B-MetricValue
50.7 -X- _ B-MetricValue
- -X- _ B-MetricValue
17.2 -X- _ I-MetricValue
HotpotQA -X- _ B-DatasetName
59.8 -X- _ B-MetricValue
32.4 -X- _ B-MetricValue
46.3 -X- _ B-MetricValue
54.6 -X- _ B-MetricValue
37.4 -X- _ B-MetricValue
- -X- _ O
Multi-75 -X- _ B-DatasetName
K -X- _ I-DatasetName
59.8 -X- _ B-MetricValue
33.0 -X- _ B-MetricValue
47.5 -X- _ B-MetricValue
56.4 -X- _ B-MetricValue
40.4 -X- _ B-MetricValue
19.2 -X- _ B-MetricValue
SQuAD -X- _ B-DatasetName
- -X- _ B-MetricValue
41.2 -X- _ I-MetricValue
47.8 -X- _ B-MetricValue
55.2 -X- _ B-MetricValue
45.4 -X- _ B-MetricValue
20.8 -X- _ B-MetricValue
NewsQA -X- _ B-DatasetName
72.1 -X- _ B-MetricValue
- -X- _ B-MetricValue
47.4 -X- _ I-MetricValue
55.9 -X- _ B-MetricValue
45.2 -X- _ B-MetricValue
20.6 -X- _ B-MetricValue
SearchQA -X- _ B-DatasetName
70.2 -X- _ B-MetricValue
40.2 -X- _ B-MetricValue
- -X- _ B-MetricValue
57.3 -X- _ I-MetricValue
45.5 -X- _ B-MetricValue
20.4 -X- _ B-MetricValue
TQA -X- _ B-DatasetName
- -X- _ I-DatasetName
G -X- _ I-DatasetName
69.9 -X- _ B-MetricValue
41.2 -X- _ B-MetricValue
50.0 -X- _ B-MetricValue
- -X- _ B-MetricValue
46.2 -X- _ I-MetricValue
20.8 -X- _ B-MetricValue
TQA -X- _ B-DatasetName
- -X- _ I-DatasetName
W -X- _ I-DatasetName
71.0 -X- _ B-MetricValue
39.2 -X- _ B-MetricValue
48.4 -X- _ B-MetricValue
55.7 -X- _ B-MetricValue
- -X- _ B-MetricValue
20.9 -X- _ I-MetricValue
HotpotQA -X- _ B-DatasetName
71.2 -X- _ B-MetricValue
39.5 -X- _ B-MetricValue
48.6 -X- _ B-MetricValue
56.6 -X- _ B-MetricValue
45.6 -X- _ B-MetricValue
- -X- _ O
Multi-75 -X- _ B-DatasetName
K -X- _ I-DatasetName
71.5 -X- _ B-MetricValue
42.1 -X- _ B-MetricValue
48.5 -X- _ B-MetricValue
56.6 -X- _ B-MetricValue
46.5 -X- _ B-MetricValue
20.4 -X- _ B-MetricValue
Table -X- _ O
4 -X- _ O
: -X- _ O
Results -X- _ O
taken -X- _ O
from -X- _ O
the -X- _ O
right -X- _ O
half -X- _ O
of -X- _ O
Table -X- _ O
4 -X- _ O
in -X- _ O
the -X- _ O
MultiQA -X- _ B-TaskName
paper -X- _ O
( -X- _ O
Talmor -X- _ O
and -X- _ O
Berant -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
as -X- _ O
that -X- _ O
section -X- _ O
is -X- _ O
directly -X- _ O
relevant -X- _ O
to -X- _ O
this -X- _ O
work -X- _ O
( -X- _ O
the -X- _ O
selfrow -X- _ O
containing -X- _ O
only -X- _ O
standard -X- _ O
fine -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
is -X- _ O
removed -X- _ O
for -X- _ O
clarity -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
find -X- _ O
similar -X- _ O
results -X- _ O
in -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018a -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
in -X- _ O
their -X- _ O
Table -X- _ O
3 -X- _ O
they -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
STILTs -X- _ B-MethodName
approach -X- _ O
outperforms -X- _ O
the280 -X- _ O
. -X- _ O

Combining -X- _ O
All -X- _ O
Tasks -X- _ O
Our -X- _ O
results -X- _ O
using -X- _ O
MTL -X- _ B-MethodName
All -X- _ I-MethodName
showed -X- _ O
that -X- _ O
although -X- _ O
MTL -X- _ B-MethodName
Allis -X- _ I-MethodName
conceptually -X- _ O
easy -X- _ O
( -X- _ O
just -X- _ O
put -X- _ O
all -X- _ O
the -X- _ O
datasets -X- _ O
together -X- _ O
) -X- _ O
it -X- _ O
does -X- _ O
not -X- _ O
lead -X- _ O
to -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
. -X- _ O

Even -X- _ O
if -X- _ O
all -X- _ O
results -X- _ O
were -X- _ O
statistically -X- _ O
significant -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
highly -X- _ O
unlikely -X- _ O
, -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
Multi-75 -X- _ B-DatasetName
K -X- _ I-DatasetName
models -X- _ O
perform -X- _ O
equal -X- _ O
or -X- _ O
better -X- _ O
on -X- _ O
2 -X- _ O
of -X- _ O
the -X- _ O
6 -X- _ O
tasks -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
not -X- _ O
statistically -X- _ O
different -X- _ O
from -X- _ O
random -X- _ O
. -X- _ O

As -X- _ O
stated -X- _ O
in -X- _ O
the -X- _ O
body -X- _ O
of -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
no -X- _ O
standard -X- _ O
deviation -X- _ O
is -X- _ O
reported -X- _ O
in -X- _ O
the -X- _ O
MultiQA -X- _ B-TaskName
paper -X- _ O
and -X- _ O
thus -X- _ O
it -X- _ O
is -X- _ O
hard -X- _ O
to -X- _ O
know -X- _ O
whether -X- _ O
the -X- _ O
difference -X- _ O
in -X- _ O
results -X- _ O
are -X- _ O
statistically -X- _ O
significant -X- _ O
. -X- _ O

TQAG -X- _ B-DatasetName
and -X- _ O
TQA -X- _ B-DatasetName
- -X- _ I-DatasetName
W -X- _ I-DatasetName
come -X- _ O
from -X- _ O
the -X- _ O
same -X- _ O
dataset -X- _ O
. -X- _ O

Note -X- _ O
that -X- _ O
both -X- _ O
models -X- _ O
Multi-75 -X- _ B-DatasetName
K -X- _ I-DatasetName
scores -X- _ O
perform -X- _ O
approximately -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
STILTs -X- _ B-MethodName
methods -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
expected -X- _ O
given -X- _ O
that -X- _ O
they -X- _ O
are -X- _ O
the -X- _ O
same -X- _ O
size -X- _ O
. -X- _ O

The -X- _ O
top -X- _ O
half -X- _ O
contains -X- _ O
the -X- _ O
results -X- _ O
using -X- _ O
the -X- _ O
DocQA -X- _ B-TaskName
model -X- _ O
while -X- _ O
the -X- _ O
bottom -X- _ O
half -X- _ O
uses -X- _ O
BERT -X- _ B-MethodName
. -X- _ O

Thus -X- _ O
, -X- _ O
although -X- _ O
the -X- _ O
MultiQA -X- _ B-TaskName
paper -X- _ O
is -X- _ O
not -X- _ O
strictly -X- _ O
comparable -X- _ O
to -X- _ O
our -X- _ O
work -X- _ O
due -X- _ O
to -X- _ O
their -X- _ O
training -X- _ O
setup -X- _ O
( -X- _ O
the -X- _ O
MTL+fine -X- _ B-MethodName
tuning -X- _ I-MethodName
) -X- _ O
, -X- _ O
their -X- _ O
results -X- _ O
agree -X- _ O
with -X- _ O
our -X- _ O
hypothesis -X- _ O
as -X- _ O
well -X- _ O
. -X- _ O

Although -X- _ O
no -X- _ O
error -X- _ B-HyperparameterName
bounds -X- _ I-HyperparameterName
or -X- _ O
standard -X- _ B-HyperparameterName
deviations -X- _ I-HyperparameterName
are -X- _ O
reported -X- _ O
in -X- _ O
their -X- _ O
paper -X- _ O
( -X- _ O
which -X- _ O
makes -X- _ O
the -X- _ O
exact -X- _ O
comparison -X- _ O
difficult -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
see -X- _ O
that -X- _ O
the -X- _ O
MTL -X- _ B-MethodName
approach -X- _ O
performs -X- _ O
equal -X- _ O
or -X- _ O
better -X- _ O
on -X- _ O
almost -X- _ O
half -X- _ O
of -X- _ O
the -X- _ O
datasets -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
MultiQA -X- _ B-TaskName
paper -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
each -X- _ O
training -X- _ O
set -X- _ O
is -X- _ O
artificially -X- _ O
controlled -X- _ O
to -X- _ O
be -X- _ O
the -X- _ O
same -X- _ O
number -X- _ O
( -X- _ O
75k -X- _ B-HyperparameterValue
instances -X- _ B-HyperparameterName
) -X- _ O
, -X- _ O
thus -X- _ O
our -X- _ O
size -X- _ O
heuristic -X- _ O
would -X- _ O
say -X- _ O
that -X- _ O
the -X- _ O
methods -X- _ O
should -X- _ O
be -X- _ O
comparable -X- _ O
. -X- _ O

How -X- _ O
does -X- _ O
this -X- _ O
relate -X- _ O
to -X- _ O
our -X- _ O
results -X- _ O
? -X- _ O
The -X- _ O
size -X- _ O
heuristic -X- _ O
says -X- _ O
that -X- _ O
MTL -X- _ B-MethodName
is -X- _ O
better -X- _ O
than -X- _ O
STILTs -X- _ B-MethodName
when -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
has -X- _ O
fewer -X- _ O
training -X- _ O
instances -X- _ O
. -X- _ O

We -X- _ O
note -X- _ O
that -X- _ O
this -X- _ O
STILTs -X- _ B-MethodName
- -X- _ O
like -X- _ O
transfer -X- _ O
with -X- _ O
the -X- _ O
MTL -X- _ B-MethodName
" -X- _ O
dataset -X- _ O
is -X- _ O
an -X- _ O
equivalent -X- _ O
method -X- _ O
to -X- _ O
doing -X- _ O
MTL -X- _ B-MethodName
and -X- _ O
then -X- _ O
fine -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
on -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
, -X- _ O
reminiscent -X- _ O
of -X- _ O
the -X- _ O
third -X- _ O
example -X- _ O
in -X- _ O
Phang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
( -X- _ O
Table -X- _ O
3 -X- _ O
, -X- _ O
GPT -X- _ B-MetricName
! -X- _ I-MetricName
{ -X- _ I-MetricName
MNLI -X- _ I-MetricName
, -X- _ I-MetricName
RTE}!RTE -X- _ I-MetricName
, -X- _ O
c.f -X- _ O
. -X- _ O

The -X- _ O
colors -X- _ O
indicate -X- _ O
visually -X- _ O
the -X- _ O
best -X- _ O
method -X- _ O
, -X- _ O
showing -X- _ O
a -X- _ O
statistically -X- _ O
significant -X- _ O
difference -X- _ O
from -X- _ O
the -X- _ O
other -X- _ O
from -X- _ O
using -X- _ O
using -X- _ O
a -X- _ O
two -X- _ B-MethodName
- -X- _ I-MethodName
sided -X- _ I-MethodName
t -X- _ I-MethodName
- -X- _ I-MethodName
test -X- _ I-MethodName
with -X- _ O
= -X- _ O
0:1 -X- _ B-HyperparameterValue
. -X- _ O

Numbers -X- _ O
in -X- _ O
cells -X- _ O
indicate -X- _ O
the -X- _ O
absolute -X- _ O
percent -X- _ O
score -X- _ O
difference -X- _ O
on -X- _ O
the -X- _ O
primary -X- _ O
task -X- _ O
when -X- _ O
using -X- _ O
MTL -X- _ B-MethodName
instead -X- _ O
of -X- _ O
STILTs -X- _ B-MethodName
( -X- _ O
positive -X- _ O
scores -X- _ O
mean -X- _ O
MTL -X- _ B-MethodName
is -X- _ O
better -X- _ O
and -X- _ O
vice -X- _ O
versa -X- _ O
) -X- _ O
. -X- _ O

Figure -X- _ O
3 -X- _ O
: -X- _ O
Results -X- _ O
comparing -X- _ O
intermediate -X- _ O
fine -X- _ O
tuning -X- _ O
( -X- _ O
STILTs -X- _ B-MethodName
) -X- _ O
vs -X- _ O
multi -X- _ B-MethodName
- -X- _ I-MethodName
task -X- _ I-MethodName
learning -X- _ I-MethodName
( -X- _ I-MethodName
MTL -X- _ I-MethodName
) -X- _ I-MethodName
with -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
. -X- _ O

They -X- _ O
then -X- _ O
show -X- _ O
results -X- _ O
for -X- _ O
STILTs -X- _ B-MethodName
transfer -X- _ O
on -X- _ O
those -X- _ O
same -X- _ O
datasets -X- _ O
along -X- _ O
with -X- _ O
the -X- _ O
MTL -X- _ B-DatasetName
dataset -X- _ I-DatasetName
( -X- _ O
their -X- _ O
data -X- _ O
is -X- _ O
reproduced -X- _ O
with -X- _ O
new -X- _ O
emphasis -X- _ O
in -X- _ O
Appendix -X- _ O
E -X- _ O
Table -X- _ O
4 -X- _ O
for -X- _ O
conve-279 -X- _ O
. -X- _ O

They -X- _ O
used -X- _ O
an -X- _ O
interesting -X- _ O
approach -X- _ O
to -X- _ O
MTL -X- _ B-MethodName
, -X- _ O
pulling -X- _ O
15k -X- _ B-HyperparameterValue
examples -X- _ B-HyperparameterName
from -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
5 -X- _ O
major -X- _ O
datasets -X- _ O
to -X- _ O
compose -X- _ O
one -X- _ O
new -X- _ O
MTL -X- _ B-MethodName
" -X- _ O
task -X- _ O
, -X- _ O
called -X- _ O
Multi-75 -X- _ B-DatasetName
K -X- _ I-DatasetName
. -X- _ O

MultiQA -X- _ B-TaskName
Talmor -X- _ O
and -X- _ O
Berant -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
MultiQA -X- _ B-TaskName
showed -X- _ O
that -X- _ O
using -X- _ O
MTL -X- _ B-MethodName
on -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
questionanswering -X- _ B-TaskName
( -X- _ I-TaskName
QA -X- _ I-TaskName
) -X- _ I-TaskName
datasets -X- _ B-DatasetName
made -X- _ O
it -X- _ O
possible -X- _ O
to -X- _ O
train -X- _ O
a -X- _ O
model -X- _ O
that -X- _ O
could -X- _ O
outperform -X- _ O
the -X- _ O
current -X- _ O
SOTA -X- _ B-MetricName
on -X- _ O
those -X- _ O
QA -X- _ B-TaskName
datasets -X- _ O
. -X- _ O

Furthermore -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
this -X- _ O
is -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
4 -X- _ O
significant -X- _ O
cells -X- _ O
in -X- _ O
our -X- _ O
matrix -X- _ O
where -X- _ O
the -X- _ O
size -X- _ B-HyperparameterName
heuristic -X- _ I-HyperparameterName
does -X- _ O
not -X- _ O
accurately -X- _ O
predict -X- _ O
the -X- _ O
best -X- _ O
method -X- _ O
. -X- _ O

How -X- _ O
does -X- _ O
this -X- _ O
compare -X- _ O
to -X- _ O
our -X- _ O
results -X- _ O
? -X- _ O
In -X- _ O
Figure -X- _ O
1 -X- _ O
we -X- _ O
see -X- _ O
that -X- _ O
our -X- _ O
results -X- _ O
also -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
STILTs -X- _ B-MethodName
method -X- _ O
is -X- _ O
better -X- _ O
than -X- _ O
the -X- _ O
MTL -X- _ B-MethodName
method -X- _ O
for -X- _ O
the -X- _ O
( -X- _ O
RTE -X- _ B-DatasetName
, -X- _ O
MNLI -X- _ B-DatasetName
) -X- _ O
pair -X- _ O
, -X- _ O
showing -X- _ O
that -X- _ O
our -X- _ O
results -X- _ O
are -X- _ O
consistent -X- _ O
with -X- _ O
those -X- _ O
in -X- _ O
the -X- _ O
literature -X- _ O
. -X- _ O

From -X- _ O
this -X- _ O
they -X- _ O
conclude -X- _ O
that -X- _ O
MTL -X- _ B-MethodName
is -X- _ O
worse -X- _ O
than -X- _ O
STILTs -X- _ B-MethodName
. -X- _ O

Their -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
STILTs -X- _ B-MethodName
provides -X- _ O
the -X- _ O
highest -X- _ O
score -X- _ O
, -X- _ O
with -X- _ O
all -X- _ O
MTL -X- _ B-MethodName
varieties -X- _ O
being -X- _ O
worse -X- _ O
. -X- _ O

Their -X- _ O
analysis -X- _ O
uses -X- _ O
MNLI -X- _ B-DatasetName
as -X- _ O
the -X- _ O
supporting -X- _ O
task -X- _ O
and -X- _ B-TaskName
RTE -X- _ I-TaskName
as -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
, -X- _ O
trying -X- _ O
MTL -X- _ B-MethodName
, -X- _ O
STILTs -X- _ B-MethodName
, -X- _ O
MTL+finetuning -X- _ B-MethodName
, -X- _ O
and -X- _ O
only -X- _ B-MethodName
fine -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
on -X- _ O
RTE -X- _ B-TaskName
. -X- _ O

However -X- _ O
, -X- _ O
at -X- _ O
the -X- _ O
end -X- _ O
of -X- _ O
Section -X- _ O
4 -X- _ O
in -X- _ O
their -X- _ O
paper -X- _ O
, -X- _ O
they -X- _ O
conduct -X- _ O
an -X- _ O
experiment -X- _ O
with -X- _ O
MTL -X- _ B-MethodName
and -X- _ O
compare -X- _ O
the -X- _ O
results -X- _ O
to -X- _ O
their -X- _ O
STILTs -X- _ B-MetricName
matrix -X- _ I-MetricName
( -X- _ O
their -X- _ O
experimental -X- _ O
results -X- _ O
are -X- _ O
reproduced -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
for -X- _ O
convenience -X- _ O
) -X- _ O
. -X- _ O

To -X- _ O
determine -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
the -X- _ O
intermediate -X- _ O
training -X- _ O
, -X- _ O
the -X- _ O
authors -X- _ O
computed -X- _ O
the -X- _ O
STILTs -X- _ B-MethodName
matrix -X- _ O
of -X- _ O
each -X- _ O
pair -X- _ O
in -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
dataset -X- _ O
. -X- _ O

Their -X- _ O
comparison -X- _ O
of -X- _ O
STILTs -X- _ B-MethodName
against -X- _ O
MTL -X- _ B-MethodName
setups -X- _ O
for -X- _ O
GPT -X- _ B-MethodName
, -X- _ O
with -X- _ O
MNLI -X- _ B-DatasetName
as -X- _ O
the -X- _ O
intermediate -X- _ O
task -X- _ O
and -X- _ O
RTE -X- _ B-TaskName
as -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
. -X- _ O

BERT -X- _ B-MethodName
on -X- _ O
STILTs -X- _ B-MethodName
Phang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
This -X- _ O
work -X- _ O
defined -X- _ O
the -X- _ O
acronym -X- _ B-MethodName
STILTs -X- _ I-MethodName
, -X- _ O
or -X- _ O
Supplementary -X- _ B-MethodName
Training -X- _ I-MethodName
on -X- _ I-MethodName
Intermediate -X- _ I-MethodName
Labeled -X- _ I-MethodName
- -X- _ I-MethodName
data -X- _ I-MethodName
Tasks -X- _ I-MethodName
, -X- _ O
which -X- _ O
has -X- _ O
been -X- _ O
an -X- _ O
inuential -X- _ O
idea -X- _ O
in -X- _ O
the -X- _ O
community -X- _ O
( -X- _ O
V -X- _ O
oskarides -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Yan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
ClarkModel -X- _ O
RTE -X- _ B-MetricName
accuracy -X- _ I-MetricName
GPT!RTE -X- _ O
54.2 -X- _ B-MetricValue
GPT!MNLI!RTE -X- _ B-MetricName
70.4 -X- _ B-MetricValue
GPT!{MNLI -X- _ B-MetricName
, -X- _ I-MetricName
RTE -X- _ I-MetricName
} -X- _ I-MetricName
68.6 -X- _ B-MetricValue
GPT!{MNLI -X- _ B-MetricName
, -X- _ I-MetricName
RTE}!RTE -X- _ I-MetricName
67.5 -X- _ B-MetricValue
Table -X- _ O
3 -X- _ O
: -X- _ O
Table -X- _ O
reproduced -X- _ O
from -X- _ O
Phang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

E -X- _ O
Additional -X- _ O
Background -X- _ O
Discussion -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
we -X- _ O
will -X- _ O
show -X- _ O
how -X- _ O
the -X- _ O
size -X- _ B-HyperparameterName
heuristic -X- _ I-HyperparameterName
is -X- _ O
supported -X- _ O
by -X- _ O
and -X- _ O
helps -X- _ O
explain -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
previous -X- _ O
work -X- _ O
in -X- _ O
this -X- _ O
area -X- _ O
. -X- _ O

We -X- _ O
follow -X- _ O
previous -X- _ O
work -X- _ O
in -X- _ O
using -X- _ O
two -X- _ O
different -X- _ O
pre -X- _ B-MethodName
- -X- _ I-MethodName
trained -X- _ I-MethodName
models -X- _ I-MethodName
for -X- _ O
our -X- _ O
analysis -X- _ O
( -X- _ O
Talmor -X- _ O
and -X- _ O
Berant -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Phang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

D -X- _ O
Alternate -X- _ O
Model -X- _ O
: -X- _ O
BERT -X- _ B-MethodName
We -X- _ O
conduct -X- _ O
the -X- _ O
same -X- _ O
analysis -X- _ O
as -X- _ O
Figure -X- _ O
1 -X- _ O
with -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
and -X- _ O
find -X- _ O
similar -X- _ O
results -X- _ O
( -X- _ O
Figure -X- _ O
3 -X- _ O
, -X- _ O
thus -X- _ O
showing -X- _ O
that -X- _ O
our -X- _ O
results -X- _ O
transfer -X- _ O
to -X- _ O
other -X- _ O
pretrained -X- _ B-MethodName
transformer -X- _ I-MethodName
models -X- _ I-MethodName
. -X- _ O

As -X- _ O
theoretical -X- _ O
explanations -X- _ O
for -X- _ O
transfer -X- _ B-MethodName
learning -X- _ I-MethodName
are -X- _ O
still -X- _ O
an -X- _ O
active -X- _ O
area -X- _ O
of -X- _ O
research -X- _ O
, -X- _ O
we -X- _ O
leave -X- _ O
them -X- _ O
to -X- _ O
future -X- _ O
work -X- _ O
and -X- _ O
provide -X- _ O
this -X- _ O
empirical -X- _ O
comparison -X- _ O
to -X- _ O
guide -X- _ O
their -X- _ O
efforts -X- _ O
and -X- _ O
the -X- _ O
current -X- _ O
efforts -X- _ O
of -X- _ O
NLP -X- _ B-TaskName
researchers -X- _ O
and -X- _ O
practitioners -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
all -X- _ O
of -X- _ O
these -X- _ O
explanations -X- _ O
also -X- _ O
fail -X- _ O
to -X- _ O
take -X- _ O
into -X- _ O
account -X- _ O
task -X- _ B-HyperparameterName
relatedness -X- _ I-HyperparameterName
, -X- _ O
which -X- _ O
likely -X- _ O
also -X- _ O
plays -X- _ O
a -X- _ O
role -X- _ O
in -X- _ O
the -X- _ O
theoretical -X- _ O
explanation -X- _ O
( -X- _ O
although -X- _ O
even -X- _ O
that -X- _ O
too -X- _ O
, -X- _ O
has -X- _ O
been -X- _ O
called -X- _ O
into -X- _ O
question -X- _ O
with -X- _ O
Chang -X- _ O
and -X- _ O
Lu -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
) -X- _ O
. -X- _ O

catastrophic -X- _ O
interference -X- _ O
) -X- _ O
and -X- _ O
therefore -X- _ O
, -X- _ O
STILTs -X- _ B-MethodName
is -X- _ O
more -X- _ O
effective -X- _ O
- -X- _ O
while -X- _ O
MTL -X- _ B-MethodName
is -X- _ O
more -X- _ O
effective -X- _ O
for -X- _ O
small -X- _ O
target -X- _ O
tasks -X- _ O
. -X- _ O

Another -X- _ O
explanation -X- _ O
could -X- _ O
be -X- _ O
that -X- _ O
a -X- _ O
larger -X- _ O
target -X- _ O
task -X- _ O
does -X- _ O
not -X- _ O
benefit -X- _ O
from -X- _ O
MTL -X- _ B-MethodName
( -X- _ O
and -X- _ O
perhaps -X- _ O
is -X- _ O
harmed -X- _ O
by -X- _ O
it -X- _ O
, -X- _ O
e.g -X- _ O
. -X- _ O

STILTs -X- _ B-MethodName
) -X- _ O
while -X- _ O
a -X- _ O
large -X- _ O
supporting -X- _ O
task -X- _ O
used -X- _ O
for -X- _ O
initialization -X- _ B-MethodName
would -X- _ O
change -X- _ O
the -X- _ O
weights -X- _ O
too -X- _ O
much -X- _ O
for -X- _ O
the -X- _ O
small -X- _ O
target -X- _ O
task -X- _ O
to -X- _ O
use -X- _ O
effectively -X- _ O
( -X- _ O
thus -X- _ O
making -X- _ O
MTL -X- _ B-MethodName
the -X- _ O
more -X- _ O
effective -X- _ O
strategy -X- _ O
for -X- _ O
a -X- _ O
larger -X- _ O
supporting -X- _ O
task -X- _ O
) -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
for -X- _ O
STILTs -X- _ B-MethodName
this -X- _ O
catastrophic -X- _ O
forgetting -X- _ O
would -X- _ O
mainly -X- _ O
effect -X- _ O
the -X- _ O
supporting -X- _ O
task -X- _ O
performance -X- _ O
, -X- _ O
not -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
performance -X- _ O
, -X- _ O
making -X- _ O
that -X- _ O
explanation -X- _ O
unlikely -X- _ O
in -X- _ O
some -X- _ O
contexts -X- _ O
( -X- _ O
e.g -X- _ O
. -X- _ O

A -X- _ O
naive -X- _ O
explanation -X- _ O
for -X- _ O
our -X- _ O
task -X- _ O
would -X- _ O
be -X- _ O
to -X- _ O
think -X- _ O
that -X- _ O
when -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
is -X- _ O
larger -X- _ O
, -X- _ O
STILTs -X- _ B-MethodName
should -X- _ O
be -X- _ O
worse -X- _ O
because -X- _ O
of -X- _ O
catastrophic -X- _ O
forgetting -X- _ O
, -X- _ O
whereas -X- _ O
MTL -X- _ B-MethodName
would -X- _ O
still -X- _ O
have -X- _ O
access -X- _ O
to -X- _ O
the -X- _ O
supporting -X- _ O
task -X- _ O
. -X- _ O

Furthermore -X- _ O
, -X- _ O
previous -X- _ O
explanations -X- _ O
for -X- _ O
why -X- _ O
the -X- _ O
STILTs -X- _ B-MethodName
method -X- _ O
works -X- _ O
has -X- _ O
been -X- _ O
called -X- _ O
into -X- _ O
question -X- _ O
( -X- _ O
Chang -X- _ O
and -X- _ O
Lu -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
leaving -X- _ O
it -X- _ O
an -X- _ O
open -X- _ O
research -X- _ O
area -X- _ O
. -X- _ O

does -X- _ O
MTL -X- _ B-MethodName
or -X- _ O
STILTs -X- _ B-MethodName
cause -X- _ O
more -X- _ O
catastrophic -X- _ O
forgetting -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
) -X- _ O
. -X- _ O

STILTs -X- _ B-MethodName
there -X- _ O
exists -X- _ O
no -X- _ O
previous -X- _ O
work -X- _ O
that -X- _ O
shows -X- _ O
how -X- _ O
these -X- _ O
methods -X- _ O
differ -X- _ O
in -X- _ O
any -X- _ O
practical -X- _ O
or -X- _ O
theoretical -X- _ O
terms -X- _ O
( -X- _ O
e.g -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
as -X- _ O
our -X- _ O
work -X- _ O
provides -X- _ O
a -X- _ O
novel -X- _ O
comparison -X- _ O
of -X- _ O
MTL -X- _ B-MethodName
vs -X- _ O
. -X- _ O

C -X- _ O
Theories -X- _ O
for -X- _ O
Transfer -X- _ B-MethodName
Effectiveness -X- _ I-MethodName
Previous -X- _ O
work -X- _ O
often -X- _ O
invokes -X- _ O
ideas -X- _ O
such -X- _ O
as -X- _ O
catastrophic -X- _ O
forgetting -X- _ O
to -X- _ O
describe -X- _ O
why -X- _ O
STILTs -X- _ B-MethodName
or -X- _ O
MTL -X- _ B-MethodName
does -X- _ O
or -X- _ O
does -X- _ O
not -X- _ O
improve -X- _ O
over -X- _ O
the -X- _ O
basic -X- _ O
fine -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
case -X- _ O
( -X- _ O
Phang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Pruksachatkun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
; -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018a -X- _ O
) -X- _ O
. -X- _ O

Section -X- _ O
4 -X- _ O
, -X- _ O
Vu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
; -X- _ O
Poth -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
) -X- _ O
, -X- _ O
you -X- _ O
would -X- _ O
be -X- _ O
able -X- _ O
to -X- _ O
make -X- _ O
even -X- _ O
larger -X- _ O
gains -X- _ O
over -X- _ O
MTL -X- _ B-MethodName
All -X- _ I-MethodName
. -X- _ O

Furthermore -X- _ O
, -X- _ O
if -X- _ O
you -X- _ O
could -X- _ O
predict -X- _ O
which -X- _ O
supplementary -X- _ O
task -X- _ O
would -X- _ O
be -X- _ O
most -X- _ O
effective -X- _ O
( -X- _ O
Pairwise -X- _ B-MethodName
Oracle -X- _ I-MethodName
, -X- _ O
c.f -X- _ O
. -X- _ O

Thus -X- _ O
, -X- _ O
although -X- _ O
MTL -X- _ B-MethodName
Allis -X- _ I-MethodName
conceptually -X- _ O
simple -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
the -X- _ O
best -X- _ O
choice -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
target -X- _ O
task -X- _ O
accuracy -X- _ O
. -X- _ O

We -X- _ O
see -X- _ O
that -X- _ O
the -X- _ O
Pairwise -X- _ B-MethodName
Oracle -X- _ I-MethodName
, -X- _ O
which -X- _ O
uses -X- _ O
the -X- _ O
best -X- _ O
supplementary -X- _ O
task -X- _ O
for -X- _ O
the -X- _ O
given -X- _ O
target -X- _ O
task -X- _ O
, -X- _ O
outperforms -X- _ O
all -X- _ O
methods -X- _ O
by -X- _ O
a -X- _ O
large -X- _ O
margin -X- _ O
. -X- _ O

Results -X- _ O
Although -X- _ O
dynamic -X- _ B-MethodName
sampling -X- _ I-MethodName
was -X- _ O
more -X- _ O
effective -X- _ O
for -X- _ O
the -X- _ O
pairwise -X- _ B-TaskName
tasks -X- _ I-TaskName
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
dynamic -X- _ B-MethodName
sampling -X- _ I-MethodName
was -X- _ O
worse -X- _ O
than -X- _ O
sampling -X- _ B-MethodName
by -X- _ I-MethodName
size -X- _ I-MethodName
when -X- _ O
using -X- _ O
MTL -X- _ B-MethodName
on -X- _ O
all -X- _ O
nine -X- _ O
datasets -X- _ O
( -X- _ O
top -X- _ O
half -X- _ O
of -X- _ O
Table -X- _ O
2).However -X- _ O
, -X- _ O
when -X- _ O
the -X- _ O
MTL -X- _ B-MethodName
Allmethod -X- _ I-MethodName
is -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
pairwise -X- _ B-MethodName
methods -X- _ I-MethodName
, -X- _ O
it -X- _ O
does -X- _ O
not -X- _ O
perform -X- _ O
as -X- _ O
well -X- _ O
( -X- _ O
bottom -X- _ O
half -X- _ O
of -X- _ O
Table -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O

Finally -X- _ O
, -X- _ O
we -X- _ O
report -X- _ O
the -X- _ O
score -X- _ O
from -X- _ O
the -X- _ O
best -X- _ O
task -X- _ O
using -X- _ O
the -X- _ O
best -X- _ O
pairwise -X- _ B-MethodName
method -X- _ I-MethodName
, -X- _ O
which -X- _ O
we -X- _ O
call -X- _ O
the -X- _ O
Pairwise -X- _ B-MethodName
Oracle -X- _ I-MethodName
. -X- _ O

We -X- _ O
also -X- _ O
show -X- _ O
the -X- _ O
average -X- _ B-MetricName
score -X- _ I-MetricName
found -X- _ O
by -X- _ O
choosing -X- _ O
MTL -X- _ B-MethodName
or -X- _ O
STILTs -X- _ B-MethodName
using -X- _ O
the -X- _ O
size -X- _ B-HyperparameterName
heuristic -X- _ I-HyperparameterName
as -X- _ O
Ave -X- _ O
. -X- _ O

To -X- _ O
illustrate -X- _ O
the -X- _ O
difference -X- _ O
between -X- _ O
MTL -X- _ B-MethodName
Alland -X- _ I-MethodName
the -X- _ O
pairwise -X- _ B-MethodName
methods -X- _ I-MethodName
, -X- _ O
we -X- _ O
show -X- _ O
the -X- _ O
average -X- _ B-MetricName
score -X- _ I-MetricName
across -X- _ O
all -X- _ O
supplementary -X- _ O
tasks -X- _ O
for -X- _ O
MTL -X- _ B-MethodName
and -X- _ O
STILTs -X- _ B-MethodName
. -X- _ O

B -X- _ O
Pairwise -X- _ B-MethodName
Approaches -X- _ I-MethodName
vs -X- _ O
MTL -X- _ B-MethodName
All -X- _ I-MethodName
Experimental -X- _ O
Setup -X- _ O
We -X- _ O
use -X- _ O
MTL -X- _ B-MethodName
Allwith -X- _ I-MethodName
three -X- _ O
different -X- _ O
sampling -X- _ O
methods -X- _ O
: -X- _ O
uniform -X- _ B-MethodName
sampling -X- _ I-MethodName
, -X- _ O
sampling -X- _ B-MethodName
by -X- _ I-MethodName
dataset -X- _ I-MethodName
size -X- _ I-MethodName
, -X- _ O
and -X- _ O
dynamic -X- _ B-MethodName
sampling -X- _ I-MethodName
. -X- _ O

Our -X- _ O
CPUs -X- _ B-HyperparameterName
use -X- _ O
12 -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
core -X- _ I-HyperparameterValue
Intel -X- _ O
Haswell -X- _ O
( -X- _ O
2.3 -X- _ B-HyperparameterValue
GHz -X- _ B-HyperparameterName
) -X- _ O
processors -X- _ O
with -X- _ O
32 -X- _ B-HyperparameterValue
GB -X- _ I-HyperparameterValue
of -X- _ O
RAM -X- _ B-HyperparameterName
. -X- _ O

We -X- _ O
train -X- _ O
for -X- _ O
10 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
, -X- _ O
checkpointing -X- _ B-MethodName
every -X- _ O
half -X- _ B-HyperparameterValue
an -X- _ O
epoch -X- _ B-HyperparameterName
and -X- _ O
use -X- _ O
the -X- _ O
best -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
development -X- _ O
set -X- _ O
for -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
scores -X- _ O
. -X- _ O

A -X- _ O
Training -X- _ O
and -X- _ O
Compute -X- _ O
Details -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
hyperparameters -X- _ O
given -X- _ O
by -X- _ O
the -X- _ O
transformer -X- _ B-MethodName
library -X- _ I-MethodName
example -X- _ I-MethodName
on -X- _ O
GLUE -X- _ B-DatasetName
as -X- _ O
the -X- _ O
default -X- _ O
for -X- _ O
our -X- _ O
model -X- _ O
( -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
2e-5 -X- _ B-HyperparameterValue
, -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
128 -X- _ B-HyperparameterValue
, -X- _ O
AdamW -X- _ B-HyperparameterName
optimizer -X- _ I-HyperparameterName
( -X- _ O
Kingma -X- _ O
and -X- _ O
Ba -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
) -X- _ O
. -X- _ O

Additionally -X- _ O
, -X- _ O
we -X- _ O
showed -X- _ O
that -X- _ O
these -X- _ O
pairwise -X- _ B-MethodName
transfer -X- _ I-MethodName
learning -X- _ I-MethodName
techniques -X- _ O
outperform -X- _ O
the -X- _ O
MTL -X- _ B-MethodName
Allapproach -X- _ I-MethodName
in -X- _ O
almost -X- _ O
every -X- _ O
case -X- _ O
. -X- _ O

This -X- _ O
simple -X- _ B-HyperparameterName
heuristic -X- _ I-HyperparameterName
, -X- _ O
which -X- _ O
holds -X- _ O
true -X- _ O
in -X- _ O
more -X- _ O
than -X- _ O
92% -X- _ B-HyperparameterValue
of -X- _ O
applicable -X- _ O
cases -X- _ O
, -X- _ O
states -X- _ O
that -X- _ O
multi -X- _ B-MethodName
- -X- _ I-MethodName
task -X- _ I-MethodName
learning275 -X- _ I-MethodName
. -X- _ O

We -X- _ O
provide -X- _ O
the -X- _ O
first -X- _ O
comprehensive -X- _ O
comparison -X- _ O
between -X- _ O
these -X- _ O
three -X- _ O
methods -X- _ O
using -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
dataset -X- _ I-DatasetName
suite -X- _ O
and -X- _ O
show -X- _ O
that -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
simple -X- _ O
rule -X- _ O
for -X- _ O
when -X- _ O
to -X- _ O
use -X- _ O
one -X- _ O
of -X- _ O
these -X- _ O
techniques -X- _ O
over -X- _ O
the -X- _ O
other -X- _ O
. -X- _ O

5 -X- _ O
Conclusion -X- _ O
We -X- _ O
examined -X- _ O
the -X- _ O
three -X- _ O
main -X- _ O
strategies -X- _ O
for -X- _ O
transfer -X- _ O
learning -X- _ O
in -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
processing -X- _ I-TaskName
: -X- _ O
training -X- _ O
on -X- _ O
an -X- _ O
intermediate -X- _ O
supporting -X- _ O
task -X- _ O
to -X- _ O
aid -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
( -X- _ O
STILTs -X- _ B-MethodName
) -X- _ O
, -X- _ O
training -X- _ O
on -X- _ O
the -X- _ O
target -X- _ O
and -X- _ O
supporting -X- _ O
task -X- _ O
simultaneously -X- _ O
( -X- _ O
MTL -X- _ B-MethodName
) -X- _ O
, -X- _ O
or -X- _ O
training -X- _ O
on -X- _ O
multiple -X- _ O
supporting -X- _ O
tasks -X- _ O
alongside -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
( -X- _ O
MTL -X- _ B-MethodName
All -X- _ I-MethodName
) -X- _ O
. -X- _ O

This -X- _ O
paper -X- _ O
is -X- _ O
orthogonal -X- _ O
to -X- _ O
those -X- _ O
, -X- _ O
as -X- _ O
we -X- _ O
examine -X- _ O
when -X- _ O
you -X- _ O
should -X- _ O
choose -X- _ O
MTL -X- _ B-MethodName
or -X- _ O
STILTs -X- _ B-MethodName
, -X- _ O
rather -X- _ O
than -X- _ O
when -X- _ O
they -X- _ O
are -X- _ O
more -X- _ O
effective -X- _ O
than -X- _ O
the -X- _ O
standard -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
case -X- _ O
( -X- _ O
in -X- _ O
fact -X- _ O
, -X- _ O
these -X- _ O
strategies -X- _ O
could -X- _ O
be -X- _ O
combined -X- _ O
to -X- _ O
predict -X- _ O
transfer -X- _ O
and -X- _ O
then -X- _ O
use -X- _ O
the -X- _ O
best -X- _ O
method -X- _ O
) -X- _ O
. -X- _ O

4 -X- _ O
Related -X- _ O
Work -X- _ O
A -X- _ O
large -X- _ O
body -X- _ O
of -X- _ O
recent -X- _ O
work -X- _ O
( -X- _ O
Sgaard -X- _ O
and -X- _ O
Bingel -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Vu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Bettgenhuser -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Peng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Poth -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
exists -X- _ O
that -X- _ O
examines -X- _ O
when -X- _ O
these -X- _ O
transfer -X- _ B-MethodName
learning -X- _ I-MethodName
methods -X- _ I-MethodName
are -X- _ O
more -X- _ O
effective -X- _ O
than -X- _ O
simply -X- _ B-MethodName
fine -X- _ I-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
on -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
. -X- _ O

Furthermore -X- _ O
, -X- _ O
using -X- _ O
the -X- _ O
size -X- _ O
heuristic -X- _ O
on -X- _ O
the -X- _ O
average -X- _ O
supplementary -X- _ O
task -X- _ O
increases -X- _ O
the -X- _ O
score -X- _ B-MetricName
by -X- _ O
5 -X- _ B-MetricValue
points -X- _ I-MetricValue
over -X- _ O
MTL -X- _ B-MethodName
All(78.3 -X- _ I-MethodName
vs -X- _ O
73.3 -X- _ B-MetricValue
) -X- _ O
. -X- _ O

the -X- _ O
target -X- _ O
task -X- _ O
score -X- _ O
: -X- _ O
on -X- _ O
a -X- _ O
randomdataset -X- _ O
simply -X- _ O
using -X- _ O
STILTs -X- _ B-MethodName
or -X- _ O
MTL -X- _ B-MethodName
will -X- _ O
likely -X- _ O
perform -X- _ O
better -X- _ O
. -X- _ O

Thus -X- _ O
, -X- _ O
although -X- _ O
MTL -X- _ B-MethodName
Allis -X- _ I-MethodName
conceptually -X- _ O
simple -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
the -X- _ O
best -X- _ O
choice -X- _ O
w.r.t -X- _ O
. -X- _ O

We -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
average -X- _ O
pairwise -X- _ O
approach -X- _ O
consistently -X- _ O
outperforms -X- _ O
the -X- _ O
MTL -X- _ B-MethodName
Allmethod -X- _ I-MethodName
, -X- _ O
except -X- _ O
for -X- _ O
the -X- _ O
RTE -X- _ B-TaskName
task -X- _ I-TaskName
( -X- _ O
Table -X- _ O
1 -X- _ O
) -X- _ O
and -X- _ O
using -X- _ O
the -X- _ O
best -X- _ O
supporting -X- _ O
task -X- _ O
outperforms -X- _ O
MTL -X- _ B-MethodName
Allin -X- _ I-MethodName
every -X- _ O
case -X- _ O
( -X- _ O
Pairwise -X- _ B-MethodName
Oracle -X- _ I-MethodName
) -X- _ O
. -X- _ O

Pairwise -X- _ B-MethodName
TL -X- _ I-MethodName
vs -X- _ O
MTL -X- _ B-MethodName
All -X- _ I-MethodName
We -X- _ O
also -X- _ O
experiment -X- _ O
with -X- _ O
MTL -X- _ B-MethodName
Allon -X- _ I-MethodName
GLUE -X- _ B-DatasetName
( -X- _ O
see -X- _ O
Appendix -X- _ O
B -X- _ O
for -X- _ O
implementation -X- _ O
details -X- _ O
) -X- _ O
. -X- _ O

Thus -X- _ O
, -X- _ O
the -X- _ O
synthetic -X- _ O
experiments -X- _ O
corroborate -X- _ O
our -X- _ O
main -X- _ O
finding -X- _ O
; -X- _ O
the -X- _ O
size -X- _ B-HyperparameterName
heuristic -X- _ I-HyperparameterName
holds -X- _ O
even -X- _ O
on -X- _ O
controlled -X- _ O
instances -X- _ O
where -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
sets -X- _ O
are -X- _ O
artificially -X- _ O
manipulated -X- _ O
. -X- _ O

Furthermore -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
when -X- _ O
both -X- _ O
datasets -X- _ O
are -X- _ O
equal -X- _ O
sizes -X- _ O
the -X- _ O
two -X- _ O
methods -X- _ O
are -X- _ O
statistically -X- _ O
similar -X- _ O
, -X- _ O
as -X- _ O
we -X- _ O
would -X- _ O
expect -X- _ O
from -X- _ O
the -X- _ O
size -X- _ B-HyperparameterName
heuristic -X- _ I-HyperparameterName
( -X- _ O
Support -X- _ B-HyperparameterName
Task -X- _ I-HyperparameterName
Proportion -X- _ I-HyperparameterName
= -X- _ O
1.0 -X- _ B-HyperparameterValue
) -X- _ O
. -X- _ O

We -X- _ O
can -X- _ O
see -X- _ O
that -X- _ O
as -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
supporting -X- _ O
dataset -X- _ O
increases -X- _ O
, -X- _ O
MTL -X- _ B-MethodName
becomes -X- _ O
more -X- _ O
effective -X- _ O
than -X- _ O
STILTs -X- _ B-MethodName
. -X- _ O

We -X- _ O
take -X- _ O
the -X- _ O
same -X- _ O
pair -X- _ O
and -X- _ O
reduce -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
of -X- _ O
QNLI -X- _ B-DatasetName
in -X- _ O
half -X- _ O
, -X- _ O
varying -X- _ O
MNLI -X- _ B-DatasetName
around -X- _ O
the -X- _ O
new -X- _ O
number -X- _ O
of -X- _ O
instances -X- _ O
in -X- _ O
the -X- _ O
QNLI -X- _ B-DatasetName
training -X- _ O
set -X- _ O
as -X- _ O
above -X- _ O
( -X- _ O
e.g -X- _ O
. -X- _ O

We -X- _ O
also -X- _ O
test -X- _ O
whether -X- _ O
these -X- _ O
results -X- _ O
hold -X- _ O
if -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
primary -X- _ O
dataset -X- _ O
is -X- _ O
changed -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
perhaps -X- _ O
there -X- _ O
is -X- _ O
something -X- _ O
special -X- _ O
about -X- _ O
the -X- _ O
current -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
QNLI -X- _ B-DatasetName
dataset -X- _ O
) -X- _ O
. -X- _ O

Other -X- _ O
than -X- _ O
dataset -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
, -X- _ O
all -X- _ O
experimental -X- _ O
parameters -X- _ O
are -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
in -X- _ O
the -X- _ O
original -X- _ O
comparison -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O

By -X- _ O
doing -X- _ O
so -X- _ O
, -X- _ O
we -X- _ O
examine -X- _ O
whether -X- _ O
the -X- _ O
size -X- _ B-HyperparameterName
heuristic -X- _ I-HyperparameterName
holds -X- _ O
while -X- _ O
explicitly -X- _ O
controlling -X- _ O
for -X- _ O
the -X- _ O
supporting -X- _ B-HyperparameterName
tasks -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
. -X- _ O

We -X- _ O
subsample -X- _ O
data -X- _ O
from -X- _ O
the -X- _ O
supporting -X- _ O
task -X- _ O
so -X- _ O
that -X- _ O
we -X- _ O
have -X- _ O
a -X- _ O
proportion -X- _ B-HyperparameterName
Kof -X- _ I-HyperparameterName
the -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
primary -X- _ O
task -X- _ O
( -X- _ O
whereK2f1=3;1=2;1;2;3 -X- _ B-MetricValue
g -X- _ I-MetricValue
) -X- _ O
. -X- _ O

We -X- _ O
choose -X- _ O
to -X- _ O
test -X- _ O
QNLI -X- _ B-DatasetName
primary -X- _ O
with -X- _ O
MNLI -X- _ B-DatasetName
supporting -X- _ O
, -X- _ O
as -X- _ O
they -X- _ O
should -X- _ O
be -X- _ O
closely -X- _ O
related -X- _ O
and -X- _ O
thus -X- _ O
have -X- _ O
the -X- _ O
potential -X- _ O
to -X- _ O
disprove -X- _ O
this -X- _ O
heuristic -X- _ O
. -X- _ O

the -X- _ O
size -X- _ B-HyperparameterName
heuristic -X- _ I-HyperparameterName
further -X- _ O
we -X- _ O
conduct -X- _ O
controlled -X- _ O
experiments -X- _ O
that -X- _ O
alter -X- _ O
the -X- _ O
amount -X- _ O
of -X- _ O
training -X- _ O
data -X- _ O
of -X- _ O
the -X- _ O
supporting -X- _ O
task -X- _ O
to -X- _ O
be -X- _ O
above -X- _ O
and -X- _ O
below -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
. -X- _ O

We -X- _ O
find -X- _ O
that -X- _ O
on -X- _ O
almost -X- _ O
every -X- _ O
task -X- _ O
, -X- _ O
pairwise -X- _ O
approaches -X- _ O
are -X- _ O
better -X- _ O
than -X- _ O
MTL -X- _ B-MethodName
All -X- _ I-MethodName
. -X- _ O

All -X- _ O
scores -X- _ O
are -X- _ O
the -X- _ O
average -X- _ O
of -X- _ O
5 -X- _ B-HyperparameterValue
random -X- _ B-HyperparameterName
seeds -X- _ I-HyperparameterName
. -X- _ O

Pairwise -X- _ B-MethodName
Oracle -X- _ I-MethodName
uses -X- _ O
the -X- _ O
best -X- _ O
supplementary -X- _ O
task -X- _ O
for -X- _ O
the -X- _ O
given -X- _ O
target -X- _ O
task -X- _ O
using -X- _ O
the -X- _ O
best -X- _ O
pairwise -X- _ O
method -X- _ O
( -X- _ O
STILTs -X- _ B-MethodName
or -X- _ O
MTL -X- _ B-MethodName
) -X- _ O
. -X- _ O

78.3 -X- _ B-MetricValue
56.1 -X- _ I-MetricValue
87.7 -X- _ I-MetricValue
92.3 -X- _ I-MetricValue
66.5 -X- _ I-MetricValue
89.0 -X- _ I-MetricValue
89.6 -X- _ I-MetricValue
87.3 -X- _ I-MetricValue
84.0 -X- _ I-MetricValue
52.1 -X- _ I-MetricValue
Pairwise -X- _ B-MethodName
Oracle -X- _ I-MethodName
80.7 -X- _ B-MetricValue
57.7 -X- _ I-MetricValue
88.8 -X- _ I-MetricValue
92.9 -X- _ I-MetricValue
76.0 -X- _ I-MetricValue
89.5 -X- _ I-MetricValue
90.6 -X- _ I-MetricValue
90.2 -X- _ I-MetricValue
84.3 -X- _ I-MetricValue
56.5 -X- _ I-MetricValue
Table -X- _ O
1 -X- _ O
: -X- _ O
Comparison -X- _ O
of -X- _ O
MTL -X- _ B-MethodName
Allto -X- _ I-MethodName
the -X- _ O
pairwise -X- _ B-MethodName
STILTs -X- _ I-MethodName
or -X- _ O
MTL -X- _ B-MethodName
approaches -X- _ O
. -X- _ O

MTL -X- _ B-MethodName
77.3 -X- _ B-MetricValue
56.1 -X- _ B-MetricValue
87.4 -X- _ B-MetricValue
91.9 -X- _ B-MetricValue
66.0 -X- _ B-MetricValue
85.6 -X- _ B-MetricValue
87.5 -X- _ B-MetricValue
87.4 -X- _ B-MetricValue
80.8 -X- _ B-MetricValue
52.7 -X- _ B-MetricValue
Avg -X- _ B-MetricName
. -X- _ O

STILTs -X- _ B-MethodName
75.8 -X- _ B-MetricValue
45.0 -X- _ I-MetricValue
87.5 -X- _ I-MetricValue
92.1 -X- _ I-MetricValue
61.9 -X- _ I-MetricValue
88.9 -X- _ I-MetricValue
89.4 -X- _ I-MetricValue
87.4 -X- _ I-MetricValue
84.0 -X- _ I-MetricValue
46.4 -X- _ I-MetricValue
Avg -X- _ B-MetricName
. -X- _ O

Approach -X- _ B-MetricName
Mean -X- _ I-MetricName
WNLI -X- _ B-DatasetName
STS -X- _ B-DatasetName
- -X- _ I-DatasetName
B -X- _ I-DatasetName
SST-2 -X- _ B-DatasetName
RTE -X- _ B-DatasetName
QQP -X- _ B-DatasetName
QNLI -X- _ B-DatasetName
MRPC -X- _ B-DatasetName
MNLI -X- _ B-DatasetName
CoLA -X- _ B-DatasetName
MTL -X- _ B-MethodName
All -X- _ I-MethodName
73.3 -X- _ B-MetricValue
54.4 -X- _ B-MetricValue
86.6 -X- _ B-MetricValue
90.8 -X- _ B-MetricValue
67.4 -X- _ B-MetricValue
80.2 -X- _ B-MetricValue
84.9 -X- _ B-MetricValue
85.4 -X- _ B-MetricValue
74.2 -X- _ B-MetricValue
35.8 -X- _ B-MetricValue
Avg -X- _ O
. -X- _ O

Dataset -X- _ B-HyperparameterName
Size -X- _ I-HyperparameterName
Experiments -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
validate274 -X- _ O
. -X- _ O

Three -X- _ O
of -X- _ O
the -X- _ O
four -X- _ O
misclassified -X- _ O
cells -X- _ O
come -X- _ O
when -X- _ O
using -X- _ O
the -X- _ O
MRPC -X- _ B-DatasetName
dataset -X- _ O
as -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
, -X- _ O
but -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
obvious -X- _ O
reason -X- _ O
why -X- _ O
it -X- _ O
fails -X- _ O
on -X- _ O
MRPC -X- _ B-DatasetName
. -X- _ O

In -X- _ O
fact -X- _ O
, -X- _ O
if -X- _ O
we -X- _ O
use -X- _ O
this -X- _ O
heuristic -X- _ O
to -X- _ O
predict -X- _ O
which -X- _ O
method -X- _ O
will -X- _ O
be -X- _ O
better -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
it -X- _ O
predicts -X- _ O
49/53 -X- _ B-MetricValue
significant -X- _ O
cells -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
equivalent -X- _ O
to -X- _ O
92.5% -X- _ B-MetricValue
accuracy -X- _ B-MetricName
. -X- _ O

We -X- _ O
can -X- _ O
summarize -X- _ O
these -X- _ O
results -X- _ O
with -X- _ O
the -X- _ O
following -X- _ O
size -X- _ O
heuristic -X- _ O
: -X- _ O
MTL -X- _ B-MethodName
is -X- _ O
better -X- _ O
than -X- _ O
STILTs -X- _ B-MethodName
when -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
has -X- _ O
fewer -X- _ O
training -X- _ O
instances -X- _ O
than -X- _ O
the -X- _ O
supporting -X- _ O
task -X- _ O
and -X- _ O
vice -X- _ O
versa -X- _ O
. -X- _ O

The -X- _ O
smallest -X- _ O
dataset -X- _ O
, -X- _ O
WNLI -X- _ B-DatasetName
, -X- _ O
has -X- _ O
zero -X- _ O
green -X- _ O
cells -X- _ O
. -X- _ O

QQP -X- _ B-DatasetName
is -X- _ O
the -X- _ O
2nd -X- _ O
largest -X- _ O
and -X- _ O
every -X- _ O
cell -X- _ O
in -X- _ O
its -X- _ O
row -X- _ O
is -X- _ O
also -X- _ O
green -X- _ O
, -X- _ O
except -X- _ O
for -X- _ O
( -X- _ O
QQP -X- _ B-DatasetName
, -X- _ O
MNLI -X- _ B-DatasetName
) -X- _ O
. -X- _ O

For -X- _ O
example -X- _ O
, -X- _ O
MNLI -X- _ B-DatasetName
is -X- _ O
the -X- _ O
largest -X- _ O
and -X- _ O
every -X- _ O
cell -X- _ O
in -X- _ O
the -X- _ O
MNLI -X- _ B-DatasetName
row -X- _ O
is -X- _ O
green -X- _ O
. -X- _ O

a -X- _ O
9 -X- _ O
point -X- _ O
difference -X- _ O
on -X- _ O
( -X- _ O
WNLI -X- _ B-DatasetName
, -X- _ O
STS -X- _ B-DatasetName
- -X- _ I-DatasetName
B -X- _ I-DatasetName
) -X- _ O
) -X- _ O
the -X- _ O
variance -X- _ O
of -X- _ O
these -X- _ O
results -X- _ O
is -X- _ O
high -X- _ O
enough -X- _ O
that -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
statistically -X- _ O
significant -X- _ O
difference -X- _ O
between -X- _ O
the -X- _ O
STILTs -X- _ B-MethodName
and -X- _ O
MTL -X- _ B-MethodName
score -X- _ O
distributions -X- _ O
. -X- _ O
We -X- _ O
order -X- _ O
the -X- _ O
datasets -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
by -X- _ O
size -X- _ O
, -X- _ O
to -X- _ O
visually -X- _ O
illustrate -X- _ O
the -X- _ O
trend -X- _ O
. -X- _ O

Scores -X- _ O
that -X- _ O
are -X- _ O
statistically -X- _ O
significant -X- _ O
are -X- _ O
color -X- _ O
coded -X- _ O
green -X- _ O
( -X- _ O
if -X- _ O
STILTs -X- _ B-MethodName
is -X- _ O
better -X- _ O
) -X- _ O
or -X- _ O
blue -X- _ O
( -X- _ O
if -X- _ O
MTL -X- _ B-MethodName
is -X- _ O
better -X- _ O
) -X- _ O
, -X- _ O
whereas -X- _ O
they -X- _ O
are -X- _ O
coded -X- _ O
grey -X- _ O
if -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
statistically -X- _ O
significant -X- _ O
difference -X- _ O
. -X- _ O

However -X- _ O
, -X- _ O
this -X- _ O
matrix -X- _ O
does -X- _ O
not -X- _ O
tell -X- _ O
us -X- _ O
whether -X- _ O
these -X- _ O
differences -X- _ O
are -X- _ O
statistically -X- _ O
significant -X- _ O
; -X- _ O
for -X- _ O
this -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
two -X- _ B-MethodName
- -X- _ I-MethodName
sample -X- _ I-MethodName
t -X- _ I-MethodName
- -X- _ I-MethodName
test -X- _ I-MethodName
to -X- _ O
compare -X- _ O
the -X- _ O
mean -X- _ O
and -X- _ O
standard -X- _ B-HyperparameterName
deviation -X- _ I-HyperparameterName
of -X- _ O
each -X- _ O
method -X- _ O
for -X- _ O
a -X- _ O
particular -X- _ O
cell -X- _ O
. -X- _ O

Thus -X- _ O
, -X- _ O
this -X- _ O
shows -X- _ O
the -X- _ O
absolute -X- _ O
score -X- _ O
gain -X- _ O
for -X- _ O
using -X- _ O
the -X- _ O
MTL -X- _ B-MethodName
method -X- _ O
instead -X- _ O
of -X- _ O
the -X- _ O
STILTs -X- _ B-MethodName
method -X- _ O
( -X- _ O
negative -X- _ O
scores -X- _ O
indicate -X- _ O
that -X- _ O
the -X- _ O
STILTs -X- _ B-MethodName
method -X- _ O
was -X- _ O
better -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
) -X- _ O
. -X- _ O

MTL -X- _ B-MethodName
vs -X- _ O
STILTs -X- _ B-MethodName
We -X- _ O
first -X- _ O
calculate -X- _ O
the -X- _ O
absolute -X- _ O
score -X- _ O
matrices -X- _ O
from -X- _ O
computing -X- _ O
the -X- _ O
MTL -X- _ B-MethodName
and -X- _ O
STILTs -X- _ B-MethodName
method -X- _ O
on -X- _ O
each -X- _ O
pair -X- _ O
of -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
dataset -X- _ O
suite -X- _ O
, -X- _ O
then -X- _ O
subtract -X- _ O
the -X- _ O
STILTs -X- _ B-MethodName
average -X- _ B-MetricName
score -X- _ I-MetricName
matrix -X- _ O
from -X- _ O
the -X- _ O
MTL -X- _ B-MethodName
one -X- _ O
( -X- _ O
Figure -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O

3 -X- _ O
Results -X- _ O
We -X- _ O
provide -X- _ O
three -X- _ O
different -X- _ O
analyses -X- _ O
: -X- _ O
a -X- _ O
comparison -X- _ O
of -X- _ O
pairwise -X- _ O
MTL -X- _ B-MethodName
vs -X- _ O
STILTs -X- _ B-MethodName
, -X- _ O
experiments -X- _ O
varying -X- _ O
dataset -X- _ O
size -X- _ O
to -X- _ O
validate -X- _ O
our -X- _ O
findings -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
comparison -X- _ O
of -X- _ O
pairwise -X- _ O
approaches -X- _ O
vs -X- _ O
MTL -X- _ B-MethodName
All -X- _ I-MethodName
. -X- _ O

ure -X- _ O
1 -X- _ B-HyperparameterValue
for -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
found -X- _ O
the -X- _ O
same -X- _ O
conclusion -X- _ O
( -X- _ O
see -X- _ O
Appendix -X- _ O
D -X- _ O
) -X- _ O
, -X- _ O
showing -X- _ O
that -X- _ O
our -X- _ O
results -X- _ O
extend -X- _ O
to -X- _ O
other -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
transformers -X- _ O
. -X- _ O

Error -X- _ O
bars -X- _ O
indicate -X- _ O
a -X- _ O
90% -X- _ B-MetricValue
CI -X- _ B-MetricName
using -X- _ O
5 -X- _ O
random -X- _ O
seeds -X- _ O
. -X- _ O

The -X- _ O
blue -X- _ O
line -X- _ O
indicates -X- _ O
MTL -X- _ B-MethodName
results -X- _ O
while -X- _ O
the -X- _ O
green -X- _ O
line -X- _ O
indicates -X- _ O
the -X- _ O
STILTs -X- _ B-MethodName
method -X- _ O
. -X- _ O

0.33 -X- _ B-HyperparameterValue
indicates -X- _ O
that -X- _ O
the -X- _ O
supporting -X- _ O
task -X- _ O
is -X- _ O
a -X- _ O
third -X- _ O
of -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
QNLI -X- _ B-DatasetName
training -X- _ O
set -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
x -X- _ O
- -X- _ O
axis -X- _ O
indicates -X- _ O
the -X- _ O
amount -X- _ O
of -X- _ O
training -X- _ O
data -X- _ O
of -X- _ O
the -X- _ O
supporting -X- _ O
task -X- _ O
( -X- _ O
MNLI -X- _ B-DatasetName
) -X- _ O
relative -X- _ O
to -X- _ O
the -X- _ O
QNLI -X- _ B-DatasetName
training -X- _ O
set -X- _ O
, -X- _ O
artificially -X- _ O
constrained -X- _ O
( -X- _ O
e.g -X- _ O
. -X- _ O

Figure -X- _ O
2 -X- _ O
: -X- _ O
Experiments -X- _ O
validating -X- _ O
the -X- _ O
size -X- _ O
heuristic -X- _ O
on -X- _ O
the -X- _ O
( -X- _ O
QNLI -X- _ B-DatasetName
, -X- _ O
MNLI -X- _ B-DatasetName
) -X- _ O
task -X- _ O
pair -X- _ O
. -X- _ O

The -X- _ O
right -X- _ O
figure -X- _ O
shows -X- _ O
training -X- _ O
on -X- _ O
100% -X- _ B-HyperparameterValue
of -X- _ O
the -X- _ O
QNLI -X- _ B-DatasetName
training -X- _ O
set -X- _ O
while -X- _ O
the -X- _ O
left -X- _ O
figure -X- _ O
shows -X- _ O
training -X- _ O
with -X- _ O
50% -X- _ B-HyperparameterValue
. -X- _ O

Our -X- _ O
purpose -X- _ O
is -X- _ O
notto -X- _ O
train -X- _ O
the -X- _ O
next -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
task -X- _ O
and -X- _ O
thus -X- _ O
the -X- _ O
absolute -X- _ O
scores -X- _ O
are -X- _ O
not -X- _ O
immediately -X- _ O
relevant -X- _ O
; -X- _ O
our -X- _ O
purpose -X- _ O
is -X- _ O
to -X- _ O
show -X- _ O
how -X- _ O
the -X- _ O
different -X- _ O
methods -X- _ O
score -X- _ O
relative -X- _ O
to -X- _ O
each -X- _ O
other -X- _ O
. -X- _ O

Model -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
DistilRoBERTa -X- _ B-MethodName
model -X- _ O
( -X- _ O
pretrained -X- _ O
and -X- _ O
distributed -X- _ O
from -X- _ O
the -X- _ O
transformers -X- _ O
library -X- _ O
similarly -X- _ O
to -X- _ O
the -X- _ O
DistilBERT -X- _ B-MethodName
model -X- _ O
in -X- _ O
Sanh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
) -X- _ O
for -X- _ O
our -X- _ O
experiments -X- _ O
, -X- _ O
due -X- _ O
to -X- _ O
its -X- _ O
strong -X- _ O
performance -X- _ O
and -X- _ O
efficiency -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
full -X- _ O
model -X- _ O
. -X- _ O

In -X- _ O
total -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
985 -X- _ B-HyperparameterValue
= -X- _ I-HyperparameterValue
360 -X- _ I-HyperparameterValue
different -X- _ O
MTL -X- _ B-MethodName
versions -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
, -X- _ O
5 -X- _ B-HyperparameterValue
MTL -X- _ B-MethodName
Allmodels -X- _ I-MethodName
, -X- _ O
and -X- _ O
95 -X- _ B-HyperparameterValue
+ -X- _ I-HyperparameterValue
95 -X- _ I-HyperparameterValue
= -X- _ I-HyperparameterValue
90 -X- _ I-HyperparameterValue
models -X- _ B-HyperparameterName
in -X- _ O
the -X- _ O
STILTs -X- _ B-MethodName
setting -X- _ O
. -X- _ O

For -X- _ O
our -X- _ O
final -X- _ O
reported -X- _ O
numbers -X- _ O
, -X- _ O
we -X- _ O
record -X- _ O
both -X- _ O
the -X- _ O
average -X- _ O
score -X- _ O
and -X- _ O
the -X- _ O
standard -X- _ O
deviation -X- _ O
, -X- _ O
comparing -X- _ O
the -X- _ O
MTL -X- _ B-MethodName
approach -X- _ O
to -X- _ O
the -X- _ O
STILTs -X- _ B-MethodName
approach -X- _ O
with -X- _ O
a -X- _ O
two -X- _ B-MethodName
- -X- _ I-MethodName
sample -X- _ I-MethodName
t -X- _ I-MethodName
- -X- _ I-MethodName
test -X- _ I-MethodName
. -X- _ O

For -X- _ O
the -X- _ O
STILTs -X- _ B-MethodName
method -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
5 -X- _ O
models -X- _ O
with -X- _ O
different -X- _ O
seeds -X- _ O
on -X- _ O
the -X- _ O
supporting -X- _ O
task -X- _ O
and -X- _ O
then -X- _ O
choose -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
those -X- _ O
models -X- _ O
to -X- _ O
train -X- _ O
with -X- _ O
5 -X- _ O
more -X- _ O
random -X- _ O
seeds -X- _ O
on -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
. -X- _ O

The -X- _ O
MTL -X- _ B-MethodName
Allsetup -X- _ I-MethodName
uses -X- _ O
the -X- _ O
same -X- _ O
MTL -X- _ B-MethodName
code -X- _ O
, -X- _ O
but -X- _ O
includes -X- _ O
all -X- _ O
9 -X- _ O
GLUE -X- _ B-DatasetName
tasks -X- _ O
. -X- _ O

Forconsistency -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
the -X- _ O
STILTs -X- _ B-MethodName
models -X- _ O
using -X- _ O
the -X- _ O
same -X- _ O
code -X- _ O
, -X- _ O
but -X- _ O
include -X- _ O
only -X- _ O
one -X- _ O
task -X- _ O
in -X- _ O
the -X- _ O
dataloader -X- _ O
instead -X- _ O
of -X- _ O
multiple -X- _ O
. -X- _ O

Thus -X- _ O
, -X- _ O
for -X- _ O
the -X- _ O
remainder -X- _ O
of -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
our -X- _ O
MTL -X- _ B-MethodName
framework -X- _ O
uses -X- _ O
dynamic -X- _ B-MethodName
sampling -X- _ I-MethodName
with -X- _ O
heterogeneous -X- _ O
batch -X- _ O
schedules -X- _ O
. -X- _ O

Our -X- _ O
initial -X- _ O
results -X- _ O
found -X- _ O
that -X- _ O
dynamic -X- _ B-MethodName
sampling -X- _ I-MethodName
was -X- _ O
indeed -X- _ O
the -X- _ O
most -X- _ O
effective -X- _ O
on -X- _ O
pairwise -X- _ O
tasks -X- _ O
. -X- _ O

Many -X- _ O
previous -X- _ O
techniques -X- _ O
have -X- _ O
been -X- _ O
proposed -X- _ O
for -X- _ O
how -X- _ O
to -X- _ O
best -X- _ O
perform -X- _ O
MTL -X- _ B-MethodName
( -X- _ O
Raffel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019b -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
a -X- _ O
recent -X- _ O
paper -X- _ O
by -X- _ O
Gottumukkala -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
compared -X- _ O
the -X- _ O
main -X- _ O
approaches -X- _ O
and -X- _ O
showed -X- _ O
that -X- _ O
a -X- _ O
new -X- _ O
dynamic -X- _ O
approach -X- _ O
provides -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
in -X- _ O
general -X- _ O
. -X- _ O

We -X- _ O
extend -X- _ O
this -X- _ O
framework -X- _ O
to -X- _ O
combine -X- _ O
multiple -X- _ O
tasks -X- _ O
into -X- _ O
a -X- _ O
single -X- _ O
PyTorch -X- _ B-MethodName
( -X- _ O
Paszke -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
dataloader -X- _ O
for -X- _ O
MTL -X- _ B-MethodName
and -X- _ O
STILTs -X- _ B-MethodName
training -X- _ O
. -X- _ O

Training -X- _ O
Framework -X- _ O
We -X- _ O
use -X- _ O
Huggingfaces -X- _ B-MethodName
transformers -X- _ I-MethodName
library -X- _ I-MethodName
( -X- _ O
Wolf -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
for -X- _ O
accessing -X- _ O
the -X- _ O
pre -X- _ B-MethodName
- -X- _ I-MethodName
trained -X- _ I-MethodName
encoder -X- _ I-MethodName
and -X- _ O
for -X- _ O
the -X- _ O
base -X- _ O
training -X- _ O
framework -X- _ O
. -X- _ O

2 -X- _ O
Experimental -X- _ O
Settings -X- _ O
Dataset -X- _ O
Suite -X- _ O
To -X- _ O
conduct -X- _ O
this -X- _ O
analysis -X- _ O
, -X- _ O
we -X- _ O
chose -X- _ O
to -X- _ O
employ -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
dataset -X- _ O
suite -X- _ O
, -X- _ O
following -X- _ O
and -X- _ O
comparing -X- _ O
to -X- _ O
previous -X- _ O
work -X- _ O
in -X- _ O
transfer -X- _ B-MethodName
learning -X- _ I-MethodName
for -X- _ O
NLP -X- _ B-TaskName
( -X- _ O
Phang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019b -X- _ O
) -X- _ O
. -X- _ O

a -X- _ O
TL -X- _ B-MethodName
method -X- _ O
and -X- _ O
will -X- _ O
open -X- _ O
up -X- _ O
future -X- _ O
research -X- _ O
into -X- _ O
understanding -X- _ O
the -X- _ O
cause -X- _ O
of -X- _ O
this -X- _ O
heuristics -X- _ O
success -X- _ O
. -X- _ O

Datasets -X- _ O
are -X- _ O
ordered -X- _ O
in -X- _ O
descending -X- _ O
size -X- _ O
( -X- _ O
WNLI -X- _ B-HyperparameterName
is -X- _ O
the -X- _ O
smallest -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
colors -X- _ O
indicate -X- _ O
visually -X- _ O
the -X- _ O
best -X- _ O
method -X- _ O
, -X- _ O
showing -X- _ O
a -X- _ O
statistically -X- _ O
significant -X- _ O
difference -X- _ O
from -X- _ O
the -X- _ O
other -X- _ O
from -X- _ O
using -X- _ O
using -X- _ O
a -X- _ O
two -X- _ B-MethodName
- -X- _ I-MethodName
sided -X- _ I-MethodName
t -X- _ I-MethodName
- -X- _ I-MethodName
test -X- _ I-MethodName
with -X- _ O
= -X- _ O
0:1 -X- _ B-HyperparameterValue
. -X- _ O

Numbers -X- _ O
in -X- _ O
cells -X- _ O
indicate -X- _ O
the -X- _ O
absolute -X- _ O
percent -X- _ O
score -X- _ O
difference -X- _ O
on -X- _ O
the -X- _ O
primary -X- _ O
task -X- _ O
when -X- _ O
using -X- _ O
MTL -X- _ B-MethodName
instead -X- _ O
of -X- _ O
STILTs -X- _ B-MethodName
( -X- _ O
positive -X- _ O
scores -X- _ O
mean -X- _ O
MTL -X- _ B-MethodName
is -X- _ O
better -X- _ O
and -X- _ O
vice -X- _ O
versa -X- _ O
) -X- _ O
. -X- _ O

Figure -X- _ O
1 -X- _ O
: -X- _ O
Results -X- _ O
comparing -X- _ O
intermediate -X- _ B-MethodName
fine -X- _ I-MethodName
tuning -X- _ I-MethodName
( -X- _ O
STILTs -X- _ B-MethodName
) -X- _ O
vs -X- _ O
multi -X- _ B-MethodName
- -X- _ I-MethodName
task -X- _ I-MethodName
learning -X- _ I-MethodName
( -X- _ O
MTL -X- _ B-MethodName
) -X- _ O
. -X- _ O

We -X- _ O
surprisingly -X- _ O
find -X- _ O
that -X- _ O
a -X- _ O
simple -X- _ O
size -X- _ O
heuristic -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
to -X- _ O
determine -X- _ O
with -X- _ O
more -X- _ O
than -X- _ O
92% -X- _ B-MetricValue
accuracy -X- _ B-MetricName
which -X- _ O
method -X- _ O
to -X- _ O
use -X- _ O
for -X- _ O
a -X- _ O
given -X- _ O
target -X- _ O
and -X- _ O
supporting -X- _ O
task -X- _ O
: -X- _ O
when -X- _ O
the -X- _ O
target -X- _ O
dataset -X- _ O
is -X- _ O
larger -X- _ O
than -X- _ O
the -X- _ O
supporting -X- _ O
dataset -X- _ O
, -X- _ O
STILTS -X- _ B-MethodName
should -X- _ O
be -X- _ O
used -X- _ O
; -X- _ O
otherwise -X- _ O
, -X- _ O
MTL -X- _ B-MethodName
should -X- _ O
be -X- _ O
used -X- _ O
( -X- _ O
MTL -X- _ B-MethodName
Allis -X- _ I-MethodName
almost -X- _ O
universally -X- _ O
the -X- _ O
worst -X- _ O
of -X- _ O
the -X- _ O
methods -X- _ O
in -X- _ O
our -X- _ O
experiments -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
work -X- _ O
we -X- _ O
perform -X- _ O
comprehensive -X- _ O
experiments -X- _ O
using -X- _ O
all -X- _ O
three -X- _ O
methods -X- _ O
on -X- _ O
the -X- _ O
9 -X- _ O
datasets -X- _ O
in -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
benchmark -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018b -X- _ O
) -X- _ O
. -X- _ O

Those -X- _ O
that -X- _ O
do -X- _ O
examine -X- _ O
them -X- _ O
do -X- _ O
so -X- _ O
with -X- _ O
a -X- _ O
limited -X- _ O
number -X- _ O
of -X- _ O
configurations -X- _ O
: -X- _ O
Phang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
examines -X- _ O
STILTS -X- _ B-MethodName
and -X- _ O
one -X- _ O
instance -X- _ O
of -X- _ O
MTL -X- _ B-MethodName
, -X- _ O
Changpinyo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
; -X- _ O
Peng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
; -X- _ O
Schrder -X- _ O
and -X- _ O
Biemann -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
compare -X- _ O
MTL -X- _ O
with -X- _ O
MTL -X- _ B-MethodName
All -X- _ I-MethodName
, -X- _ O
and -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018a -X- _ O
) -X- _ O
; -X- _ O
Talmor -X- _ O
and -X- _ O
Berant -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
; -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019b -X- _ O
) -X- _ O
; -X- _ O
Phang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
use -X- _ O
MTL -X- _ B-MethodName
All -X- _ I-MethodName
and -X- _ O
STILTs -X- _ O
but -X- _ O
not -X- _ O
pairwise -X- _ B-MethodName
MTL -X- _ I-MethodName
. -X- _ O

* -X- _ O
Corresponding -X- _ O
author -X- _ O
, -X- _ O
oweller2@jhu.eduthere -X- _ O
are -X- _ O
an -X- _ O
exponential -X- _ O
number -X- _ O
of -X- _ O
ways -X- _ O
to -X- _ O
combine -X- _ O
or -X- _ O
alternate -X- _ O
between -X- _ O
the -X- _ O
target -X- _ O
and -X- _ O
supporting -X- _ O
tasks -X- _ O
, -X- _ O
three -X- _ O
predominant -X- _ O
methods -X- _ O
have -X- _ O
emerged -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
fine -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
on -X- _ O
a -X- _ O
supporting -X- _ O
task -X- _ O
and -X- _ O
then -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
consecutively -X- _ O
, -X- _ O
often -X- _ O
called -X- _ O
STILTs -X- _ B-MethodName
( -X- _ O
Phang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
; -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
fine -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
on -X- _ O
a -X- _ O
supporting -X- _ O
task -X- _ O
and -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
simultaneously -X- _ O
( -X- _ O
here -X- _ O
called -X- _ O
pairwise -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
learning -X- _ O
, -X- _ O
or -X- _ O
simply -X- _ O
MTL -X- _ B-MethodName
) -X- _ O
; -X- _ O
and -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
fine -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
on -X- _ O
all -X- _ O
Navailable -X- _ O
supporting -X- _ O
tasks -X- _ O
and -X- _ O
the -X- _ O
target -X- _ O
tasks -X- _ O
together -X- _ O
( -X- _ O
MTL -X- _ B-MethodName
All -X- _ I-MethodName
, -X- _ O
N -X- _ O
> -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O

When -X- _ O
additional -X- _ O
non -X- _ O
- -X- _ O
target -X- _ O
supervised -X- _ O
datasets -X- _ O
are -X- _ O
available -X- _ O
during -X- _ O
fine -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
, -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
always -X- _ O
clear -X- _ O
how -X- _ O
to -X- _ O
best -X- _ O
make -X- _ O
use -X- _ O
of -X- _ O
the -X- _ O
supporting -X- _ O
data -X- _ O
( -X- _ O
Phang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019b -X- _ O
, -X- _ O
a -X- _ O
; -X- _ O
Pruksachatkun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
hope -X- _ O
this -X- _ O
study -X- _ O
will -X- _ O
aid -X- _ O
others -X- _ O
as -X- _ O
they -X- _ O
choose -X- _ O
between -X- _ O
TL -X- _ B-MethodName
methods -X- _ O
for -X- _ O
NLP -X- _ B-TaskName
tasks.1 -X- _ O
1 -X- _ O
Introduction -X- _ O
The -X- _ O
standard -X- _ O
supervised -X- _ O
training -X- _ O
paradigm -X- _ O
in -X- _ O
NLP -X- _ B-TaskName
research -X- _ O
is -X- _ O
to -X- _ O
fine -X- _ B-MethodName
- -X- _ I-MethodName
tune -X- _ I-MethodName
a -X- _ I-MethodName
pre -X- _ I-MethodName
- -X- _ I-MethodName
trained -X- _ I-MethodName
language -X- _ I-MethodName
model -X- _ I-MethodName
on -X- _ O
some -X- _ O
target -X- _ O
task -X- _ O
( -X- _ O
Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Raffel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Gururangan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O

Furthermore -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
MTL -X- _ B-MethodName
Allis -X- _ I-MethodName
worse -X- _ O
than -X- _ O
the -X- _ O
pairwise -X- _ O
methods -X- _ O
in -X- _ O
almost -X- _ O
every -X- _ O
case -X- _ O
. -X- _ O

The -X- _ O
simplicity -X- _ O
and -X- _ O
effectiveness -X- _ O
of -X- _ O
this -X- _ O
heuristic -X- _ O
is -X- _ O
surprising -X- _ O
and -X- _ O
warrants -X- _ O
additional -X- _ O
exploration -X- _ O
by -X- _ O
the -X- _ O
TL -X- _ B-MethodName
community -X- _ O
. -X- _ O

We -X- _ O
show -X- _ O
that -X- _ O
this -X- _ O
holds -X- _ O
true -X- _ O
in -X- _ O
more -X- _ O
than -X- _ O
92% -X- _ B-MetricValue
of -X- _ O
applicable -X- _ O
cases -X- _ O
on -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
dataset -X- _ O
and -X- _ O
validate -X- _ O
this -X- _ O
hypothesis -X- _ O
with -X- _ O
experiments -X- _ O
varying -X- _ O
dataset -X- _ O
size -X- _ O
. -X- _ O

We -X- _ O
find -X- _ O
that -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
simple -X- _ O
heuristic -X- _ O
for -X- _ O
when -X- _ O
to -X- _ O
use -X- _ O
one -X- _ O
of -X- _ O
these -X- _ O
techniques -X- _ O
over -X- _ O
the -X- _ O
other -X- _ O
: -X- _ O
pairwise -X- _ B-MethodName
MTL -X- _ I-MethodName
is -X- _ O
better -X- _ O
than -X- _ O
STILTs -X- _ B-MethodName
when -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
has -X- _ O
fewer -X- _ O
instances -X- _ O
than -X- _ O
the -X- _ O
supporting -X- _ O
task -X- _ O
and -X- _ O
vice -X- _ O
versa -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
all -X- _ O
three -X- _ O
TL -X- _ B-MethodName
methods -X- _ O
in -X- _ O
a -X- _ O
comprehensive -X- _ O
analysis -X- _ O
on -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
dataset -X- _ O
suite -X- _ O
. -X- _ O

Three -X- _ O
main -X- _ O
strategies -X- _ O
have -X- _ O
emerged -X- _ O
for -X- _ O
making -X- _ O
use -X- _ O
of -X- _ O
multiple -X- _ O
supervised -X- _ O
datasets -X- _ O
during -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
: -X- _ O
training -X- _ O
on -X- _ O
an -X- _ O
intermediate -X- _ O
task -X- _ O
before -X- _ O
training -X- _ O
on -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
( -X- _ O
STILTs -X- _ B-MethodName
) -X- _ O
, -X- _ O
using -X- _ O
multi -X- _ B-MethodName
- -X- _ I-MethodName
task -X- _ I-MethodName
learning -X- _ I-MethodName
( -X- _ I-MethodName
MTL -X- _ I-MethodName
) -X- _ I-MethodName
to -X- _ O
train -X- _ O
jointly -X- _ O
on -X- _ O
a -X- _ O
supplementary -X- _ O
task -X- _ O
and -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
( -X- _ O
pairwise -X- _ B-MethodName
MTL -X- _ I-MethodName
) -X- _ O
, -X- _ O
or -X- _ O
simply -X- _ O
using -X- _ O
MTL -X- _ B-MethodName
to -X- _ O
train -X- _ O
jointly -X- _ O
on -X- _ O
all -X- _ O
available -X- _ O
datasets -X- _ O
( -X- _ O
MTL -X- _ B-MethodName
All -X- _ I-MethodName
) -X- _ O
. -X- _ O

Proceedings -X- _ O
of -X- _ O
the -X- _ O
60th -X- _ O
Annual -X- _ O
Meeting -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ B-TaskName
Linguistics -X- _ I-TaskName
Volume -X- _ O
2 -X- _ O
: -X- _ O
Short -X- _ O
Papers -X- _ O
, -X- _ O
pages -X- _ O
272 -X- _ O
- -X- _ O
282 -X- _ O
May -X- _ O
22 -X- _ O
- -X- _ O
27 -X- _ O
, -X- _ O
2022 -X- _ O
c -X- _ O
2022 -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ B-TaskName
Linguistics -X- _ I-TaskName
When -X- _ O
to -X- _ O
Use -X- _ O
Multi -X- _ B-MethodName
- -X- _ I-MethodName
Task -X- _ I-MethodName
Learning -X- _ I-MethodName
vs -X- _ O
Intermediate -X- _ B-MethodName
Fine -X- _ I-MethodName
- -X- _ I-MethodName
Tuning -X- _ I-MethodName
for -X- _ O
Pre -X- _ O
- -X- _ O
Trained -X- _ O
Encoder -X- _ O
Transfer -X- _ B-MethodName
Learning -X- _ I-MethodName
Orion -X- _ O
Weller -X- _ O
* -X- _ O
Johns -X- _ O
Hopkins -X- _ O
UniversityKevin -X- _ O
Seppi -X- _ O
Brigham -X- _ O
Young -X- _ O
UniversityMatt -X- _ O
Gardner -X- _ O
Microsoft -X- _ O
Semantic -X- _ O
Machines -X- _ O
Abstract -X- _ O
Transfer -X- _ B-MethodName
learning -X- _ I-MethodName
( -X- _ I-MethodName
TL -X- _ I-MethodName
) -X- _ I-MethodName
in -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
processing -X- _ I-TaskName
( -X- _ I-TaskName
NLP -X- _ I-TaskName
) -X- _ I-TaskName
has -X- _ O
seen -X- _ O
a -X- _ O
surge -X- _ O
of -X- _ O
interest -X- _ O
in -X- _ O
recent -X- _ O
years -X- _ O
, -X- _ O
as -X- _ O
pre -X- _ B-MethodName
- -X- _ I-MethodName
trained -X- _ I-MethodName
models -X- _ I-MethodName
have -X- _ O
shown -X- _ O
an -X- _ O
impressive -X- _ O
ability -X- _ O
to -X- _ O
transfer -X- _ O
to -X- _ O
novel -X- _ O
tasks -X- _ O
. -X- _ O

